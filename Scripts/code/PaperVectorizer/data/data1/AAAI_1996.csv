,conference_year,category,title,author,abstract,download_url,keywords
0,1996,Contents,Preface,"Dan Weld, Bill Clancey, Usama M. Fayyad, Howard Shrobe",Preface to the AAAI-96 and IAAI-96 proceedings.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-292.pdf,
1,1996,Contents,AAAI Organization,Carol Hamilton,List of officiations of the American Association for Artificial Intelligence.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-293.pdf,
2,1996,Contents,AAAI–96 Program Committee,"Dan Weld, Bill Clancey",List of organizers of the AAAI–96 Conference.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-294.pdf,
3,1996,Contents,AAAI–96 Best Paper Awards,"Dan Weld, Bill Clancey",AAAI-96 Conference best paper awards.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-295.pdf,
4,1996,Interaction,Agent Amplified Communication,"Henry Kautz, Bart Selman, Al Milewski","We propose an agent-based framework for assisting and simplifying person-to-person communication for information gathering tasks. As an example, we focus on locating experts for any specified topic. In our approach, the informal person-to-person networks that exist within an organization are used to ""referral chain"" requests for expertise. User-agents help automate this process. The agents generate referrals by analyzing records of email communication patterns. Simulation results show that the higher responsiveness of an agent-based system can be effectively traded for the higher accuracy of a completely manual approach. Furthermore, preliminary experience with a group of users on a prototype system has shown that useful automatic referrals can be found in practice. Our experience with actual users has also shown that privacy concerns are central to the successful deployment of personal agents: an advanced agent-based system will therefore need to reason about issues involving trust and authority.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-001.pdf,
5,1996,Interaction,The ContactFinder Agent: Answering Bulletin Board Questions with Referrals,"Bruce Krulwich, Chad Burkey","ContactFinder is an intelligent agent whose approach to assisting users is valuable and innovative in the following four ways. First, ContactFinder operates proactively in reading and responding to messages on electronic bulletin boards rather than acting in response to user queries. Second, ContactFinder assists users by referring them to other people who can help them, rather than attempting to find information that directly answers the user’s specific question. Third, ContactFinder categorizes messages and extracts their topic areas using a set of heuristics that are very efficient and demonstrably highly effective. Fourth, ContactFinder posts its referrals back to the bulletin boards rather than simply communicating with specific users, to increase the information density and connectivity of the system. This paper discusses these aspects of the system and demonstrates their effectiveness in over six months of use on a large-scale internal bulletin board.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-002.pdf,
6,1996,Interaction,Deciding to Remind during Collaborative Problem Solving: Empirical Evidence for Agent Strategies,"Pamela W. Jordan, Marilyn A. Walker","Previous work suggests that reminding a conversational partner of mutually known information depends on the conversants’ attentional state, their resource limits and the resource demands of the task. In this paper, we propose and evaluate several models of how an agent decides whether or not to communicate a reminder. We elaborate on previous findings by exploring how attentional state and resource bounds are incorporated into the decision making process so that reminders aid the performance of agents during collaborative problem solving. We test two main hypotheses using a multi-agent problem solving simulation testbed: (1) an agent decides to present salient knowledge only when it reduces overall problem solving effort (2) an agent can use its own attentional state as a model of the attentional state of its partner when assessing the effort trade-offs of communicating a reminder. Our results support both hypotheses, suggesting that the models we propose should be further tested for multi-agent communication in problem solving situations.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-003.pdf,
7,1996,Interaction,Toward a Semantics for an Agent Communications Language Based on Speech-Acts,"Ira A. Smith, Philip R. Cohen","Systems based on distributed agent architectures require an agent communications language having a clearly defined semantics. This paper demonstrates that a semantics for an agent communications language can be founded on the premise that agents are building, maintaining, and disbanding teams through their performance of communicative acts. This view requires that definitions of basic communicative acts, such as requesting, be recast in terms of the formation of a joint intention - a mental state that has been suggested underlies team behavior. To illustrate these points, a semantics is developed for a number of communication actions that can form and dissolve teams. It is then demonstrated how much of the structure of popular finite-state dialogue models, such as Winograd and Flores’ basic conversation for action, follows as a consequence of the logical relationships that are created by the redefined communicative actions.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-004.pdf,
8,1996,Internet Agents,Planning to Gather Information,"Chung T. Kwok, Daniel S. Weld","We describe Occam, a query planning algorithm that determines the best way to integrate data from different sources. As input, Occam takes a library of site descriptions and a user query. As output, Occam automatically generates one or more plans that encode alternative ways to gather the requested information. Occam has several important features: (1) it integrates both legacy systems and full relational databases with an efficient, domain-independent, query-planning algorithm, (2) it reasons about the capabilities of different information sources, (3) it handles partial goal satisfaction i.e., gathers as much data as possible when it can’t gather exactly all that the user requested, (4) it is both sound and complete, (5) it is efficient. We present empirical results demonstrating Occam’s performance on a variety of information gathering tasks.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-005.pdf,
9,1996,Internet Agents,Query-Answering Algorithms for Information Agents,"Alon Y. Levy, Anand Rajaraman, Joann J. Ordille","We describe the architecture and query-answering algorithms used in the Information Manifold, an implemented information gathering system that provides uniform access to structured information sources on the World-Wide Web. Our architecture provides an expressive language for describing information sources, which makes it easy to add new sources and to model the fine-grained distinctions between their contents. The query-answering algorithm guarantees that the descriptions of the sources are exploited to access only sources that are relevant to a given query. Accessing only relevant sources is crucial to scale up such a system to large numbers of sources. In addition, our algorithm can exploit run-time information to further prune information sources and to reduce the cost of query planning.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-006.pdf,
10,1996,Internet Agents,Hybrid Hill-Climbing and Knowledge-Based Methods for Intelligent News Filtering,Kenrick J. Mock,"As the size of the Internet increases, the amount of data available to users has dramatically risen, resulting in an information overload for users. This work involved the creation of an intelligent information news filtering system named INFOS (Intelligent News Filtering Organizational System) to reduce the user’s search burden by automatically eliminating Usenet news articles predicted to be irrelevant. These predictions are learned automatically by adapting an internal user model that is based upon features taken from articles and collaborative features derived from other users. The features are manipulated through keyword-based techniques and knowledge-based techniques to perform the actual filtering. Knowledge-based systems have the advantage of analyzing input text in detail, but at the cost of computational complexity and the difficulty of scaling up to large domains. In contrast, statistical and keyword approaches scale up readily but result in a shallower understanding of the input. A hybrid system integrating both approaches improves accuracy over keyword approaches, supports domain knowledge, and retains scalability. The system would be enhanced by more robust word disambiguation.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-007.pdf,
11,1996,Internet Agents,Syskill and Webert: Identifying Interesting Web Sites,"Michael J. Pazzani, Jack Muramatsu, Daniel Billsus","We describe Syskill and Webert, a software agent that learns to rate pages on the World Wide Web (WWW), deciding what pages might interest a user. The user rates explored pages on a three point scale, and Syskill and Webert learns a user profile by analyzing the information on each page. The user profile can be used in two ways. First, it can be used to suggest which links a user would be interested in exploring. Second, it can be used to construct a LYCOS query to find pages that would interest a user. We compare six different algorithms from machine learning and information retrieval on this task. We find that the naive Bayesian classifier ofsers several advantages over other learning algorithms on this task. Furthermore, we find that an initial portion of a web page is sufficient for making predictions on its interestingness substantially reducing the amount of network transmission required to make predictions.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-008.pdf,
12,1996,Multiagent Learning,Learning Models of Intelligent Agents,"David Carmel, Shaul Markovitch","Agents that operate in a multi-agent system need an efficient strategy to handle their encounters with other agents involved. Searching for an optimal interactive strategy is a hard problem because it depends mostly on the behavior of the others. In this work, interaction among agents is represented as a repeated two-player game, where the agents’ objective is to look for a strategy that maximizes their expected sum of rewards in the game. We assume that agents’ strategies can be modeled as finite automata. A model-bused approach is presented as a possible method for learning an effective interactive strategy. First, we describe how an agent should find an optimal strategy against a given model. Second, we present an unsupervised algorithm that infers a model of the opponent’s automaton from its input/output behavior. A set of experiments that show the potential merit of the algorithm is reported as well.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-009.pdf,
13,1996,Multiagent Learning,Cooperative Learning over Composite Search Spaces: Experiences with a Multi-Agent Design System,"M V Nagendra Prasad, Susan E. Lander, Victor R. Lesser","We suggest the use of two learning techniques - short term and long term - to enhance search efficiency in a multi-agent design system by letting the agents learn about non-local requirements on the local search process. The first technique allows an agent to accumulate and apply constraining information about global problem solving, gathered as a result of agent communication, to further problem solving within the same problem instance. The second technique is used to classify problem instances and appropriately index and retrieve constraining information to apply to new problem instances. These techniques will be presented within the context of a multi-agent parametric-design application called STEAM. We show that learning conclusively improves solution quality and processing-time results.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-010.pdf,
14,1996,Multiagent Learning,Scaling Up: Distributed Machine Learning with Cooperation,"Foster John Provost, Daniel N. Hennessy","Machine-learning methods are becoming increasingly popular for automated data analysis. However, standard methods do not scale up to massive scientific and business data sets without expensive hardware. This paper investigates a practical alternative for scaling up: the use of distributed processing to take advantage of the often dormant PCs and workstations available on local networks. Each workstation runs a common rule-learning program on a subset of the data. We first show that for commonly used rule-evaluation criteria, a simple form of cooperation can guarantee that a rule will look good to the set of cooperating learners if and only if it would look good to a single learner operating with the entire data set. We then show how such a system can further capitalize on different perspectives by sharing learned knowledge for significant reduction in search effort. We demonstrate the power of the method by learning from a massive data set taken from the domain of cellular fraud detection. Finally, we provide an overview of other methods for scaling up machine learning.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-011.pdf,
15,1996,Multiagent Learning,Tracking Dynamic Team Activity,Milind Tambe,"AI researchers are striving to build complex multi-agent worlds with intended applications ranging from the RoboCup robotic soccer tournaments, to interactive virtual theatre, to large-scale real-world battlefield simulations. Agent tracking - monitoring other agent’s actions and inferring their higher-level goals and intentions - is a central requirement in such worlds. While previous work has mostly focused on tracking individual agents, this paper goes beyond by focusing on agent teams. Team tracking poses the challenge of tracking a team’s joint goals and plans. Dynamic, real-time environments add to the challenge, as ambiguities have to be resolved in real-time. The central hypothesis underlying the present work is that an explicit team-oriented perspective enables effective team tracking. This hypothesis is instantiated using the model tracing technology employed in tracking individual agents. Thus, to track team activities, team models are put to service. Team models are a concrete application of the joint intentions framework and enable an agent to track team activities, regardless of the agent’s being a collaborative participant or a non-participant in the team. To facilitate real-time ambiguity resolution with team models: (i) aspects of tracking are cast as constraint satisfaction problems to exploit constraint propagation techniques; and (ii) a cost minimality criterion is applied to constrain tracking search. Empirical results from two separate tasks in real-world, dynamic environments - one collaborative and one competitive - are provided.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-012.pdf,
16,1996,Multiagent Problem Solving,Nearly Monotonic Problems: A Key to Effective FA/C Distributed Sensor Interpretation?,"Norman Carver, Victor Lesser, Robert Whitehair","The functionally-accurate, cooperative (FA/C) distributed problem-solving paradigm is one approach for organizing distributed problem solving among homogeneous, cooperating agents. A key assumption of the FA/C model has been that the agents’ local solutions can substitute for the raw data in determining the global solutions. This is not the case in general, however. Does this mean that researchers’ intuitions have been wrong and/or that FA/C problem solving is not likely to be effective ? We suggest that some domains have a characteristic that can account for the success of exchanging mainly local solutions. We call such problems nearly monotonic. This concept is discussed in the context of FA/C-based distributed sensor interpretation.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-013.pdf,
17,1996,Multiagent Problem Solving,Analysis of Utility-Theoretic Heuristics for Intelligent Adaptive Network Routing,"Armin R. Mikler, Vasant Honavar, Johnny S. K. Wong","Utility theory offers an elegant and powerful theoretical framework for design and analysis of autonomous adaptive communication networks. Routing of messages in such networks presents a real-time instance of a multi-criterion optimization problem in a dynamic and uncertain environment. In this paper, we incrementally develop a set of heuristic decision functions that can be used to guide messages along a near-optimal (e.g., minimum delay) path in a large network. We present an analysis of properties of such heuristics under a set of simplifying assumptions about the network topology and load dynamics and identify the conditions under which they are guaranteed to route messages along an optimal path. The paper concludes with a discussion of the relevance of the theoretical results presented in the paper to the design of intelligent autonomous adaptive communication networks and an outline of some directions of future research.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-014.pdf,
18,1996,Multiagent Problem Solving,The Use of Artificially Intelligent Agents with Bounded Rationality in the Study of Economic Markets,"Vijay Rajan, James R. Slagle","The concepts of knowledge and rationality are of central importance to fields of science that are interested in human behavior and learning, such as artificial intelligence, economics, and psychology. The similarity between artificial intelligence and economics - both are concerned with intelligent thought, rational behavior, and the use and acquisition of knowledge - has led to the use of economic models as a paradigm for solving problems in distributed artificial intelligence (DAI) and multi agent systems (MAS). What we propose is the opposite; the use of artificial intelligence in the study of economic markets. Over the centuries various theories of market behavior have been advanced. The prevailing theory holds that an asset’s current price converges to the risk adjusted value of the rationally expected dividend stream. While this rational expectations model holds in equilibrium or near-equilibrium conditions, it does not sufficiently explain conditions of market disequilibrium. An example of market disequilibrium is the phenomenon of a speculative bubble. We present an example of using artificially intelligent agents with bounded rationality in the study of speculative bubbles.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-015.pdf,
19,1996,Multiagent Problem Solving,Total-Order Multi-Agent Task-Network Planning for Contract Bridge,"S. J. J. Smith, D. S. Nau, T. A. Throop","This paper describes the results of applying a modified version of hierarchical task-network (HTN) planning to the problem of declarer play in contract bridge. We represent information about bridge in a task network that is extended to represent multi-agency and uncertainty. Our game-playing procedure uses this task network to generate game trees in which the set of alternative choices is determined not by the set of possible actions, but by the set of available tactical and strategic schemes. This approach avoids the difficulties that traditional game-tree search techniques have with imperfect-information games such as bridge-but it also differs in several significant ways from the planning techniques used in typical HTN planners. We describe why these modifications were needed in order to build a successful planner for bridge. This same modified HTN planning strategy appears to be useful in a variety of application domains-for example, we have used the same planning techniques in a process-planning system for the manufacture of complex electromechanical devices (Hebbar et al. 1996). We discuss why the same technique has been successful in two such diverse domains.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-016.pdf,
20,1996,Negotiation & Coalition,Learning other Agents’ Preferences in Multiagent Negotiation,"H. H. Bui, D. Kieronska, S. Venkatesh","In multiagent systems, an agent does not usually have complete information about the preferences and decision making processes of other agents. This might prevent the agents from making coordinated choices, purely due to their ignorance of what others want. This paper describes the integration of a learning module into a communication-intensive negotiating agent architecture. The learning module gives the agents the ability to learn about other agents’ preferences via past interactions. Over time, the agents can incrementally update their models of other agents’ preferences and use them to make better coordinated decisions. Combining both communication and learning, as two complement knowledge acquisition methods, helps to reduce the amount of communication needed on average, and is justified in situations where communication is computationally costly or simply not desirable (e.g. to preserve the individual privacy).",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-017.pdf,
21,1996,Negotiation & Coalition,Incorporating Opponent Models into Adversary Search,"David Carmel, Shaul Markovitch","This work presents a generalized theoretical frame-work that allows incorporation of opponent models into adversary search. We present the M* algorithm, a generalization of minimax that uses an arbitrary opponent model to simulate the opponent’s search. The opponent model is a recursive structure consisting of the opponent’s evaluation function and its model of the player. We demonstrate experimentally the potential benefit of using an opponent model. Pruning in M* is impossible in the general case. We prove a sufficient condition for pruning and present the ab* algorithm which returns the M* value of a tree while searching only necessary branches.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-018.pdf,
22,1996,Negotiation & Coalition,Advantages of a Leveled Commitment Contracting Protocol,"Tuomas W. Sandholm, Victor R. Lesser","In automated negotiation systems consisting of self-interested agents, contracts have traditionally been binding. Such contracts do not allow agents to efficiently accommodate future events. Game theory has proposed contingency contracts to solve this problem. Among computational agents, contingency contracts are often impractical due to large numbers of interdependent and unanticipated future events to be conditioned on, and because some events are not mutually observable. This paper proposes a leveled commitment contracting protocol that allows self-interested agents to efficiently accommodate future events by having the possibility of unilaterally decommitting from a contract based on local reasoning. A decommitment penalty is assigned to both agents in a contract: to be freed from the contract, an agent only pays this penalty to the other party. It is shown through formal analysis of several contracting settings that this leveled commitment feature in a contracting protocol increases Pareto efficiency of deals and can make contracts individually rational when no full commitment contract can. This advantage holds even if the agents decommit manipulatively.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-019.pdf,
23,1996,Negotiation & Coalition,A Kernel-Oriented Model for Coalition-Formation in General Environments: Implementation and Results,"Onn Shehory, Sarit Kraus","In this paper we present a model for coalition formation and payoff distribution in general environments. We focus on a reduced complexity kernel-oriented coalition formation model, and provide a detailed algorithm for the activity of the single rational agent. The model is partitioned into a social level and a strategic level, to distinguish between regulations that must be agreed upon and are forced by agent-designers, and strategies by which each agent acts at will. In addition, we present an implementation of the model and simulation results. From these we conclude that implementing the model for coalition formation among agents increases the benefits of the agents with reasonable time consumption. It also shows that more coalition formations yield more benefits to the agents.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-020.pdf,
24,1996,Video,Coping with Temporal Constraints in Multimedia Presentation Planning,"Elisabeth André, Thomas Rist","Computer-based presentation systems enable the realization of effective and dynamic presentation styles that incorporate multiple media. Obvious examples are animated user interface agents which verbally comment on multimedia objects displayed on the screen while performing cross-media and cross-window pointing gestures. The design of such presentations must account for the temporal coordination of media output and the agent’s behavior. In this paper we describe a new presentation system which not only creates the multimedia objects to be presented, but also generates a script for presenting the material to the user. In our system, this script is forwarded to an animated presentation agent running the presentation. The paper details the kernel of the system which is a component for planning temporally coordinated multimedia.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-021.pdf,
25,1996,Video,Declarative Camera Control for Automatic Cinematography,"David B. Christianson, Sean E. Anderson, Li-Wei He, David H. Salesin, Daniel S. Weld, Michael F. Cohen","Animations generated by interactive 3D computer graphics applications are typically portrayed either from a particular character’s point of view or from a small set of strategically-placed viewpoints. By ignoring camera placement, such applications fail to realize important storytelling capabilities that have been explored by cinematographers for many years. In this paper, we describe several of the principles of cinematography and show how they can be formalized into a declarative language, called the Declarative Camera Control Language (DCCL). We describe the application of DCCL within the context of a simple interactive video game and argue that DCCL represents cinematic knowledge at the same level of abstraction as expert directors by encoding 16 idioms from a film textbook. These idioms produce compelling animations, as demonstrated on the accompanying videotape.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-022.pdf,
26,1996,Video,A Model of Poetic Comprehension,Kenneth Haase,"This article introduces an account of aesthetic comprehension and experience together with an implemented miniature which generates analogical interpretations from a semi-automatic parse of Wordsworth’s ""Lines Written in Early Spring"". In our account, a poem serves as an analogy teaching machine by using formal structure to cue the formation of novel analogies. This account builds on an analogical model of comprehension previously applied to large corpora of newspaper summaries. In the miniature, an automatic grammatical and semantic analysis of the text is augmented with information about rhyme and rhythm. These formal cues allow the system to determine analogies which it would not otherwise consider. The article describes the comprehension framework, the annotated piece, and the matcher’s performance on the piece. It closes with a discussion of possible objections to aspects of the thesis or experiment and suggested directions for future work.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-023.pdf,
27,1996,Video,A Framework for Plot Control in Interactive Story Systems,"N. M. Sgouros, G. Papakonstantinou, P. Tsanakas","This paper presents a framework for plot control in interactive story systems. In this framework, the user takes the place of the main character of the story, the protagonist. The rest of the cast consists of discrete characters, each playing a specific role in the story. A separate module in this system, the plot manager, controls the behavior of the cast and specifies what the protagonist can do. The story plot is dynamically shaped by the interference between cast members and their social interactions. The system accepts as input a story map which provides the main metaphor for organizing the plot and localizes the interaction of the protagonist with the rest of the cast. We are implementing this framework in PEGASUS, an interactive travel story environment for Greek mythology.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-024.pdf,
28,1996,Constraint Satisfaction,Approximate Resolution of Hard Numbering Problems,"Olivier Bailleux, Jean-Jacques Chabrier","We present a new method for estimating the number of solutions of constraint satisfaction problems’ . We use a stochastic forward checking algorithm for drawing a sample of paths from a search tree. With this sample, we compute two values related to the number of solutions of a CSP instance. First, an unbiased estimate, second, a lower bound with an arbitrary low error probability. We will describe applications to the Boolean Satisfiability problem and the Queens problem. We shall give some experimental results for these problems.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-025.pdf,
29,1996,Constraint Satisfaction,Mixed Constraint Satisfaction: A Framework for Decision Problems under Incomplete Knowledge,"Hélène Fargier, Jérôme Lang, Thomas Schiex","Constraint satisfaction is a powerful tool for representing and solving decision problems with complete knowledge about the world. We extend the CSP framework so as to represent decision problems under incomplete knowledge. The basis of the extension consists in a distinction between controllable and uncontrollable variables - hence the terminology ""mixed CSP"" - and a ""solution"" gives actually a conditional decision. We study the complexity of deciding the consistency of a mixed CSP. As the problem is generally intractable, we propose an algorithm for finding an approximate solution.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-026.pdf,
30,1996,Constraint Satisfaction,Russian Doll Search for Solving Constraint Optimization Problems,"Gérard Verfaillie, Michel Lemaître, Thomas Schiex","If the Constraint Satisfaction framework has been extended to deal with Constraint Optimization problems, it appears that optimization is far more complex than satisfaction. One of the causes of the inefficiency of complete tree search methods, like Depth First Branch and Bound, lies in the poor quality of the lower bound on the global valuation of a partial assignment, even when using Forward Checking techniques. In this paper, we introduce the Russian Doll Search algorithm which replaces one search by n successive searches on nested subproblems (n being the number of problem variables), records the results of each search and uses them later, when solving larger subproblems, in order to improve the lower bound on the global valuation of any partial assignment. On small random problems and on large real scheduling problems, this algorithm yields surprisingly good results, which greatly improve as the problems get more constrained and the bandwidth of the used variable ordering diminishes.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-027.pdf,
31,1996,Constraint Satisfaction,Enhancements of Branch and Bound Methods for the Maximal Constraint Satisfaction Problem,Richard J. Wallace,"Two methods are described for enhancing performance of branch and bound methods for overconstrained CSPS. These methods improve either the upper or lower bound, respectively, during search, so the two can be combined. Upper bounds are improved by using heuristic repair methods before search to find a good solution quickly, whose cost is used as the initial upper bound. The method for improving lower bounds is an extension of directed arc consistency preprocessing, used in conjunction with forward checking. After computing directed arc consistency counts, inferred counts are computed for all values based on minimum counts for values of adjacent variables that are later in the search order. This inference process can be iterated, so that counts are cascaded from the end to the beginning of the search order, to augment the initial counts. Improvements in time and effort are demonstrated for both techniques using random problems.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-028.pdf,
32,1996,Data Consistency,Path-Consistency: When Space Misses Time,"Assef Chmeiss, Philippe Jégou","Within the framework of constraint programming, particulary concerning the Constraint Satisfaction Problems (CSPs), the techniques of preprocessing based on filtering algorithms were shown to be very important for the search phase. In particular, two filtering methods have been studied, these methods exploit two properties of local consistency: arc- and path-consistency. Concerning the arc-consistency methods, there is a linear time algorithm (in the size of the problem) which is efficient in practice (Bessiere, Freuder, and Régin 1995). But the limitations of the arc-consistency algorithms requires often filtering methods with higher order like path-consistency filterings. The best path-consistency algorithm proposed is PC-6, a natural generalization of AC-6 to path-consistency. Its time complexity is O(n^3d^3) and its space complexity is O(n^3d^2), where n is the number of variables and d is the size of domains. We have remarked that PC-6, though it is widely better than PC-4, was not very efficient in practice, specialy for those classes of problems that require an important space to be run. Therefore, we propose here a new path-consistency algorithm called PC-7, its space complexity is O(n2d2) but its time complexity is O(n^3d^4) i.e. worse than that of PC-6. However, the simplicity of PC-7 as well as the data structures used for its implementation offer really a higher performance than PC-6. Furthermore, it turns out that when the size of domains is a constant of the problems, the time compPexity of PC-7 becomes, like PC-6, optimal i.e. O(n^3).",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-029.pdf,
33,1996,Data Consistency,Neighborhood Inverse Consistency Preprocessing,"Eugene C. Freuder, Charles D. Elfe","Constraint satisfaction consistency preprocessing methods are used to reduce search effort. Time and especially space costs limit the amount of preprocessing that will be cost effective. A new form of consistency preprocessing, neighborhood inverse consistency, can achieve more problem pruning than the usual arc consistency preprocessing in a cost effective manner. There are two basic ideas: 1) Common forms of consistency enforcement basically operate by identifying and remembering solutions to subproblems for which a consistent value cannot be found for some additional problem variable. The space required for this memory can quickly become prohibitive. Inverse consistency basically operates by removing values for variables that are not consistent with any solution to some subproblem involving additional variables. The space requirement is at worst linear. 2) Typically consistency preprocessing achieves some level of consistency uniformly throughout the problem. A subproblem solution will be tested against each additional variable that constrains any subproblem variable. Neighborhood consistency focuses attention on the subproblem formed by the variables that are all constrained by the value in question. By targeting highly relevant subproblems we hope to ""shim the cream"", obtaining a high payoff for a limited cost.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-030.pdf,
34,1996,Data Consistency,Generalized Arc Consistency for Global Cardinality Constraint,Jean-Charles Régin,"In this paper, we present an efficient way of implementing generalized arc consistency for a gcc. The algorithm we propose is based on a new theorem of flow theory. We also show how this algorithm can efficiently be combined with other filtering techniques.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-031.pdf,
35,1996,Data Consistency,Lazy Arc Consistency,"Thomas Schiex, Jean-Charles Régin, Christine Gaspin, Gérard Verfaillie","Arc consistency filtering is widely used in the framework of binary constraint satisfaction problems: with a low complexity, inconsistency may be detected,and domains are filtered. In this paper, we show that when detecting inconsistency is the objective, a systematic domain filtering is useless and a lazy approach is more adequate. Whereas usual arc consistency algorithms produce the maximum arc consistent sub-domain, when it exists, we propose a method, called LACY, which only looks for any arc consistent sub-domain. The algorithm is then extended to provide the additional service of locating one variable with a minimum domain cardinality in the maximum arc consistent sub-domain, without necessarily computing all domain sizes. Finally, we compare traditional AC enforcing and lazy AC enforcing using several benchmark problems, both randomly generated CSP and real life problems.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-032.pdf,
36,1996,Game-Tree Search,Searching Game Trees Under Memory Constraints,"Subir Bhattacharya, Amitava Bagchi","The best-first game-tree search algorithm SSS* has greater pruning power than the depth-first algorithm Alpha-Beta. Yet it is seldom used in practice because it is slow in execution and requires substantial memory. Variants of SSS* have been proposed in recent years that overcome some, but not all, of its limitations. The recursive controlled-memory best-first search scheme MemSSS* described here is a new derivative of SSS* that compares favourably with Alpha-Beta in respect of all three major performance measures, namely, pruning power, running time and memory needs. MemSSS* improves upon an earlier controlled-memory algorithm IterSSS* which has most of the desired properties but is slow in execution.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-033.pdf,
37,1996,Game-Tree Search,Partition Search,Matthew L. Ginsberg,"We introduce a new form of game search called partition search that incorporates dependency analysis, allowing substantial reductions in the portion of the tree that needs to be expanded. Both theoretical results and experimental data are presented. For the game of bridge, partition search provides approximately as much of an improvement over existing methods as a-b pruning provides over minimax.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-034.pdf,
38,1996,Game-Tree Search,Exploiting Graph Properties of Game Trees,"Aske Plaat, Jonathan Schaeffer, Wim Pijls, Arie de Bruin","The state space of most adversary games is a directed graph. However, due to the success of simple recursive algorithms based on Alpha-Beta, theoreticians and practitioners have concentrated on the traversal of trees, giving the field the name ""game-tree search."" This paper shows that the focus on trees has obscured some important properties of the underlying graphs. One of the hallmarks of the field of game-tree search has been the notion of the minimal tree, the smallest tree that has to be searched by any algorithm to find the minimax value. In fact, for most games it is a directed graph. As demonstrated in chess and checkers, we show that the minimal graph is significantly smaller than previously thought, proving that there is more room for improvement of current algorithms. We exploit the graph properties of the search space to reduce the size of trees built in practice by at least 25%. For over a decade, fixed-depth Alpha-Beta searching has been considered a closed subject, with research moving on to more application-dependent techniques. This work opens up new avenues of research for further application-independent improvements.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-035.pdf,
39,1996,Game-Tree Search,Forward Estimation for Game-Tree Search,Weixiong Zhang,"It is known that bounds on the minimax values of nodes in a game tree can be used to reduce the computational complexity of minimax search for two-player games. We describe a very simple method to estimate bounds on the minimax values of interior nodes of a game tree, and use the bounds to improve minimax search. The new algorithm, called forward estimation, does not require additional domain knowledge other than a static node evaluation function, and has small constant overhead per node expansion. We also propose a variation of forward estimation, which provides a tradeoff between computational complexity and decision quality. Our experimental results show that forward estimation outperforms alpha-beta pruning on random game trees and the game of Othello.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-036.pdf,
40,1996,Phase Transition,The Constrainedness of Search,"Ian P. Gent, Ewan MacIntyre, Patrick Prosser, Toby Walsh","We introduce a parameter that measures the ""constrainedness"" of an ensemble of combinatorial problems. If problems are over-constrained, they are likely to be insoluble. If problems are under-constrained, they are likely to be soluble. This constrainedness parameter generalizes a number of parameters previously used in different NP-complete problem classes. Phase transitions in different NP classes can thus be directly compared. This parameter can also be used in a heuristic to guide search. The heuristic captures the intuition of making the most constrained choice first, since it is often useful to branch into the least constrained subproblem. Many widely disparate heuristics can be seen as minimizing constrainedness.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-037.pdf,
41,1996,Phase Transition,Exploiting a Theory of Phase Transitions in Three-Satisfiability Problems,"David M. Pennock, Quentin F. Stout","In the past few years there have been several empirical discoveries of phase transitions in constraint satisfaction problems (CSPs), and a growth of interest in the area among the artificial intelligence community. This paper extends a simple analytical theory of phase transitions in three-satisfiability (3-SAT) problems in two directions. First, a more accurate, problem-dependent calculation leads to a new polynomial time probabilistic estimate of the satisfiability of 3-SAT problems called PE-SAT (Probabilistic Estimate SATisfiability algorithm). PE-SAT empirically classifies 3-SAT problems with about 70% accuracy at the hardest region (the so-called crossover point or 50% satisfiable region) of random 3-SAT space. Furthermore, the estimate has a meaningful magnitude such that extreme estimates are much more likely to be correct. Second, the same estimate is used to improve the running time of a backtracking search for a solution to 3-SAT by pruning unlikely branches of the search. The speed-up is achieved at the expense of accuracy--the search remains sound but is no longer complete. The trade-off between speed-up and accuracy is shown to improve as the size of problems increases.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-038.pdf,
42,1996,Phase Transition,A Second Order Parameter for 3SAT,Tuomas W. Sandholm,"The 3-satisfiability problem (3SAT) has had a central role in the study of complexity. It was recently found that 3SAT instances transition sharply from satisfiable to nonsatisfiable as the ratio of clauses to variables increases. Because this phase transition is so sharp, the ratio - an order parameter - can be used to predict satisfiability. This paper describes a second order parameter for 3SAT. Like the classical order parameter, it can be computed in linear time, but it analyzes the structure of the problem instance more deeply. We present an analytical method for using this new order parameter in conjunction with the classical one to enhance satisfiability prediction accuracy. The assumptions of the method are verified by rigorous statistical testing. The method significantly increases the satisfiability prediction accuracy over using the classical order parameter alone. Hardness - i.e. how long it takes to determine satisfiability - results for one complete and one incomplete algorithm from the literature are also presented as a function of the two order parameters. The importance of new order parameters lies in the fact that they refine the locating of satisfiable vs. nonsatisfiable and hard vs. easy formulas in the space of all problem instances by adding a new dimension in the analysis.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-039.pdf,
43,1996,Phase Transition,The Very Particular Structure of the Very Hard Instances,Dan R. Vlasie,"We show that the algorithms which behave well on average may have difficulty only for highly structured, non-random inputs, except in a finite number of cases. The formal framework is provided by the theory of Kolmogorov complexity. An experimental verification is done for graph S-colorability with Brhlaz’s algorithm.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-040.pdf,
44,1996,Search Control,Heuristic-Biased Stochastic Sampling,John L. Bresina,"This paper presents a search technique for scheduling problems, called Heuristic-Biased Stochastic Sampling (HBSS). The underlying assumption behind the HBSS approach is that strictly adhering to a search heuristic often does not yield the best solution and, therefore, exploration off the heuristic path can prove fruitful. Within the HBSS approach, the balance between heuristic adherence and exploration can be controlled according to the confidence one has in the heuristic. By varying this balance, encoded as a bias function, the HBSS approach encompasses a family of search algorithms of which greedy search and completely random search are extreme members. We present empirical results from an application of HBSS to the realworld problem of observation scheduling. These results show that with the proper bias function, it can be easy to outperform greedy search.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-041.pdf,
45,1996,Search Control,Easy and Hard Testbeds for Real-Time Search Algorithms,"Sven Koenig, Reid G. Simmons","Although researchers have studied which factors influence the behavior of traditional search algorithms, currently not much is known about how domain properties influence the performance of real-time search algorithms. In this paper we demonstrate, both theoretically and experimentally, that Eulerian state spaces (a superset of undirected state spaces) are very easy for some existing real-time search algorithms to solve: even real-time search algorithms that can be intractable, in general, are efficient for Eulerian state spaces. Because traditional real-time search testbeds (such as the eight puzzle and gridworlds) are Eulerian, they cannot be used to distinguish between efficient and inefficient real-time search algorithms. It follows that one has to use non-Eulerian domains to demonstrate the general superiority of a given algorithm. To this end, we present two classes of hard-to-search state spaces and demonstrate the performance of various real-time search algorithms on them.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-042.pdf,
46,1996,Search Control,Improved Limited Discrepancy Search,Richard E. Korf,"We present an improvement to Harvey and Ginsberg’s limited discrepancy search algorithm, which eliminates much of the redundancy in the original, by generating each path from the root to the maximum search depth only once. For a complete binary tree of depth d, this reduces the asymptotic complexity from O((d+2/2)(2^d)) to O(2^d). The savings is much less in a partial tree search, or in a heavily pruned tree. The overhead of the improved algorithm on a complete b-ary tree is only a factor of b/(b - 1) compared to depth-first search. While this constant factor is greater on a heavily pruned tree, this improvement makes limited discrepancy search a viable alternative to depth-first search, whenever the entire tree may not be searched. Finally, we present both positive and negative empirical results on the utility of limited discrepancy search, for the problem of number partitioning.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-043.pdf,
47,1996,Search Control,Efficient Goal-Directed Exploration,"Yury Smirnov, Sven Koenig, Manuela M. Veloso, Reid G. Simmons","If a state space is not completely known in advance, then search algorithms have to explore it sufficiently to locate a goal state and a path leading to it, performing therefore what we call goal-directed exploration. Two paradigms of this process are pure exploration and heuristic-driven exploitation: the former approaches explore the state space using only knowledge of the physically visited portion of the domain, whereas the latter approaches totally rely on heuristic knowledge to guide the search towards goal states. Both approaches have disadvantages: the first one does not utilize available knowledge to cut down the search effort, and the second one relies too much on the knowledge, even if it is misleading. We have therefore developed a framework for goal-directed exploration, called VECA, that combines the advantages of both approaches by automatically switching from exploitation to exploration on parts of the state space where exploitation does not perform well. VECA provides better performance guarantees than previously studied heuristic-driven exploitation algorithms, and experimental evidence suggests that this guarantee does not deteriorate its average-case performance.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-044.pdf,
48,1996,Search & Learning,A Complexity Analysis of Space-Bounded Learning Algorithms for the Constraint Satisfaction Problem,"Roberto J. Bayardo, Jr., Daniel P. Miranker","Learning during backtrack search is a space-intensive process that records information (such as additional constraints) in order to avoid redundant work. In this paper, we analyze the effects of polynomial-space-bounded learning on runtime complexity of backtrack search. One space-bounded learning scheme records only those constraints with limited size, and another records arbitrarily large constraints but deletes those that become irrelevant to the portion of the search space being explored. We find that relevance-bounded learning allows better runtime bounds than size-bounded learning on structurally restricted constraint satisfaction problems. Even when restricted to linear space, our relevance-bounded learning algorithm has runtime complexity near that of unrestricted (exponential space-consuming) learning schemes.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-045.pdf,
49,1996,Search & Learning,Improving the Learning Efficiencies of Realtime Search,"Toru Ishida, Masashi Shimbo","The capability of learning is one of the salient features of realtime search algorithms such as LRTA*. The major impediment is, however, the instability of the solution quality during convergence: (1) they try to find all optimal solutions even after obtaining fairly good solutions, and (2) they tend to move towards unexplored areas thus failing to balance exploration and exploitation. We propose and analyze two new realtime search algorithms to stabilize the convergence process. E-search (weighted realtime search) allows suboptimal solutions with E error to reduce the total amount of learning performed. d-search (realtime search with upper bounds) utilizes the upper bounds of estimated costs, which become available after the problem is solved once. Guided by the upper bounds, d-search can better control the tradeoff between exploration and exploitation.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-046.pdf,
50,1996,Search & Learning,Dynamic Improvements of Heuristic Evaluations during Search,"Gerhard Kainz, Hermann Kaindl","Heuristic search algorithms employ evaluation functions that utilize heuristic knowledge of the given domain. We call such functions static evaluation functions when they only make use of knowledge applied to the given state but not results of any search in this state space - neither the search guided by the evaluation nor extra search like look-ahead. Static evaluation functions typically evaluate with some error. An approach to improve on the accuracy of a given static evaluation function is to utilize results of a search. Since this involves dynamic changes, we call resulting functions dynamic evaluation functions. We devised a new approach to dynamic improvements that we named diflerence approach. It utilizes differences of known costs and their heuristic estimates from a given evaluation function to improve other heuristic estimates from this function. This difference approach can be applied in a wide variety of known search algorithms. We show how it fits into a unifying view of dynamic improvements, that also covers already existing approaches as viewed from this perspective. Finally, we report experimental data for two different domains that represent significant improvements over previously published results.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-047.pdf,
51,1996,Search & Learning,Inference-Based Constraint Satisfaction Supports Explanation,"Mohammed H. Sqalli, Eugene C. Freuder","Constraint satisfaction problems are typically solved using search, augmented by general purpose consistency inference methods. This paper proposes a paradigm shift in which inference is used as the primary problem solving method, and attention is focused on special purpose, domain specific inference methods. While we expect this approach to have computational advantages, we emphasize here the advantages of a solution method that is more congenial to human thought processes. Specifically we use inference-based constraint satisfaction to support explanations of the problem solving behavior that are considerably more meaningful than a trace of a search process would be. Logic puzzles are used as a case study. Inference-based constraint satisfaction proves surprisingly powerful and easily extensible in this domain. Problems drawn from commercial logic puzzle booklets are used for evaluation. Explanations are produced that compare well with the explanations provided by these booklets.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-048.pdf,
52,1996,Stochastic Search,Constraint Satisfaction Using a Hybrid Evolutionary Hill-Climbing Algorithm that Performs Opportunistic Arc and Path Revision,"James Bowen, Gerry Dozier","This paper introduces a hybrid evolutionary hillclimbing algorithm that quickly solves (!onstraint, Satisfaction Problems (CSPs). This hybrid uses opportunistic arc and path revision in an interleaved fashion to reduce the size of the search space and to realize when to quit if a CSP is based on an inconsistent, constraint network. This hybrid out,performs a well known hill-climbing algorithm, the Iterat,ive Descent. Method, on a test suit,e of 750 randomly generated CSPs.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-049.pdf,
53,1996,Stochastic Search,Adding New Clauses for Faster Local Search,"Byungki Cha, Kazuo Iwama","A primary concern when using local search methods for CNF satisfiability is how to get rid of local minimas. Among many other heuristics, Weighting by Morris (1993) and Selman and Kautz (1993) works overwhelmingly better than others (Cha and Iwama 1995). Weighting increases the weight of each clause which is unsatisfied at a local minima. This paper introduces a more sophisticated weighting strategy, i.e., adding new clauses (ANC) that are unsatisfied at the local minima. As those new clauses, we choose resolvents of the clauses unsatisfied at the local minima and randomly selected neighboring clauses. The idea is that ANC is to make the slope of search space more smooth than the simple weighting. Experimental data show that ANC is faster than simple weighting: (i) When the number of variables is 200 or more, ANC is roughly four to ten times as fast as weighting in terms of the number of search steps. (ii) It might be more important that the divergence of computation time for each try is much smaller in ANC than in weighting. (iii) There are several possible reasons for ANC’s superiority, one of which is that ANC returns the same local minima much less frequently than weighting.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-050.pdf,
54,1996,Stochastic Search,Weighting for Godot: Learning Heuristics for GSAT,Jeremy Frank,"We investigate an improvement to GSAT which associates a weight with each clause. GSAT moves to assignments maximizing the weight of satisfied clauses and this weight is incremented when GSAT moves to an assignment in which this clause is unsatisfied. We present results showing that this algorithm and its variants outperform one of the best known modifications of GSAT to date using two metrics: number of solved problems on a single try, and minimum mean number of flips to solve a test suite of problems.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-051.pdf,
55,1996,Stochastic Search,Duplication of Coding Segments in Genetic Programming,Thomas Haynes,"Research into the utility of non-coding segments, or introns, in genetic-based encodings has shown that they expedite the evolution of solutions in domains by protecting building blocks against destructive crossover. We consider a genetic programming system where non-coding segments can be removed, and the resultant chromosomes returned into the population. This parsimonious repair leads to premature convergence, since as we remove the naturally occurring non-coding segments, we strip away their protective backup feature. We then duplicate the coding segments in the repaired chromosomes, and place the modified chromosomes into the population. The duplication method significantly improves the learning rate in the domain we have considered. We also show that this method can be applied to other domains.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-052.pdf,
56,1996,Stochastic Search,A Graph-Based Method for Improving GSAT,"Kalev Kask, Rina Dechter","GSAT is a randomized greedy local repair procedure that was introduced for solving propositional satisfiability and constraint satisfaction problems. We present an improvement to GSAT that is sensitive to the problem’s structure. When the problem has a tree structure the algorithm is guaranteed to find a solution in linear time. For non-tree networks, the algorithm designates a subset of nodes, called cutset, and executes a regular GSAT algorithm on this set of variables. On all the rest of the variables it executes a specialized local search algorithm for trees. This algorithm finds an assignment that, like GSAT, locally minimizes the sum of unsatisfied constraints and also globally minimizes the number of conflicts in every tree-like subnetwork. We will present results of experiments showing that this new algorithm outperforms regular GSAT on sparse networks whose cycle-cutset size is bounded by 3OYo of the nodes.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-053.pdf,
57,1996,Stochastic Search,Tuning Local Search for Satisfiability Testing,"Andrew J. Parkes, Joachim P. Walser","Local search algorithms, particularly GSAT and WSAT, have attracted considerable recent attention, primarily because they are the best known approaches to several hard classes of satisfiability problems. However, replicating reported results has been difficult because the setting of certain key parameters is something of an art, and because details of the algorithms, not discussed in the published papers, can have a large impact on performance. In this paper we present an efficient probabilistic method for finding the optimal setting for a critical local search parameter, Maxflips, and discuss important details of two differing versions of WSAT. We then apply the optimization method to study performance of WSAT on satisfiable instances of Random 3SAT at the crossover point and present extensive experimental results over a wide range of problem sizes. We find that the results are well described by having the optimal value of Maxflips scale as a simple power of the number of variables, n, and the average run time scale sub-exponentially (basically as n^log(n)) over the range n = 25, . . . ,400.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-054.pdf,
58,1996,Stochastic Search,Tabu Search Techniques for Large High-School Timetabling Problems,Andrea Schaerf,The high-school timetabling problem consists in assigning all the lectures of a high school to the time periods in such a way that no teacher (or class) is involved in more than one lecture at a time and other side constraints are satisfied. The problem is NP-complete and is usually tackled using heuristic methods. This paper describes a solution algorithm (and its implementation) based on Tabu Search. The algo- rithm interleaves different types of modes and makes use of an adaptive relaxation of the hard constraints. The implementation of the algorithm has been successfully experimented in some large high schools with various kinds of side constraints.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-055.pdf,
59,1996,Stochastic Search,Combining Local Search and Backtracking Techniques for Constraint Satisfaction,"Jian Zhang, Hantao Zhang","Backtracking techniques are well-known traditional methods for solving many constraint satisfaction problems (CSPs), including the satisfiability (SAT) problem in the propositional logic. In recent years, it has been reported that local search techniques are very effective in solving some large-scale instances of the SAT problem. In this research, we combine the backtracking and local search techniques into a single method for solving SAT and CSPs. When setting a parameter of the method to either of its two extreme values, we obtain the ordinary backtracking procedure or the local search procedure. For some problems, if the parameter takes values in the middle of the two extremes, the new method is much more effective than either backtracking or local search. We tested the method with classical problems like the n-Queens and random SAT instances, as well as some difficult problems from finite mathematics. In particular, using the new method, we solved four open problems in design theory.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-056.pdf,
60,1996,Temporal Reasoning,A Simple Way to Improve Path Consistency Processing in Interval Algebra Networks,Christian Bessière,"Reasoning about qualitative temporal information is essential in many artificial intelligence problems. In particular, many tasks can be solved using the interval-based temporal algebra introduced by Allen (A1183). In this framework, one of the main tasks is to compute the transitive closure of a network of relations between intervals (also called path consistency in a CSP-like terminology). Almost all previous path consistency algorithms proposed in the temporal reasoning literature were based on the constraint reasoning algorithms PC-l and PC-2 (Mac77). In this paper, we first show that the most efficient of these algorithms is the one which stays the closest to PC-2. Afterwards, we propose a new algorithm, using the idea ""one support is sufficient"" (as AC-3 (Mac77) does for arc consistency in constraint networks). Actually, to apply this idea, we simply changed the way composition-intersection of relations was achieved during the path consistency process in previous algorithms.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-057.pdf,
61,1996,Temporal Reasoning,A Representation for Efficient Temporal Reasoning,"James P. Delgrande, Arvind Gupta","It has been observed that the temporal reasoning component in a knowledge-based system is frequently a bottleneck. We investigate here a class of graphs appropriate for an interesting class of temporal domains and for which very efficient algorithms for reasoning are obtained, that of series-parallel graphs. These graphs can be used for example to model process execution, as well as various planning or scheduling activities. Events are represented by nodes of a graph and relationships are represented by edges labeled by <= or <. Graphs are composed using a sequence of series and parallel steps (recursively) on series-parallel graphs. We show that there is an 0(n) time pre-processing algorithm that allows us to answer queries about the events in O(1) time. Our results make use of a novel embedding of the graphs on the plane that is of independent interest. Finally we argue that these results may be incorporated in general graphs representing temporal events by extending the approach of Gerevini and Schubert.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-058.pdf,
62,1996,Temporal Reasoning,Maximal Tractable Subclasses of Allen’s Interval Algebra: Preliminary Report,"Thomas Drakengren, Peter Jonsson","This paper continues Nebel and Biirckert’s investigation of Allen’s interval algebra by presenting nine more maximal tractable subclasses of the algebra, in addition to their previously reported ORD-Horn subclass. Furthermore, twelve tractable subclasses are identified, whose maximality is not decided. Four of these can express the notion of sequentiality between intervals, which is not possible in the ORD-Horn algebra. The satisfiability algorithm, which is common for all the algebras, is shown to be linear.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-059.pdf,
63,1996,Temporal Reasoning,A New Proof of Tractability for ORD-Horn Relations,Gérard Ligozat,"This paper gives an elementary proof of the tractability of a sub-class of temporal relations in Allen’s algebra and related temporal calculi, the class of preconvex relations. In Allen’s case, this subclass coincides with the class of ORD-Horn relations. Nebel and Biirckert defined ORD-Horn relations and proved that path-consistency is a sufficient condition for consistency of a network for this sub-class. We prove a stronger result: for each path-consistent network in the sub-class, we give an effective method for constructing a feasible scenario without backtrack.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-060.pdf,
64,1996,Education,A Novel Application of Theory Refinement to Student Modeling,"Paul T. Baffes, Raymond J. Mooney",Theory refinement systems developed in machine learning automatically modify a knowledge base to render it consistent with a set of classified training examples. We illustrate a novel application of these techniques to the problem of constructing a student model for an intelligent tutoring system (ITS). Our approach is implemented in an ITS authoring system called ASSERT which uses theory refinement to introduce errors into an initially correct knowledge base so that it models incorrect student behavior. The efficacy of the approach has been demonstrated by evaluating a tutor developed with ASSERT with 75 students tested on a classification task covering concepts from an introductory course on the C++ programming language. The system produced reasonably accurate models and students who received feedback based on these models performed significantly better on a post test than students who received simple reteaching.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-061.pdf,
65,1996,Education,A Simulation-Based Tutor that Reasons about Multiple Agents,"Christopher Rhodes Eliot III, Beverly Park Woolf","This paper examines the problem of modeling multiple agents within an intelligent simulation-based tutor. Multiple agent and planning technology were used to enable the system to critique a human agent’s reasoning about multiple agents. This perspective arises naturally whenever a student must learn to lead and coordinate a team of people. The system dynamically selected teaching goals, instantiated plans and modeled the student and the domain as it monitored the student’s progress. The tutor provides one of the first complete integrations of a real-time simulation with knowledge-based reasoning. Other novel techniques of the system are reported, such as common-sense reasoning about plans, reasoning about protocol mechanisms, and using a real-time simulation for training.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-062.pdf,
66,1996,Education,Scaling Up Explanation Generation: Large-Scale Knowledge Bases and Empirical Studies,"James C. Lester, Bruce W. Porter","To explain complex phenomena, an explanation system must be able to select information from a formal representation of domain knowledge, organize the selected information into multisentential discourse plans, and realize the discourse plans in text. Although recent years have witnessed significant progress in the development of sophisticated computational mechanisms for explanation, empirical results have been limited. This paper reports on a seven year effort to empirically study explanation generation from semantically rich, large-scale knowledge bases. We first describe Knight, a robust explanation system that constructs multi-sentential and multi-paragraph explanations from the Biology Knowledge Base, a large-scale knowledge base in the domain of botanical anatomy, physiology, and development. We then introduce the Two Panel evaluation methodology and describe how Knight' s performance was assessed with this methodology in the most extensive empirical evaluation conducted on an explanation system. In this evaluation, Knight scored within ""half a grade"" of domain experts, and its performance exceeded that of one of the domain experts.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-063.pdf,
67,1996,Education,Dynamically Sequencing an Animated Pedagogical Agent,"Brian A. Stone, James C. Lester","One of the most promising opportunities introduced by rapid advances in knowledge-based learning environments and multimedia technologies is the possibility of creating animated pedagogical agents. These agents should exhibit three properties: timely domain coverage (they should clearly communicate fundamental concepts and relationships within the allotted time); contextuality (they should provide explanations in appropriate problem-solving contexts); and continuity (their activities and utterances should be pedagogically, visually, and aurally coherent). We have developed the coherence-structured behavior space approach to creating animated pedagogical agents. This is a two-step approach. First, we design a behavior space of animation and audio segments that are structured by prerequisite relationships and a continuity metric. Second, we navigate coherent paths through the space to dynamically sequence behaviors. This creates seamless global behaviors that communicate fundamental knowledge and provide contextualized problem-solving advice. The coherence-structured behavior space approach has been implemented in Herman the Bug, an animated pedagogical agent for Design-A-Plant, a knowledge-based learning environment for botanical anatomy and physiology. Formative evaluations of the agent with middle school students are encouraging.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-064.pdf,
68,1996,"Information Retrieval& Natural Language Processing",Machine Learning of User Profiles: Representational Issues,"Eric Bloedorn, Inderjeet Mani, T. Richard MacMillan","As more information becomes available electronically, tools for finding information of interest to users becomes increasingly important. The goal of the research described here is to build a system for generating comprehensible user profiles that accurately capture user interest with minimum user interaction. The research described here focuses on the importance of a suitable generalization hierarchy and representation for learning profiles which are predictively accurate and comprehensible. In our experiments we evaluated both traditional features based on weighted term vectors as well as subject features corresponding to categories which could be drawn from a thesaurus. Our experiments, conducted in the context of a content-based profiling system for on-line newspapers on the World Wide Web (the IDD News Browser), demonstrate the importance of a generalization hierarchy and the promise of combining natural language processing techniques with machine learning (ML) to address an information retrieval (IR) problem.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-065.pdf,
69,1996,"Information Retrieval& Natural Language Processing",Interactive Information Retrieval Systems with Minimalist Representation,"Eric Domeshek, Smadar Kedar, Andrew Gordon","Almost any information you might want is becoming available on-line. The problem is how to find what you need. One strategy to improve access to existing information sources, is intelligent information agents - an approach based on extensive representation and inference. Another alternative is to simply concentrate on better information organization and indexing. Our systems use a form of conceptual indexing sensitive to users9 task-specific information needs. We aim for minimalist representation, coding only select aspects of stored items. Rather than supporting reliable automated inference, the primary purpose of our representations is to provide sufficient discrimination and guidance to a user for a given domain and task. This paper argues, using case studies, that minimal representations can make strong contributions to the usefulness and usability of interactive information systems, while minimizing knowledge engineering effort. We demonstrate this approach in several broad spectrum applications including video retrieval and advisory systems.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-066.pdf,
70,1996,"Information Retrieval& Natural Language Processing",Learning Word Meanings by Instruction,Kevin Knight,"We develop techniques for learning the meanings of unknown words in context. Working within a compositional semantics framework, we write down equations in which a sentence' s meaning is some combination function of the meaning of its words. When one of the words is unknown, we ask for a paraphrase of the sentence. We then compute the meaning of the unknown word by inverting parts of the semantic combination function. This technique can be used to learn word-concept mappings, decomposed meanings, and mappings between syntactic and semantic roles. It works for all parts of speech.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-067.pdf,
71,1996,"Information Retrieval& Natural Language Processing",Significant Lexical Relationships,"Ted Pedersen, Mehmet Kayaalp, Rebecca Bruce","Statistical NLP inevitably deals with a large number of rare events. As a consequence, NLP data often violates the assumptions implicit in traditional statistical procedures such as significance testing. We describe a significance test, an exact conditional test, that is appropriate for NLP data and can be performed using freely available software. We apply this test to the study of lexical relationships and demonstrate that the results obtained using this test are both theoretically more reliable and different from the results obtained using previously applied tests.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-068.pdf,
72,1996,Knowledge-Based Systems,Knowledge-Based Navigation of Complex Information Spaces,"Robin D. Burke, Kristian J. Hammond, Benjamin C. Young","While the explosion of on-line information has brought new opportunities for finding and using electronic data, it has also brought to the forefront the problem of isolating useful information and making sense of large multi-dimension information spaces. We have built several developed an approach to building data ""tour guides,"" called FINDME systems. These programs know enough about an information space to be able to help a user navigate through it. The user not only comes away with items of useful information but also insights into the structure of the information space itself. In these systems, we have combined ideas of instance-based browsing, structuring retrieval around the critiquing of previously-retrieved examples, and retrieval strategies, knowledge-based heuristics for finding relevant information. We illustrate these techniques with several examples, concentrating especially on the RENTME system, a FINDME system for helping users find suitable rental apartments in the Chicago metropolitan area.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-069.pdf,
73,1996,Knowledge-Based Systems,Explicit Representations of Problem-Solving Strategies to Support Knowledge Acquisition,"Yolanda Gil, Eric Melz","Role-limiting approaches support knowledge acquisition (KA) by centering knowledge base construction on common types of tasks or domain-independent problem-solving strategies. Within a particular problem-solving strategy, domain-dependent knowledge plays specific roles. A KA tool then helps a user to fill these roles. Although role-limiting approaches are useful for guiding KA, they are limited because they only support users in filling knowledge roles that have been built in by the designers of the KA system. EXPECT takes a different approach to KA by representing problem-solving knowledge explicitly, and deriving from the current knowledge base the knowledge gaps that must be resolved by the user during KA. This paper contrasts role-limiting approaches and EXPECT' s approach, using the propose-and-revise strategy as an example. EXPECT not only supports users in filling knowledge roles, but also provides support in making other modifications to the knowledge base, including adapting the problem-solving strategy. EXPECT’s guidance changes as the knowledge base changes, providing a more flexible approach to knowledge acquisition. This work provides evidence supporting the need for explicit representations in building knowledge-based systems.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-070.pdf,
74,1996,Knowledge-Based Systems,CommonKADS Models for Knowledge-Based Planning,"John Kingston, Nigel Shadbolt, Austin Tate","The CommonKADS methodology is a collection of structured methods for building knowledge-based systems. A key component of CommonKADS is the library of generic inference models which can be applied to tasks of specified types. These generic models can either be used as frameworks for knowledge acquisition, or to verify the completeness of models developed by analysis of the domain. However. the generic models for some task types, such as knowledge-based planning, are not well-developed. Since knowledge-based planning is an important commercial application of Artificial Intelligence, there is a clear need for the development of generic models for planning tasks. Many of the generic models which currently exist have been derived from modelling of existing AI systems. These models have the strength of proven applicability. There are a number of well-known and well-tried AI planning systems in existence; one of the best known is the Open Planning Architecture (O-Plan). This paper describes the development of a CommonKADS generic inference model for knowledge-based planning tasks, based on the capabilities of the O-Plan system. The paper also describes the verification of this model in the context of a real-life planning task: the assignment and management of Royal Air Force Search and Rescue operations.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-071.pdf,
75,1996,Knowledge-Based Systems,Detecting Knowledge Base Inconsistencies Using Automated Generation of Text and Examples,"Vibhu O. Mittal, Johanna D. Moore","Verifying the fidelity of domain representation in large knowledge bases (KBs) is a difficult problem: domain experts are typically not experts in knowledge representation languages, and as knowledge bases grow more complex, visual inspection of the various terms and their abstract definitions, their inter-relationships and the limiting, boundary cases becomes much harder. This paper presents an approach to help verify and refine abstract term definitions in knowledge bases. It assumes that it is easier for a domain expert to determine the correctness of individual concrete examples than it is to verify and correct all the ramifications of an abstract, intensional specification. To this end, our approach presents the user with an interface in which abstract terms in the KB are described using examples and natural language generated from the underlying domain representation. Problems in the KB are therefore manifested as problems in the generated description. The user can then highlight specific examples or parts of the explanation that seem problematic. The system reasons about the underlying domain model by using the discourse plan generated for the description. This paper briefly describes the working of the system and illustrates three possible types of problem manifestations using an example of a specification of floating-point numbers in Lisp.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-072.pdf,
76,1996,Knowledge Compilation,Path-Based Rules in Object-Oriented Programming,"James M. Crawford, Daniel Dvorak, Diane Litman, Anil Mishra, Peter F. Patel-Schneider","Object-oriented programming has recently emerged as one of the most important programming paradigms. While object-oriented programming clearly owes an intellectual debt to AI, it appears to be displacing some AI techniques, such as rule-based programming, from the marketplace. This need not be so as path-based rules-forward-chaining production rules that are restricted to follow pointers between objects-fit into the object-oriented paradigm in a clean and elegant way. The combination of path-based rules and object-oriented programming should be useful in AI applications, and in the more general problem of transferring AI techniques to the larger computer science community.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-073.pdf,
77,1996,Knowledge Compilation,Approximate Knowledge Compilation: The First Order Case,Alvaro del Val,"Knowledge compilation procedures make a knowledge base more explicit so as make inference with respect to the compiled knowledge base tractable or at least more efficient. Most work to date in this area has been restricted to the propositional case, despite the importance of first order theories for expressing knowledge concisely. Focusing on (LUB) approximate compilation (Selman and Kautz 1991), our contribution is twofold: We present a new ground algorithm for approximate compilation which can produce exponential savings with respect to the previously known algorithm (Selman and Kautz 1991). d We show that both ground algorithms can be lifted to the first order case preserving their correctness for approximate compilation.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-074.pdf,
78,1996,Knowledge Compilation,A New Algorithm for Computing Theory Prime Implicates Compilations,"Pierre Marquis, Samira Sadaoui","We present a new algorithm (called TPI /BDD) for computing the theory prime implicates compilation of a knowledge base S. In contrast to many compilation algorithms, TPI /BDD does not require the prime implicates of S to be generated. Since their number can easily be exponential in the size of S, TPI/BDD can save a lot of computing. Thanks to TPI/BDD, we can now conceive of compiling knowledge bases impossible to before.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-075.pdf,
79,1996,Knowledge Compilation,Compilation for Critically Constrained Knowledge Bases,Robert Schrag,"We show that many ""critically constrained"" Random 3SAT knowledge bases (KBs) can be compiled into disjunctive normal form easily by using a variant of the ""Davis-Putnam"" proof procedure. From these compiled KBs we can answer all queries about entailment of conjunctive normal formulas, also easily - compared to a ""brute-force"" approach to approximate knowledge compilation into unit clauses for the same KBs. We exploit this fact to develop an aggressive hybrid approach which attempts to compile a KB exactly until a given resource limit is reached, then falls back to approximate compilation into unit clauses. The resulting approach handles all of the critically constrained Random 3SAT KBs with average savings of an order of magnitude over the brute-force approach.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-076.pdf,
80,1996,Abstraction,Spatial Aggregation: Language and Applications,"Christopher Bailey-Kellogg, Feng Zhao, Kenneth Yip","Spatial aggregation is a framework for organizing computations around image-like, analogue representations of physical processes in data interpretation and control tasks. It conceptualizes common computational structures in a class of implemented problem solvers for difficult scientific and engineering problems. It comprises a mechanism, a language, and a programming style. The spatial aggregation mechanism transforms a numerical input field to successively higher-level descriptions by applying a small, identical set of operators to each layer given a metric, neighborhood relation and equivalence relation. This paper describes the spatial aggregation language and its applications. The spatial aggregation language provides two abstract data types - neighborhood graph and field - and a set of interface operators for constructing the transformations of the field, together with a library of component implementations from which a user can mix-and-match and specialize for a particular application. The language allows users to isolate and express important computational ideas in different problem domains while hiding low-level details. We illustrate the use of the language with examples ranging from trajectory grouping in dynamics interpretation to region growing in image analysis. Programs for these different task domains can be written in a modular, concise fashion in the spatial aggregation language.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-077.pdf,
81,1996,Abstraction,Computing Abstraction Hierarchies by Numerical Simulation,"Alan Bundy, Fausto Giunchiglia, Roberto Sebastiani, Toby Walsh","We present a novel method for building ABSTRIPS-style abstraction hierarchies in planning. The aim of this method is to minimize the amount of backtracking between abstraction levels. Previous approaches have determined the criticality of operator preconditions by reasoning about plans directly. Here, we adopt a simpler and faster approach where we use numerical simulation of the planning process. We demonstrate the theoretical advantages of our approach by identifying some simple properties lacking in previous approaches but possessed by our method. We demonstrate the empirical advantages of our approach by a set of four benchmark experiments using the ABTWEAK system. We compare the quality of the abstraction hierarchies generated with those built by the ALPINE and HIGHPOINT algorithms.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-078.pdf,
82,1996,Abstraction,Hierarchical A*: Searching Abstraction Hierarchies Efficiently,"Robert C. Holte, M. B. Perez, R. M. Zimmer, A. J. MacDonald","Abstraction, in search, problem solving, and planning, works by replacing one state space by another (the ""abstract"" space) that is easier to search. The results of the search in the abstract space are used to guide search in the original space. For instance, the length of the abstract solution can be used as a heuristic for A* in searching in the original space. However, there are two obstacles to making this work efficiently. The first is a theorem (Valtorta, 1984) stating that for a large class of abstractions, ""embedding abstractions,"" every state expanded by blind search must also be expanded by A* when its heuristic is computed in this way. The second obstacle arises because in solving a problem A* needs repeatedly to do a full search of the abstract space while computing its heuristic. This paper introduces a new abstraction-induced search technique, ""Hierarchical A*,"" that gets around both of these difficulties: first, by drawing from a different class of abstractions, ""homomorphism abstractions,"" and, secondly, by using novel caching techniques to avoid repeatedly expanding the same states in successive searches in the abstract space. Hierarchical A* outperforms blind search on all the search spaces studied.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-079.pdf,
83,1996,Abstraction,Commitment Strategies in Hierarchical Task Network Planning,"Reiko Tsuneto, Kutluhan Erol, James Hendler, Dana Nau","This paper compares three commitment strategies for HTN planning: (1) a strategy that delays variable bindings as much as possible; (2) a strategy in which no non-primitive task is expanded until all variable constraints are committed; and (3) a strategy that chooses between expansion and variable instantiation based on the number of branches that will be created in the search tree. Our results show that while there exist planning domains in which the first two strategies do well, the third does well over a broader range of planning domains.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-080.pdf,
84,1996,Belief & Belief Revision,A Semantic Characterization of an Algorithm for Estimating Others’ Beliefs from Observation,"Hideki Isozaki, Hirofumi Katsuno","Human beings often estimate others’ beliefs and intentions when they interact with others. Estimation of others’ beliefs will be useful also in controlling the behavior and utterances of artificial agents, especially when lines of communication are unstable or slow. But, devising such estimation algorithms and background theories for the algorithms is difficult, because of many factors affecting one' s belief. We have proposed an algorithm that estimates others’ beliefs from observation in the changing world. Experimental results show that this algorithm returns natural answers to various queries. However, the algorithm is only heuristic, and how the algorithm deals with beliefs and their changes is not entirely clear. We propose certain semantics based on a nonstandard structure for modal logic. By using these semantics, we shed light on a logical meaning of the belief estimation that the algorithm deals with. We also discuss how the semantics and the algorithm can be generalized.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-081.pdf,
85,1996,Belief & Belief Revision,What Is Believed Is What Is Explained (Sometimes),"Renwei Li, Luís Moniz Pereira","This paper presents a formal and computational methodology for incorporation of new knowledge into knowledge bases about actions and changes. We employ Gelfond and Lifschitz' action description language A to describe domains of actions. The knowledge bases on domains of actions are defined and obtained by a new translation from domain descriptions in J into abductive normal logic programs, where a time dimension is incorporated. The knowledge bases are shown to be both sound and complete with respect to their domain descriptions. In particular, we propose a possible causes approach (PCA) to belief update based on the slogan: What is believed is what is explained. A possible cause of new knowledge consists of abduced occurrences of actions and value propositions about the initial state of the domain of actions, that would allow to derive the new knowledge. We show how to compute possible causes with abductive logic programming, and present some techniques to improve search efficiency. We use examples to compare our possible causes approach with Ginsberg’s possible worlds approach (P WA) and Winslett' s possible models approach (PMA).",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-082.pdf,
86,1996,Belief & Belief Revision,The Complexity of Model Checking for Belief Revision and Update,"Paolo Liberatore, Marco Schaerf","One of the main challenges in the formal modeling of common-sense reasoning is the ability to cope with the dynamic nature of the world. Among the approaches put forward to address this problem are belief revision and update. Given a knowledge base T, representing our knowledge of the ""state of affairs"" of the world of interest, it is possible that we are lead to trust another piece of information P, possibly inconsistent with the old one 7' . The aim of revision and update operators is to characterize the revised knowledge base T' that incorporates the new formula P into the old one T while preserving consistency and, at the same time, avoiding the loss of too much information in this process. In this paper we study the computational complexity of one of the main computational problems of belief revision and update: deciding if an interpretation M is a model of the revised knowledge base.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-083.pdf,
87,1996,Belief & Belief Revision,Updating Knowledge Bases with Disjunctive Information,"Yan Zhang, Norman Y. Foo","It is well known that the minimal change principle was widely used in knowledge base updates. However, recent research has shown that conventional minimal change methods, eg. the PMA (Winslett 1988), are generally problematic for updating knowledge bases with disjunctive information. In this paper, we propose two different approaches to deal with this problem - one is called the minimal change with exceptions (MCE), the other is called the minimal change with maximal disjunctive inclusions (MCD). The first method is syntax-based, while the second is model-theoretic. We show that these two approaches are equivalent for propositional knowledge base updates, and the second method is also appropriate for first order knowledge base updates. We then prove that our new update approaches still satisfy the standard Katsuno and Mendelzon’s update postulates.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-084.pdf,
88,1996,Description Logics & Probabilistic Reasoning,Irrelevance and Conditioning in First-Order Probabilistic Logic,"Daphne Koller, Joseph Y. Halpern","First-order probabilistic logic is a powerful knowledge representation language. Unfortunately, deductive reasoning based on the standard semantics for this logic does not support certain desirable patterns of reasoning, such as indifference to irrelevant information or substitution of constants into universal rules. We show that both these patterns rely on a first-order version of probabilistic independence, and provide semantic conditions to capture them. The resulting insight enables us to understand the effect of conditioning on independence, and allows us to describe a procedure for determining when independencies are preserved under conditioning. We apply this procedure in the context of a sound and powerful inference algorithm for reasoning from statistical knowledge bases.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-085.pdf,
89,1996,Description Logics & Probabilistic Reasoning,The Limits on Combining Recursive Horn Rules with Description Logics,"Alon Y. Levy, Marie-Christine Rousset","Horn rule languages have formed the basis for many Artificial Intelligence application languages, but are not expressive enough to model domains with a rich hierarchical structure. Description logics have been designed especially to model rich hierarchies. Several applications would significantly benefit from combining the expressive power of both formalisms. This paper focuses on combining recursive function-free Horn rules with the expressive description logic ALCNR, and shows exactly when a hybrid language with decidable inference can be obtained. First, we show that several of the core constructors of description logics lead by themselves to undecidability of inference when combined with recursive function-free Horn rules. We then show that without these constructors we obtain a maximal subset of ALCNR that yields a decidable hybrid language. Finally, we describe a restriction on the Horn rules that guarantees decidable inference when combined with all of ALCNR, and covers many of the common usages of recursive rules.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-086.pdf,
90,1996,Description Logics & Probabilistic Reasoning,Verification of Knowledge Bases Based on Containment Checking,"Alon Y. Levy, Marie-Christine Rousset","Building complex knowledge based applications requires encoding large amounts of domain knowledge. After acquiring knowledge from domain experts, much of the effort in building a knowledge base goes into verifying that the knowledge is encoded correctly. We consider the problem of verifying hybrid knowledge bases that contain both Horn rules and a terminology in a description logic. Our approach to the verification problem is based on showing a close relationship to the problem of query containment. Our first contribution, based on this relationship, is presenting a thorough analysis of the decidability and complexity of the verification problem, for knowledge bases containing recursive rules. Second, we show that important new classes of constraints on correct inputs and outputs can be expressed in a hybrid setting, in which a description logic class hierarchy is also considered, and we present the first complete algorithm for verifying such hybrid knowledge bases.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-087.pdf,
91,1996,Description Logics & Probabilistic Reasoning,Closed Terminologies in Description Logics,Robert A. Weida,"We introduce a predictive concept recognition methodology for description logics based on a new closed terminology assumption. During knowledge engineering, our system adopts the standard open terminology assumption as it automatically classifies concept descriptions into a taxonomy via subsumption inferences. However, for applications like configuration, the terminology becomes fixed during problem solving. Then, closed terminology reasoning is more appropriate. In our interactive configuration application, a user incrementally specifies an individual computer system in collaboration with a configuration engine. Choices can be made in any order and at any level of abstraction. We distinguish between abstract and concrete concepts to formally define when an individual’s description may be considered finished. We also take advantage of the closed terminology assumption, together with the terminology’s subsumption-based organization, to efficiently track the types of systems and components consistent with current choices, infer additional constraints on current choices, and appropriately guide future choices. Thus, we can help focus the efforts of both user and configuration engine.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-088.pdf,
92,1996,Knowledge Bases & Context,Quantificational Logic of Context,Sasa Buvac,"In this paper we extend the Propositional Logic of Context to the quantificational (predicate calculus) case. This extension is important in the declarative representation of knowledge for two reasons. Firstly, since contexts are objects in the semantics which can be denoted by terms in the language and which can be quantified over, the extension enables us to express arbitrary first-order properties of contexts. Secondly, since the extended language is no longer only propositional, we can express that an arbitrary predicate calculus formula is true in a context. The paper describes the syntax and the semantics of a quantificational language of context, gives a Hilbert style formal system, and outlines a proof of the system’s completeness.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-089.pdf,
93,1996,Knowledge Bases & Context,Utilizing Knowledge-Base Semantics in Graph-Based Algorithms,Adnan Darwiche,"Graph-based algorithms convert a knowledge base with a graph structure into one with a tree structure (a join-tree) and then apply tree-inference on the result. Nodes in the join-tree are cliques of variables and tree-inference is exponential in w*, the size of the maximal clique in the join-tree. A central property of join-trees that validates tree-inference is the running-intersection property: the intersection of any two cliques must belong to every clique on the path between them. We present two key results in connection to graph-based algorithms. First, we show that the running-intersection property, although sufficient, is not necessary for validating tree-inference. We present a weaker property for this purpose, called running-interaction, that depends on non-structural (semantical) properties of a knowledge base. We also present a linear algorithm that may reduce w* of a join-tree, possibly destroying its running-intersection property, while maintaining its running-interaction property and, hence, its validity for tree-inference. Second, we develop a simple algorithm for generating trees satisfying the running-interaction property. The algorithm bypasses triangulation (the standard technique for constructing join-trees) and does not construct a join-tree first. We show that the proposed algorithm may in some cases generate trees that are more efficient than those generated by modifying a join-tree.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-090.pdf,
94,1996,Knowledge Bases & Context,Scaling up Logic-Based Truth Maintenance Systems via Fact Garbage Collection,"John O. Everett, Kenneth D. Forbus","Truth maintenance systems provide caches of beliefs and inferences that support explanations and search. Traditionally, the cost of using a TMS is monotonic growth in the size of this cache. In some applications this cost is too high; for example, intelligent learning environments may require students to explore many alternatives, which leads to unacceptable performance. This paper describes an algorithm for fact garbage collection that retains the explanation-generating capabilities of a TMS while eliminating the increased storage overhead. We describe the application context that motivated this work and the properties of applications that benefit from this technique. We present the algorithm, showing how to balance the tradeoff between maintaining a useful cache and reclaiming storage, and analyze its complexity. We demonstrate that this algorithm can eliminate monotonic storage growth, thus making it more practical to field large-scale TMS-based systems.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-091.pdf,
95,1996,Knowledge Bases & Context,Contextual Reasoning Is NP-Complete,Fabio Massacci,"The logic of context with the ist (c,p) modality has been proposed by McCarthy as a foundation for contextual reasoning. This paper shows that propositional logic of context is NP-complete and therefore more tractable than multimodal logics or Multi Language hierarchical logics which are PSPACE-complete, This result is given in a proof-theoretical way by providing a tableau calculus, which can be used as a decision procedure for automated reasoning. The computational gap between logic of context and modal logics is analyzed and some indications for the use of either formalisms are drawn on the basis of the tradeoff between compactness of representation and tractability of reasoning.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-092.pdf,
96,1996,Nonmonotonic Reasoning,Toward Efficient Default Reasoning,"David W. Etherington, James M. Crawford","Early work on default reasoning aimed to formalize the notion of quickly jumping to conclusions. Unfortunately, the resulting formalisms have proven more computationally complex than classical logics. This has dramatically limited the applicability of formal methods to real problems involving defaults. The complexity of consistency checking is one of the two problems that must be addressed to reduce the complexity of default reasoning. We propose to approximate consistency checking using a novel synthesis of limited contexts and fast incomplete checks, and argue that this combination overcomes the limitations of its component parts. Our approach trades correctness for speed, but we argue that the nature of default reasoning makes this trade relatively inexpensive and intuitively plausible. We present a prototype implementation of a default reasoner based on these ideas, and a preliminary empirical evaluation.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-093.pdf,
97,1996,Nonmonotonic Reasoning,Situation Calculus on a Dense Flow of Time,Akira Fusaoka,"In this paper, we attempt to reconstruct the situation calculus on a dense flow of time. The proposed system: ISC, which is formulated in the framework of S2S (the monoadic second-order theory of two successor functions), allows to deal with temporal properties of time duration such as the continuity of fluents. Also it incorporates an intensional feature into the situation calculus so that the inferential process itself can be represented in ISC. On the basis of this modification, we define a nonmonotonice schema called epistemological minimization which selects the preferable model with respect to the information order in the inferential process. This method of nonmonotonic reasoning is useful for a temporal explanation problem because a sequence of events is interpreted sometimes depending on the information order in the inferential process rather than the chronological order of the actual process.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-094.pdf,
98,1996,Nonmonotonic Reasoning,Reasoning about Continuous Processes,"Christoph S. Herrmann, Michael Thielscher","Overcoming the disadvantages of equidistant discretization of continuous actions, we introduce an approach that separates time into slices of varying length bordered by certain events. Such events are points in time at which the equations describing the system’s behavior-that is, the equations which specify the ongoing processes-change. Between two events the system' s parameters stay continuous. A high-level semantics for drawing logical conclusions about dynamic systems with continuous processes is presented, and we have developed an adequate calculus to automate this reasoning process. In doing this, we have combined deduction and numerical calculus, offering logical reasoning about precise, quantitative system information. The scenario of multiple balls moving in 1-dimensional space interacting with a pendulum serves as demonstration example of our method.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-095.pdf,
99,1996,Nonmonotonic Reasoning,Splitting a Default Theory,Hudson Turner,"This paper presents mathematical results that can sometimes be used to simplify the task of reasoning about a default theory, by ""splitting it into parts."" These so-called Splitting Theorems for default logic are related in spirit to ""partial evaluation"" in logic programming, in which results obtained from one part of a program are used to simplify the remainder of the program. In this paper we focus primarily on the statement and proof of the Splitting Theorems for default logic. We illustrate the usefulness of the results by applying them to an example default theory for commonsense reasoning about action.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-096.pdf,
100,1996,Reasoning about Action,Formalizing Narratives Using Nested Circumscription,"Chitta Baral, Alfredo Gabaldon, Alessandro Provetti","The representation of narratives of actions and observations is a current issue in Knowledge Representation, where traditional plan-oriented treatments of action seem to fall short. To address narratives, Pinto and Reiter have extended Situation Calculus axioms, Kowalski and Sergot have introduced the Event Calculus in Logic Programming, and Baral et al. have defined the specification language C which allows to express actual and hypothetical situations in a uniform setting. The L entailment relation can formalize several forms of reasoning about actions and change. In this paper we illustrate a translation of L theories into Nested Abnormality Theories, a novel form of circumscription. The proof of soundness and completeness of the translation is the main technical result of the paper, but attention is also devoted to the features of Nested Abnormality Theories to capture commonsense reasoning in general and to clarify which assumptions a logical formalization forces upon a domain. These results also help clarifying the relationship between L and other recent circumscriptive formalizations for narratives, such as Miller and Shanahan’s.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-097.pdf,
101,1996,Reasoning about Action,Reasoning about Nondeterministic and Concurrent Actions: A Process Algebra Approach,"Guiseppe De Giacomo, Xiao Jun Chen","In this paper, we study reasoning about actions following a model checking approach in contrast to the usual validity checking one. Specifically, we model a dynamic system as a transition graph which represents all the possible system evolutions in terms of state changes caused by actions. Such a transition graph is defined by means of a suitable process algebra associated with an explicit global store. To reason about system properties we introduce an extension of modal m-calculus. This setting, although directly applicable only when complete information on the system is available, has several interesting features for reasoning about actions. On one hand, it inherits from the vast literature on process algebras tools for dealing with complex systems, treating suitably important aspects like parallelism, communications, interruptions, coordinations among agents. On the other hand, reasoning by model checking is typically much easier than more general logical services such as validity checking.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-098.pdf,
102,1996,Reasoning about Action,On the Range of Applicability of Baker’s Approach to the Frame Problem,G. Neelakantan Kartha,"We investigate the range of applicability of Baker’s approach to the frame problem using an action language. We show that for temporal projection and deterministic domains, Baker’s approach gives the intuitively expected results.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-099.pdf,
103,1996,Reasoning about Action,Embracing Causality in Specifying the Indeterminate Effects of Actions,Fangzhen Lin,"This paper makes the following two contributions to formal theories of actions: Showing that a causal minimization framework can be used effectively to specify the effects of indeterminate actions; and showing that for certain classes of such actions, regression, an effective computational mechanism, can be used to reason about them.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-100.pdf,
104,1996,Case-Based Reasoning,Improving Case Retrieval by Remembering Questions,"Richard Alterman, Daniel Griffin","This paper discusses techniques that improve the performance of a case retrieval system, after it is deployed, as a result of the continued usage of the system, by remembering previous episodes of question answering. The user generates a request for information and the system responds with the retrieval of relevant case(s). A history of such transactional behavior over a given set of data is maintained by the system and used as a foundation for adapting its future retrieval behavior. With each transaction, the system acquires information about the usage of the system that is subsequently used to adjust the behavior of the system. This notion of a case retrieval system draws on a distinction between the system in isolation and the system as it is used for a particular set of cases. It also draws on distinctions between the designed system, the deployed system, and the system that emerges as it is used.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-101.pdf,
105,1996,Case-Based Reasoning,Acquiring Case Adaptation Knowledge: A Hybrid Approach,"David B. Leake, Andrew Kinley, David Wilson","The ability of case-based reasoning (CBR) systems to apply cases to novel situations depends on their case adaptation knowledge. However, endowing CBR systems with adequate adaptation knowledge has proven to be a very difficult task. This paper describes a hybrid method for performing case adaptation, using a combination of rule-based and case-based reasoning. It shows how this approach provides a framework for acquiring flexible adaptation knowledge from experiences with autonomous adaptation and suggests its potential as a basis for acquisition of adaptation knowledge from interactive user guidance. It also presents initial experimental results examining the benefits of the approach and comparing the relative contributions of case learning and adaptation learning to reasoning performance.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-102.pdf,
106,1996,Case-Based Reasoning,Detecting Discontinuities in Case-Bases,"Hideo Shimazu, Yosuke Takashima","This paper describes a discontinuity detection method for case-bases and data bases. A discontinuous case or data record is defined as a case or data record whose specific attribute values are very different from those of other records retrieved with identical or similar input specifications. Using the proposed method, when a user gives an input specification, he/she can retrieve not only exactly-matched cases, but also similar cases and discontinuous cases. The proposed method has three steps: (1) Retrieving case records with input specifications which are the same as or similar to a user’s input specification (Mcaybe Similar Case, MSC), (2) Selecting a case record which most closely matches the user’s input specification among MSCs (Base Case, BC), and (3) Detecting cases among MSCs whose output specifications are very different from those of BC. The proposed method has been implemented in the CARET case-based retrieval tool operating on commercial RDBMS. Because case-based reasoning systems rely on the underlying assumption that similar input specifications retrieve similar case records, discontinuity detection in case-bases is indispensable, and our proposed method is especially useful.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-103.pdf,
107,1996,Case-Based Reasoning,Source Selection for Analogical Reasoning: An Empirical Approach,"William A. Stubblefield, George F. Luger","The effectiveness of an analogical reasoner depends upon its ability to select a relevant analogical source. In many problem domains, however, too little is known about target problems to support effective source selection. This paper describes the design and evaluation of SCAVENGER, an analogical reasoner that applies two techniques to this problem: (1) An assumption-based approach to matching that allows properties of candidate sources to match unknown target properties in the absence of evidence to the contrary. (2) The use of empirical learning to improve memory organization based on problem solving experience.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-104.pdf,
108,1996,Decision Trees,An Efficient Algorithm for Finding Optimal Gain-Ratio Multiple-Split Tests on Hierarchical Attributes in Decision Tree Learning,"Hussein Almuallim, Yasuhiro Akiba, Shigeo Kaneda","Given a set of training examples S and a tree-structured attribute x, the goal in this work is to find a multiple-split test defined on x that maximizes Quinlan’s gain-ratio measure. The number of possible such multiple-split tests grows exponentially in the size of the hierarchy associated with the attribute. It is, therefore, impractical to enumerate and evaluate all these tests in order to choose the best one. We introduce an efficient algorithm for solving this problem that guarantees maximizing the gain-ratio over all possible tests. For a training set of m examples and an attribute hierarchy of height d, our algorithm runs in time proportional to dm, which makes it efficient enough for practical use.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-105.pdf,
109,1996,Decision Trees,Learning Trees and Rules with Set-Valued Features,William W. Cohen,"In most learning systems examples are represented as fixed-length ""feature vectors"", the components of which are either real numbers or nominal values. W e propose an extension of the feature-vector representation that allows the value of a feature to be a set of strings; for instance, to represent a small white and black dog with the nominal features size and species and the set-valued feature color, one might use a feature vector with size=small, species=canis-familiaris and color={ white, black}. Since we make no assumptions about the number of possible set elements, this extension of the traditional feature-vector representation is closely connected to Blum’s ""infinite attribute"" representation. We argue that many decision tree and rule learning algorithms can be easily extended to set-valued features. We also show by example that many real-world learning problems can be efficiently and naturally represented with set-valued features; in particular, text categorization problems and problems that arise in propositionalizing first-order representations lend themselves to set-valued features.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-106.pdf,
110,1996,Decision Trees,Lazy Decision Trees,"Jerome H. Friedman, Ron Kohavi, Yeogirl Yun","Lazy learning algorithms, exemplified by nearest-neighbor algorithms, do not induce a concise hypothesis from a given training set; the inductive process is delayed until a test instance is given. Algorithms for constructing decision trees, such as C4.5, ID3, and CART create a single ""best"" decision tree during the training phase, and this tree is then used to classify test instances. The tests at the nodes of the constructed tree are good on average, but there may be better tests for classifying a specific instance. We propose a lazy decision tree algorithm-LazyDT-that conceptually constructs the ""best"" decision tree for each test instance. In practice, only a path needs to be constructed, and a caching scheme makes the algorithm fast. The algorithm is robust with respect to missing values without resorting to the complicated methods usually seen in induction of decision trees. Experiments on real and artificial problems are presented.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-107.pdf,
111,1996,Decision Trees,"Bagging, Boosting, and C4. 5",J. R. Quinlan,"Breiman’s bagging and Freund and Schapire’s boosting are recent methods for improving the predictive power of classifier learning systems. Both form a set of classifiers that are combined by voting, bagging by generating replicated boot-strap samples of the data, and boosting by adjusting the weights of training instances. This paper reports results of applying both techniques to a system that learns decision trees and testing on a representative collection of datasets. While both approaches substantially improve predictive accuracy, boosting shows the greater benefit. On the other hand, boosting also produces severe degradation on some datasets. A small change to the way that boosting combines the votes of learned classifiers reduces this downside and also leads to slightly better results on most of the datasets considered.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-108.pdf,
112,1996,Discovery,The Discovery of the Causes of Leprosy: A Computational Analysis,"Vincent Corruble, Jean-Gabriel Ganascia","The role played by the inductive inference has been studied extensively in the field of Scientific Discovery. The work presented here tackles the problem of induction in medical research. The discovery of the causes of leprosy is analyzed and simulated using computational means. An inductive algorithm is proposed, which is successful in simulating some essential steps in the progress of the understanding of the disease. It also allows us to simulate the false reasoning of previous centuries through the introduction of some medical a priori inherited form archaic medicine. Corroborating previous research, this problem illustrates the importance of the social and cultural environment on the way the inductive inference is performed in medicine.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-109.pdf,
113,1996,Discovery,Machine Discovery Based on Numerical Data Generated in Computer Experiments,"Tsuyoshi Murata, Masamichi Shimura","In the discovery of useful theorems or formulas, experimental data acquisition plays a fundamental role. Most of the previous discovery systems which have the abilities for experimentation, however, require much knowledge for evaluating experimental results, or require plans of common experiments which are given to the systems in advance. Only few systems have been attempted to make experiments which enable the discovery based on acquired experimental data without depending on given initial knowledge. This paper proposes a new approach for discovering useful theorems in the domain of plane geometry by employing experimentation. In this domain, drawing a figure and observing it correspond to making experimentation since these two processes are preparations for acquiring geometrical data. EXPEDITION, a discovery system based on experimental data acquisition, generates figures by itself and acquires expressions describing relations among line segments and angles in the figures. Such expressions can be extracted from the numerical data obtained in the computer experiments. By using simple heuristics for drawing and observing figures, the system succeeds in discovering many new useful theorems and formulas as well as rediscovering well-known theorems, such as power theorems and Thales’ theorem.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-110.pdf,
114,1996,Discovery,Using a Hybrid Genetic Algorithm and Fuzzy Logic for Metabolic Modeling,"John Yen, Bogju Lee, James C. Liao","The identification of metabolic systems is a complex task due to the complexity of the system and limited knowledge about the model. Mathematical equations and ODE’s have been used to capture the structure of the model, and the conventional optimization techniques have been used to identify the parameters of the model. In general, however, a pure mathematical formulation of the model is difficult due to parametric uncertainty and incomplete knowledge of mechanisms. In this paper, we propose a modeling approach that (1) uses fuzzy rule-based model to augment algebraic enzyme models that are incomplete, and (2) uses a hybrid genetic algorithm to identify uncertain parameters in the model. The hybrid genetic algorithm (GA) integrates a GA with the simplex method in functional optimization to improve the GA’s convergence rate. We have applied this approach to modeling the rate of three enzyme reactions in E. coli central metabolism. The proposed modeling strategy allows (1) easy incorporation of qualitative insights into a pure mathematical model and (2) adaptive identification and optimization of key parameters to fit system behaviors observed in biochemical experiments.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-111.pdf,
115,1996,Discovery,Incremental Discovery of Hidden Structure: Applications in Theory of Elementary Particles,"Jan M. Zytkow, Paul J. Fischer","Discovering hidden structure is a challenging, universal research task in Physics, Chemistry, Biology, and other disciplines. Not only must the elements of hidden structure be postulated by the discoverer, but they can only be verified by indirect evidence, at the level of observable objects. In this paper we describe a framework for hidden structure discovery, built on a constructive definition of hidden structure. This definition leads to operators that build models of hidden structure step by step, postulating hidden objects, their combinations and properties, reactions described in terms of hidden objects, and mapping between the hidden and the observed structure. We introduce the operator dependency diagram, which shows the order of operator application and model evaluation. Different observational knowledge supports different evaluation criteria, which lead to different search systems with verifiable sequences of operator applications. Isomorphfree structure generation is another issue critical for efficiency of search. We apply our framework in the system GELL-MANN, that hypothesizes hidden structure for elementary particles and we present the results of a large scale search for quark models.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-112.pdf,
116,1996,Enhancing Efficiency,Formalizing Dependency Directed Backtracking and Explanation Based Learning in Refinement Search,Subbarao Kambhampati,"The ideas of dependency directed backtracking (DDB) and explanation based learning (EBL) have developed independently in constraint satisfaction, planning and problem solving communities. In this paper, I formalize and unify these ideas under the task-independent framework of refinement search, which can model the search strategies used in both planning and constraint satisfaction. I show that both DDB and EBL depend upon the common theory ofexplaining search failuresand regressing them to higher levels of the search tree. The relevant issues of importance include (a) how the failures are explained and (b) how many failure explanations are remembered. This task-independent understanding of DDB and EBL helps support cross-fertilization of ideas among Constraint Satisfaction, Planning and Explanation-Based Learning communities.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-113.pdf,
117,1996,Enhancing Efficiency,Learning Efficient Rules by Maintaining the Explanation Structure,"Jihie Kim, Paul S. Rosenbloom","Many learning systems suffer from the utility problem; that is, that time after learning is greater than time before learning. Discovering how to assure that learned knowledge will in fact speed up system performance has been a focus of research in explanation-based learning (EBL). One way to analyze the utility problem is by examining the differences between the match process (match search) of the learned rule and the problem-solving process from which it is learned. Prior work along these lines examined one such difference. It showed that if the search-control knowledge used during problem solving is not maintained in the match process for learned rules, then learning can engender a slowdown; but that this slowdown could be eliminated if the match is constrained by the original search-control knowledge. This article examines a second difference - when the structure of the problem solving differs from the structure of the match process for the learned rules, time after learning can be greater than time before learning. This article also shows that this slowdown can be eliminated by making the learning mechanism sensitive to the problem-solving structure; i.e., by reflecting such structure in the match of the learned rule.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-115.pdf,
118,1996,Enhancing Efficiency,Compilation of Non-Contemporaneous Constraints,"Robert E. Wray III, John E. Laird, Randolph M. Jones","Hierarchical execution of domain knowledge is a useful approach for intelligent, real-time systems in complex domains. In addition, well-known techniques for knowledge compilation allow the reorganization of knowledge hierarchies into more efficient forms. However, these techniques have been developed in the context of systems that work in static domains. Our investigations indicate that it is not straightforward to apply knowledge compilation methods for hierarchical knowledge to systems that generate behavior in dynamic environments One particular problem involves the compilation of non-contemporaneous constraints. This problem arises when a training instance dynamically changes during execution. After defining the problem, we analyze several theoretical approaches that address non-contemporaneous constraints. We have implemented the most promising of these alternatives within Soar, a software architecture for performance and learning. Our results demonstrate that the proposed solutions eliminate the problem in some situations and suggest that knowledge compilation methods are appropriate for interactive environments.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-115.pdf,
119,1996,Fundamental Issues,Sequential Inductive Learning,Jonathan Gratch,"This article advocates a new model for inductive learning. Called sequential induction, it helps bridge classical fixed-sample learning techniques (which are efficient but difficult to formally characterize), and worst-case approaches (which provide strong statistical guarantees but are too inefficient for practical use). Learning proceeds as a sequence of decisions which are informed by training data. By analyzing induction at the level of these decisions, and by utilizing the only enough data to make each decision, sequential induction provides statistical guarantees but with substantially less data than worst-case methods require. The sequential inductive model is also useful as a method for determining a sufficient sample size for inductive learning and as such, is relevant to learning problems where the preponderance of data or the cost of gathering data precludes the use of traditional methods.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-116.pdf,
120,1996,Fundamental Issues,Learning to Take Actions,Roni Khardon,"We formalize a model for supervised learning of action strategies in dynamic stochastic domains, and show that pat-learning results on Occam algorithms hold in this model as well. We then identify a particularly useful bias for action strategies based on production rule systems. We show that a subset of production rule systems, including rules in predicate calculus style, small hidden state, and unobserved support predicates, is properly learnable. The bias we introduce enables the learning algorithm to invent the recursive support predicates which are used in the action strategy, and to reconstruct the internal state of the strategy. It is also shown that hierarchical strategies are learnable if a helpful teacher is available, but that otherwise the problem is computationally hard.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-117.pdf,
121,1996,Fundamental Issues,Testing the Robustness of the Genetic Algorithm on the Floating Building Block Representation,"Robert K. Lindsay, Annie S. Wu","Recent studies on a floating building block representation for the genetic algorithm (GA) suggest that there are many advantages to using the floating representation. This paper investigates the behavior of the GA on floating representation problems in response to three different types of pressures: (1) a reduction in the amount of genetic material available to the GA during the problem solving process, (2) functions which have negative-valued building blocks, and (3) randomizing non-coding segments. Results indicate that the GA’s performance on floating representation problems is very robust. Significant reductions in genetic material (genome length) may be made with relatively small decrease in performance. The GA can effectively solve problems with negative building blocks. Randomizing non-coding segments appears to improve rather than harm GA performance.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-118.pdf,
122,1996,Inductive Learning,Identifying and Eliminating Mislabeled Training Instances,"Carla E. Brodley, Mark A. Friedl","This paper presents a new approach to identifying and eliminating mislabeled training instances. The goal of this technique is to improve classification accuracies produced by learning algorithms by improving the quality of the training data. The approach employs an ensemble of classifiers that serve as a filter for the training data. Using an n-fold cross validation, the training data is passed through the filter. Only instances that the filter classifies correctly are passed to the final learning algorithm. We present an empirical evaluation of the approach for the task of automated land cover mapping from remotely sensed data. Labeling error arises in these data from a multitude of sources including lack of consistency in the vegetation classification used, variable measurement techniques, and variation in the spatial sampling resolution. Our evaluation shows that for noise levels of less than 40%, filtering results in higher predictive accuracy than not filtering, and for levels of class noise less than or equal to 20% filtering allows the base-line accuracy to be retained. Our empirical results suggest that the ensemble filter approach is an effective method for identifying labeling errors, and further, that the approach will significantly benefit ongoing research to develop accurate and robust remote sensing-based methods to map land cover at global scales.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-119.pdf,
123,1996,Inductive Learning,Generation of Attributes for Learning Algorithms,"Yuh-Jyh Hu, Dennis Kibler","Inductive algorithms rely strongly on their representational biases, Constructive induction can mitigate representational inadequacies. This paper introduces the notion of a relative gain measure and describes a new constructive induction algorithm (GALA) which is independent of the learning algorithm. Unlike most previous research on constructive induction, our methods are designed as preprocessing step before standard machine learning algorithms are applied. We present the results which demonstrate the effectiveness of GALA on artificial and real domains for several learners: C4.5, CN2, perceptron and backpropagation.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-120.pdf,
124,1996,Inductive Learning,Structural Regression Trees,Stefan Kramer,"In many real-world domains the task of machine learning algorithms is to learn a theory for predicting numerical values. In particular several standard test domains used in Inductive Logic Programming (ILP) are concerned with predicting numerical values from examples and relational and mostly non-determinate background knowledge. However, so far no ILP algorithm except one can predict numbers and cope with nondeterminate background knowledge. (The only exception is a covering algorithm called FORS.) In this paper we present Structural Regression Trees (SRT), a new algorithm which can be applied to the above class of problems. SRT integrates the statistical method of regression trees into ILP. It constructs a tree containing a literal (an atomic formula or its negation) or a conjunction of literals in each node, and assigns a numerical value to each leaf. SRT provides more comprehensible results than purely statistical methods, and can be applied to a class of problems most other ILP systems cannot handle. Experiments in several real-world domains demonstrate that the approach is competitive with existing methods, indicating that the advantages are not at the expense of predictive accuracy.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-121.pdf,
125,1996,Knowledge Bases,Discovering Robust Knowledge from Dynamic Closed-World Data,"Chun-Nan Hsu, Craig A. Knoblock","Many applications of knowledge discovery require the knowledge to be consistent with data. Examples include discovering rules for query optimization, database integration, decision support, etc. However, databases usually change over time and make machine-discovered knowledge inconsistent with data. Useful knowledge should be robust against database changes so that it is unlikely to become inconsistent after database changes. This paper defines this notion of robustness, describes how to estimate the robustness of Hornclause rules in closed-world databases, and describes how the robustness estimation can be applied in rule discovery systems.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-122.pdf,
126,1996,Knowledge Bases,Post-Analysis of Learned Rules,"Bing Liu, Wynne Hsu","Rule induction research implicitly assumes that after producing the rules from a dataset, these rules will be used directly by an expert system or a human user. In real-life applications, the situation may not be as simple as that, particularly, when the user of the rules is a human being. The human user almost always has some previous concepts or knowledge about the domain represented by the dataset. Naturally, he/she wishes to know how the new rules compare with his/her existing knowledge. In dynamic domains where the rules may change over time, it is important to know what the changes are. These aspects of research have largely been ignored in the past. With the increasing use of machine learning techniques in practica1 applications such as data mining, this issue of post analysis of rules warrants greater emphasis and attention. In this paper, we propose a technique to deal with this problem. A system has been implemented to perform the post analysis of classification rules generated by systems such as C4.5. The proposed technique is general and highly interactive. It will be particularly useful in data mining and data analysis.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-123.pdf,
127,1996,Knowledge Bases,KI: A Tool for Knowledge Integration,Kenneth S. Murray,Knowledge integration is the process of incorporating new information into a body of existing knowledge. It involves determining how new and existing knowledge interact and how existing knowledge should be modified to accommodate the new information. KI is a machine learning program that performs knowledge integration. Through actively investigating the interaction of new information with existing knowledge KI is capable of detecting and exploiting a variety of diverse learning opportunities during a single learning episode. Empirical evaluation suggests that KI provides significant assistance to knowledge engineers while integrating new information into a large knowledge base.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-124.pdf,
128,1996,Planning,Multi-Strategy Learning of Search Control for Partial-Order Planning,"Tara A. Estlin, Raymond J. Mooney","Most research in planning and learning has involved linear, state-based planners. This paper presents SCOPE, a system for learning search-control rules that improve the performance of a pczrtial-order planner. SCOPE integrates explanation-based and inductive learning techniques to acquire control rules for a partial-order planner. Learned rules are in the form of selection heuristics that help the planner choose between competing plan refinements. Specifically, SCOPE learns domain-specific control rules for a version of the UCPOP planning algorithm. The resulting system is shown to produce significant speedup in two different planning domains.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-125.pdf,
129,1996,Planning,Design and Implementation of a Replay Framework Based on a Partial Order Planner,"Laurie H. Ihrig, Subbarao Kambhampati","In this paper we describe the design and implementation of the derivation replay framework, DERSNLP+EBL (Derivational SNLP+EBL), which is based within a partial order planner. DERSNLP+EBL replays previous plan derivations by first repeating its earlier decisions in the context of the new problem situation, then extending the replayed path to obtain a complete solution for the new problem. When the replayed path cannot be extended into a new solution, explanation-based learning (EBL) techniques are employed to identify the features of the new problem which prevent this extension. These features are then added as censors on the retrieval of the stored case. To keep retrieval costs low, DERSNLP+EBL normally stores plan derivations for individual goals, and replays one or more of these derivations in solving multi-goal problems. Cases covering multiple goals are stored only when subplans for individual goals cannot be successfully merged. The aim in constructing the case library is to predict these goal interactions and to store a multi-goal case for each set of negatively interacting goals. We provide empirical results demonstrating the effectiveness of DERSNLP+EBL in improving planning performance on randomly-generated problems drawn from a complex domain.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-126.pdf,
130,1996,Planning,Is There Any Need for Domain-Dependent Control Information?: A Reply,Steven Minton,"In this paper, we consider the role that domain-dependent control knowledge plays in problem solving systems. Ginsberg and Geddis have claimed that domain-dependent control information has no place in declarative systems; instead, they say, such information should be derived from declarative facts about the domain plus domain-independent principles. We dispute their conclusion, arguing that it is impractical to generate control knowledge solely on the basis of logical derivations. We propose that simplifying abstractions are crucial for deriving control knowledge, and, as a result, empirical utility evaluation of the resulting rules will frequently be necessary to validate the utility of derived control knowledge. We ihustrate our arguments with examples from two implemented systems.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-127.pdf,
131,1996,Planning,Searching for Planning Operators with Context-Dependent and Probabilistic Effects,"Tim Oates, Paul R. Cohen","Providing a complete and accurate domain model for an agent situated in a complex environment can be an extremely difficult task. Actions may have different effects depending on the context in which they are taken, and actions may or may not induce their intended effects, with the probability of success again depending on context. We present an algorithm for automatically learning planning operators with context-dependent and probabilistic effects in environments where exogenous events change the state of the world. Empirical results show that the algorithm successfully finds operators that capture the true structure of an agent’s interactions with its environment, and avoids spurious associations between actions and exogenous events.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-128.pdf,
132,1996,Reinforcement Learning,Learning Robust Plans for Mobile Robots from a Single Trial,Sean P. Engelson,"We address the problem of learning robust plans for robot navigation by observing particular robot behaviors. In this paper we present a method which can learn a robust reactive plan from a single example of a desired behavior. The system operates by translating a sequence of events arising from the eflector system into a plan which represents the dependencies among such events. This method allows us to rely on the underlying stability properties of low-level behavior processes in order to produce robust plans. Since the resultant plan reproduces the original behavior of the robot at a high level, it generalizes over small environmental changes and is robust to sensor and eflector noise.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-129.pdf,
133,1996,Reinforcement Learning,An Average-Reward Reinforcement Learning Algorithm for Computing Bias-Optimal Policies,Sridhar Mahadevan,"Average-reward reinforcement learning (ARL) is an undiscounted optimality framework that is generally applicable to a broad range of control tasks. ARL computes gain-optimal control policies that maximize the expected payoff per step. However, gain-optimality has some intrinsic limitations as an optimality criterion, since for example, it cannot distinguish between different policies that all reach an absorbing goal state, but incur varying costs. A more selective criterion is bias optimality, which can filter gain-optimal policies to select those that reach absorbing goals with the minimum cost. While several ARL algorithms for computing gain-optimal policies have been proposed, none of these algorithms can guarantee bias optimality, since this requires solving at least two nested optimality equations. In this paper, we describe a novel model-based ARL algorithm for computing bias-optimal policies. We test the proposed algorithm using an admission control queuing system, and show that it is able to utilize the queue much more efficiently than a gain-optimal method by learning bias-optimal policies.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-130.pdf,
134,1996,Reinforcement Learning,Auto-Exploratory Average Reward Reinforcement Learning,"DoKyeong Ok, Prasad Tadepalli","We introduce a model-based average reward Reinforcement Learning method called H-learning and compare it with its discounted counterpart, Adaptive Real-Time Dynamic Programming, in a simulated robot scheduling task. We also introduce an extension to H-learning, which automatically explores the unexplored parts of the state space, while always choosing greedy actions with respect to the current value function. We show that this ""Auto-exploratory H-learning"" performs better than the original H-learning under previously studied exploration methods such as random, recency-based, or counter-based exploration.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-131.pdf,
135,1996,Video,Evolution-Based Discovery of Hierarchical Behaviors,"Justinian P. Rosca, Dana H. Ballard","Procedural representations of control policies have two advantages when facing the scale-up problem in learning tasks. First they are implicit, with potential for inductive generalization over a very large set of situations. Second they facilitate modularization. In this paper we compare several randomized algorithms for learning modular procedural representations. The main algorithm, called Adaptive Representation through Learning (ARL) is a genetic programming extension that relies on the discovery of subroutines. ARL is suitable for learning hierarchies of subroutines and for constructing policies to complex tasks. ARL was successfully tested on a typical reinforcement learning problem of controlling an agent in a dynamic and nondeterministic environment where the discovered subroutines correspond to agent behaviors.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-132.pdf,
136,1996,Mobile Robots,Estimating the Absolute Position of a Mobile Robot Using Position Probability Grids,"Wolfram Burgard, Dieter Fox, Daniel Hennig, Timo Schmidt","In order to re-use existing models of the environment mobile robots must be able to estimate their position and orientation in such models. Most of the existing methods for position estimation are based on special purpose sensors or aim at tracking the robot’s position relative to the known starting point. This paper describes the position probability grid approach to estimating the robot’s absolute position and orientation in a metric model of the environment. Our method is designed to work with standard sensors and is independent of any knowledge about the starting point. It is a Bayesian approach based on certainty grids. In each cell of such a grid we store the probability that this cell refers to the current position of the robot. These probabilities are obtained by integrating the likelihoods of sensor readings over time. Results described in this paper show that our technique is able to reliably estimate the position of a robot in complex environments. Our approach has proven to be robust with respect to inaccurate environmental models, noisy sensors, and ambiguous situations.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-133.pdf,
137,1996,Mobile Robots,Navigation for Everyday Life,"Daniel D. Fu, Kristian J. Hammond, Michael J. Swain","Past work in navigation has worked toward the goal of producing an accurate map of the environment. While no one can deny the usefulness of such a map, the ideal of producing a complete map becomes unrealistic when an agent is faced with performing real tasks. And yet an agent accomplishing recurring tasks should navigate more efficiently as time goes by. We present a system which integrates navigation, planning, and vision. In this view, navigation supports the needs of a larger system as opposed to being a task in its own right. Whereas previous approaches assume an unknown and unstructured environment, we assume a structured environment whose organization is known, but whose specifics are unknown. The system is endowed with a wide range of visual capabilities as well as search plans for informed exploration of a simulated store constructed from real visual data. We demonstrate the agent finding items while mapping the world. In repeatedly retrieving items, the agent’s performance improves as the learned map becomes more useful.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-134.pdf,
138,1996,Mobile Robots,Guaranteeing Safety in Spatially Situated Agents,"Robert C. Kohout, James A. Hendler, David J. Musliner","""Mission-critical"" systems, which include such diverse applications as nuclear power plant controllers, ""fly-by-wire"" airplanes, medical care and monitoring systems, and autonomous mobile vehicles, are characterized by the fact that system failure is potentially catastrophic. The high cost of failure justifies the expenditure of considerable effort at design-time in order to guarantee the correctness of system behavior. This paper examines the problem of guaranteeing safety in a well studied class of robot motion problems known as the ""asteroid avoidance problem."" We establish necessary and sufficient conditions for ensuring safety in the simple version of this problem which occurs most frequently in the literature, as well as sufficient conditions for a more general and realistic case. In doing so, we establish functional relationships between the number, size and speed of obstacles, the robot' s maximum speed and the conditions which must be maintained in order to ensure safety.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-135.pdf,
139,1996,Video,Recognizing and Interpreting Gestures on a Mobile Robot,"David Kortenkamp, Eric Huber, R. Peter Bonasso","Gesture recognition is an important skill for robots that work closely with humans. Gestures help to clarify spoken commands and are a compact means of relaying geometric information. We have developed a real-time, three-dimensional gesture recognition system that resides on-board a mobile robot. Using a coarse three-dimensional model of a human to guide stereo measurements of body parts, the system is capable of recognizing six distinct gestures made by an unadorned human in an unaltered environment. An active vision approach focuses the vision system’s attention on small, moving areas of space to allow for frame rate processing even when the person and/or the robot are moving. This paper describes the gesture recognition system, including the coarse model and the active vision approach. This paper also describes how the gesture recognition system is integrated with an intelligent control architecture to allow for complex gesture interpretation and complex robot action. Results from experiments with an actual mobile robot are given.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-136.pdf,
140,1996,Video,Classifying and Recovering from Sensing Failures in Autonomous Mobile Robots,"Robin R. Murphy, David Hershberger","This paper presents a characterization of sensing failures in autonomous mobile robots, a methodology for classification and recovery, and a demonstration of this approach on a mobile robot performing landmark navigation. A sensing failure is any event leading to defective perception, including sensor malfunctions, software errors, environmental changes, and errant expectations. The approach demonstrated in this paper exploits the ability of the robot to interact with its environment to acquire additional information for classification (i.e., active perception). A Generate and Test strategy is used to generate hypotheses to explain the symptom resulting from the sensing failure. The recovery scheme replaces the affected sensing processes with an alternative logical sensor. The approach is implemented as the Sensor Fusion Effects Exception Handling (SFX-EH) architecture. The advantages of SFX-EN are that it requires only a partial causal model of sensing failure, the control scheme strives for a fast response, tests are constructed so as to prevent confounding from collaborating sensors which have also failed, and the logical sensor organization allows SFX-EH to be interfaced with the behavioral level of existing robot architectures.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-137.pdf,
141,1996,Video,"GARGOYLE: An Environment for Real-Time, Context-Sensitive Active Vision","Peter N. Prokopowicz, Michael J. Swain, R. James Firby, Roger E. Kahn","Researchers in robot vision have access to several excellent image processing packages (e.g., Khoros, Vista, Susan, MIL, and XVision to name only a few) as a base for any new vision software needed in most navigation and recognition tasks. Our work in automonous robot control and human-robot interaction, however, has demanded a new level of run-time flexibility and performance: on-the-fly configuration of visual routines that exploit up-to-the-second context from the task, image, and environment. The result is Gargoyle: an extendible, on-board, real-time vision software package that allows a robot to configure, parameterize, and execute image-processing pipelines at run-time. Each operator in a pipeline works at a level of resolution and over regions of interest that are computed by upstream operators or set by the robot according to task constraints. Pipeline configurations and operator parameters can be stored as a library of visual methods appropriate for different sensing tasks and environmental conditions. Beyond this, a robot may reason about the current task and environmental constraints to construct novel visual routines that are too specialized to work under general conditions, but that are well-suited to the immediate environment and task. We use the RAP reactive plan-execution system to select and configure pre-compiled processing pipelines, and to modify them for specific constraints determined at run-time.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-138.pdf,
142,1996,Video,Robot Navigation Using Image Sequences,"Christopher Rasmussen, Gregory D. Hager","We describe a framework for robot navigation that exploits the continuity of image sequences. Tracked visual features both guide the robot and provide predictive information about subsequent features to track. Our hypothesis is that image-based techniques will allow accurate motion without a precise geometric model of the world, while using predictive information will add speed and robustness. A basic component of our framework is called a scene, which is the set of image features stable over some segment of motion. When the scene changes, it is appended to a stored sequence. As the robot moves, correspondences and dissimilarities between current, remembered, and expected scenes provide cues to join and split scene sequences, forming a map-like directed graph. Visual servoing on features in successive scenes is used to traverse a path between robot and goal map locations. In our framework, a human guide serves as a scene recognition oracle during a map-learning phase; thereafter, assuming a known starting position, the robot can independently determine its location without general scene recognition ability. A prototype implementation of this framework uses as features color patches, sum-of-squared differences (SSD) subimages, or image projections of rectangles.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-139.pdf,
143,1996,Video,Integrating Grid-Based and Topological Maps for Mobile Robot Navigation,"Sebastian Thrun, Arno Bücken","Research on mobile robot navigation has produced two major paradigms for mapping indoor environments: grid-based and topological. While grid-based methods produce accurate metric maps, their complexity often prohibits efficient planning and problem solving in large-scale indoor environments. Topological maps, on the other hand, can be used much more efficiently, yet accurate and consistent topological maps are considerably difficult to learn in large-scale environments. This paper describes an approach that integrates both paradigms: grid-based and topological. Grid-based maps are learned using artificial neural networks and Bayesian integration. Topological maps are generated on top of the grid-based maps, by partitioning the latter into coherent regions. By combining both paradigms-grid-based and topological-, the approach presented here gains the best of both worlds: accuracy/consistency and efficiency. The paper gives results for autonomously operating a mobile robot equipped with sonar sensors in populated multi-room environments.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-140.pdf,
144,1996,Model-Based Reasoning,Improving Model-Based Diagnosis through Algebraic Analysis: The Petri Net Challenge,Luigi Portinale,"The present paper describes the empirical evaluation of a linear algebra approach to model-based diagnosis, in case the behavioral model of the device under examination is described through a Petri net model. In particular, we show that algebraic analysis based on P-invariants of the net model, can significantly improve the performance of a model-based diagnostic system, while keeping the integrity of a general framework defined from a formal logical theory. A system called INVADS is described and experimental results, performed on a car fault domain and involving the comparison of different implementations of P-invariant based diagnosis, are then discussed.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-141.pdf,
145,1996,Model-Based Reasoning,A Model-Based Approach to Blame Assignment: Revising the Reasoning Steps of Problem Solvers,"Eleni Stroulia, Ashok K. Goel","Blame assignment is a classical problem in learning and adaptation. Given a problem solver that fails to deliver the behaviors desired of it, the blame-assignment task has the goal of identifying the cause(s) of the failure. Broadly categorized, these causes can be knowledge faults (errors in the organization, content, and representation of the problem-solver’s domain knowledge) or processing faults (errors in the content, and control of the problem-solving process). Much of AI research on blame assignment has focused on identifying knowledge and control-of-processing faults based on the trace of the failed problem-solving episode. In this paper, we describe a blame-assignment method for identifying content-of-processing faults, i.e., faults in the specification of the problem-solving operators. This method uses a structure-behavior-function (SBF) model of the problem-solving process, which captures the functional semantics of the overall task and the operators of the problem solver, the compositional semantics of its problem-solving methods that combine the operators’ inferences into the outputs of the overall task, and the ""causal"" inter-dependencies between its tasks, methods and domain knowledge. We illustrate this model-based blame-assignment method with examples from AUTOGNOSTIC.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-142.pdf,
146,1996,Model-Based Reasoning,Qualitative Multiple-Fault Diagnosis of Continuous Dynamic Systems Using Behavioral Modes,"Siddarth Subramanian, Raymond J. Mooney","Most model-based diagnosis systems, such as GDE and Sherlock, have concerned discrete, static systems such as logic circuits and use simple constraint propagation to detect inconsistencies. However, sophisticated systems such as QSIM and QPE h ave been developed for qualitative modeling and simulation of continuous dynamic systems. We present an integration of these two lines of research as implemented in a system called QDOCS for multiple-fault diagnosis of continuous dynamic systems using QSIM models. The main contributions of the algorithm include a method for propagating dependencies while solving a general constraint satisfaction problem and a method for verifying the consistency of a behavior with a model across time. Through systematic experiments on two realistic engineering systems, we demonstrate that QDOCS demonstrates a better balance of generality, accuracy, and efficiency than competing methods.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-143.pdf,
147,1996,Model-Based Reasoning,A Model-Based Approach to Reactive Self-Configuring Systems,"Brian C. Williams, P. Pandurang Nayak","This paper describes Livingstone, an implemented kernel for a model-based reactive self-configuring autonomous system. It presents a formal characterization of Livingstone’s representation formalism, and reports on our experience with the implementation in a variety of domains. Livingstone provides a reactive system that performs significant deduction in the sense/response loop by drawing on our past experience at building fast propositional conflict-based algorithms for model-based diagnosis, and by framing a model-based configuration manager as a propositional feedback controller that generates focused, optimal responses. Livingstone’s representation formalism achieves broad coverage of hybrid hardware/software systems by coupling the transition system models underlying concurrent reactive languages with the qualitative representations developed in model-based reasoning. Livingstone automates a wide variety of tasks using a single model and a single core algorithm, thus making significant progress towards achieving a central goal of model-based reasoning. Livingstone, together with the HSTS planning and scheduling engine and the RAPS executive, has been selected as part of the core autonomy architecture for NASA’s first New Millennium spacecraft.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-144.pdf,
148,1996,Qualitative Physics,Trajectory Constraints in Qualitative Simulation,"Giorgio Brajnik, Daniel J. Clancy","We present a method for specifying temporal constraints on trajectories of dynamical systems and enforcing them during qualitative simulation. This capability can be used to focus a simulation, simulate non-autonomous and piecewise-continuous systems, reason about boundary condition problems and incorporate observations into the simulation. The method has been implemented in TeQSIM, a qualitative simulator that combines the expressive power of qualitative differential equations with temporal logic. It interleaves temporal logic model checking with the simulation to constrain and refine the resulting predicted behaviors and to inject discontinuous changes into the simulation.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-145.pdf,
149,1996,Qualitative Physics,A Formal Hybrid Modeling Scheme for Handling Discontinuities in Physical System Models,"Pieter J. Mosterman, Gautam Biswas","Physical systems are by nature continuous, but often exhibit nonhnearities that make behavior generation complex and hard to analyze. Complexity is often reduced by linearizing model constraints and by abstracting the time scale for behavior generation. In either case, the physical components are modeled to operate in multiple modes, with abrupt changes between modes. This paper discusses a hybrid modeling methodology and analysis algorithms that combine continuous energy flow modeling and localized discrete signal flow modeling to generate complex, multi-mode behavior in a consistent and correct manner. Energy phase space analysis is employed to demonstrate the correctness of the algorithm, and the reachability of a continuous mode.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-146.pdf,
150,1996,Qualitative Physics,Building Steady-State Simulators via Hierarchical Feedback Decomposition,Nicolas F. Rouquette,"In recent years, compositional modeling and self-explanatory simulation techniques have simplified the process of building dynamic simulators of physical systems. Building steady-state simulators is, conceptually, a simpler task consisting in solving a set algebraic equations. This simplicity hides delicate technical issues of convergence and search-space size due to the potentially large number of unknown parameters. We present an automated technique for reducing the dimensionality of the problem by 1) automatically identifying feedback loops (a generally NP-complete problem), 2) hierarchically decomposing the set of equations in terms of feedback loops, and 3) structuring a simulator where equations are solved either serially without search or in isolation within a feedback loop. This paper describes the key algorithms and the results of their implementation on building simulators for a two-phase evaporator loop system across multiple combinations of causal and non-causal approximations.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-147.pdf,
151,1996,Qualitative Physics,Managing Occurrence Branching in Qualitative Simulation,Lance Tokuda,"Qualitative simulators can produce common sense abstractions of complex behaviors given only partial knowledge about a system. One of the problems which limits the applicability of qualitative simulators is the intractable branching of successor states encountered with model of even modest size. Some branches may be unavoidable due to the complex nature of a system. Other branches may be accidental results of the model chosen. A common source of intractability is occurrence branching. Occurrence branching occurs when the state transitions of two variables are unordered with respect to each other. This paper extends the QSIM model to distinguish between interesting occurrence branching and uninteresting occurrence branching. A representation, algorithm, and simulator for efficiently handling uninteresting branching is presented.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-148.pdf,
152,1996,Spatial & Functional Reasoning,Diagrammatic Reasoning and Cases,"Michael Anderson, Robert McCartney","We believe that many problem domains that lend themselves to a case-based reasoning solution can benefit from an diagrammatic implementation and propose a diagrammatic case-based solution to what we term the n-queens best solution problem where the best solution is defined as that which solves the probfem moving the fewest queens. A working system, based on a novel combination of diagrammatic and case-based reasoning, is described.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-149.pdf,
153,1996,Spatial & Functional Reasoning,Augmenting the Diagnostic Power of Flow-Based Approaches to Functional Reasoning,"Luca Chittaro, Roberto Ranon","In this paper, we consider flow-based approaches to functional diagnosis. First, we contrast the existing approaches, pointing out the major limitations of each. Then, we choose one of them and extend it in order to overcome the identified limitations. Finally, we show how the proposed extension can be introduced into the other flow-based approaches.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-150.pdf,
154,1996,Spatial & Functional Reasoning,A Qualitative Model of Physical Fields,Monika Lundell,"A qualitative model of the spatio-temporal behaviour of distributed parameter systems based on physical fields is presented. Field-based models differ from the object-based models normally used in qualitative physics by treating parameters as continuous entities instead of as attributes of discrete objects. This is especially suitable for natural physical systems, e.g. in ecology. The model is divided into a static and a dynamic part. The static model describes the distribution of each parameter as a qualitative physical field. Composite fields are constructed from intersection models of pairs of fields. The dynamic model describes processes acting on the fields, and qualitative relationships between parameters. Spatio-temporal behaviour is modelIed by interacting temporal processes, influencing single points in space, and spatial processes that gradually spread temporal processes over space. We give an example of a qualitative model of a natural physical system and discuss the ambiguities that arise during simulation.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-151.pdf,
155,1996,Spatial & Functional Reasoning,Generating Multiple New Designs from a Sketch,"Thomas F. Stahovich, Randall Davis, Howard Shrobe","We describe a program called SKETCHIT that transforms a single sketch of a mechanical device into multiple families of new designs. It represents each of these families with a ""BEP-Model,"" a parametric model augmented with constraints that ensure the device produces the desired behavior. The program is based on qualitative configuration space (qc-space), a novel representation that captures mechanical behavior while abstracting away its implementation. The program employs a paradigm of abstraction and resynthesis: it abstracts the initial sketch into qc-space then maps from qc-space to new implementations.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-152.pdf,
156,1996,Learning,Tree-Bank Grammars,Eugene Charniak,"By a ""tree-bank grammar"" we mean a context-free grammar created by reading the production rules directly from hand-parsed sentences in a tree bank. Common wisdom has it that such grammars do not perform well, though we know of no published data on the issue. The primary purpose of this paper is to show that the common wisdom is wrong. In particular, we present results on a tree-bank grammar based on the Penn WaII Street Journal tree bank. To the best of our knowledge, this grammar outperforms all other non-word-based statistical parsers/grammars on this corpus. That is, it outperforms parsers that consider the input as a string of tags and ignore the actual words of the corpus.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-153.pdf,
157,1996,Learning,Left-Corner Unification-Based Natural Language Processing,"Steven L. Lytinen, Noriko Tomuro","In this paper, we present an efficient algorithm for parsing natural language using unification grammars. The algorithm is an extension of left-corner parsing, a bottom-up algorithm which utilizes top-down expectations. The extension exploits unification grammar’s uniform representation of syntactic, semantic, and domain knowledge, by incorporating all types of grammatical knowledge into parser expectations. In particular, we extend the notion of the reachability table, which provides information as to whether or not a top-down expectation can be realized by a potential subconstituent, by including all types of grammatical information in table entries, rather than just phrase structure information. While our algorithm’s worstcase computational complexity is no better than that of many other algorithms, we present empirical testing in which average-case linear time performance is achieved. Our testing indicates this to be much improved average-case performance over previous leftcorner techniques.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-154.pdf,
158,1996,Learning,Left-Corner Unification-Based Natural Language Processing,Ellen Riloff,"Many corpus-based natural language processing systems rely on text corpora that have been manually annotated with syntactic or semantic tags. In particular, all previous dictionary construction systems for information extraction have used an annotated training corpus or some form of annotated input. We have developed a system called AutoSlog-TS that creates dictionaries of extraction patterns using only untagged text. AutoSlog-TS is based on the AutoSlog system, which generated extraction patterns using annotated text and a set of heuristic rules. By adapting AutoSlog and combining it with statistical techniques, we eliminated its dependency on tagged text. In experiments with the MUC-4 terrorism domain, AutoSlog-TS created a dictionary of extraction patterns that performed comparably to a dictionary created by AutoSlog, using only preclassified texts as input.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-155.pdf,
159,1996,Learning,Learning to Parse Database Queries Using Inductive Logic Programming,"John M. Zelle, Raymond J. Mooney","This paper presents recent work using the CHILL parser acquisition system to automate the construction of a natural-language interface for database queries. CHILL treats parser acquisition as the learning of search-control rules within a logic program representing a shift-reduce parser and uses techniques from Inductive Logic Programming to learn relational control knowledge. Starting with a general framework for constructing a suitable logical form, CHILL is able to train on a corpus comprising sentences paired with database queries and induce parsers that map subsequent sentences directly into executable queries. Experimental results with a complete database-query application for U.S. geography show that CHILL is able to learn parsers that outperform a pre-existing, hand-crafted counterpart. These results demonstrate the ability of a corpus-based system to produce more than purely syntactic representations. They also provide direct evidence of the utility of an empirical approach at the level of a complete natural language application.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-156.pdf,
160,1996,Semantics & Discourse,Hunter-Gatherer: Three Search Techniques Integrated for Natural Language Semantics,"Stephen Beale, Sergei Nirenburg, Kavi Mahesh","This work integrates three related AI search techniques - constraint satisfaction, branch-and-bound and solution synthesis - and applies the result to semantic processing in natural language (NL). We summarize the approach as ""Hunter-Gatherer:"" branch-and-bound and constraint satisfaction allow us to ""hunt down"" non-optimal and impossible solutions and prune them from the search space. Solution synthesis methods then ""gather"" all optimal solutions avoiding exponential complexity. Each of the three techniques is briefly described, as well as their extensions and combinations used in our system. We focus on the combination of solution synthesis and branch-and-bound methods which has enabled near-linear-time processing in our applications. Finally, we illustrate how the use of our technique in a large-scale MT project allowed a drastic reduction in search space.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-157.pdf,
161,1996,Semantics & Discourse,Semantic Interpretation of Nominalizations,"Richard D. Hull, Fernando Gomez","A computational approach to the semantic interpretation of nominalizations is described. Interpretation of nominalizations involves three tasks: deciding whether the nominalization is being used in a verbal or non-verbal sense; disambiguating the nominalized verb when a verbal sense is used; and determining the fillers of the thematic roles of the verbal concept or predicate of the nominalization. A verbal sense can be recognized by the presence of modifiers that represent the arguments of the verbal concept. It is these same modifiers which provide the semantic clues to disambiguate the nominalized verb. In the absence of explicit modifiers, heuristics are used to discriminate between verbal and non-verbal senses. A correspondence between verbs and their nominalizations is exploited so that only a small amount of additional knowledge is needed to handle the nominal form. These methods are tested in the domain of encyclopedic texts and the results are shown.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-158.pdf,
162,1996,Semantics & Discourse,Building Up Rhetorical Structure Trees,Daniel Marcu,"I use the distinction between the nuclei and the satellites that pertain to discourse relations to introduce a compositionality criterion for discourse trees. I provide a first-order formalization of rhetorical structure trees and, on its basis, I derive an algorithm that constructs all the valid rhetorical trees that can be associated with a given discourse.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-159.pdf,
163,1996,Semantics & Discourse,Using Plan Reasoning in the Generation of Plan Descriptions,R. Michael Young,Previous work on the generation of natural language descriptions of complex activities has indicated that the unwieldy amount of text needed to describe complete plans makes for ineffective and unnatural descriptions. We argue here that concise and effective text descriptions of plans can be generated by exploiting a model of the hearer’s plan reasoning capabilities. We define a computational model of the hearer’s interpretation process that views the interpretation of plan descriptions as refinement search through a space of partial plans. This model takes into account the hearer’s plan preferences and the resource limitations on her reasoning capabilities to determine the completed plans she will construct from a given partial description.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-160.pdf,
164,1996,Perception,Interfacing Sound Stream Segregation to Automatic Speech Recognition -- Preliminary Results on Listening to Several Sounds Simultaneously,"Hiroshi G. Okuno, Tomohiro Nakatani, Takeshi Kawabata","This paper reports the preliminary results of experiments on listening to several sounds at once. like issues are addressed: segregating speech streams from a mixture of sounds, and interfacing speech stream segregation with automatic speech recognition (AD). Speech stream segregation (SSS) is modeled as a process of extracting harmonic fragments, grouping these extracted harmonic fragments, and substituting some sounds for non-harmonic parts of groups. This system is implemented by extending the harmonic-based stream segregation system reported at AAAI-94 and IJCAI-95. The main problem in interfacing SSS with HMM-based ASR is how to improve the recognition performance which is degraded by spectral distortion of segregated sounds caused mainly by the binaural input, grouping, and residue substitution. Our solution is to re-train the parameters of the HMM with training data binauralized for four directions, to group harmonic fragments according to their directions, and to substitute the residue of harmonic fragments for non-harmonic parts of each group. Experiments with 500 mixtures of two women’s utterances of a word showed that the cumulative accuracy of word recognition up to the 10th candidate of each woman’s utterance is, on average, 75%.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-161.pdf,
165,1996,Perception,Motion and Color Analysis for Animat Perception,"Tamer F. Rabie, Demetri Terzopoulos","We propose novel gaze control algorithms for active perception in mobile autonomous agents with directable, foveated vision sensors. Our agents are realistic artificial animals, or animats, situated in physics-based virtual worlds. Their active perception systems continuously analyze photorealistic retinal image streams to glean information useful for controlling the animat eyes and body. The vision system computes optical flow and segments moving targets in the low-resolution visual periphery. It then matches segmented targets against mental models of colored objects of interest. The eyes saccade to increase acuity by foveating objects. The resulting sensorimotor control loop supports complex behaviors, such as predation.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-162.pdf,
166,1996,Perception,Noise and the Common Sense Informatic Situation for a Mobile Robot,Murray Shanahan,"Any model of the world a robot constructs on the basis of its sensor data is necessarily both incomplete, due to the robot’s limited window on the world, and uncertain, due to sensor and motor noise. This paper supplies a logical account of sensor data assimilation in which such models are constructed through an abductive process which hypothesises the existence, locations, and shapes of objects. Noise is treated as a kind of non-determinism, and is dealt with by a consistency-based form of abduction.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-163.pdf,
167,1996,Vision,A Hybrid Learning Approach for Better Recognition of Visual Objects,"Ibrahim F. Imam, Srinivas Gutta","Real world images often contain similar objects but with different rotations, noise, or other visual alterations. Vision systems should be able to recognize objects regardless of these visual alterations. This paper presents a novel approach for learning optimized structures of classifiers for recognizing visual objects regardless of certain types of visual alterations. The approach consists of two phases. The first phase is concerned with learning classifications of a set of standard and altered objects. The second phase is concerned with discovering an optimized structure of classifiers for recognizing objects from unseen images. This paper presents an application of this approach to a domain of 15 classes of hand gestures. The experimental results show significant improvement in the recognition rate rather than using a single classifier or multiple classifiers with thresholds.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-164.pdf,
168,1996,Vision,Using Elimination Methods to Compute Thermophysical Algebraic Invariants from Infrared Imagery,"J. D. Michel, N. Nandhakumar, Tushar Saxena, Deepak Kapur","We describe a new approach for computing invariant features in infrared (IR) images. Our approach is unique in the field since it considers not just surface reflection and surface geometry in the specification of invariant features, but it also takes into account internal object composition and thermal state which affect images sensed in the non-visible spectrum. We first establish a non-linear energy balance equation using the principle of conservation of energy at the surface of the imaged object. We then derive features that depend only on material parameters of the object and the sensed radiosity. These features are independent of the scene conditions and the scene-to-scene transformation of the ""driving conditions"" such as ambient temperature, and wind speed. The algorithm for deriving the invariant features is based on the algebraic elimination of the transformation parameters from the non-linear relationships. The elimination approach is a general method based on the extended Dixon resultant. Results on real IR imagery are shown to illustrate the performance of the features derived in this manner when used for an object recognition system that deals with multiple classes of objects.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-165.pdf,
169,1996,Video,Approximate World Models: Incorporating Qualitative and Linguistic Information into Vision Systems,"Claudio S. Pinhanez, Aaron F. Bobick","Approximate world models are coarse descriptions of the elements of a scene, and are intended to be used in the selection and control of vision routines in a vision system. In this paper we present a control architecture in which the approximate models represent the complex relationships among the objects in the world, allowing the vision routines to be situation or context specific. Moreover, because of their reduced accuracy requirements, approximate world models can employ qualitative information such as those provided by linguistic descriptions of the scene. The concept is demonstrated in the development of automatic cameras for a TV studio - SmartCams. Results are shown where SmartCams use vision processing of real imagery and information written in the script of a TV show to achieve TV-quality framing.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-166.pdf,
170,1996,Video,Integrating Visual Information across Camera Movements with a Visual-Motor Calibration Map,"Peter N. Prokopowicz, Paul R. Cooper","Facing the competing demands for wider field of view and higher spatial resolution, computer vision will evolve toward greater use of foveal sensors and frequent camera movements. Integration of visual information across movements becomes a fundamental problem. We show that integration is possible using a biologically-inspired representation we call the visual-motor calibration map. The map is a memory-based model of the relationship between camera movements and corresponding pixel locations before and after any movement. The map constitutes a self-calibration that can compensate for non-uniform sampling, lens distortion, mechanical misalignments, and arbitrary pixel reordering. Integration takes place entirely in a retinotopic frame, using a short-term, predictive visual memory.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-167.pdf,
171,1996,The Environment,A Bias towards Relevance: Recognizing Plans where Goal Minimization Fails,"Abigail S. Gertner, Bonnie L. Webber","Domains such as multiple trauma management, in which there are multiple interacting goals that change over time, are ones in which plan recognition’s standard inductive bias towards a single explanatory goal is inappropriate. In this paper we define and argue for an alternative bias based on identifying contextually ""relevant"" goals. We support this claim by showing how a complementary planning system in TraumAID 2.0, a decision-support system for the management of multiple trauma, allows us to define a four-level scale of relevance and therefore, of measurable deviations from relevance. This in turn allows definition of a bias towards relevance in the incremental recognition of physician plans by TraumAID’s critiquing interface, TraumaTIQ.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-168.pdf,
172,1996,The Environment,What Is Planning in the Presence of Sensing?,Hector J. Levesque,"Despite the existence of programs that are able to generate so-called conditional plans, there has yet to emerge a clear and general specification of what it is these programs are looking for: what exactly is a plan in this setting, and when is it correct? In this paper, we develop and motivate a specification within the situation calculus of conditional and iterative plans over domains that include binary sensing actions. The account is built on an existing theory of action which includes a solution to the frame problem, and an extension to it that handles sensing actions and the effect they have on the knowledge of a robot. Plans are taken to be programs in a new simple robot program language, and the planning task is to find a program that would be known by the robot at the outset to lead to a final situation where the goal is satisfied. This specification is used to analyze the correctness of a small example plan, as well as variants that have redundant or missing sensing actions. We also investigate whether the proposed robot program language is powerful enough to serve for any intuitively achievable goal.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-169.pdf,
173,1996,The Environment,Opportunity Recognition in Complex Environments,Louise Pryor,"An agent operating in an unpredictable world must be able to take advantage of opportunities but cannot afford to perform a detailed analysis of the effects of every nuance of the current situation on its goals if it is to respond in a timely manner. This paper describes a filtering mechanism that enables the effective recognition of opportunities. The mechanism is based on a characterization of the world in terms of reference features, features that are both cheap and functional and that appear to be prevalent in everyday life. Its use enables the plan execution system PARETO to recognize types of opportunities that other systems cannot. Reference features can also play a role in the detection of threats, and may be involved in the development of expertise.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-170.pdf,
174,1996,The Environment,Generalizing Indexical-Functional Reference,"Marcel Schoppers, Richard Shu","The goals of situated agents generally do not specify particular objects: they require only that some suitable object should be chosen and manipulated (e.g. any red block). Situated agents engaged in deictic reference grounding, however, may well track a chosen referent object with such fixity of purpose that an unchosen object may be regarded as an obstacle even though it satisfies the agent’s goals. In earlier work this problem was bridged by hand-coding. This paper lifts the problem to the symbol level, endowing agents with perceptual referent selection actions and performing those actions as required to allow or disallow opportunistic re-selection of referents. Our work preserves the ability of situated agents to find and track specific objects, adds an ability to automatically exploit the opportunities allowed by nonspecific references, and provides a starting point for studying how much opportunistic perception is appropriate.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-171.pdf,
175,1996,Handling Uncertainty,Rewarding Behaviors,"Fahiem Bacchus, Craig Boutilier, Adam Grove","Markov decision processes (MDPs) are a very popular tool for decision theoretic planning (DTP), partly because of the well-developed, expressive theory that includes effective solution techniques. But the Markov assumption - that dynamics and rewards depend on the current state only, and not on history - is often inappropriate. This is especially true of rewards: we frequently wish to associate rewards with behaviors that extend over time. Of course, such reward processes can be encoded in an MDP should we have a rich enough state space (where states encode enough history). However it is often difficult to ""hand craft"" suitable state spaces that encode an appropriate amount of history. We consider this problem in the case where non-Markovian rewards are encoded by assigning values to formulas of a temporal logic. These formulas characterize the value of temporally extended behaviors. We argue that this allows a natural representation of many commonly encountered non-Markovian rewards. The main result is an algorithm which, given a decision process with non-Markovian rewards expressed in this manner, automatically constructs an equivalent MDP (with Markovian reward structure), allowing optimal policy construction using standard techniques.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-172.pdf,
176,1996,Handling Uncertainty,Computing Optimal Policies for Partially Observable Decision Processes Using Compact Representations,"Craig Boutilier, David Poole","Partially-observable Markov decision processes provide a general model for decision theoretic planning problems, allowing trade-offs between various courses of actions to be determined under conditions of uncertainty, and incorporating partial observations made by an agent. Dynamic programming algorithms based on the belief state of an agent can be used to construct optimal policies without explicit consideration of past history, but at high computational cost. In this paper, we discuss how structured representations of system dynamics can be incorporated in classic POMDP solution algorithms. We use Bayesian networks with structured conditional probability matrices to represent POMDPs, and use this model to structure the belief space for POMDP algorithms, allowing irrelevant distinctions to be ignored. Apart from speeding up optimal policy construction, we suggest that such representations can be exploited in the development of useful approximation methods.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-173.pdf,
177,1996,Handling Uncertainty,A Qualitative Model for Temporal Reasoning with Incomplete Information,Hector Geffner,"We clevelop a qualitative framework for temporal reasoning with incomplete information that features a modeling language based on rules and a semantics based on infinitesimal probabilities. The framework relates logical and probabilistical models, and accommodates in a natural way features that, have been found problematic in other models like non-determinism, action qualifications, parallel actions, and abduction to actions and fluents.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-174.pdf,
178,1996,Handling Uncertainty,On the Size of Reactive Plans,"Peter Jonsson, Christer Bäckström","One of the most widespread approaches to reactive planning is Schoppers’ universal plans. We propose a stricter definition of universal plans which guarantees a weak notion of soundness not present in the original definition. Furthermore, we isolate three different types of completeness which capture different behaviours exhibited by universal plans. We show that universal plans which run in polynomial time and are of polynomial size cannot satisfy even the weakest type of completeness unless the polynomial hierarchy collapses. However, by relaxing either the polynomial time or the polynomial space requirement, the construction of universal plans satisfying the strongest type of completeness becomes trivial.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-175.pdf,
179,1996,Search,"Is ""Early Commitment"" in Plan Generation Ever a Good Idea?","David Joslin, Martha E. Pollack","Partial-Order Causal Link planners typically take a ""least-commitment"" approach to some decisions (notably, step ordering), postponing those decisions until constraints force them to be made. However, these planners rely to some degree on early commitments in making other types of decisions, including threat resolution and operator choice. We show why existing planners cannot support full least-commitment decision-making, and present an alternative approach that can. The approach has been implemented in the Descartes system, which we describe. We also provide experimental results that demonstrate that a least-commitment approach to planning can be profitably extended beyond what is done in POCL and similar planners, but that taking a least-commitment approach to every planning decision can be inefficient: early commitment in plan generation is sometimes a good idea.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-176.pdf,
180,1996,Search,"Pushing the Envelope: Planning, Propositional Logic, and Stochastic Search","Henry Kautz, Bart Selman","Planning is a notoriously hard combinatorial search problem. In many interesting domains, current planning algorithms fail to scale up gracefully. By combining a general, stochastic search algorithm and appropriate problem encodings based on propositional logic, we are able to solve hard planning problems many times faster than the best current planning systems. Although stochastic methods have been shown to be very effective on a wide range of scheduling problems, this is the first demonstration of its power on truly challenging classical planning instances. This work also provides a new perspective on representational issues in planning.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-177.pdf,
181,1996,Search,Finding Optimal Solutions to the Twenty-Four Puzzle,"Richard E. Korf, Larry A. Taylor","We have found the first optimal solutions to random instances of the Twenty-Four Puzzle, the 5 x 5 version of the well-known sliding-tile puzzles. Our new contribution to this problem is a more powerful admissible heuristic function. We present a general theory for the automatic discovery of such heuristics, which is based on considering multiple subgoals simultaneously. In addition, we apply a technique for pruning duplicate nodes in depth-first search using a finite-state machine. Finally, we observe that as heuristic search problems are scaled up, more powerful heuristic functions become both necessary and cost-effective.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-178.pdf,
182,1996,Search,Linear Time Near-Optimal Planning in the Blocks World,"John Slaney, Sylvie Thiébaux","This paper reports an analysis of near-optimal Blocks World planning. Various methods are clarified, and their time complexity is shown to be linear in the number of blocks, which improves their known complexity bounds. The speed of the implemented programs (ten thousand blocks are handled in a second) enables us to make empirical observations on large problems. These suggest that the above methods have very close average performance ratios, and yield a rough upper bound on those ratios well below the worst case of 2. Further, they lead to the conjecture that in the limit the simplest linear time algorithm could be just as good on average as the optimal one.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-179.pdf,
183,1996,Temporal Reasoning,Planning for Temporally Extended Goals,"Fahiem Bacchus, Froduald Kabanza","In planning, goals have traditionally been viewed as specifying a set of desirable final states. Any plan that transforms the current state to one of these desirable states is viewed to be correct. Goals of this form are limited as they do not allow us to constrain the manner in which the plan achieves its objectives. We propose viewing goals as specifiying desirable sequences of states, and a plan to be correct if its execution yields one of these desirable sequences. We present a logical language, a temporal logic, for specifying goals with this semantics. Our language is rich and allows the representation of a range of temporally extended goals, including classical goals, goals with temporal deadlines, quantified goals (with both universal and existential quantification), safety goals, and maintenance goals. Our formalism is simple and yet extends previous approaches in this area. We also present a planning algorithm that can generate correct plans for these goals. This algorithm has been implemented, and we provide some exam;les of the foralism at work. the end result is a planning system which can generate plans that satisfy a novel and useful set of conditions.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-180.pdf,
184,1996,Temporal Reasoning,A Cost-Directed Planner: Preliminary Report,"Eithan Ephrati, Martha E. Pollack, Marina Milshtein","We present a cost-directed heuristic planning algorithm, which uses an A* strategy for node selection. The heuristic evaluation function is computed by a deep lookahead that calculates the cost of complete plans for a set of pre-defined top-level subgoals, under the (generally false) assumption that they do not interact. This approach leads to finding low-cost plans, and in many circumstances it also leads to a significant decrease in total planning time. This is due in part to the fact that generating plans for subgoals individually is often much less costly than generating a complete plan taking interactions into account, and in part to the fact that the heuristic can effectively focus the search. We provide both analytic and experimental results.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-181.pdf,
185,1996,Temporal Reasoning,Monitoring the Progress of Anytime Problem-Solving,"Eric A. Hansen, Shlomo Zilberstein","Anytime algorithms offer a tradeoff between solution quality and computation time that has proved useful in applying artificial intelligence techniques to time-critical problems. To exploit this tradeoff, a system must be able to determine the best time to stop deliberation and act on the currently available solution. When the rate of improvement of solution quality is uncertain, monitoring the progress of the algorithm can improve the utility of the system. This paper introduces a technique for run-time monitoring of anytime algorithms that is sensitive to the variance of the algorithm’s performance, the time-dependent utility of a solution, the ability of the run-time monitor to estimate the quality of the currently available solution, and the cost of monitoring. The paper examines the conditions under which the technique is optimal and demonstrates its applicability.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-182.pdf,
186,1996,Temporal Reasoning,A Linear-Programming Approach to Temporal Reasoning,"Peter Jonsson, Christer Bäckström","We present a new formalism, Horn Disjunctive Linear Relations (Horn DLRs), for reasoning about temporal constraints. We prove that deciding satisfiability of sets of Horn DLRs is polynomial by exhibiting an algorithm based upon linear programming. Furthermore, we prove that most other approaches to tractable temporal constraint reasoning can be encoded as Horn DLRs, including the ORD-Horn algebra and most methods for purely quantitative reasoning.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-183.pdf,
187,1996,Rule-Based Reasoning & Connectionism,Production Systems Need Negation as Failure,"Phan Minh Dung, Paolo Mancarella","We study action rule based systems with two forms of negation, namely classical negation and ""negation as failure to find a course of actions"". We show by several examples that adding negation as failure to such systems increase their expressiveness, in the sense that real life problems can be represented in a natural and simple way. Then, we address the problem of providing a formal declarative semantics to these extended systems, by adopting an argumentation based approach, which has been shown to be a simple unifying framework for understanding the declarative semantics of various nonmonotonic formalisms. In this way, we naturally define the grounded (well-founded), stable and preferred semantics for production systems with negation as failure. Next, we characterize the class of stratified production systems, which enjoy the properties that the above mentioned semantics coincide and that negation as failure can be computed by a simple bottom-up operator.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-184.pdf,
188,1996,Rule-Based Reasoning & Connectionism,Using Constraints to Model Disjunctions in Rule-Based Reasoning,"Bing Liu, Joxan Jaffar","Rule-based systems have long been widely used for building expert systems to perform practical knowledge intensive tasks. One important issue that has not been addressed satisfactorily is the disjunction, and this significantly limits their problem solving power. In this paper, we show that some important types of disjunction can be modeled with Constraint Satisfaction Problem (CSP) techniques, employing their simple representation schemes and efticient algorithms. A key idea is that disjunctions are represented as constraint variables, relations among disjunctions are represented as constraints, and rule chaining is integrated with constraint solving. In this integration, a constraint variable or a constraint is regarded as a special fact, and rules can be written with constraints and information about constraints. Chaining of rules may trigger constraint propagation, and constraint propagation may cause firing of rules. A prototype system (called CFR) based on this idea has been implemented.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-185.pdf,
189,1996,Rule-Based Reasoning & Connectionism,A Connectionist Framework for Reasoning: Reasoning with Examples,Dan Roth,"We present a connectionist architecture that supports almost instantaneous deductive and abductive reasoning. The deduction algorithm responds in few steps for single rule queries and in general, takes time that is linear with the number of rules in the query. The abduction algorithm produces an explanation in few steps and the best explanation in time linear with the size of the assumption set. The size of the network is polynomially related to the size of other representations of the domain, and may even be smaller. We base our connectionist model on Valiant’s Neuroidal model (Va194) and thus make minimal assumptions about the computing elements, which are assumed to be classical threshold elements with states. Within this model we develop a reasoning framework that utilizes a model-based approach to reasoning (KKS93; KR94b). In particular, we suggest to interpret the connectionist architecture as encoding examples of the domain we reason about and show how to perform various reasoning tasks with this interpretation. We then show that the representations used can be acquired efficiently from interactions with the environment and discuss how this learning process influences the reasoning performance of the network.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-186.pdf,
190,1996,Bayesian Networks,Goal Oriented Symbolic Propagation in Bayesian Networks,"Enrique Castillo, José Manuel Gutiérrez, Ali S. Hadi","The paper presents an efficient goal oriented algorithm for symbolic propagation in Bayesian networks. The proposed algorithm performs symbolic propagation using numerical methods. It first takes advantage of the independence relationships among the variables and produce a reduced graph which contains only the relevant nodes and parameters required to compute the desired propagation. Then, the symbolic expression of the solution is obtained by performing numerical propagations associated with specific values of the symbolic parameters. These specific values are called the canonical components. Substantial savings are obtained with this new algorithm. Furthermore, the canonical components allow us to obtain lower and upper bounds for the symbolic expressions resulting from the propagation. An example is used to illustrate the proposed methodology.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-187.pdf,
191,1996,Bayesian Networks,A Clinician’s Tool for Analyzing Non-Compliance,"David Maxwell Chickering, Judea Pearl","We describe a computer program to assist a clinician with assessing the efficacy of treatments in experimental studies for which treatment assignment is random but subject compliance is imperfect. The major difficulty in such studies is that treatment efficacy is not ""identifiable"", that is, it cannot be estimated from the data, even when the number of subjects is infinite, unless additional knowledge is provided. Our system combines Bayesian learning with Gibbs sampling using two inputs: (1) the investigator' s prior probabilities of the relative sizes of subpopulations and (2) the observed data from the experiment. The system outputs a histogram depicting the posterior distribution of the average treatment effect, that is, the probability that the average outcome (e.g., survival) would attain a given level, had the treatment been taken uniformly by the entire population. This paper describes the theoretical basis for the proposed approach and presents experimental results on both simulated and real data, showing agreement with the theoretical asymptotic bounds.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-188.pdf,
192,1996,Bayesian Networks,Building Classifiers Using Bayesian Networks,"Nir Friedman, Moises Goldszmidt","Recent work in supervised learning has shown that a surprisingly simple Bayesian classifier with strong assumptions of independence among features, called naive Bayes, is competitive with state of the art classifiers such as C4.5. This fact raises the question of whether a classifier with less restrictive assumptions can perform even better. In this paper we examine and evaluate approaches for inducing classifiers from data, based on recent results in the theory of learning Bayesian networks. Bayesian networks are factored representations of probability distributions that generalize the naive Bayes classifier and explicitly represent statements about independence. Among these approaches we single out a method we call Tree AugmentedNaive Bayes (TAN), which outperforms naive Bayes, yet at the same time maintains the computational simplicity (no search involved) and robustness which are characteristic of naive Bayes. We experimentally tested these approaches using benchmark problems from the U. C. Irvine repository, and compared them against C4.5, naive Bayes, and wrapper-based feature selection methods.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-189.pdf,
193,1996,Bayesian Networks,Generalized Queries on Probabilistic Context-Free Grammars,"David V. Pynadath, Michael P. Wellman","Probabilistic context-free grammars (PCFGs) provide a simple way to represent a particular class of distributions over sentences in a context-free language. Efficient parsing algorithms for answering particular queries about a PCFG (i.e., calculating the probability of a given sentence, or finding the most likely parse) have been applied to a variety of pattern-recognition problems. We extend the class of queries that can be answered in several ways: (1) allowing missing tokens in a sentence or sentence fragment, (2) supporting queries about intermediate structure, such as the presence of particular nonterminals, and (3) flexible conditioning on a variety of types of evidence. Our method works by constructing a Bayesian network to represent the distribution of parse trees induced by a given PCFG. The network structure mirrors that of the chart in a standard parser, and is generated using a similar dynamic-programming approach. We present an algorithm for constructing Bayesian networks from PCFGs, and show how queries or patterns of queries on the network correspond to interesting queries on PCFGs.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-190.pdf,
194,1996,Foundations,On the Foundations of Qualitative Decision Theory,"Ronen I. Brafman, Moshe Tennenholtz","This paper investigates the foundation of maximin, one of the central qualitative decision criteria, using the approach taken by Savage (Savage 1972) to investigate the foundation and rationality of classical decision theory. This approach asks ""which behaviors could result from the use of a particular decision procedure?"" The answer to this question provides two important insights: (1) under what conditions can we employ a particular agent model, and (2) how rational is a particular decision procedure. Our main result is a constructive representation theorem in the spirit of Savage’s result for expected utility maximization, which uses two choice axioms to characterize the maximin criterion. These axioms characterize agent behaviors that can be modeled compactly using the maxcirnin model, and, with some reservations, indicate that maximin is a reasonable decision criterion.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-191.pdf,
195,1996,Foundations,Plausibility Measures and Default Reasoning,"Nir Friedman, Joseph Y. Halpern","In recent years, a number of different semantics for defaults have been proposed, such as preferential structures, E-semantics, possibilistic structures, and K-rankings, that have been shown to be characterized by the same set of axioms, known as the KLM properties (for Kraus, Lehmann, and Magidor). While this was viewed as a surprise, we show here that it is almost inevitable. We do this by giving yet another semantics for defaults that uses plausibility measures, a new approach to modeling uncertainty that generalize other approaches, such as probability measures, belief functions, and possibility measures. We show that all the earlier approaches to default reasoning can be embedded in the framework of plausibility. We then provide a necessary and sufficient condition on plausibilities for the KLM properties to be sound, and an additional condition necessary and sufficient for the KLM properties to be complete. These conditions are easily seen to hold for all the earlier approaches, thus explaining why they are characterized by the KLM properties.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-192.pdf,
196,1996,Foundations,First-Order Conditional Logic Revisited,"Nir Friedman, Joseph Y. Halpern, Daphne Koller","Conditional logics play an important role in recent attempts to investigate default reasoning. This paper investigates first-order conditional logic. We show that, as for first-order probabilistic logic, it is important not to confound statistical conditionals over the domain (such as ""most birds fly""), and subjective conditionals over possible worlds (such as ""I believe that Tweety is unlikely to fly""). We then address the issue of ascribing semantics to first-order conditional logic. As in the propositional case, there are many possible semantics. To study the problem in a coherent way, we use plausibility structures. These provide us with a general framework in which many of the standard approaches can be embedded. We show that while these standard approaches are all the same at the propositional level, they are significantly different in the context of a first-order language. We show that plausibilities provide the most natural extension of conditional logic to the first-order case: We provide a sound and complete axiomatization that contains only the KLM properties and standard axioms of first-order modal logic. We show that most of the other approaches have additional properties, which result in an inappropriate treatment of an infinitary version of the lottery paradox.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-193.pdf,
197,1996,Foundations,A Counterexample to Theorems of Cox and Fine,Joseph Y. Halpern,Cox’s well-known theorem justifying the use of probability is shown not to hold in finite domains. The counterexample also suggests that Cox’s assumptions are insufficient to prove the result even in infinite domains. The same counterexample is used to disprove a result of Fine on comparative conditional probability.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-194.pdf,
198,1996,AAAI-96 Invited Presentations,Robots with AI: A Retrospective on the AAAI Robot Competitions and Exhibitions,"Pete Bonasso, Tom Dean","There have been five years of robot competitions and exhibitions since the inception of this annual event in 1992. Since that first show we have seen 30 different teams compete and almost that many more exhibit their robots. These teams ranged from universities to industry and government research labs to one or two inventors working out of garages. Their composition ranged from seasoned AI researchers to eager undergraduates, and they hailed from the United States, Canada, Europe and the Far East. Despite the concerns of some about the relevance and even the appropriateness of such an event, the robots have become a key attraction of the national and international conferences. In this talk, we look back on the form and function of the five years of exhibitions and competitions and attempt to draw some lessons in retrospect as well as future implications for the AI community and our society at large.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-195.pdf,
199,1996,AAAI-96 Invited Presentations,Moving Up the Information Food Chain: Deploying Softbots on the World Wide Web,Oren Etzioni,"I view the World Wide Web as an information food chain (figure 1). The maze of pages and hyperlinks that comprise the Web are at the very bottom of the chain. The WebCrawlers and Alta Vistas of the world are information herbivores; they graze on Web pages and regurgitate them as searchable indices. Today, most Web users feed near the bottom of the information food chain, but the time is ripe to move up. Since 1991, we have been building information carnivores, which intelligently hunt and feast on herbivores in Unix, on the Internet and on the Web.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-196.pdf,
200,1996,AAAI-96 Invited Presentations,Brain Dynamics in the Genesis of Trust as the Basis for Communication by Representations,Walter J. Freeman,"A theory of brain dynamics is proposed according to which brains construct external representations by actions into the world for communication. The prior brain patterns constitute meanings, not representations of meanings. The representations have no meaning in themselves. They are shaped in accordance with meaning inside transmitting brains, and they can elicit the construction of meaning inside receiving brains, provided that trust has been established between the transmitters and the receivers through appropriate neurochemical changes.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-197.pdf,
201,1996,AAAI-96 Invited Presentations,Using Multi-Agent Systems to Represent Uncertainty,Joseph Y. Halpern,"I consider a logical framework for modeling uncertainty, based on the use of possible worlds, that incorporates knowledge, probability, and time. This turns out to be a powerful approach for modeling many problems of interest. I show how it can be used to give insights into (among other things) several well-known puzzles.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-198.pdf,
202,1996,AAAI-96 Invited Presentations,Refinement Planning: Status and Prospectus,Subbarao Kambhampati,"Most current-day AI planning systems operate by iteratively refining a partial plan until it meets the goal requirements. In the past five years, significant progress has been made in our understanding of the spectrum and capabilities of such refinement planners. In this talk, I will summarize this understanding in terms of a unified framework for refinement planning and discuss several current research directions.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-199.pdf,
203,1996,AAAI-96 Invited Presentations,Boosting Theory Towards Practice: Recent Developments in Decision Tree Induction and the Weak Learning Framework,Michael Kearns,"One of the original goals of computational learning theory was that of formulating models that permit meaningful comparisons between the different machine learning heuristics that are used in practice [Kearns et aI., 19871. Despite the other successes of computational learning theory, this goal has proven elusive. Empirically successful machine learning algorithms such as 64.5 and the backpropagation algorithm for neural networks have not met the criteria of the well-known Probably Approximately Correct (PAC) model [Valiant, 19841 and its variants, and thus such models are of little use in drawing distinctions among the heuristics used in applications. Conversely, the algorithms suggested by computational learning theory are usually too limited in various ways to find wide application.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-200.pdf,
204,1996,AAAI-96 Invited Presentations,Challenge Problems for Artificial Intelligence,"Bart Selman, Rodney A. Brooks, Thomas Dean, Eric Horvitz, Tom M. Mitchell, Nils J. Nilsson","AI textbooks and papers often discuss the big questions, such as ""how to reason with uncertainty"", ""how to reason efficiently"", or ""how to improve performance through learning ."" It is more difficult, however, to find descriptions of concrete problems or challenges that are still ambitious and interesting, yet not so open-ended. The goal of this panel is to formulate a set of such challenge problems for the field. Each panelist was asked to formulate one or more challenges. The emphasis is on problems for which there is a good chance that they will be resolved within the next five to ten years.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-201.pdf,
205,1996,AAAI-96 Invited Presentations,The Database Approach to Knowledge Representation,Jeffrey D. Ullman,"The database theory community, centered around the PODS (Principles of Database Systems) conference has had a long-term interest in logic as a way to represent ""data, "" ""information,"" and ""knowledge"" (take your pick on the term - it boils down to facts or atoms and rules, usually Horn clauses). The approach of this community has been ""slow and steady,"" preferring to build up carefully from simple special cases to more general ideas, always paying attention to how efficiently we can process queries and perform other operations on the facts and rules. A powerful theory has developed, and it is beginning to have some impact on applications, especially information-integration engines.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-202.pdf,
206,1996,AAAI-96 Robot Competition & Exhibition Abstracts,A Reactive Mobile Robot Based on a Formal Theory of Action,"C. Baral, L. Floriano, A. Gabaldon, D. Morales, T. Son, R. Watson","One of the agenda behind research in reasoning about actions is to develop autonomous agents (robots) that can act in a dynamic world. The early attempts to use theories of reasoning about actions and planning to formulate a robot control architecture were not successful for several reasons: The early theories based on STRIPS and its extensions allowed only observations about the initial state. A robot control architecture using these theories was usually of the form: (i) make observations (ii) Use the action theory to construct a plan to achieve the goal, and (iii) execute the plan. For such an architecture to work the world must be static so that it does not change during the execution of the plans. This assumption is not valid for a dynamic world where other agents may change the world and/or the robot may not have all the information about the environment when it makes the plan. Moreover, planning is a time consuming activity and it is not usually wise for the robot to spend a lot of time creating a plan, especially when it is supposed to interact with the environment in real time. This led to the development of several robot control architectures that were reactive in nature and usually were based on the paradigm of situated activity which emphasized ongoing physical interaction with the environment as the main aspect in designing autonomous agents. These approaches were quite successful, especially in the domain of mobile robots. But most of them distanced themselves from the traditional approach based on theories of actions.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-203.pdf,
207,1996,AAAI-96 Robot Competition & Exhibition Abstracts,CoMRoS: Cooperative Mobile Robots Stuttgart,"Thomas Bräunl, Martin Kalbacher, Paul Levi, Günter Mamier","Project CoMRoS has the goal to develop intelligent cooperating mobile robots. Several different vehicles are to solve a single task autonomously by exchanging plans without a central control (Levi, Braunl, Muscholl, Rausch. 1994). We use ""II"" vehicles from Robosoft France, adapted to our needs. The standard vehicle has very little local intelligence (VME bus system) and is controlled remotely by wireless Ethernet for sending steering commands and receiving sonar sensor data. A wireless video link is used to transmit camera images. Data exchange between vehicles is then performed among the corresponding workstations. The remote control is basically used to simplify testing and debugging of robot programs. However, each vehicle can also be driven completely autonomous by using a laptop PC. (Bayer, Braunl, Rausch, Sommerau, Levi 1995).",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-204.pdf,
208,1996,AAAI-96 Robot Competition & Exhibition Abstracts,McMaster University’s Artificial Computing System,"Andrew Dawes, Mark Bentley","This will be McMaster University’s first entry into the AAAI Mobile Robotics competition. As such, this year will serve as a testing ground for future developments. It is the goal of the designers to experiment with new techniques and approaches based on their engineering background.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-205.pdf,
209,1996,AAAI-96 Robot Competition & Exhibition Abstracts,Doing Tasks with Multiple Mini-Robots,"John Fischer, Paul Rybski, Dirk Edmonds, Maria Gini",We are interested in building robots that are simple and have limited computing power yet are capable of surviving in an unstructured environment while achieving their assigned task. We have shown that even with limited computing small robots can learn how to achieve their task (Hougen et al. 1996)) provided that the task is not extremely difficult and the learning algorithm is capable of fast learning.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-206.pdf,
210,1996,AAAI-96 Robot Competition & Exhibition Abstracts,"Lola, the Mobile Robot from North Carolina State University","Ricardo Gutierrez-Osuna, Daniel S. Schudel, Jason A. Janet, Ren C. Luo","The North Carolina State University team intends to participate in the 1996 Mobile Robot Competition and Exhibition with Lola, a Nomad 200. This year marks our third entry in this competition. Lola is a Nomad 200 with a standard 16-transducer sonar ring and tactile bumper sensors. We have taken advantage of the Nomad’s modularity and moved 3 of the rear sonars to the front just above the bumper. This provides Lola with the ability t,o sense chairs and other potential obstacles that might otherwise be unseen.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-207.pdf,
211,1996,AAAI-96 Robot Competition & Exhibition Abstracts,Clementine: Colorado School of Mines,Robin R. Murphy,"The Colorado School of Mines (CSM) is fielding a team comprised of undergraduates in Computer Science or Engineering who are enrolled in the Robotics and AI Minor. The intent is to provide a forum for the students to a) transfer what they have learned in the classroom to a more realistic setting, b) meet with top researchers in the field, c) have an undergraduate research experience, and d) have fun. The students work with the team advisor and graduate students at CSM to integrate and modify code developed for NSF, ARPA, and NASA funded research projects. This will be the fourth year CSM has participated in the competition. The team’s platform is Oementine, a Denning-Branch MRV-4 research robot. She has a ring of 24 ultrasonics, a laser navigation system, and supports two cameras. All processing is done onboard by a 75MHz Pentium processor. A SoundBlaster board and speakers provides feedback on the robot’s activities. Clementine is used for research in indoor task domains such as the surveillance and maintenance of stockpiles of hazardous materials, site assessment of dangerous environments such as a burning building or a collapsed mine, or security. A custom robot, C2, is used for outdoor environments.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-208.pdf,
212,1996,AAAI-96 Robot Competition & Exhibition Abstracts,Mobile Robot Navigation and Control: A Case Study,"Nicholas Roy, Gregory Dudek, Michael Daum","Robotic systems (and in particular mobile autonomous agents) embody a complex interaction of computational processes, mechanical systems, sensors, and communications hardware. System integration can present significant difficulties to the construction of a real system, because the hardware is often built around convenience of design rather than convenience of system integration. Nonetheless, in order for robots to perform real-world tasks such as navigation, localization and exploration, the different subsystems of motion, sensing and computation must be merged into a single, realisable unit. Our group is investigating particular problems in the domain of computational perception, in the context of mobile robotics. In particular, we are concerned with environment exploration, position estimation, and map construction. We have several mobile platforms integrating different sensing modalities, which we are able to control simultaneously from a single source.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-209.pdf,
213,1996,AAAI-96 Robot Competition & Exhibition Abstracts,YODA: The Young Observant Discovery Agent,"Wei-Min Shen, Jafar Adibi, Bonghan Cho, Gal Kaminka, Jihie Kim, Behnam Salemi, Sheila Tejada","The YODA project at USC/ISI consists of a group of young researchers who share a passion for autonomous systems that can bootstrap their knowledge of real environments by exploration, experimentation, learning, and discovery. Our goal is to create a mobile agent that can autonomously learn from its environment based on its own actions, percepts, and missions.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-210.pdf,
214,1996,AAAI-96 Robot Competition & Exhibition Abstracts,Amelia,"Reid Simmons, Sebastian Thrun, Greg Armstrong, Richard Goodwin, Karen Haigh, Sven Koenig, Shyjan Mahamud, Daniel Nokovski, Joseph O'Sullivan","Amelia was built by Real World Interface (RWI) using Xavier-a mobile robot platform developed at CMU on a B24 base from RWI-as a prototype. Amelia has substantial engineering improvements over Xavier. Amelia is built on a B21 base. It has a top speed of 32 inches per second, while improved integral dead-reckoning insures extremely accurate drive and position controls.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-211.pdf,
215,1996,SIGART/AAAI Doctoral Consortium Abstracts,Selection of Passages for Information Reduction,Jody J. Daniels,"There currently exists a bottleneck in extracting information from pre-existing texts to generate a symbolic representation of the text that can be used by a case-based reasoning (CBR) system. Symbolic case representations are used in legal and medical domains among others. Finding similar cases in the legal domain is crucial because of the importance precedents play when arguing a case. Further, by examining the features and decisions of previous cases, an advocate or judge can decide how to handle a current problem. In the medical domain, remembering or finding cases similar to the current patient’s may be key to making a correct diagnosis: they may provide insight as to how an illness should be treated or which treatments may prove to be the most effective.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-212.pdf,
216,1996,SIGART/AAAI Doctoral Consortium Abstracts,Towards a Unified Approach to Concept Learning,Pedro Domingos,"Rule induction (either directly or by means of decision trees) and case-based learning (forms of which are also known as instance-based, memory-based and nearest-neighbor learning) arguably constitute the two leading symbolic approaches to concept and classification learning. Rule-based methods discard the individual training examples, and remember only abstractions formed from them. At performance time, rules are applied by logical match (i.e., only rules whose preconditions are satisfied by an example are applied to it). Case-based methods explicitly memorize some or all of the examples; they avoid forming abstractions, and instead invest more effort at performance time in finding the most similar cases to the target one.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-213.pdf,
217,1996,SIGART/AAAI Doctoral Consortium Abstracts,A Computational Theory of Turn-Taking,Toby Donaldson,"My research is concerned with the problem of turn-taking in discourse, especially as applied to intelligent interfaces, such as advice-giving systems or software help systems. A limitation of many discourse systems is their need for explicit turn-ending signals (e.g. pressing a return key). In such systems, mid-turn interruptions are impossible, although there are practical examples of where mid-turn interruptions are highly desirable. For example, an interface agent should promptly inform the user of important pieces of information, such as a lack of disk space or the loss of network connection, especially if the user is enaged in some activity that relies on that information.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-214.pdf,
218,1996,SIGART/AAAI Doctoral Consortium Abstracts,Learning in Multi-Agent Systems,Claudia V. Goldman,"Learning agents acting in a multi agent environment can improve their performance. These agents might decide upon their course of action by learning about other agents with whom they interact. The learning agents can learn about the others’ information and rules of behavior. The agents will not need to plan their actions beforehand, each time they are asked to solve the same problem they have already solved or when dealing with similar problems.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-215.pdf,
219,1996,SIGART/AAAI Doctoral Consortium Abstracts,Bounding the Cost of Learned Rules: A Transformational Approach,Jihie Kim,"My dissertation research centers on application of machine learning techniques to speed up problem solving. In fact, many speed-up learning systems suffer from the utility problem; time after learning is greater than time before learning. Discovering how to assure that learned knowledge will in fact speed up system performance has been a focus of research in explanation-based learning (EBL). One way of finding a solution which can guarantee that cost after learning is bounded by cost of problem solving is to analyze all the sources of cost increase in the learning process and then eliminate these sources. I began on this task by decomposing the learning process into a sequence of transformations that go from a problem solving episode, through a sequence of intermediate problem solving/rule hybrids, to a learned rule. This transformational analysis itself is important to understand the characteristics of the learning system, including cost changes through learning.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-216.pdf,
220,1996,SIGART/AAAI Doctoral Consortium Abstracts,Agent-Centered Search: Situated Search with Small Look-Ahead,Sven Koenig,"Situated search is the process of achieving a goal in the world. Traditional single-agent search algorithms (such as the A* algorithm) usually assume completely known, stationary domains with deterministic actions. These assumptions favor search approaches that first determine open-loop plans (sequences of actions) that can then be executed blindly in the world. Consequently, single-agent search in AI is often performed in a mental model of the world (state space): states are represented as memory images and search is a process inside the computer (search-in-memory).",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-217.pdf,
221,1996,SIGART/AAAI Doctoral Consortium Abstracts,Recurrent Expert Networks,Cathie LeBlanc,"Research has shown that computational techniques such as neural networks often provide classification abilities that are more accurate than methods which rely on explicit knowledge acquisition alone. On the other hand, because no ""reason"" for a particular classification can be given when a computational technique has been used, human experts tend to be skeptical of such systems. As a result, many researchers have developed tools, called hybrid systems, which combine the pattern recognition capabilities and parallel processing of neural systems while retaining the domain knowledge encoded in expert systems (Medsker 1994).",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-218.pdf,
222,1996,SIGART/AAAI Doctoral Consortium Abstracts,Semi-Deterministic Reasoning,Chengjiang Mao,"In typical AI systems, we employ so-called non-deterministic reasoning (NDR), which resorts to some systematic search with backtracking in the search spaces defined by knowledge bases (KBs) . An eminent property of NDR is that it facilitates programming, especially programming for those difficult AI problems such as natural language processing for which it is difficult to find algorithms to tell computers what to do at every step. However, poor efficiency of NDR is still an open problem. Our work aims at overcoming this efficiency problem.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-219.pdf,
223,1996,SIGART/AAAI Doctoral Consortium Abstracts,A Connectionist Model of Instructed Learning,David C. Noelle,The focus of this research is on how people blend knowledge gained through explicit instruction with knowledge gained through experience. The product of this work will be a cognitively plausible computational learning model which integrates instructed learning with inductive generalization from examples. The success of this model will require the attainment of both a technical and a scientific goal.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-220.pdf,
224,1996,SIGART/AAAI Doctoral Consortium Abstracts,Symptom Management for Schizophrenic Agents,Phoebe Sengers,"Behavior-based paradigms are a promising avenue towards creating full-blown integrated autonomous agents. However, until now they have had a major stumbling block: programmers can create robust, subtle, and expressive behaviors, but the agent’s overall behavior gradually falls apart as these behaviors are combined. For small numbers of behaviors, this disintegration can be managed by the programmer, but as more behaviors are combined their interactions become so complex that they become at least time-consuming and at worst impossible to manage.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-221.pdf,
225,1996,SIGART/AAAI Doctoral Consortium Abstracts,Adaptive Shared Control for an Intelligent Power Wheelchair,"Richard C. Simpson, Simon P. Levine","The NavChair Assistive Navigation System is being developed to increase the mobility of severely handicapped individuals by providing navigation assistance for a power wheelchair. While designing the NavChair it became clear that obtaining the full range of desired functionality required several different ""operating modes,"" each of which was appropriate in different contexts. This also necessarily created a need for a method of choosing between these modes. One solution is for the user to manage the task of mode determination, which may place unacceptable performance burdens on NavChair users with severe disabilities. Instead, a means for the NavChair to automatically choose the proper operating mode is being sought.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-222.pdf,
226,1996,SIGART/AAAI Doctoral Consortium Abstracts,Induction of Selective Bayesian Networks from Data,Moninder Singh,"Bayesian networks (Pearl 1988), which provide a compact graphical way to express complex probabilistic relationships among several random variables, are rapidly becoming the tool of choice for dealing with uncertainty in knowledge based systems. Amongst the many advantages offered by Bayesian networks over other representations such as decision trees and neural networks are the ease of comprehensibility to humans, effectiveness as complex decision making models and elicitability of informative prior distributions.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-223.pdf,
227,1996,SIGART/AAAI Doctoral Consortium Abstracts,Why Dissect a Frog When You Can Simulate a Lion?,Brian K. Smith,"We are concerned with creating computer-based learning environments which provide students with opportunities to develop causal explanations of complex phenomena through experimentation and observation. We combine video and simulation to facilitate such exploration in high school biology classrooms. Specifically, we focus on issues in behavioral ecology and the predation behaviors of the Serengeti lion.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-224.pdf,
228,1996,SIGART/AAAI Doctoral Consortium Abstracts,Algorithm Evolution for Signal Understanding,Astro Teller,"Automated program evolution has existed in some form for over thirty years. Signal understanding (e.g., signal classification) has been a scientific concern for even longer than that. Interest in generating, through machine learning techniques, a general signal understanding system is a newer topic, but has recently attracted considerable attention. First, I have proposed to define and create a machine learning mechanism for generating signal understanding systems independent of the signal' s type and size. Second, I have proposed to do this through an evolutionary strategy that is an extension of genetic programming. Third, I have proposed to introduce a suite of sub-mechanisms that not only contribute to the power of the thesis mechanism, but are also contributions to the understanding of the learning technique developed.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-225.pdf,
229,1996,SIGART/AAAI Doctoral Consortium Abstracts,The Use of Knowledge-Based Systems Techniques for Risk Assessment,Botond Virginas,"Several accidents during the last decade have emphasized the need to properly analyse and manage the low probability high consequence risks associated with plant operations in the nuclear, chemical and other industries. Formal risk assessment methods are vital tools for this task, and include a number of qualitative and quantitative techniques.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-226.pdf,
230,1996,AAAI-96 Student Abstracts,Efficient Planning by Graph Rewriting,"José Luis Ambite, Craig A. Knoblock","Planning involves the generation of a network of actions that achieves a desired goal given an initial state of the world. There has been significant progress in the analysis of planning algorithms, particularly in partial-order and in hierarchical task network (HTN) planning (Kambhampati 95; Erol et al. 94). In this abstract we propose a more general framework in which planning is seen as a graph rewriting process. This approach subsumes previous work and offers new opportunities for efficient planning.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-227.pdf,
231,1996,AAAI-96 Student Abstracts,Expecting the Unexpected: Detecting and Reacting to Unplanned-for World States,"Ella M. Atkins, Edmund H. Durfee, Kang G. Shin",Developing autonomous systems is challenging because complete and correct models do not exist for complex domains such as aircraft flight. Realistic systems bound the state set expanded during planning and compensate for unexpected situations with reactive mechanisms. This abstract describes a method by which a system can determine if it is unprepared for the current world state and a means to successfully respond to such an unhandled state.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-228.pdf,
232,1996,AAAI-96 Student Abstracts,Experiments in Evolutionary Synthesis of Robotic Neurocontrollers,"Karthik Balakrishnan, Vasant Honavar","Artificial neural networks offer an attractive paradigm for the design of behavior and control systems in robots and autonomous agents for a variety of reasons, including: ability to adapt and learn, potential for resistance to noise, faults and component failures, potential for real-time performance in dynamic environments (through massive parallelism and suitable hardware realization) etc.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-229.pdf,
233,1996,AAAI-96 Student Abstracts,A Reinforcement Learning Framework for Combinatorial Optimization,Justin A. Boyan,"The combination of reinforcement learning methods with neural networks has found success on a growing number of large-scale applications, including backgammon move selection, elevator control, and job-shop scheduling. In this work, we modify and generalize the scheduling paradigm used by Zhang and Dietterich to produce a general reinforcement-learning-based framework for combinatorial optimization.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-230.pdf,
234,1996,AAAI-96 Student Abstracts,Learning Topological Maps: An Alternative Approach,"Arno Bücken, Sebastian Thrun","Our goal is autonomous real-time control of a mobile robot. In this paper we want to show a possibility to learn topological maps of a large-scale indoor environment autonomously. In the literature there are two paradigms how to store information on the environment of a robot: as a grid-based (geometric) or as a topological map. While grid-based maps are considerably easy to learn and maintain, topological maps are quite compact and facilitate fast motion-planning.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-231.pdf,
235,1996,AAAI-96 Student Abstracts,Computing Default Logic Extensions: An Implementation,"A. P. Courtney, N. Y. Foo, G. Antoniou","Default logic is a useful formalism for reasoning with incomplete information, its intuitive characteristics making it particularly suited for applications. Exten is a system currently capable of computing first-order Reiter, Justified and Constrained default extensions. It is part of a project to create a full default logic workbench, with future work involving query evaluation, further support for default variants and integration with belief revision. As such, it has been implemented in an object-oriented manner, and is designed to facilitate experimentation. The interface is based around a small language, giving the user flexibility in editing default theories and changing various parameters (such as compute next n extensions or carry out success checks every m steps).",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-232.pdf,
236,1996,AAAI-96 Student Abstracts,Characterizing Temporal Repetition,"Diana Cukierman, James Delgrande","We are investigating the representation and reasoning about schedulable, repeated activities, specified using calendars. Examples of such activities include meeting every Tuesday and Thursday during a semester and at tending a seminar every first day of a month. This research provides for a valuable framework for scheduling systems, financial systems and, in general, date-based systems. Very recently work has been done related to reasoning about repetition in the Artificial Intelligence community and others. A partial reference list is provided here. However, to our knowledge no extensive taxonomy of repetition has been proposed in the literature. We believe that reasoning about repeated activities calls for a study and precise definition of the topological characteristics in a repetitive series. In this abstract we summarize a proposal to classify types of repetition according to parameters. The combination of all possible values of these parameters provides a complete taxonomy of repetitive classes with respect to the proposed parameters. Several notions of repetition are considered, some are extremely general, some are very specific.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-233.pdf,
237,1996,AAAI-96 Student Abstracts,Achieving Agent Coordination via Distributed Preferences,"Joseph G. D'Ambrosio, William P. Birmingham","Agent-based systems provide hope for solving a wide variety of distributed problems. One key aspect of agent-based system is coordinating agent actions to achieve coherent behavior. For example, in concurrent engineering (CE), it is necessary to ensure that the individual decision made by constituents in a design organization achieve overall organizational objectives (e.g., increase market share), while still allowing individuals to exploit their expertise. We believe CE is representative of many multiagent problems, in that agent coordination must include facilities to support both solving a hierarchically decomposed problem, e.g., the contract net and interactions among peers as well.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-234.pdf,
238,1996,AAAI-96 Student Abstracts,Fast Discovery of Simple Rules,Pedro Domingos,"The recent emergence of data mining as a major application of machine learning has led to increased interest in fast rule induction algorithms. These are able to efficiently process large numbers of examples, under the constraint of still achieving good accuracy. If e is the number of examples, many rule learners have O(e^4) asymptotic time complexity in noisy domains, and C4.5RULES has been empirically observed to sometimes require O(e^3) time. Recent advances have brought this bound down to O(elog^2 e), while maintaining accuracy at the level of C4.5RULES’s (Cohen 1995). Ideally, we would like to have an algorithm capable of inducing accurate rules in time linear in e, without becoming too expensive in other factors. This extended abstract presents such an algorithm.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-235.pdf,
239,1996,AAAI-96 Student Abstracts,Multistrategy Learning: A Case Study,Pedro Domingos,"Two of the most popular approaches to induction are instance-based learning (IBL) and rule generation. Their strengths and weaknesses are largely complementary. IBL methods are able to identify small details in the instance space, but have trouble with attributes that are relevant in some parts of the space but not others. Conversely, rule induction methods may overlook small exception regions, but are able to select different attributes in different parts of the instance space. The two methods have been unified in the RISE algorithm (Domingos 1995). RISE views instances as maximally specific rules, forms more general rules by gradually clustering instances of the same class, and classifies a test example by letting the nearest rule win. This approach potentially combines the advantages of rule induction and IBL, and has indeed been observed to be more accurate than each on a large number of benchmark datasets. However, it is important to determine if this performance is indeed due to the hypothesized advantages, and to define the situations in which RISE’s bias will and will not be preferable to those of the individual approaches. This abstract reports experiments to this end in artificial domains.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-236.pdf,
240,1996,AAAI-96 Student Abstracts,Simple Bayesian Classifiers Do Not Assume Independence,"Pedro Domingos, Michael Pazzani","Here we show that the SBC is in fact optimal evenwhen the independence assumption is grossly violated,and thus applicable to a far broader range of domainsthan previously thought.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-237.pdf,
241,1996,AAAI-96 Student Abstracts,"CADI - An Intelligent, Multimedia Tutor for Cardiac Auscultation",Kurt D. Fenstermacher,"Cardiac auscultation is the difficult skill of listening to the human heart and using the sounds heard as clues in diagnosis. The CADI (Cardiac Auscultation Diagnosis Instruction) system is designed to tutor medical students and residents in both phases of auscultation: hearing the sounds and diagnosing illness based on what is heard. The system' s design draws on the case-based teaching architecture (Schank 1991), which in turn is built on goal-based scenarios and case-based reasoning (Hammond 1989).",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-238.pdf,
242,1996,AAAI-96 Student Abstracts,Integration of an Expert Teaching Assistant with Distance Learning Software,"Steven P. Fonseca, Nancy E. Reed","The Remote Teaching Assistant (RTA) software currently under development at UC Davis allows students and Teaching Assistants (TA’s) to interact through multimedia communication via the Internet. To resolve the problem of TA unavailability and limited knowledge, an Expert Teaching Assistant (ETA) module is being developed. When TA’s are not on-line, students in need of help consult ETA. The focus of this research is the development and integration of ETA with RTA, the establishment of an architecture suitable for use with education (the domain) in any sub-domain (course), and the creation of a mechanism usable by non-technical personnel to maintain knowledge bases.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-239.pdf,
243,1996,AAAI-96 Student Abstracts,Self-Adaptation of Mutation Rates and Dynamic Fitness,"Matthew R. Glickman, Katia P. Sycara","In any search via artificial evolution, the likelihood of stagnation at local optima is determined by the particular choices of representation and search operators. Because the performance impact of these design choices is difficult to predict, it is an attractive option to let the representation and/or operators themselves evolve. However, effective evolution at this meta-level can be difficult to achieve for a number of reasons, including: (1) The complexity of the search space is increased; and (2) selection acts at the level of the fitness function and only indirectly at the meta-level, favoring variations only to the extent to which they are stochastically associated with fitness improvements. The question then becomes: Under what conditions is evolution of the representation and/or operators likely to be most effective?",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-240.pdf,
244,1996,AAAI-96 Student Abstracts,Heterogeneous and Homogeneous Robot Group Behavior,Dani Goldberg,"When working with groups of robots it may be very difficult to determine what characteristics the group requires in order to perform a task most efficiently-i.e., in the least time. Some researchers have used groups of behaviorally differentiated robots-where the robots do not perform the same actions-and others have used behaviorally homogeneous groups. None of this research, however, explicitly compares the behavior of heterogeneous and homogeneous groups of robots to determine which performs a task more efficiently. The research described here makes such a comparison and aims at developing guidelines to aid in the design of the heterogeneous/homogeneous characteristics that will allow a group of robots to perform a task efficiently.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-241.pdf,
245,1996,AAAI-96 Student Abstracts,Inducing Design Biases that Characterize Successful Experimentation in Weak-Theory Domains: TIPS,Vanathi Gopalakrishnan,"Experiment design in domains with weak theories is largely a trial-and-error process. In such domains, the effects of actions are unpredictable due to insufficient knowledge about the causal relationships among entities involved in an experiment. Thus, experiments are designed based on heuristics obtained from prior experience. Assuming that past experiment designs leading to success or failure can be recorded electronically, this thesis research proposes one method for analyzing these designs to yield hints regarding effective operator application sequences. This work assumes that the order in which operators are applied matters to the overall success of experiments. Experiment design can also be thought of as a form of planning, since it involves generation of a sequence of steps comprising of one or more operations that can change the environment by changing values of some of the parameters that describe the environment. Experiment design operators can therefore be thought of as plan operators at higher levels of abstraction. This thesis proposes a method for learning contexts within which applying certain sequences of operators has favored successful experimentation in the past.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-242.pdf,
246,1996,AAAI-96 Student Abstracts,Belief Network Algorithms: A Study of Performance,Nathalie Jitnah,This abstract gives an overview of the work described in (Nicholson and Jitnah 1996). We present survey of Belief Network algorithms and propose a domain characterisation system to be used as a basis for algorithm comparison and for predicting algorithm performance.,https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-243.pdf,
247,1996,AAAI-96 Student Abstracts,Proposed Interestingness Measure for Characteristic Rules,"Micheline Kamber, Rajjan Shinghal","Knowledge discovery systems can be used to generate rules describing data from databases. Typically, only a small fraction of the rules generated are of interest. Measures of rule interestingness are hence essential for filtering out useless information. Such measures have been predominantly objective, based on statistics underlying the discovered rules, or patterns. Examples include the J-measure, rule strength, and certainty. Although these measures help assess the interestingness of discriminant rules, they do not fully serve their purpose when applied to characteristic rules. Discriminant rules describe how objects of a class differ from objects of other classes.We propose an interestingness measure for characteristic rules, based on the technical definition of sufficiency.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-244.pdf,
248,1996,AAAI-96 Student Abstracts,A Transformational Analysis of the EBL Utility Problem,"Jihie Kim, Paul S. Rosenbloom","We show that how the cost increaseof a learned rule in an EBL system can be analyzed bycharacterizing the learning process as a sequence of trans-formations from a problem solving episode to a learned rule.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-245.pdf,
249,1996,AAAI-96 Student Abstracts,Controlling State-Space Abstraction in Bayesian Networks,Chao-Lin Liu,"Many applications require computational systems to respond to queries by a particular deadline. Failure to meet the deadlines may render the returned solution useless. Moreover, the deadlines of such time-critical applications are often uncertain at system design time. Anytime algorithms have been suggested to cope with these challenges by trading the quality of the solutions for the reactiveness of the systems at run time [ 13. We have introduced an anytime evaluation algorithm [2] for a formalism commonly used in uncertain reasoning: Bayesian networks. Empirical results indicate that approximations of good quality can be obtained within a much shorter time than would be required to directly evaluate the networks by exact algorithms. Also the quality of the approximation improves with the allocated computational time on average.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-246.pdf,
250,1996,AAAI-96 Student Abstracts,Ad Hoc Attribute-Value Prediction,Gabor Melli,"The evolving ease and efficiency in accessing large amounts of data presents an opportunity to execute prediction tasks based on this data. Research in learning-from-example has addressed this opportunity with algorithms that induce either decision structures (ID3) or classification rules (AQ15). Lazy learning research on the other hand, delay the model construction to strictly satisfy a prediction task. To support a prediction query against a data set, current techniques require a large amount of preprocessing to either construct a complete domain model, or to determine attribute relevance. Our work in this area is to develop an algorithm that will automatically return a probabilistic classification rule for a prediction query with equal accuracy to current techniques but with no preprocessing requirements. The proposed algorithm, DBPredictor, combines the delayed model construction approach of lazy learning along with the information theoretic measure and top-down heuristic search of learning-from-example algorithms. The algorithm induces only the information required to satisfy the prediction query and avoids the attribute relevance tests required by the nearest-neighbour measures of lazy learning.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-247.pdf,
251,1996,AAAI-96 Student Abstracts,An Incremental Interactive Algorithm for Regular Grammar Inference,"Rajesh Parekh, Vasant Honavar","Grammar inference, a problem with many applications in pattern recognition and language learning, is defined as follows: For an unknown grammar G, given a finite set of positive examples S+ that belong to L(G), and possibly a finite set of negative examples S-, infer a grammar G* equivalent to G. Different restrictions on S+ and S- and the interaction of the learner with the teacher or the environment give rise to different variants of this task. We present, an interactive incremental algorithm for inference of a finite state automaton (FSA) corresponding to an unknown regular grammar.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-248.pdf,
252,1996,AAAI-96 Student Abstracts,Constructive Neural Network Learning Algorithms,"Rajesh Parekh, Jihoon Yang, Vasant Honavar","Constructive Algorithms offer an approach for incremental construction of potentially minimal neural network architectures for pattern classification tasks. These algorithms obviate the need for an ad-hoc apriori choice of the network topology. The constructive algorithm design involves alternately augmenting the existing network topology by adding one or more threshold logic units and training the newly added threshold neuron(s) using a stable variant of the perceptron learning algorithm (e.g., pocket algorithm, thermal perceptron, and barycentric correction procedure). Several constructive algorithms including tower, pyramid, tiling, upstart, and perceptron cascade have been proposed for a-category pattern classification. These algorithms differ in terms of their topological and connectivity constraints as well as the training strategies used for individual neurons.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-249.pdf,
253,1996,AAAI-96 Student Abstracts,A Computational Model of Persistent Beliefs,Sunju Park,"In this abstract, we summarize our work on developing acomputational model of persistent beliefs, which supportsboth the temporal information and the nested belief model.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-250.pdf,
254,1996,AAAI-96 Student Abstracts,Contracting Strategy Based on Markov Process Modeling,"Sunju Park, Edmund H. Durfee","One of the fundamental activities in multiagent systems is the exchange of tasks among agents . In particular, we are interested in contracts among self-interested agents, where a contractor desires to find a contractee that will perform the task for the lowest payment, and a contractee wants to perform tasks that maximize its profit (payment received less the cost of doing the task). Multiple, concurrent contracts take place such that a contract may be retracted because of other contracts.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-251.pdf,
255,1996,AAAI-96 Student Abstracts,Learning Procedural Planning Knowledge in Complex Environments,Douglas J. Pearson,"Autonomous agents functioning in complex and rapidly changing environments can improve their task performance if they update and correct their world model over the life of the agent. Existing research on this problem can be divided into two classes. First, reinforcement learners that use weak inductive methods to directly modify an agent’s procedural execution knowledge. These systems are robust in dynamic and complex environments but generally do not support planning or the pursuit of multiple goals and learn slowly as a result of their weak methods. In contrast, the second category, theory revision systems, learn declarative planning knowledge through stronger methods that use explicit reasoning to identify and correct errors in the agent’s domain knowledge. However, these methods are generally only applicable to agents with instantaneous actions in fully sensed domains.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-252.pdf,
256,1996,AAAI-96 Student Abstracts,"MarketBayes: A Distributed, Market-Based Bayesian Network",David M. Pennock,"This paper presents initial work on a system called MarketBayes, a computational market economy where distributed agents trade in uncertain propositions. For any Bayesian network, we have defined a corresponding economy of goods, consumers and producers that essentially ""computes"" the same information. Although our research thus far has only verified the existence of a market structure capable of Bayesian calculations, our hope is that such a system may address a variety of interesting problems of distributed uncertain reasoning. For example, the economic framework should be well suited for belief aggregation, since the bids of numerous agents with varying beliefs, confidence levels and wealth are concisely ""summarized"" in the going prices of goods.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-253.pdf,
257,1996,AAAI-96 Student Abstracts,The Kritzel System for Handwriting Interpretation,Gaofeng Qian,"We present a new system for recognizing on-line cursive handwriting. The system, which is called the Kritzel System, has four features. First, the system characterizes handwriting as a sequence of feature vectors. Second, the system adapts to a particular writing style itself through a learning process. Third, the reasoning of the system is formulated in propositional logic with likelihoods. Fourth, the system can be readily linked with other English processing systems for lexical and contextual checking.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-254.pdf,
258,1996,AAAI-96 Student Abstracts,SplitNet: A Dynamic Hierarchical Network Model,Jürgen Rahmel,"We investigate the information that is contained in the structure of a topology preserving neural network. We consider a topological map as a graph G, propose certain properties of the structure and formulate the respective expectable results of network interpretation.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-255.pdf,
259,1996,AAAI-96 Student Abstracts,Symbolic Performance and Learning in Continuous Environments,Seth O. Rogers,"We present an approach which enables an agent to learn to achieve goals in continuous environments using a symbolic architecture. Symbolic processing has an advantage over numerical regression techniques because it can interface more easily with other symbolic systems, such as systems for natural language and planning. Our approach is to endow an agent with qualitative ""seed"" knowledge and allow it to experiment in its environment. Continuous environments consist of a set of quantitative state variables which may vary over time. The agent represents goals as a user-specified desired value for a variable and a deadline for its achievement. To determine the correct action given the current situation and goals, the agent maps the numbers to symbolic regions, then maps these regions to an action. The learning task of the agent is to develop these mappings.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-256.pdf,
260,1996,AAAI-96 Student Abstracts,Effects of Local Information on Group Behavior,"Shounak Roychowdhury, Neeraj Arora, Sandip Sen","Researchers in the field of Distributed Artificial Intelligence have studied the effects of local decision-making on overall system performance in both cooperative and self-interested agent groups. The performance of individual agents depends critically on the quality of information available to it about local and global goals and resources. Whereas in general it is assumed that the more accurate and up-to-date the available information, the better is the expected performance of the individual and the group, this conclusion can be challenged in a number of scenarios.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-257.pdf,
261,1996,AAAI-96 Student Abstracts,Automated Formulation of Constraint Satisfaction Problems,"Mihaela Sabin, Eugene C. Freuder","A wide variety of problems can be represented as constraint satisfaction problems (CSPs), and once so represented can be solved by a variety of effective algorithms. However, as with other powerful, general AI problem solving methods, we must still address the task of moving from a natural statement of the problem to a formulation of the problem as a CSP. This research addresses the task of automating this problem formulation process, using logic puzzles as a testbed. Beyond problem formulation per se, we address the issues of effective problem formulation, i.e. finding formulations that support more efficient solution, as well as incremental problem formulation that supports reasoning from partial information and are congenial to human thought processes.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-258.pdf,
262,1996,AAAI-96 Student Abstracts,Dynamic Constraint-Based Planning in Trauma Management,Moninder Singh,"This research deals with planning in domains with dynamically changing, multiple, interacting goals. What distinguishes this work from reactive planners (e.g. (Firby 1987)) is the fact that the goals for which planning is done are not known in advance; rather, goals are formed and change rapidly during the planning process itself. Although planners that produce appropriate plans exist for such domains (Rymon et al. 1993), we want a planner that also provides a basis for explaining why some action is chosen over another or why some goal is no longer relevant etc., which is necessary for effective decision support (Gertner 1994).",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-259.pdf,
263,1996,AAAI-96 Student Abstracts,Blocking as a Middle-Ground for Step-Order Commitments in Planning,"Biplav Srivastava, Subbarao Kambhampati","Partial order planners commit only to the relative positions of the steps in the plan, and leave both their absolute positions as well as the relative distance between the different steps unspecified until the end of planning. Although this is seen as an advantageous feature of partial order planning, it can sometimes be a mixed-blessing. Because the relative distances between the steps are unspecified, any unordered step may be able to come between any existing steps and cause interactions and the planner may spend inordinate effort considering all possible interleavings of the subplans of the individual goals. This happens in cases where top-level goals are serializable but have long sub-plans which have internal interactions, plan-space planners would consider all simple-establishments and threats between steps of a the subplan of a top-level goal gi (represented by P,;) and Ps3 which could affect its performance drastically. State-space planners, on the other hand, fix both the distance and position, and this is often more commitment than is needed, causing extensive backtracking.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-260.pdf,
264,1996,AAAI-96 Student Abstracts,Experimentation-Driven Operator Learning,Kang Soo Tae,"Expert-provided operator descriptions are expensive, incomplete, and incorrect. Given the assumptions of noise-free information and an completely-observable state, OBSERVER can autonomously learn and refines new operators through observation and practice (Wang 1995). WISER, our learning system, relaxes these assumptions and learns operator preconditions through experimentation utilizing imperfect expert-provided knowledge. Our decision-theoretic formula calculates a probably best state S' for experimentation based on the imperfect knowledge. When a robotic action is executed successfully for the first time in a state S, the corresponding operator’s initial preconditions are learned as parameterized S. We empirically show the number of training examples required to learn the initial preconditions as a function of the amount of injected error. The learned preconditions contain all the necessary positive literals, but no negative literals.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-261.pdf,
265,1996,AAAI-96 Student Abstracts,Hybrid Knowledge- and Databases,Merwyn Taylor,"In the modern era, databases have been created spanning many domains. However, these databases do not contain general knowledge about their respective domains. For example, whereas a medical database could contain an entry for a patient with some medical disorder, it would not normally contain taxonomic information about medical disorders, known causal agents, symptoms, etc. Collections of this sort of general information are usually called knowledge bases and powerful tools have been developed for querying these collections in complex and flexible ways. The research described in this abstract aims to develop methodologies for merging existing databases with knowledge bases, so that the power and flexibility of knowledge base technology can be applied to existing collections of data.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-262.pdf,
266,1996,AAAI-96 Student Abstracts,Learning Models for Multi-Source Integration,"Sheila Tejada, Craig A. Knoblock, Steven Minton","Because of the growing number of information sources available through the internet there are many cases in which information needed to solve a problem or answer a question is spread across several information sources. For example, when given two sources, one about comic books and the other about super heroes, you might want to ask the question ""Is Spiderman a Marvel Super Hero?"" This query accesses both sources; therefore, it is necessary to have information about the relationships of the data within each source and between sources to properly access and integrate the data retrieved. The SIMS information broker captures this type of information in the form of a model. All the information sources map into the model providing the user a single interface to multiple sources.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-263.pdf,
267,1996,AAAI-96 Student Abstracts,Rabbi: Exploring the Inner World through Stories,Marina Umaschi,"In the oral tradition, stories were told by the elder sages in order to give indirect advice. Today most stories are told in order to entertain. While some research on storytelling systems has focused on drama/theater metaphors and adventure/mystery simulation games (Bates et al., 1995), my research emphasizes the counseling and self-awareness possibilities of storytelling.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-264.pdf,
268,1996,AAAI-96 Student Abstracts,Constructive Induction of Features for Planning,Michael van Lent,"Constructive induction techniques use constructors to combine existing features into new features. Usually the goal is to improve the accuracy and/or efficiency of classification. An alternate use of new features is to create representations which allow planning in more efficient state spaces. An inefficient state space may be too fine grained, requiring deep search for plans with many steps, may be too fragmented, requiring separate plans for similar cases, or may be unfocused, resulting in poorly directed search. Modifying the representation with constructive induction can improve the state space and overcome these inefficiencies. Additionally, since most learning systems depend on good domain features, constructive induction will compliment the action of other algorithms.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-265.pdf,
269,1996,AAAI-96 Student Abstracts,Agents Modeling Agents in Information Economies,"José M. Vidal, Edmund H. Durfee","Our goal is to design and build agents that act intelligently when placed in an agent-based information economy, where agents buy and sell services (e.g. thesaurus, search, task planning services, etc.). The economy we are working in is the University of Michigan Digital Library (UMDL), a large scale multidisciplinary effort to build an infrastructure for the delivery of library services [2]. In contrast with a typical economy, an information economy deals in goods and services that are often derived from unique sources (authors, analysts, etc.), so that many goods and services are not interchangeable. Also, the cost of replicating and transporting goods is usually negligible, and the quality of goods and services is difficult to measure objectively: even two sources with essentially the same information might appeal to different audiences. Thus, each agent has its own assessment of the quality of goods and services delivered.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-266.pdf,
270,1996,AAAI-96 Student Abstracts,Optimal Factory Scheduling Using Stochastic Dominance A*,Peter R. Wurman,"Generating optimal production schedules for manufacturing facilities is an area of great theoretical and practical importance. During the last decade, an effort has been made to reconcile the techniques developed by the AI and OR communities. The work described here aims to continue in this vein by showing how a class of well-defined stochastic scheduling problems can be mapped into a general search procedure. This approach improves upon other methods by handling the general case of multidimensional stochastic costs.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-267.pdf,
271,1996,AAAI-96 Student Abstracts,Dynamic Map: Representation of Interactions between Robots,Christian Zanardi,"As robotics applications become more complex, the need for tools to analyze and explain interactions between robots has become more acute. We introduce the concept of Dynamic Map (DM), which can serve as a generic tool to analyze interactions between robots or with their environment. We show that this concept can be applied to different kinds of applications, like a predator-prey situation, or collision avoidance.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-268.pdf,
272,1996,AAAI-96 Student Abstracts,Neural Network Guided Search Control in Partial Order Planning,"Terry Zimmerman, Subbarao Kambhampati","The development of efficient search control methods is an active research topic in the field of planning (Kambhampati, Katukam, and Qu 1996). Investigation of a planning program integrated with a neural network (NN) that assists in search control is underway, and has produced promising preliminary results.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-269.pdf,
273,1996,Invited Talks,The BOEING 777 - Concurrent Engineering and Digital Pre-Assembly,Bob Abarbanel,"The processes created on the 777 for checking designs were called ""digital preassembly"". Using FlyThru(tm), a spinoff of a Boeing advanced computing research project, engineers were able to view up to 1500 models (15000 solids) in 3d traversing that data at high speed. FlyThru(tm) was rapidly deployed in 1991 to meet the needs of the 777 for large scale product visualization and verification. The digital preassembly process has had fantastic results. The 777 has had far fewer assembly and systems problems compared to previous airplane programs. Today, FlyThru(tm) is installed on hundreds of workstations on almost every airplane program, and is being used on Space Station, F22, AWACS, and other defense projects. It’s applications have gone far beyond just design review. In many ways, FlyThru is a Data Warehouse supported by advanced tools for analysis. It is today being integrated with Knowledge Based Engineering geometry generation tools.",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-288.pdf,
274,1996,Invited Talks,Data Mining and Knowledge Discovery in Databases: Applications in Astronomy and Planetary Science,Usama M. Fayyad,"Knowledge Discovery in Databases (KDD) is a new field of research concerned with the extraction of high-level information (knowledge) from low-level data (usually stored in large databases) [1]. It is an area of interest to researchers and practitioners from many fields including: AI, statistics, pattern recognition, databases, visualization, and high-performance and parallel computing. The basic problem is to search databases for patterns or models that can be useful in accomplishing one or more goals. Examples of such goals include: prediction (e.g. regression and classification), descriptive or generative modeling (e.g. clustering), data summarization (e.g. report generation), or visualization of either data or extracted knowledge (e.g. to support decision making or exploratory data analysis). KDD is a process that includes many steps. Among these steps are: data preparation and cleaning, data selection and sampling, preprocessing and transformation, data mining to extract patterns and models, interpretation and evaluation of extracted information, and finally evaluation, rendering, or use of final extracted knowledge. Note that under this view, data mining constitutes one of the steps of the overall KDD process. The other steps are essential to make the application of data mining possible, and to make the results useful. Within data mining, methods for deriving patterns or extracting models originate from statistics, machine learning, statistical pattern recognition, uncertainty management, and database methods such as on-line analysis processing (OLAP) or association rules [2]. The process is typically highly interactive and may involve many iterations before useful knowledge is extracted from the underlying data. This talk will give an overview and summary of the rapidly growing field of KDD, and then focus on two specific applications in scientific data analysis to illustrate the potential, limitations, challenges, and promise of KDD. An overview of the KDD process is given in [3].",https://aaai.org/Library/AAAI/1996/../../../Papers/AAAI/1996/AAAI96-289.pdf,
