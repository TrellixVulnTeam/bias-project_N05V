,conference_year,category,title,author,abstract,download_url,keywords
0,1984,AI and Education,An Interactive Computer-Based Tutor for LISP,"Robert G. Farrell, John R. Anderson, Brian J. Reiser",This paper describes an intelligent computer-based tutor for LISP that incorporates some of the Ingredients of good private tutoring. The tutor consists of a problem-solver that generates steps toward a solution and an advisor that compares the problem-solver’s steps to the student’s steps. Our system can interact with students in a number of different problem spaces for algorithm design and coding. The tutor reduces memory demands by displaying relevant contextual information and directs problem-solving by immediately intervening when a student generates an unacceptable partial answer. Initial experiments indicate that our tutor is approximately twice as effective as classroom instruction.,https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-001.pdf,
1,1984,AI and Education,Intention-Based Diagnosis of Programming Errors,Elliot Soloway,"PROUST is a system which identifies the non-syntactic bugs in novices’ programs and provides novices with help as to the misconceptions under which they were laboring that caused the bugs. In this paper we will discuss the methods which PROUST uses to identify and diagnose non-syntactic bugs. Key in this enterprise is PROUST’s ability to cope with the significant variability exhibited by novices’ programs: novice programs are designed and implemented in a variety of different ways, and usually have numerous bugs. We argue that diagnostic techniques that attempt to reason from faulty behavior to bugs are not effective in the face of such variability. Rather, PROUST'S approach is to construct a causal model of the programmer’s intentions and their realization (or non-realization) in the code. This model serves as a framework for bug recognition, and allows PROUST to reason about the consequences of the programmer’s decisions in order to determine where errors were committed and why.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-002.pdf,
2,1984,AI and Education,Context-Dependent Transitions in Tutoring Discourse,David D. McDonald,"Successful machine tutoring, like other forms of human-machine discourse, requires sophisticated communication skills and a deep understanding of the student’s knowledge. A system must have the ability to reason about a student’s knowledge and to assess the effect of the discourse on him. In this paper we describe Meno-tutor, a LISP program that deliberately plans the rhetorical structure of its output and customizes its responses to the level of understanding of the individual student.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-003.pdf,
3,1984,AI Architectures and Languages,Hardware and Software Architectures for Efficient Al,Michael F. Deering,"With recent advances in AI technology, there has been increased interest in improving AI computational throughput and reducing cost, as evidenced by a number of current projects. To obtain maximum benefit from these efforts, it is necessary to scrutinize possible efficiency improvements at every level, both hardware and software. Custom AI machines, better AI language compilers, and massively parallel machines can all contribute to efficient AI computations. However, little information is available concerning how to achieve these efficiencies. A systematic study was undertaken to fill this gap. This paper describes the main results of that study, and points out specific improvements that can be made. The areas covered include: AI language semantics, AI language compilers, machine instruction set design, parallelism, and important functional candidates for VLSI implementation such as matching, associative memories, and signal to symbol processing for vision and speech.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-004.pdf,
4,1984,AI Architectures and Languages,Syntax Programming,Stefan Feyock,"This paper describes a new programming technology that is to syntax analysis as formal logic is to logic programming, and which we have accordingly named syntax programming. The table-driven nature of bottom-up parsers provides this approach with a number of attractive features, among which are compactness, portability, and introspective capability. Syntax programming has been success- fully used for a number of applications, including expert system construction and robot control as well as non-AI problems.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-005.pdf,
5,1984,AI Architectures and Languages,Initial Assessment of Architectures for Production Systems,"Anoop Gupta, Allen Newell, Robert Wedig","Although production systems are appropriate for many applications in the artificial intelligence and expert systems areas, there are applications for which they are not fast enough to be used. If they are to be used for very large problems with severe time constraints, speed increases are essential. Recognizing that substantial further increases are not likely to be achieved through software techniques, the PSM project has begun investigating the use of hardware support for production system interpreters. The first task undertaken in the project was to attempt to understand the space of architectural possibilities and the trade-offs involved. This articlc presents the initial findings of the project. Briefly, the preliminary results indicate that the most attractive architecture for production systems is a machine containing a small number of very simple and very fast processors.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-006.pdf,
6,1984,AI Architectures and Languages,Five Parallel Algorithms for Production System Execution on the DADO Machine,Salvatore J. Stolfo,"In this paper we specify five abstract algorithms for the parallel execution of production systems on the DAD0 machine. Each algorithm is designed to capture the inherent parallelism in a variety of different production system programs. Ongoing research aims to substantiate our conclusions by empirically evaluating the performance of each algorithm on the DAD02 prototype, presently under construction at Columbia University.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-007.pdf,
7,1984,Automated Reasoning,Generalization Heuristics for Theorems Related to Recursively Defined Functions,"S. Kamal Abdali, Jan Vytopil","This paper is concerned with the problem of generalizing theorems about recursively defined functions, so as to make these theorems amenable to proof by induction. Some generalization heuristics are presented for certain special forms of theorems about functions specified by certain recursive schemas. The heuristics are based upon the analysis of computational sequences associated with the schemas. If applicable, the heuristics produce generalizations that are guaranteed to be theorems.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-008.pdf,
8,1984,Automated Reasoning,A Self-Modifying Theorem Prover,Cynthia A. Brown,"Theorem provers can be viewed as containing declarative knowledge (in the form of axioms and lemmas) and procedural knowledge (in the form of an algorithm for proving theorems). Sometimes, as in the case of commutative laws in a Knuth-Bendix prover, it is appropriate or necessary to transfer knowledge from one category to the other. We describe a theorem proving system that independently recognizes opportunities for such transfers and performs them dynamically.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-009.pdf,
9,1984,Automated Reasoning,Focusing in Plan Recognition,"Norman F. Carver, Victor R. Lesser, Daniel L. McCue","A plan recognition architecture is presented which exploits application-specific heuristic knowledge to quickly focus the search to a small set of plausible plan interpretations from the very large set of possible interpretations. The heuristic knowledge is formalized for use in a truth maintenance system where interpretation assumptions and their heuristic justifications are recorded. By formalizing this knowledge, the system is able to reason about the assumptions behind the current state of the interpretations. This makes intelligent backtracking and error detection possible.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-010.pdf,
10,1984,Automated Reasoning,A Forward Inference Engine to Aid in Understanding Specifications,Donald Cohen,"An important part of understanding a specification is recognizing the consequences of what is stated. We describe a program that can help a user acquire this understanding. It does this by deriving interesting, though not deep consequences of a set of input axioms, while avoiding (a typically much larger set of) uninteresting consequences. The heuristics for obtaining that effect are described and justified. The program has been used in a symbolic evaluator that helps a user to understand and debug specifications written in the Gist specification language.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-011.pdf,
11,1984,Automated Reasoning,Towards a Better Understanding of Bidirectional Search,"Henry W. Davis, Randy B. Pollack, Thomas Sudkamp","Three admissible bidirectional search algorithms have been described in the literature: A Cartesian product approach due to Doran, Pohl’s BHPA, and Champeaux and Sint’s BHFFA2. This paper describes an algorithm, GP, which contains the latter two and others. New admissibility results are obtained. A first order analysis is made comparing the run times of Cartesian product search, two versions of GP, and unidirectional A . The goal is to gain insight on when bidirectional search is useful and direction for seeking better bidirectional search algorithms.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-012.pdf,
12,1984,Automated Reasoning,Choices Without Backtracking,Johan de Kleer,"Artificial Intelligence problem solvers are frequently confronted with the necessity to make choices among equally plausible alternatives. These may concern the choice of which goal to try to achieve next, which priority to assign to a task or which plausible inference to draw from incomplete data. Choices can be wrong: later problem solving may determine that an earlier choice was incorrect. In such cases most problem solvers invoke some form of backtracking to undo the faulty choice, retract the inferences that were made from that choice and make some other choice. This paper discusses a method of dealing with choice that does not involve any backtracking yet explores no more alternatives than the best backtracking schemes. It has an additional advantage over backtracking schemes that it is possible to easily compare two alternative incompatible choices - this cannot be done in backtracking schemes because of their necessity of requiring a globally consistent set of assertions.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-013.pdf,
13,1984,Automated Reasoning,Qualitative Reasoning With Higher-Order Derivatives,"Johan de Kleer, Daniel G. Bobrow","The goals of qualitative physics are to identify the distinctions and laws which govern qualitative behavior of devices such that it is possible to predict and explain the behavior of physical devices without recourse to quantitative methods. Although qualitative analysis lacks quantitative information, it predicts significant characteristics of device functioning such as feedback, ringing oscillation, etc. This paper defines higher-order qualitative derivatives and uses them to formulate six fundamental laws which govern the gross-time behavior of physical devices. These qualitative laws are based on the Mean Value Theorem and Taylor’s Expansion of the quantitative calculus. They substitute for what often requires sophisticated problem-solving. We claim they are the best that can be achieved relying on qualitative information.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-014.pdf,
14,1984,Automated Reasoning,A Theory of Action for MultiAgent Planning,Michael Georgeff,"A theory of action suitable for reasoning about events in multiagent or dynamically changing environments is presented. A device called a process model is used to represent the observable behavior of an agent in performing an action. This model is more general than previous models of action, allowing sequencing, selection, nondeterminism, iteration, and parallelism to be represented. It is shown how this model can be utilized in synthesizing plans and reasoning about concurrency. In particular, conditions are derived for determining whether or not concurrent actions are free from mutual interference. It is also indicated how this theory provides a basis for understanding and reasoning about action sentences in both natural and programming languages.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-015.pdf,
15,1984,Automated Reasoning,Non-Monotonic Reasoning Using Dempster’s Rule,Matthew L. Ginsberg,"Rich’s suggestion that the arcs of semantic nets be labelled so as to reflect confidence in the properties they represent is investigated in greater detail. If these confidences are thought of as ranges of acceptable probabilities, existing statistical methods can be used effectively to combine them. The framework developed also seems to be a natural one in which to describe higher levels of deduction, such as ""reasoning about reasoning.""",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-016.pdf,
16,1984,Automated Reasoning,Diagnosing Circuits With State: An Inherently Underconstrained Problem,"Walter Hamscher, Randall Davis","""Hard problems"" can be hard because they are computationally intractable, or because they are underconstrained. Here we describe candidate generation for digital devices with state, a fault localization problem that is intractable when the devices are described at low levels of abstraction, and is underconstrained when described at higher levels of abstraction. Previous work [l] has shown that a fault in a combinatorial digital circuit can be localized using a constraint-based representation of structure and behavior. ln this paper we (1) extend this representation to model a circuit with state by choosing a time granularity and vocabulary of signals appropriate to that circuit; (2) demonstrate that the same candidate generation procedure that works for combinatorial circuits becomes indiscriminate when applied to a state circuit modeled in that extended representation;(3) show how the common technique of single-stepping can be viewed as a divide-and-conquer approach to overcoming that lack of constraint; and (4) illustrate how using structural detail can help to make the candidate generator discriminating once again, but only at great cost.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-017.pdf,
17,1984,Automated Reasoning,Meta-Level Control Through Fault Detection and Diagnosis,"Eva Hudlicka, Victor R. Lesser","Control strategies in most complex problem-solving systems, though highly parameterized, are not adaptive to the characteristics of the particular task being solved. If the characteristics of the task are atypical, a fixed control strategy may cause incorrect or inefficient processing. We present an approach for adapting the control strategy by introducing a meta-level control component into the problem-solving architecture. This meta-level control component is based on the paradigm of Fault Detection/Diagnosis. Our presentation will concentrate on modeling the problem-solving system and on the inference techniques necessary to use this model for diagnosis. We feel that meta-level control based on the Fault Detection/Diagnosis paradigm represents a new approach to introducing more sophisticated control into a problem- solving system.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-018.pdf,
18,1984,Automated Reasoning,A General Bottom-up Procedure for Searching And/Or Graphs,Vipin Kumar,"This paper summarizes work on a general bottom- up procedure for searching AND/OR graphs which includes a number of procedures for searching AND/OR graphs, state-space graphs, and dynamic programming procedures as its special cases. The paper concludes with comments on the significance of this work in the context of the author’s unified approach to search procedures.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-019.pdf,
19,1984,Automated Reasoning,How to Cope With Anomalies in Parallel Approximate Branch-and-Bound Algorithms,"Guo-jie Li, Benjamin W. Wah","A genera! technique for solving a wide variety of search problems is the branch-and-bound (B&B) algorithm. We have adapted and extended B&B algorithms for parallel processing. Anomalies owing to parallelism may occur. In this paper sufficient conditions to guarantee that parallelism will not degrade the performance are presented. Necessary conditions for allowing parallelism to have a speedup greater than the number of processors are also shown. Anomalies are found to occur infrequently when optimal solutions are sought; however, they are frequent in approximate B&B algorithms. Theoretical analysis and simulations show that a best-first search is robust for parallel processing.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-020.pdf,
20,1984,Automated Reasoning,D-Node Retargeting in Bidirectional Heuristic Search,"George Politowski, Ira Pohl","AIthough it is generally agreed that bidirectional heuristic search is potentially more efficient than unidirectional heuristic search, so far there have been no algorithms which realize this potential. The basic difficulty is that the two search trees (one rooted at the start, the other at the goal) do not meet in the middle. This results in essentially two unidirectional starches and poorer performance. In this paper we present an efficient algorithm for bidirectional heuristic search which overcomes this difficulty. We also compare this algorithm with de Champeaux’s BHFFA (2,3) on the basis of search efficiency, solution quality, and computational cost.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-021.pdf,
21,1984,Automated Reasoning,Qualitative Modeling in the Turbojet Engine Domain,Raman Rajagopalan,This paper addresses some of the issues involved in modeling the domain of turbojet engine operation. A causal model based on the relationships between engine parameters has been developed and used to implement an engine simulation. The implementation includes a facility for explaining the results of the simulation.,https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-022.pdf,
22,1984,Automated Reasoning,Knowledge Inversion,"Yoav Shoham, Drew V. McDermott","We define the direction of knowledge, and what it means to extend that direction. A special case is function inversion, and we give three algorithms for function inversion. Their performance on non-trivial problems and their shortcomings are demonstrated. All algorithms are implemented in Prolog.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-023.pdf,
23,1984,Automated Reasoning,A Mechanical Solution of Schubert’s Steamroller by Many-Sorted Resolution,Christoph Walther,"We demonstrate the advantage of using a many-sorted resolution calculus by a mechanical solution of a challenge problem. This problem known as ""Schubert’s Steamroller"" had been unsolved by automated theorem provers until now. Our solution clearly demonstrates the power of a many-sorted resolution calculus. The proposed method is applicable to all resolution-based inference systems.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-024.pdf,
24,1984,Automated Reasoning,The Use of Continuity in a Qualitative Physics,Brian C. Williams,The ability to reason about a series of complex events over time is essential in analyzing physical systems. This paper discusses the role of continuity in qualitative physics and its application in a system for analyzing the behavior of Digital MOS circuits that exhibit analog behavior. The discussion begins with a brief overview of the reasoning steps necessary to perform a qualitative simulation using Temporal Qualitative (TQ) Analysis. The discussion then focuses in on the use of continuity and the relationship between quantities and their higher order derivatives in describing how physical quantities change over time.,https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-025.pdf,
25,1984,Cognitive Modeling,A Model of Lexical Access of Ambiguous Words,Garrison W. Cottrell,"Recent psycholinguistic work in the study of lexical access has supported a modular view of the process. That is, lexical access proceeds indepedently of the sentential context. Herein we describe a connectionist model of the process which retains modularity, explains apparent anomalies in the results, and makes empirically verifiable predictions.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-026.pdf,
26,1984,Cognitive Modeling,Automated Cognitive Modeling,"Pat Langley, Stellan Ohlsson","In this paper we describe an approach to automating the construction of cognitive process models. We make two psychological assumptions: that cognition can be modeled as a production system, and that cognitive behavior involves search through some problem space. Within this framework, we employ a problem reduction approach to constructing cognitive models,in which one begins with a set of independent, overly general condition-action rules, adds appropriate conditions to each of these rules, and then recombines the more specific rules into a final model. Conditions are determined using a discrimination learning method. which requires a set of positive and negative instances for each rule. These instances are based on inferred solution paths that lead to the same answers as those observed in a human subject. We have implemented ACM, a cognitive modeling system that incorporates these methods and applied the system to error data from the domain of multi-column subtraction problems.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-027.pdf,
27,1984,Cognitive Modeling,Phenomenologically Plausible Parsing,"David L. Waltz, Jordan B. Pollack","This is a description of research in developing a natural language processing system with modular knowledge sources but strongly interactive processing. The system offers insights into a variety of linguistic phenomena and allows easy testing of a variety of hypotheses. Language interpretation takes place on a activation network which is dynamically created from input, recent context, and long-term knowledge. Initially ambiguous and unstable, the network settles on a single interpretation, using a parallel, analog relaxation process. We also describe a parallel model for the representation of context and priming of concepts. Examples illustrating contextual influence on meaning interpretation and ""semantic garden path"" sentence processing are included.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-029.pdf,
28,1984,Expert Systems,Personal Construct Theory and the Transfer of Human Expertise,John H. Boose,The bottleneck in the process of building expert svstems is retrieving the appropriate problem-solving knowledge from the human expert. Methods of knowledge elicitation and analysis from psychotherapy based on enhancements to George Kelly’s Personal Construct Theory are applied to this process. The Expertise Transfer System is described which interviews a human expert and then constructs and analyzes the knowledge that the expert uses to solve his particular problem. The first version of the system elicits the initial knowledge needed to solve analysis problems without the intervention of a knowledge engineering team. Fast (two hour) initial prototyping of expert systems which run on KS- 300 (an extended version of EMYCIN) and OPS5 is also performed. Conflicts in the problem-solving methods of the expert may also be enumerated and explored.,https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-030.pdf,
29,1984,Expert Systems,Classification Problem Solving,William J. Clancey,"A broad range of heuristic programs-embracing forms of diagnosis, catalog selection, and skeletal planning-accomplish a kind of well-structured problem solving called classification. These programs have characteristic inference structure that systematically relates data to pre-enumerated set of solutions by abstraction, heuristic association, and refinement. This level of description specifies the knowledge needed to solve a problem, independent of its representation in a particular computer language. The classification problem-solving model provides a useful framework for recognizing and representing similar problems, for designing representation tools, and for understanding why non-classification problems require different problem-solving methods.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-031.pdf,
30,1984,Expert Systems,YES/MVS: A Continuous Real Time Expert System,"J. H. Griesmer, S. J. Hong, M. Karnaugh, J. K. Kastner, M. I. Schor, R. L. Ennis, D. A. Klein, K. R. Milliken, H. M. VanWoerkom","YES/MVS (Yorktown Expert System for MVS operators) is a continuous, real time expert system that exerts interactive control over an operating system as an aid to computer operators. This paper discusses the YES/MVS system, its domain of application, and issues that arise in the design and development of an expert system that runs continuously in real time.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-032.pdf,
31,1984,Expert Systems,Self-Explanatory Financial Planning Models,"Donald W. Kosy, Ben P. Wise","A financial model is a representation of the activities of a business in terms of quantitative relationships among variables that can help an analyst understand the financial consequences of past activities or assumed future activities. The equations comprising such models form a kind of knowledge base which can be used to generate explanations. In this paper we give some background on financial models, discuss two sorts of explanations in this domain, and present a procedure for explaining model results.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-033.pdf,
32,1984,Expert Systems,Selective Abstraction of Al System Activity,"Jasmina Pavlin, Daniel D. Corkill","The need for presenting useful descriptions of problem solving activities has grown with the size and complexity of contemporary AI systems. Simply tracing and explaining the activities that led to a solution is no longer satisfactory. We describe a domain-independent approach for selectively abstracting the chronological history of problem solving activity (a system trace) based upon user-supplied abstraction goals. An important characteristic of our approach is that, given different abstraction goals, abstracted traces with significantly different emphases can be generated from the same original trace. Although we are not concerned here with the generation of an explanation from the abstracted trace, this approach is a useful step towards such an explanation facility.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-034.pdf,
33,1984,Expert Systems,Continuous Belief Functions for Evidential Reasoning,Thomas M. Strat,"Some recently developed expert systems have used the Shafer-Dempster theory for reasoning from multiple bodies of evidence. Many expert-system applications require belief to be specified over arbitrary ranges of scalar variables, such as time, distance or sensor measurements. The utility of the existing Shafer- Dempster theory is limited by the lack of an effective approach for dealing with beliefs about continuous variables. This paper introduces a new representation of belief for continuous variables that provides both a conceptual framework and a computationally tractable implementation within the Shafer-Dempster theory.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-035.pdf,
34,1984,Knowledge Representation,The Tractability of Subsumption in Frame-Based Description Languages,"Ronald J. Brachman, Hector J. Levesque","A knowledge representation system provides an important service to the rest of a knowledge-based system: it computes automatically a set of inferences over the beliefs encoded within it. Given that the knowledge-based system relies on these inferences in the midst of its operation (i.e., its diagnosis, planning, or whatever), their computational tractability is an important concern. Here we present evidence as to how the cost of computing one kind of inference is directly related to the expressiveness of the representation language. As it turns out, this cost is perilously sensitive to small changes in the representation language. Even a seemingly simple frame-based description language can pose intractable computational obstacles.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-036.pdf,
35,1984,Knowledge Representation,"Likelihood, Probability, and Knowledge","Joseph Y. Halpern, David A. McAllester","The modal logic LL was introduced by Halpern and Rabin [HR] as a means of doing qualitative reasoning about likelihood. Here the relationship between LL and probability theory is examined. It is shown that there is a way of translating probability assertions into LL in a sound manner, so that LL in some sense can capture the probabilistic interpretation of likelihood. However, the translation is subtle; several more obvious attempts are shown to lead to inconsistencies. We also extend LL by adding modal operators for knowledge. The propositional version of the resulting logic LLK is shown to have a complete axiomatization and to be decidable in exponential time, provably the best possible.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-037.pdf,
36,1984,Knowledge Representation,A Logic of Implicit and Explicit Belief,Hector J. Levesque,"As part of an on-going project to understand the foundations of Knowledge Representation, we are attempting to characterize a kind of belief that forms a more appropriate basis for Knowledge Representation systems than that captured by the usual possible-world formalizations begun by Hintikka. In this paper, we point out deficiencies in current semantic treatments of knowledge and belief (including recent syntactic approaches) and suggest a new analysis in the form of a logic that avoids these shortcomings and is also more viable computationally.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-038.pdf,
37,1984,Knowledge Representation,A Self-Organizing Retrieval System for Graphs,Robert Levinson,The design of a general knowledge base for labeled graphs is presented. The design involves a partial ordering of graphs represented as subsets of nodes of a universal graph. The knowledge base’s capabilities of fast retrieval and self-organization are a result of its ability to recognize common patterns among its data items. The system is being used to support a knowledge base in Organic Chemistry.,https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-039.pdf,
38,1984,Knowledge Representation,A Set-Theoretic Framework for the Processing of Uncertain Knowledge,"S. Y. Lu, H. E. Stephanou","In this paper, a knowledge base is represented by an input space, an output space, and a set of mappings that associate subsets of the two spaces. Under this representation, knowledge processing has three major parts: (1) The user enters observations of evidence in the input space and assigns a degree of certainty to each observation (2) A piece of evidence that receives a non-zero certainty activates a mapping. This certainty is multiplied by the certainty associated with the mapping, and is thus propagated to a proposition in the output space. (3) The consensus among all the propositions that have non-zero certainties is computed, and a final set of conclusions is drawn. A degree of support is associated with each conclusion.The underlying model of certainty in this processing scheme is based on the Dempster-Shafer mathematical theory of evidence. The computation of the consensus among the propositions uses Dempster’s rule of combination. The inverse of the rule of combination, which we call the rule of decomposition, is derived in this paper. Given an expected consensus, the inverse rule can generate the certainty required for each proposition. Thus, the certainties in the mappings can be inferred iteratively through alternating use of the rule of combination and the rule of decomposition.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-040.pdf,
39,1984,Knowledge Representation,Processing Entailments and Accessing Facts in a Uniform Frame System,Anthony S. Maida,"This paper: 1) describes the structure of a ""uniform"" frame system; 2) shows how entailments can be computed within the system; and, 3) shows how contingent facts that are related to a concept can become accessible as a function of how deeply the meaning of that concept is processed. The system is called Uni- Frame and differs from slot-filler frame systems primarily in its commitment to uniformly representing all concepts and to maintaining a representation which is semantically well knit.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-041.pdf,
40,1984,Knowledge Representation,Expressiveness of Languages,"Jock Mackinlay, Michael R. Genesereth","Specialized languages are often a good choice for expressing a set of facts. However, many specialized languages are limited in their expressive power. This paper presents methods for determining when a set of facts is expressible in a language. Some specialized languages have the property that when some collections of facts are stated explicitly, additional facts are stated implicitly. A set of facts should not be stated in such a language unless these implicit facts are correct. This paper presents an algorithm for identifying implicit facts so that they can be checked for correctness. Criteria are also presented for choosing between languages that are sufficiently expressible for a set of facts. This research is being used to build a system that automatically determines when a specialized language is appropriate. It is also relevant to system designers who wish to use specialized languages.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-042.pdf,
41,1984,Knowledge Representation,Constraint Equations: A Concise Compilable Representation for Quantified Constraints in Semantic Networks,Matthew Morgenstern,"Constraint Equations provide a concise declarative language for expressing semantic constraints that require consistency among several relations. The constraints provide a natural addition to semantic networks, as shown by an extension to the KL-ONE/NIKL representation language. The Equations have a more natural and perspicuous structure than the predicate calculus formulas into which they may be translated, and they also have an executable interpretation. Both universal and existential quantifiers are expressible conveniently in Constraint Equations, as are cardinality quantifiers and transitive closure. For a subclass of these constraints, a prototype compiler automatically generates programs which will enforce these constraints and perform the actions needed to reestablish consistency.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-043.pdf,
42,1984,Knowledge Representation,Implicit Ordering of Defaults in Inheritance Systems,David S. Touretzky,There is a natural partial ordering of defaults in inheritance systems that resolves ambiguities in an intuitive way. This is not the shortest-path ordering used by most existing inheritance reasoners. The flaws of the shortest-path ordering become apparent when we consider multiple inheritance. We define the correct partial ordering to use in inheritance and show how it applies to semantic network systems. Use of this ordering also simplifies the representation of inheritance in default logic.,https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-044.pdf,
43,1984,Knowledge Representation,Very-High-Level Programming of Knowledge Representation Schemes,Stephen J. Wesffold,"This paper proposes building knowledge-based systems using a programming system based on a very-high-level language. It gives an overview of such a programming system, BC, and shows how BC can be used to implement knowledge representation features, providing as examples, automatic maintenance of inverse links and property inheritance. The specification language of BC can be extended to include a knowledge representation language by describing its knowledge representation features. This permits a knowledge-based program and its knowledge base to be written in the same very-high-level language which allows the knowledge to be more efficiently incorporated into the program as well as making the system as a whole easier to understand and extend.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-045.pdf,
44,1984,Learning,Constraint Limited Generalization: Acquiring Procedures From Examples,Peter M. Andreae,Generallzatlon is an essential part of any system that can acquire knowledge from examples. l argue that generallzatlon must be limited by a variety of constraints in order to be useful. This paper gives three principles on how generallzation processes should be constrained. It also describes a system for acquiring procedures from examples which is based on these principles and is used to illustrate them.,https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-046.pdf,
45,1984,Learning,Learning Problem Classes by Means of Experimentation and Generalization,Agustin A. Araya,"We discuss a method of learning by practice based on the idea of determining classes of problems that can be solved in simplified ways. A description of a class is obtained by processes that hypothesize descriptions, generate and classify problem variations, and test the hypotheses against them. The approach has been implemented in a system that learns by practice in a domain of elementary physics. The system has two main components, a Problem Solver and a Learning Agent. The Problem Solver handles the problems in the domain and the Learning Agent does the actual learning. To perform its tasks the Learning Agent utilizes algorithms, heuristics, and domain knowledge, and for this reason it can be regarded as an expert system whose expertise resides in being able to learn by experimentation and generalization.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-047.pdf,
46,1984,Learning,Learning About Systems That Contain State Variables,Thomas G. Dietterich,"It is difficult to learn about systems that contain state variables when those variables are not directly observable. This paper formalizes this learning problem and presents a method called the iterative extension method for solving it. In the iterative extension method, the learner gradually constructs a partial theory of the state-containing system. At each stage, the learner applies this partial theory to interpret the I/O behavior of the system and obtain additional constraints on the structure and values of its state variables. These constraints can be applied to extend the partial theory by hypothesizing additional internal state variables. The improved theory can then be applied to interpret more complex I/O behavior. This process continues until a theory of the entire system is obtained. Several sufficient conditions for the success of this method are presented including (a) the observability and decomposability of the state information in the system. (b) the learnability of individual state transitions in the system, (c) the ability of the learner to perform synthesis of straight-line programs and conjunctive predicates from examples and (d) the ability of the learner to perform theory-driven data interpretation. The method is being implemented and applied to the problem of learning UNIX file system commands by observing a tutorial interaction with UNIX.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-048.pdf,
47,1984,Learning,Towards Chunking as a General Leaming Mechanism,"John E. Laird, Paul S. Rosenbloom, Allen Newell","Chunks have long been proposed as a basic organizational unit for human memory. More recently chunks have been used to model human learning on simple perceptual-motor skills. In this paper we describe recent progress in extending chunking to be a general learning mechanism by implementing it within a general problem solver. Using the Soar problem-solving architecture, we take significant steps toward a general problem solver that can learn about all aspects of its behavior. We demonstrate chunking in Soar on three tasks: the Eight Puzzle, Tic-Tat-Toe, and a part of the RI computer-configuration task. Not only is there improvement with practice, but chunking also produces significant transfer of learned behavior, and strategy acquisition.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-049.pdf,
48,1984,Learning,Maintaining Diversity in Genetic Search,Michael L. Mauldin,"Genetic adaptive algorithms provide an efficient way to search large function spaces, and are increasingly being used in learning systems. One problem plaguing genetic learning algorithms is premature convergence, or convergence of the pool of active structures to a sub-optimal point in the space being searched. An improvement to the standard genetic adaptive algorithm is presented which guarantees diversity of the gene pool throughout the search. Maintaining genetic diversity is shown to improve off-line (or best) performance of these algorithms at the expense of poorer on-line (or average) performance, and to retard or prevent premature convergence.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-050.pdf,
49,1984,Learning,Constraint-Based Generalization: Learning Game-Playing Plans From Single Examples,Steven Minton,"Constraint-based Generalization is a technique for deducing generalizations from a single example. We show how this technique can be used for learning tactical combinations in games and discuss an implementation which learns forced wins in tic-tat-toe, go-moku, and chess.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-051.pdf,
50,1984,Learning,Generalization for Explanation-Based Schema Acquisition,Paul O'Rorke,"This paper is about explanation-based learning for heuristic problem solvers which ""build"" solutions using schemata (frames like scripts) as both ""bricks"" and ""mortar"". The heart of the paper is a description of a generalization method which is designed to extract as much information as possible from examples of successful problem solving behavior. A related generalizer, (less powerful but more efficient), has been implemented as part of an experimental apprentice.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-052.pdf,
51,1984,Learning,Leaming Operator Transformations,"Bruce Porter, Dennis Kibler",A relational model representation of the effect of operators is learned and used to improve the acquisition of heuristics for problem solving. A model for each operator in a problem solving domain is learned from example applications of the operator. The representation is shown to improve the rate of learning heuristics for solving symbolic integration problems.,https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-053.pdf,
52,1984,Natural Language,Referential Determinism and Computational Efficiency: Posting Constraints from Deep Structure,"Gavan Duffy, John C. Mallery","Most transformational linguists would no longer create explicit deep structures. Instead they adopt a surface-interpretive approach. We find deep structures indispensable for projection into a semantic network. In conjunction with a reference architecture based on constraint-posting, they minimize referential non-determinisms. We extend Marcus’ Determinism Hypothesis to include immediate reference, a foundational subc!ass of reference. This Referential Determinism Hypothesis, constitutes a semantic constraint on theories of syntactic analysis, arguing for theories that minimize referential non-determinism. We show that our combination of deep structures and constraint-posting eliminates non-determinism in immediate reference. We conclude that constraint-posting, deep-structure parsers satisfy the referential determinism hypothesis.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-054.pdf,
53,1984,Natural Language,A Semantic Process for Syntactic Disambiguation,Graeme Hirst,"Structural ambiguity in a sentence cannot be resolved without semantic help. We present a process for structural disambiguation that uses verb expectations, presupposition satisfaction, and plausibility, and an algorithm for making the final choice when these cues give conflicting information. The process, called the Semantic Enquiry Desk, is part of a semantic interpreter that makes sure all its partial results are well-formed semantic objects; it is from this that it gains much of its power.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-055.pdf,
54,1984,Natural Language,Living Up To Expectations: Computing Expert Responses,"Aravind Joshi, Bonnie Webber, Ralph M. Weischedel","In cooperative man-machine interaction, it is necessary but not sufficient for a system to respond truthfully and informatively to a user’s question. In particular, if the system has reason to believe that its planned response might mislead the user, then it must block that conclusion by modifying its response. This paper focusses on identifying and avoiding potentially misleading responses by acknowledging types of ""informing behavior"" usually expected of an expert. We attempt to give a formal account of several types of assertions that should be included in response to questions concerning the achievement of some goal (in addition to the simple answer), lest the questioner otherwise be misled.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-056.pdf,
55,1984,Natural Language,Frame Selection in Parsing,Steven L. Lytinen,"The problem of frame selection in parsing is discussed, with the focus on the selection of a frame for texts which contain highly ambiguous or vague words. An approach to frame selection is presented which involves the use of a small number of general inference rules, in conjunction with a hierarchically-organized conceptual memory. This is in contrast to various other methods, which rely either on disambiguation rules stored in the dictionary definitions of ambiguous words, or on previously-activated frames to guide the selection of new frames. The selection of frames for vague or ambiguous words using these previous methods is shown to be problematic. The method presented here does not suffer from these same problems because of the hierarchical organization of memory and the general inference rules used.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-057.pdf,
56,1984,Natural Language,A Production Rule System for Message Summarization,"Elaine Marsh, Henry Hamburger, Ralph Grishman","In summarizing a message, it is necessary to access knowledge about linguistic relations, subject matter knowledge about the domain of discourse, and knowledge about the user’s goals for the summary. This paper investigates the feasibility of integrating these knowledge sources by using computational linguistic and expert system techniques to generate one-line summaries from the narrative content of a class of Navy messages. For deriving a knowledge representation of the narrative content, we have adapted an approach developed by Sager et al. at New York University. This approach, called information formatting, uses an explicit grammar of English and a classification of the semantic relationships within the domain to derive a tabular representation of the information in a message narrative. A production system, written in OPS5, then interprets the information in the table and automatically generates a summary line. The use of a production rule system provides insight into the mechanisms of summarization. A comparison of computer-generated summaries with those obtained manually showed good agreement, indicating that it is possible to automatically process message narrative and generate appropriate, and ultimately useful, summaries.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-058.pdf,
57,1984,Perception,Reconstructing a Visible Sufface,A. Blake,"We address the problem of reconstructing the visible surface in stereoscopic vision. We point out the need for viewpoint invariance in the reconstruction scheme and demonstrate the undesirable ""wobble"" effect that can occur when such invariance is lacking. The design of an invariant scheme is discussed.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-059.pdf,
58,1984,Perception,A System of Plans for Connected Speech Recognition,"Renato DeMori, Yu F. Mong",A planning system for recognising connected letters is described and some preliminary experimental results are reported.,https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-060.pdf,
59,1984,Perception,A Representation for Image Curves,David H. Marimont,"A representation for image curves and an algorithm for its computation are introduced. The representation is designed to facilitate matching of image curves to completely specified model plane curves and estimation of their orientation in space, despite the presence of noise. variable resolution, or partial occlusion. This is an important subproblem of model-based vision. A curve may be represented at a variety of scales, and a strategy for selecting natural scales is proposed. At each scale, the representaion is simply a list of positions in the plane, with tangent directions and curvatures specified at each position; each curvature is either a zero or an extremum (hereafter critical points). The algorithm for computing the representation involves smoothing with gaussians at different scales: extracting tile critical points from the smoothed curves. and using dynamic programming to construct a list of critical points which best approximate the curve for each length of list possible. We propose to examine the tradeoff between the error of the approximation and length of the lists to find natural scales.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-062.pdf,
60,1984,Perception,Shading Into Texture,Alex P. Pentland,"Shape-from-shading and shape-from-texture methods have the serious drawback that they are applicable only to smooth surfaces, while real surfaces are often rough and crumpled. To extend such methods to real surfaces we must have a model that also applies to rough surfaces. The fractal surface model [Pentland 831 provides a formalism that is competent to describe such natural 3-D surfaces and, in addition, is able to predict human perceptual judgments of smoothness versus roughness - thus allowing the reliable application of shape estimation techniques that assume smoothness. This model of surface shape has been used to derive a technique for 3-D shape estimation that treats shading and texture in a unified manner.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-063.pdf,
61,1984,Perception,"Efficient Multiresolution Algorithms for Computing Lightness, Shape-From-Shading, and Optical Flow",Demetri Terzopoulos,"Problems in machine vision that are posed as variational principles or partial differential equations can often be solved by local, iterative, and parallel algorithms. A disadvantage of these algorithms is that they are inefficient at propagating constraints across large visual representations. Application of multigrid methods has overcome this drawback with regard to the computation of visible-surface representations. We argue that our multiresolution approach has wide applicability in vision. In particular, we describe efficient multiresolution iterative algorithms for computing lightness, shape-from-shading, and optical flow, and evaluate the performance of these algorithms using synthesized images.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-064.pdf,
62,1984,Perception,The Shape of Subjective Contours,"Jon A. Webb, Edward Pervin","We develop a theoretical framework for interpolating visual contours and apply it to subjective contours. The theory is based on the idea of consistency: a curve fitting algorithm must give consistent answers when presented with more data consistent with its hypothesis, or the same data under different conditions. Using this assumption, we prove that the subjective contour through two point-tangents is a parabola. We extend the theory to include multiple point-tangents and points. Sample output of programs implementing the theory is provided.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-065.pdf,
63,1984,Perception,Fingerprints Theorems,"A. L. Yuille, T. Poggio","We prove that the scale map of the zero-crossings of almost all signals filtered by a gaussian of variable size determines the signal uniquely, up to a constant scaling. Exceptions are signals that are antisymmetric about all their zeros (for instance infinitely periodic gratings). Our proof provides a method for reconstructing almost all signals from knowledge of how the zero-crossing contours of the signal, filtered by a gaussian filter, change with the size of the filter. The proof assumes that the filtered signal can be represented as a polynomial of finite, albeit possibly very high, order. The result applies to zero- and level-crossings of signals filtered by gaussian filters. The theorem is extended to two dimensions, that is to images. These results imply that extrema (for instance of derivatives) at different scales are a complete representation of a signal.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-066.pdf,
64,1984,Robotics,Task Frames in Robot Manipulation,Dana H. Ballard,"Most robotics computations refer to a single world- based frame of reference; however, several advantages accrue with the introduction of a second frame, termed a task frame. A task frame is a coordinate frame that can be attached to different objects that are to be manipulated. The task frame is related to the world-based coordinate frame by a simple geometric transformation. The virtues of such a frame are: (1) certain actions that are difficult to specify in the world frame are easily expressed in the task frame: (2) the task-frame to task-uorld transformation provides a formalism for describing physical actions; and (3) the task frame can be related to the world frame by proprioception.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-067.pdf,
65,1984,Robotics,Path Relaxation: Path Planning for a Mobile Robot,Charles E. Thorpe,"Path Relaxation is a method of planning safe paths around obstacles for mobile robots. It works in two steps: a global grid starch that finds a rough path, followed by a local relaxation step that adjusts each node on the path to lower the overall path cost. The representation used by Path Relaxation allows an explicit tradeoff among length of path, clearance away from obstacles, and distance traveled through unmapped areas.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-068.pdf,
66,1984,Robotics,Three Findpath Problems,Richard S. Wallace,"Three findpath problems are considered. First, the problem of finding a collision-free trajectory for a tentacle manipulator is examined. Second, a new findpath algorithm for a mobile robot rover is presented. This algorithm differs from earlier ones in its use of quantitative information about the uncertainty in the position of the robot to keep the robot away from obstacles without going too near them and without going too far out of its way to avoid them. Third, a method for coordinating two moving arms so that they avoid collisions with each other is presented. The two-arm findpath algorithm here is restricted to cases where coordinated collision-free trajectories can be found by controlling the velocities of the arms. Each of these findpath problemssuggests a heuristic end of the paper.",https://aaai.org/Library/AAAI/1984/../../../Papers/AAAI/1984/AAAI84-069.pdf,
