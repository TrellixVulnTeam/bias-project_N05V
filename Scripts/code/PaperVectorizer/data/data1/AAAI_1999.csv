,conference_year,category,title,author,abstract,download_url,keywords
0,1999,Technical Papers,Time-Quality Tradeoffs in Reallocative Negotiation with Combinatorial Contract Types,"Martin Andersson and Tuomas Sandholm, Washington University","The capability to reallocate items - e.g. tasks, securities, bandwidthslices, Mega Watt hours of electricity, and collectibles - is a keyfeature in automated negotiation. Especially when agents havepreferences over combinations of items, this is highly nontrivial.Marginal cost based reallocation leads to an anytime algorithm whereevery agent’s payoff increases monotonically over time. Differentcontract types head toward different locally optimal allocations ofitems, and OCSM-contracts head toward the global optimum. Reaching itcan take impractically long, so it is important to trade off solutionquality against negotiation time. To construct negotiation protocolsthat lead to good allocations quickly, we evaluated original (O),cluster (C), swap (S), and multiagent (M) contracts experimentally.O-contracts led to the highest social welfare when the ratio of agentsto tasks was large, and C-contract were best when that ratio was small.O-contracts led to the largest number of contracts made.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-001.pdf,
1,1999,Technical Papers,"Power, Dependence and Stability in Multiagent Plans","Sviatoslav Brainov and Tuomas Sandholm, Washington University","In this paper we present a decision-theoretic model of social power andsocial dependence that accounts for origins of different choicesavailable in different situations. According to the model almost everygroup activity, whether it is cooperation or exploitation, has itsorigins in resolving some dependence or power relation. The model isintended for self-interested agents and explains power and dependence interms of relations between agents’ plans. It is a generalization of thedependence network model and accounts for situations of groupdependence, i.e., situations in which an agent depends on a group or agroup depends on an agent. The model is applied to the analysis ofstability of multiagent plans. Stable dependence structures ofmultiagent plans are identified. Necessary and sufficient conditions forstability of joint plans are provided.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-002.pdf,
2,1999,Technical Papers,Combatting Maelstroms in Networks of Communicating Agents,"James E. Hanson and Jeffrey O. Kephart, IBM Thomas J. Watson Research Center","Multi-agent systems in which agents can respond to messages byautomatically generating and multi-casting other messages are inherentlyvulnerable to a phenomenon we call a maelstrom. We define a maelstrom tobe a self-sustaining chain reaction in which a single message canunintentionally trigger the generation of a rapidly growing, potentiallyinfinite number of messages, quickly incapacitating the communicationsnetwork. There is reason to fear that modest advances in agenttechnology and usability could lead to spontaneous maelstroms on theInternet in the near future, particularly in the realm of electronicmail. In this article we describe various classes of maelstrom that mayarise due to automated forwarding of messages, and propose a novel andpractical means of combatting them.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-003.pdf,
3,1999,Technical Papers,Learning Quantitative Knowledge for Multiagent Coordination,"David Jensen, Michael Atighetchi, Régis Vincent, and Victor Lesser, University of Massachusetts at Amherst","A central challenge of multiagent coordination is reasoning about howthe actions of one agent can affect the actions of another. Knowledge ofthese interrelationships can help coordinate agents -- preventingconflicts and exploiting beneficial relationships among actions. Weexplore three interlocking methods that can be used to learnquantitative knowledge of such non-local effects in TAEMS, awell-developed framework for multiagent coordination. The surprisingsimplicity and effectiveness of these methods demonstrates how agentscan learn domain-specific knowledge quickly, extending the utility ofcoordination frameworks that explicitly represent coordinationknowledge.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-004.pdf,
4,1999,Technical Papers,Distributed Games: From Mechanisms to Protocols,"Dov Monderer and Moshe Tennenholtz, Technion - Israel Institute of Technology","The theory of mechanism design in economics/game theorydeals with a center who wishes to maximize an objectivefunction which depends on a vector of information variables.The value of each variable is known only to a selfish agent,which is not controlled by the center. In order to obtain itsobjective the center constructs a game, in which every agentparticipates and reveals its information, because these actionsmaximize its utility. However, several crucial newissues arisewhen one tries to transform existing economic mechanismsinto protocols to be used in computational environments. Inthis paper we deal with two such issues: 1. The communicationstructure, and 2. the representation (syntax) of theagents’ information. The existing literature on mechanismdesign implicitly assumes that these two features are not relevant.In particular, it assumes a communication structurein which every agent is directly connected to the center. Wepresent new protocols that can be implemented in a large varietyof communication structures, and discuss the sensitivityof these protocols to the way in which information is presented.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-005.pdf,
5,1999,Technical Papers,Evolutionary Economic Agents,"Fergus Nolan, Jarek Wilkiewicz, Dipankar Dasgupta, and Stan Franklin, The University of Memphis","An empirical work is described which compares the optimization levelsproduced by a group of economic agents versus those of a similar groupof economic agents which additionally employ a Genetic Algorithm toattain a higher level of optimization. The problem domain is multimodal.It incorporates multiple hard and soft constraints, and dynmicalbehaviors. It has areas of infeasibility and non-linear behaviors. Thesimulated model environment provides several types of sensors, actuatorsand opportunities for inter-agent resource mediation. Evidence isoffered to support the theory that multiple weak methods, operating inconcert, on a shared problem, can produce better results than theindividual weak methods acting alone. The problem area is resistant tothe use of strong methods.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-006.pdf,
6,1999,Technical Papers,Bargaining with Deadlines,"Tuomas Sandholm, Washington University, and Nir Vulkan, University of Bristol","This paper analyzes automated distributive negotiation where agents havefirm deadlines that are private information. The agents are allowed tomake and accept offers in any order in continuous time. We show that theonly sequential equilibrium outcome is one where the agents wait untilthe first deadline, at which point that agent concedes everything to theother. This holds for pure and mixed strategies. So, interestingly,rational agents can never agree to a nontrivial split because offerssignal enough weakness of bargaining power (early deadline) so that therecipient should never accept. Similarly, the offerer knows that itoffered too much if the offer gets accepted: the offerer could have donebetter by out-waiting the opponent. In most cases, the deadline effectcompletely overrides time discounting and risk aversion: an agent’spayoff does not change with its discount factor or risk attitude.Several implications for the design of negotiating agents are discussed.We also present an effective protocol that implements the equilibriumoutcome in dominant strategies.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-007.pdf,
7,1999,Technical Papers,Verifying that Agents Implement a Communication Language,"Michael Wooldridge, Queen Mary & Westfield College","In recent years, a number of attempts have been made to developstandardized agent communication languages. A key issue in suchlanguages is that of conformance testing. That is, given a program whichclaims to semantically conform to some agent communication standard, howcan we determine whether or not it does indeed conform to it? In thisarticle, we present an expressive agent communication language, and givea semantics for this language in such a way that verifying semanticconformance becomes a realistic possibility. The techniques we developdraw upon those used to give a semantics to reactive systems intheoretical computer science. To illustrate the approach, we give anexample of a simple agent system, and show that it does indeed respectthe semantics.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-008.pdf,
8,1999,Technical Papers,"AI & the World Wide WebRecognizing Structure in Web Pages Using Similarity Queries","William W. Cohen, AT&T Labs - Research","We present general-purpose methods for recognizing certain types ofstructure in HTML documents. The methods are implemented using WHIRL, a""soft"" logic that incorporates a notion of textual similarity developedin the information retrieval community. In an experimental evaluation on82 Web pages, the top-ranked structure is ""meaningful"" (a structure thatwas used in a hand-coded ""wrapper"" for the page) nearly 70% of the time,improving on a value of 50% obtained by an earlier method. Withappropriate background information, the structure-recognition methods wedescribe can also be used to learn a wrapper from examples, or formaintaining a wrapper as a Web page changes format. In these settings,this measure of performance can improved to 85%.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-009.pdf,
9,1999,Technical Papers,Navigational Plans for Data Integration,"Marc Friedman, Alon Levy, and Todd Millstein, University of Washington","We consider the problem of building data integration systems when thedata sources are webs of data, rather than sets of relations. Previousapproaches to modeling data sources are inappropriate in this contextbecause they do not capture the relationships between linked data andthe need to navigate through a paths in the data source in order toobtain certain pieces of data. We first describe a language for modelingdata sources in this new context. We show that our language has therequired expressive power, and that minor extensions to it would causesignificant computational cost in answering queries. We provide a soundand complete algorithm for reformulating a user query into a query overthe data sources, and we show how to create query execution plans thatboth query and navigate the data sources.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-010.pdf,
10,1999,Technical Papers,Regression Testing for Wrapper Maintenance,"Nicholas Kushmerick, University College Dublin","Recent work on Internet information integration assumes a library ofwrappers, specialized information extraction procedures. Maintainingwrappers is difficult, because the formatting regularities on which theyrely often change. The wrapper verification problem is to determinewhether a wrapper is correct. Standard regression testing approaches areinappropriate, because both the formatting regularities and a site’sunderlying content may change. We introduce RAPTURE, afully-implemented, domain-independent verification algorithm. RAPTUREuses well-motivated heuristics to compute the similarity between awrapper’s expected and observed output. Experiments with 27 actualInternet sites show a substantial performance improvement over standardregression testing.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-011.pdf,
11,1999,Technical Papers,A Knowledge-Based Approach to Organizing Retrieved Documents,"Wanda Pratt, University of California, Irvine; Marti A. Hearst, University of California, Berkeley; Lawrence M. Fagan, Stanford University","When people use computer-based tools to find answers to generalquestions, they often are faced with a daunting list of search resultsor hits returned by the search engine. Many search tools address thisproblem by helping users to make their searches more specific. However,when dozens or hundreds of documents are relevant to their question,users need tools that help them to explore and to understand theirsearch results, rather than ones that eliminate a portion of thoseresults. In this paper, we present DynaCat, a tool that dynamicallycategorizes search results into a hierarchical organization by usingknowledge of important kinds of queries and a model of the domainterminology. Results from our evaluation show that DynaCat helps usersfind answers to those important types of questions more quickly andeasily than when they use a relevance-ranking system or a clusteringsystem.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-012.pdf,
12,1999,Technical Papers,A Limitation of the Generalized Vickrey Auction in Electronic Commerce: Robustness against False-Name Bids,"Yuko Sakurai, Makoto Yokoo, and Shigeo Matsubara, NTT Communication Science Laboratories","Electronic Commerce (EC) has rapidly grown with the expansion of theInternet. Among these activities, auctions have recently achieved hugepopularity, and have become a promising field for applying agent andArtificial Intelligence technologies. Although the Internet provides aninfrastructure for much cheaper auctioning with many more sellers andbuyers, we must consider the possibility of a new type of cheating,i.e., an agent tries to get some profit by submitting several bids underfictitious names (false-name bids). Although false-name bids are easierto execute than forming coalitions, the vulnerability of auctionprotocols to false-name bids has not been discussed before. In thispaper, we examine the robustness of the generalized Vickrey auction(G.V.A.) against false-name bids. The G.V.A. has the best theoreticalbackground among various auction mechanisms, i.e., it has proved to beincentive compatible and be able to achieve a Pareto efficientallocation. We show that false-name bids can be effective, i.e., theG.V.A. is no longer incentive compatible under the possibilities offalse-name bids, when the marginal utility of an item increases or goodsare complements. Moreover, we prove that under these conditions, thereexists no single-round sealed-bid auction protocol that simultaneouslysatisfies individual rationality, Pareto efficiency, and incentivecompatibility.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-013.pdf,
13,1999,Technical Papers,Hybrid Neural Plausibility Networks for News Agents,"Stefan Wermter, Christo Panchev, and Garen Arevian, University of Sunderland","This paper describes a learning news agent HyNeT which uses hybridneural network techniques for classifying news titles as they appear onan internet newswire. Recurrent plausibility networks with local memoryare developed and examined for learning robust text routing. HyNeT isdescribed for the first time in this paper. We show that a carefulhybrid integration of techniques from neural network architectures,learning and information retrieval can reach consistent recall andprecision rates of more than 92% on an 82 000 word corpus; this isdemonstrated for 10 000 unknown news titles from the Reuters newswire.This new synthesis of neural networks, learning and informationretrieval techniques allows us to scale up to a real-world task anddemonstrates a lot of potential for hybrid plausibility networks forsemantic text routing agents on the internet.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-014.pdf,
14,1999,Cognitive Systems,Cognitive Classification,"Janet Aisbett and Greg Gibbon, The University of Newcastle","Classification assigns an entity to a category on the basis of featurevalues encoded from a stimulus. Provided they are presented withsufficient training data, inductive classifier builders such as C4.5 arelimited by encoding deficiencies and noise in the data, rather than bythe method of deciding the category. However, such classificationtechniques do not perform well on the small, dirty /or and dynamic datasets which are all that are available in many decision making domains.Moreover, their computational overhead may not be justified. This paperdraws on conjectures about human categorization processes to design afrugal algorithm for use with such data. On presentation of anobservation, case-specific rules are derived from a small subset of thestored examples, where the subset is selected on the basis of similarityto the encoded stimulus. Attention is focused on those features thatappear to be most useful for distinguishing categories of observationssimilar to the current one. A measure of logical semantic informationvalue is used to discriminate between categories that remain plausibleafter this. The new classifier is demonstrated against neural net anddecision tree classifiers on some standard UCI data sets and shown toperform well.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-015.pdf,
15,1999,Cognitive Systems,What Are Contentful Mental States? Dretske’s Theory of Mental Content Viewed in the Light of Robot Learning and Planning Algorithms,"Paul Cohen, University of Massachusetts, and Mary Litch, University of Alabama","One concern of philosophy of mind is how sensorimotor agents such ashuman infants can develop contentful mental states. This paper discussesFred Dretske’s theory of mental content in the context of results fromour work with mobile robots. We argue that Dretske’s theory, whileattractive in many ways, relies on a distinction between kinds ofrepresentations that cannot be practically maintained when the subjectof one’s study is robotic agents. In addition, Dretske fails todistinguish classes of representations that carry different kinds ofmental content. We conclude with directions for a theory of mentalcontent that maintains the strengths of Dretske’s theory.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-016.pdf,
16,1999,Cognitive Systems,Student-Sensitive Multimodal Explanation Generation for 3D Learning Environments,"Brent H. Daniel, North Carolina State University; William H. Bares, University of Southwestern Louisiana; Charles B. Callaway and James C. Lester, North Carolina State University","Intelligent multimedia systems hold great promise for knowledge-basedlearning environments. Because of recent advances in our understandingof how to dynamically generate multimodal explanations and the rapidgrowth in the performance of 3D graphics technologies, it is becomingfeasible to create multimodal explanation generators that operate inrealtime. Perhaps most compelling about these developments is theprospect of enabling generators to create explanations that arecustomized to the ongoing ""dialogue"" in which they occur. To addressthese issues, we have developed a student-sensitive multimodalexplanation generation framework that exploits a discourse history toautomatically create explanations whose content, cinematography, andaccompanying natural language utterances are customized to the dialoguecontext. By these means, they create integrative explanations thatactively promote knowledge integration. This framework has beenimplemented in CineSpeak, student-sensitive multimodal explanationgenerator and incorporated in a testbed learning environment for thedomain of botanical anatomy and physiology.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-017.pdf,
17,1999,Cognitive Systems,Moving Right Along: A Computational Model of Metaphoric Reasoning about Events,"Srinivas Narayanan, University of California, Berkeley","This paper describes the results of an implemented computational modelthat cashes out the belief that reasoning about abstract events andactions relies on metaphoric projections of embodied primitives. Thespecific task addressed is the interpretation of simple causalnarratives in the domains of Politics and Economics. The stories aretaken from newspaper articles in these domains. When presented with a surface-parsed version of these narratives as input, the systemdescribed is able to generate commonsense inferences consistent with theinput. Our results show the surprising number, variety, and subtlety ofroles played by embodied features in processing narratives aboutabstract plans and actions.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-018.pdf,
18,1999,Cognitive Systems,Delivering Hints in a Dialogue-Based Intelligent Tutoring System,"Yujian Zhou, Illinois Institute of Technology; Reva Freedman, University of Pittsburgh; Michael Glass, Illinois Institute of Technology; Joel A. Michael and Allen A. Rovick, Rush Medical College; Martha W. Evens, Illinois Institute of Technology","Hinting is an important tutoring tactic in one-on-one tutoring, usedwhen the tutor needs to respond to an unexpected answer from thestudent. To issue a follow up hint that is pedagogically helpful andconversationally smooth, the tutor needs to suit the hinting strategy tothe student’s need while making the strategy fit in with the high leveltutoring plan and the tutoring context. This paper describes a study ofthe hinting strategies in a corpus of human tutoring transcripts and theimplementation of these strategies in a dialogue-based intelligenttutoring system, Circsim-Tutor v. 2. We isolated a set of hintingstrategies from human tutoring transcripts. We describe our analysis ofthese strategies and a model for choosing among them based on domainknowledge, the type of error made by the student, the focus of thetutor’s question, and the conversational history. We have tested ourmodel with two classes totaling 74 medical students. Use of thisextended model of hinting increases the percentage of questions thatstudents are able to answer for themselves rather than needing to betold.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-019.pdf,
19,1999,Constraint Satisfaction Problems,On Integrating Constraint Propagation and Linear Programming for Combinatorial Optimization,"John N. Hooker, Carnegie Mellon University; Greger Ottosson, Uppsala University; Erlendur S. Thorsteinsson and Hak-Jin Kim, Carnegie Mellon University","Linear programming and constraint propagation are complementarytechniques with the potential for integration to benefit the solution ofcombinatorial optimization problems. Attempts to combine them havemainly focused on incorporating either technique into the framework ofthe other -- traditional models have been left intact. We argue that arethinking of our modeling traditions is necessary to achieve thegreatest benefit of such an integration. We propose a declarativemodeling framework in which the structure of the constraints indicateshow LP and CP can interact to solve the problem.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-020.pdf,
20,1999,Constraint Satisfaction Problems,Hierarchical Constraint Satisfaction in Spatial Databases,"Dimitris Papadias, Panos Kalnis, and Nikos Mamoulis, Hong Kong University of Science and Technology","Several content-based queries in spatial databases and geographicinformation systems (GISs) can be modelled and processed as constraintsatisfaction problems (CSPs). Regular CSP algorithms, however, work formain memory retrieval and do not utilize secondary memory indices toprune the search space. This paper shows how systematic and local searchtechniques can take advantage of the hierarchical decomposition ofspace, preserved by spatial data structures, to efficiently guidesearch. We study the conditions under which hierarchical constraintsatisfaction outperforms traditional methods with extensiveexperimentation.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-021.pdf,
21,1999,Constraint Satisfaction Problems,A Constraint-Based Model for Cooperative Response Generation in Information Dialogues,"Yan Qu, CLARITECH Corporation, and Steve Beale, New Mexico State University","This paper presents a constraint-based model for cooperative responsegeneration for information systems dialogues, with an emphasis ondetecting and resolving situations in which the user’s information needshave been over-constrained. Our model integrates and extends the AItechniques of constraint satisfaction, solution synthesis and constrainthierarchy to provide an incremental computational mechanism forconstructing and maintaining partial parallel solutions. Such amechanism supports immediate detection of over-constrained situations.In addition, we explore using the knowledge in the solution synthesisnetwork to support different relaxation strategies.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-022.pdf,
22,1999,Constraint Satisfaction Problems,Solving Crossword Puzzles as Probabilistic Constraint Satisfaction,"Noam M. Shazeer, Michael L. Littman, and Greg A. Keim, Duke University","Crossword puzzle solving is a classic constraint satisfaction problem,but, when solving a real puzzle, the mapping from clues to variabledomains is not perfectly crisp. At best, clues induce a probabilitydistribution over viable targets, which must somehow be respected alongwith the constraints of the puzzle. Motivated by this type of problem,we provide a formal model of constraint satisfaction with probabilisticpreferences on variable values. Two natural optimization problems aredefined for this model: maximizing the probability of a correctsolution, and maximizing the number of correct words (variable values)in the solution. We provide an efficient iterative approximation for thelatter based on dynamic programming and present very encouraging resultson a collection of real and artificial crossword puzzles.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-023.pdf,
23,1999,Constraint Satisfaction Problems,Encodings of Non-Binary Constraint Satisfaction Problems,"Kostas Stergiou and Toby Walsh, University of Strathclyde","We perform a detailed theoretical and empirical comparison of the dualand hidden variable encodings of nonbinary constraint satisfactionproblems. We identify a simple relationship between the two encodings byshowing how we can translate between the two by composing or decomposingrelations. This translation suggests that we will tend to achieve morepruning in the dual than in the hidden variable encoding. We prove thatachieving arc-consistency on the dual encoding is strictly stronger thanachieving arc-consistency on the hidden variable, and this itself isequivalent to achieving generalized arc-consistency on the original(non-binary) problem. We also prove that, as a consequence of theunusual topology of the constraint graph in the hidden variableencoding, inverse consistencies like neighborhood inverse consistencyand path inverse consistency collapse down onto arc-consistency.Finally, we propose the ""double encoding,"" which combines together boththe dual and the hidden variable encodings.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-024.pdf,
24,1999,Constraint Satisfaction Problems,A Generic Customizable Framework for Inverse Local Consistency,"Gérard Verfaillie and David Martinez, ONERA-CERT; Christian Bessière, LIRMM-CNRS","Local consistency enforcing is at the core of CSP (ConstraintSatisfaction Problem) solving. Although arc consistency is still themost widely used level of local consistency, researchers are going oninvestigating more powerful levels, such as path consistency,k-consistency, (i,j)-consistency. Recently, more attention has beenturned to inverse local consistency levels, such as path inverseconsistency, k-inverse consistency, neighborhood inverse consistency,that do not suffer from the drawbacks of the other local consistencylevels (changes in the constraint definitions and in the constraintgraph, prohibitive memory requirements). In this paper, we propose ageneric framework for inverse local consistency that includes most ofthe previously defined levels and allows a rich set of new levels to bedefined. The first benefit of such a generic framework is to allow auser to define and test many different inverse local consistency levels,in accordance with the problem or even the instance he has to solve. Thesecond benefit is to allow a generic algorithm to be defined. Thisalgorithm, that is parameterized by the chosen inverse local consistencylevel, generalizes the AC7 algorithm used for arc consistency, andproduces from any instance its locally consistent closure at the chosenlevel.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-025.pdf,
25,1999,Constraint Satisfaction Problems,Functional Elimination and 0/1/All Constraints,"YuanLin Zhang, Roland H. C. Yap, and Joxan Jaffar, National University of Singapore","We present new complexity results on the class of 0/1/All constraints.The central idea involves functional elimination, a general method ofelimination whose focus is on the subclass of functional constraints.One result is that for the subclass of All constraints, strongn-consistency and minimality is achievable in O(en) time, where e, n arethe number of constraints and variables. The main result is that we cansolve 0/1/All constraints in O(e(d+n)) time, where d is the domain size.This is an improvement over known results, which are O(ed(d+n)).Furthermore, our algorithm also achieves strong n-consistency andminimality.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-026.pdf,
26,1999,Hybrid Methods,An Evolvable Hardware Chip and Its Application as a Multi-Function Prosthetic Hand Controller,"Isamu Kajitani and Tsutomu Hoshino, University of Tsukuba; Nobuki Kajihara, Adaptive Devices NEC Laboratory, RWCP; Masaya Iwata and Tetsuya Higuchi, Electrotechnical Laboratory","This paper describes the application of genetic algorithms to thebiomedical engineering problem of a multi-function myoelectricprosthetic hand controller. This is achieved by an innovative LSI chip(EHW chip), i.e., a VLSI implementation of Evolvable Hardware (EHW),which can adapt its own circuit structure to its environmentautonomously and quickly by using genetic algorithms. This paper showsthat the EHW chip controller is a viable alternative to neural networkcontrollers. There are plans to commercialize the prosthetic hand withthe EHW chip, and the medical department of Hokkaido University hasalready decided to adopt this for clinical treatment.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-027.pdf,
27,1999,Hybrid Methods,Initializing RBF-Networks with Small Subsets of Training Examples,"Miroslav Kubat and Martin Cooperson, Jr., University of Southwestern Louisiana","An important research issue in RBF networks is how to determine thegaussian centers of the radial-basis functions. We investigate atechnique that identifies these centers with carefully selected trainingexamples, with the objective to minimize the network’s size. Theessence is to select three very small subsets rather than one largersubset whose size would exceed the size of the three small subsetsunified. The subsets complement each other in the sense that when usedby a nearest-neighbor classifier, each of them incurs errors in adifferent part of the instance space. The paper describes the example-selection algorithm and shows, experimentally, its merits in thedesign of RBF networks.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-028.pdf,
28,1999,Hybrid Methods,A Neural Network Model of Dynamically Fluctuating Perception of Necker Cube as well as Dot Patterns,"Hiroaki Kudo, Nagoya University; Tsuyoshi Yamamura, Aichi Prefectural University; Noboru Ohnishi, Nagoya University; Shin Kobayashi and Noboru Sugie, Meijo University","The mechanism underlying perceptual grouping of visual stimuli is notstatic, but dynamic. In this paper, the dynamical grouping process isimplemented with a neural network model consisting of an array of(hyper)columns suggested by Hubel & Wiesel, where intracolumnarinhibition and intercolumnar facilitation are incorporated. The modelwas applied successfully to figures consisting of a set of dots yieldingeither of two ways of groupings from time to time due to neuralfluctuations and fatigue. Then the model was extended to introducedependency on fixation points as well as neural fluctuations andfatigue. Then, it was applied to the Necker Cube. The model output fromtime to time either of two ways of 3D interpretations depending on thefixation points.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-029.pdf,
29,1999,Hybrid Methods,What’s in a Fuzzy Set?,"Marco Piastra, Universitè degli Studi di Pavia","A modified version of the first-order logic of probability presented in(Halpern 1990) - with probability on possible worlds - makes it possibleto formulate an alternative characterisation of fuzzy sets. In thisapproach, fuzzy sets are no longer seen as primitive entities with anintuitive justification, but rather as structured entities emerging in asuitable logical framework. Some fuzzy techniques of practical relevanceare shown to be encodable in this way. In addition, the resultingapproach leads to a clearer epistemological analysis in that itclarifies the purposive nature of the kind of uncertainty that can bemodeled by fuzziness.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-030.pdf,
30,1999,Hybrid Methods,ARGUS: An Automated Multi-Agent Visitor Identification System,"Rahul Sukthankar, Just Research and Carnegie Mellon University; and Robert G. Stockton, Just Research","ARGUS is a multi-agent visitor identification system distributed overseveral workstations. Human faces are extracted from security cameraimages by a neural-network-based face detector, and identified asfrequent visitors by ARENA, a memory-based face recognition system.ARGUS then uses a messaging system to notify hosts that their guestshave arrived. An interface agent enables users to submit feedback, whichis immediately incorporated by ARENA to improve its face recognitionperformance. The ARGUS components were rapidly developed using JGram, anagent framework that is also detailed in this paper. JGram automaticallyconverts high-level agent specifications into Java source code, andassembles complex tasks by composing individual agent services into aJGram pipeline. ARGUS has been operating successfully in an outdoorenvironment for several months.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-031.pdf,
31,1999,Hybrid Methods,Implicative and Conjunctive Fuzzy Rules -- A Tool for Reasoning from Knowledge and Examples,"Laurent Ughetto, IRISA, IUT de Lannion; Didier Dubois and Henri Prade, IRIT - CNRS Université Paul Sabatier","Fuzzy rule-based systems have been mainly used as a convenient tool forsynthesizing control laws from data. Recently, in a knowledgerepresentation-oriented perspective, a typology of fuzzy rules has beenlaid bare, by emphasizing the distinction between implicative andconjunctive fuzzy rules. The former describe pieces of generic knowledgeeither tainted with uncertainty or tolerant to similarity, while thelatter encode examples-originated information expressing either merepossibilities or how typical situations can be extrapolated. Thedifferent types of fuzzy rules are first contrasted, and theirrepresentation discussed in the framework of possibility theory. Then,the paper studies the conjoint use of fuzzy rules expressing knowledge(as fuzzy constraints which restrict the possible states of the world),or gathering examples (which testify the possibility of appearance ofsome states). Coherence and inference issues are briefly addressed.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-032.pdf,
32,1999,Knowledge Acquisition,Does Prior Knowledge Facilitate the Development of Knowledge-Based Systems?,"Paul Cohen, University of Massachusetts; Vinay Chaudhri, SRI International; Adam Pease, Teknowledge; Robert Schrag, IET Inc.","One factor that affects the rate of knowledge base construction is theavailability and reuse of prior knowledge in ontologies anddomain-specific knowledge bases. This paper reports an empirical studyof reuse performed in the first year of the High Performance KnowledgeBases (HPKB) initiative. The study shows that some kinds of priorknowledge help more than others, and that several factors affect howmuch use is made of the knowledge.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-033.pdf,
33,1999,Knowledge Acquisition,Representing Problem-Solving for Knowledge Refinement,"Susan Craw and Robin Boswell, The Robert Gordon University","Knowledge refinement tools seek to correct faulty knowledge basedsystems (KBSs) by identifying and repairing potentially faulty rules.The goal of the KRUSTWorks project is to provide a source of refinementcomponents from which specialised refinement tools tailored to the needsof a range of KBSs are built. A core refinement algorithm reasons aboutthe knowledge that has been applied, but this approach demands generalknowledge structures to represent the reasoning of a particular problemsolving episode. This paper investigates some complex forms of ruleinteraction and defines a knowledge structure encompassing these. Theapproach has been applied to KBSs built in four shells and isdemonstrated on a small example that incorporates some of the complexityfound in real applications.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-034.pdf,
34,1999,Knowledge Acquisition,Deriving Expectations to Guide Knowledge Base Creation,"Jihie Kim and Yolanda Gil, University of Southern California","Successful approaches to developing knowledge acquisition tools useexpectations of what the user has to add or may want to add, based onhow new knowledge fits within a knowledge base that already exists. Whena knowledge base is first created or undergoes significant extensionsand changes, these tools cannot provide much support. This paperpresents an approach to creating expectations when a new knowledge baseis built, and describes a knowledge acquisition tool that we implementedusing this approach that supports users in creating problem-solvingknowledge. As the knowledge base grows, the knowledge acquisition toolderives more frequent and more reliable expectations that result fromenforcing constraints in the knowledge representation system, lookingfor missing pieces of knowledge in the knowledge base, and working outincrementally the inter-dependencies among the different components ofthe knowledge base. Our preliminary evaluations show a thirty percenttime savings during knowledge acquisition. Moreover, by providing toolsto support the initial phases of knowledge base development manymistakes are detected early on and even avoided altogether. We believethat our approach contributes to improving the quality of the knowledgeacquisition process and of the resulting knowledge-based systems aswell.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-035.pdf,
35,1999,Knowledge Acquisition,Designing Scripts to Guide Users in Modifying Knowledge-Based Systems,"Marcelo Tallis and Yolanda Gil, University of Southern California","Knowledge Acquisition (KA) Scripts capture typical modificationsequences that users follow when they modify knowledge bases. KA toolscan use these scripts to guide users in making these modifications,ensuring that they follow all the ramifications of the change until itis completed. This paper describes our approach to design, develop, andorganize a library of KA Scripts. We report the results of threedifferent analysis to develop this library, including a detail study ofactual modification scenarios in two knowledge bases. In addition toidentifying a good number of KA Scripts, we found a set of usefulattributes to describe and organize the KA Scripts. These attributesallow us to analyze the size of the library and generate new KA Scriptsin a systematic way. We have implemented a portion of this library andconducted two different studies to evaluate it. The result of thisevaluation showed a 28 to 36 percent time savings in modifying knowledgebases and that the library included relevant and useful KA Scripts toassist users in realistic settings.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-036.pdf,
36,1999,Knowledge Acquisition,An Integrated Shell and Methodology for Rapid Development of Knowledge-Based Agents,"Gheorghe Tecuci, Mihai Boicu, Kathryn Wright, Seok Won Lee, Dorin Marcu, and Michael Bowman, George Mason University","This paper introduces the concept of learning agent shell as a new classof tools for rapid development of practical end-to-end knowledge-basedagents, by domain experts, with limited assistance from knowledgeengineers. A learning agent shell consists of a learning and knowledgeacquisition engine as well as an inference engine and supports buildingan agent with a knowledge base consisting of an ontology and a set ofproblem solving rules. The paper describes a specific learning agentshell and its associated agent building methodology. The process ofdeveloping an agent relies on importing ontologies from existingrepositories of knowledge, using the Open Knowledge Base Connectivityprotocol, and on teaching the agent how to perform various tasks, in away that resembles how an expert would teach a human apprentice whensolving problems in cooperation. This shell and methodology represent apractical integration of knowledge representation, knowledgeacquisition, learning and problem solving, and are illustrated with aplanning agent that was developed and evaluated as part of the DARPA’sHigh Performance Knowledge Bases program.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-037.pdf,
37,1999,Knowledge Representation,A New Method for Consequence Finding and Compilation in Restricted Languages,"Alvaro del Val, Universidad Autènoma de Madrid","We introduce kernel resolution, a new complete method for first orderconsequence finding. The method generalizes Tison’s method for computingthe prime implicates of a propositional theory, in three ways: it isfirst order, it supports incremental and lazy computation, and it isindependent of any given search strategy. We also present twoapplications of the method. First, in the restricted form ofskip-filtered kernel (SFK) deduction, it can be used forconsequence-finding in restricted sublanguages, and for the related taskof finding the LUB approximation of a theory; of special interest is itsability to obtain approximations of polynomial size (e.g. all implicatesof size less than some constant). Directional resolution turns out to bean special case of SFK resolution. Second, we define an incrementalversion of one of the most successful knowledge compilation algorithms,with support for lazy and query-directed compilation.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-038.pdf,
38,1999,Knowledge Representation,Constraint-Based Integrity Checking in Abductive and Nonmonotonic Extensions of Constraint Logic Programming,"Aditya K. Ghose, University of Wollongong and Srinivas Padmanabhuni, University of Alberta, Edmonton","Recent research on the integration of the abductive and constraint logicprogramming paradigms has led to systems which are both expressive andcomputationally efficient. This paper investigates therole ofconstraints in integrity checking in the context of such systems.Providing support for constraints in this role leads to a framework thatis significantly more expressive, without sacrificing efficiency. Weaugment the Abductive Constraint Logic Programming framework withconstraint assumptions and provide model- and proof-theoretic accountsof two variants: one which involves commitment to such assumptions, andone which does not. We also show that such accounts extend easily to aconstraint logic programming framework which supports both negation andconstraint assumptions. The gains in expressivity in these frameworksturn out to be particularly useful in a variety of application domains,including scheduling and constraint database updates.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-039.pdf,
39,1999,Knowledge Representation,Partonomic Reasoning as Taxonomic Reasoning in Medicine,"Udo Hahn, Freiburg University; Stefan Schulz and Martin Romacker, Freiburg University and Freiburg University Hospital","The development of powerful, ubiquitous and comprehensive medicalontologies that support formal reasoning on a large scale is one of thekey requirements for advanced clinical computing. Taxonomic medicalknowledge, a major portion of these ontologies, is fundamentallycharacterized by is-a and part-whole relationships between concepts.While reasoning in generalization hierarchies is a well-understoodprocess, no fully conclusive mechanism as yet exists for partonomicreasoning. We here propose a new representation construct for part-wholerelations based on the formal framework of description logics, i.e., thewell-known concept language ALC, and show how part-whole reasoning cannaturally be emulated via classification-based reasoning withoutextending the expressiveness of the underlying terminological system.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-040.pdf,
40,1999,Knowledge Representation,Verbalization of High-Level Formal Proofs,"Amanda M. Holland-Minkley, Cornell University; Regina Barzilay, Columbia University; Robert L. Constable, Cornell University","We propose a new approach to text generation from formal proofs thatexploits the high-level and interactive features of a tactic-styletheorem prover. The design of our system is based on communicationconventions identified in a corpus of texts. We show how to use dialoguewith the theorem prover to obtain information that is required forcommunication but is not explicitly used in reasoning.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-041.pdf,
41,1999,Knowledge Representation,On Criteria for Formal Theory Building: Applying Logic and Automated Reasoning Tools to the Social Sciences,"Jaap Kamps, University of Amsterdam","This paper provides practical operationalizations of criteria forevaluating scientific theories, such as the consistency andfalsifiability of theories and the soundness of inferences, that takeinto account definitions. The precise formulation of these criteria istailored to the use of automated theorem provers and automated modelgenerators--generic tools from the field of automated reasoning. The useof these criteria is illustrated by applying them to a first order logicrepresentation of a classic organization theory, Thompson’sOrganizations in Action.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-042.pdf,
42,1999,Knowledge Representation,A Policy Description Language,"Jorge Lobo, Randeep Bhatia and Shamim Naqvi, Bell Labs","A policy describes principles or strategies for a plan of actiondesigned to achieve a particular set of goals. We define a policy as afunction that maps a series of events into a set of actions. In thispaper we introduce PDL, a simple but expressive language to specifypolicies. The design of the language has been strongly influenced by theaction languages of Geffner and Bonet [GB98] and Gelfond and Lifschitz[GL93b] and the composite temporal event language of Motakis and Zaniolo[MZ97]. The semantics is founded on recent results on formaldescriptions of action theories based on automata and their applicationto active databases. We summarize some complexity results on thehardness of evaluating polices and briefly describe the implementationof a policy server being used to provide centralized administration of asoft switch in a communication network.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-043.pdf,
43,1999,Knowledge Representation,A Semantic Decomposition of Defeasible Logics,"M. J. Maher and G. Governatori, Griffith University","We investigate defeasible logics using a technique which decomposes thesemantics of such logics into two parts: a specification of thestructure of defeasible reasoning and a semantics for the meta-languagein which the specification is written. We show that Nute’s DefeasibleLogic corresponds to Kunen’s semantics, and develop a defeasible logicfrom the well-founded semantics of Van Gelder, Ross and Schlipf. We alsoobtain a new defeasible logic which extends an existing language bymodifying the specification of Defeasible Logic. Thus our approach isproductive in analysing, comparing and designing defeasible logics.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-044.pdf,
44,1999,Knowledge Representation,Sacre: A Constraint Satisfaction Problem Based Theorem Prover,"Jean-Michel Richer and Jean-Jacques Chabrier, LIRSIA, Université de Bourgogne","The purpose of this paper is to present a new approach for solvingfirst-order predicate calculus problems stated in conjunctive normalform. We propose to combine resolution with the Constraint SatisfactionProblem (CSP) paradigm to prove the inconsistency and find a model of aproblem. The resulting method benefits from resolution and constraintsatisfaction techniques and seems very efficient when confronted to someproblems of the CADE-13 competition.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-045.pdf,
45,1999,Learning,Exploiting the Architecture of Dynamic Systems,"Xavier Boyen and Daphne Koller, Stanford University","Consider the problem of monitoring the state of a complex dynamicsystem, and predicting its future evolution. Exact algorithms for thistask typically maintain a belief state -- the distribution over thestates at some point in time. Unfortunately, these algorithms fail whenapplied to complex processes such as those represented as dynamicBayesian networks (DBNs), as the representation of the belief stategrows exponentially with the size of the process. Boyen and Kollerrecently proposed an efficient approximate tracking algorithm thatmaintains an approximate belief state that has a compact representationas a set of independent factors. Their analysis relies on a bound on theerror introduced by approximating a belief state of this process by afactored one. They argue informally that their algorithm is justified incases where the interaction between variables in the processes is""weak."" In this paper, we give formal information-theoretic definitionsfor notions such as weak interaction and sparse interaction ofprocesses. We use these notions to analyze the conditions under whichthe error induced by this type of approximation is small. We demonstrateseveral cases where our results formally support intuitions aboutstrength of interaction.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-046.pdf,
46,1999,Learning,Estimating Generalization Error Using Out-of-Bag Estimates,"Tom Bylander and Dennis Hanzlik, University of Texas at San Antonio","We introduce a mechanism called ""morphing"" for introducing structure orrandomness into a wide variety of problems. We illustrate the usefulnessof morphing by performing several different experimental studies. Thesestudies identify the impact of a ""small-world"" topology on the cost ofcoloring graphs, of asymmetry on the cost of finding the optimal TSPtour, and of the dimensionality of space on the cost of finding theoptimal TSP tour. We predict that morphing will find many other uses.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-047.pdf,
47,1999,Learning,Relational Learning of Pattern-Match Rules for Information Extraction,"Mary Elaine Califf, Illinois State University, and Raymond J. Mooney, University of Texas at Austin","Information extraction is a form of shallow text processing that locatesa specified set of relevant items in a natural-language document.Systems for this task require significant domain-specific knowledge andare time-consuming and difficult to build by hand, making them a goodapplication for machine learning. This paper presents a system, RAPIER,that takes pairs of sample documents and filled templates and inducespattern-match rules that directly extract fillers for the slots in thetemplate. RAPIER employs a bottom-up learning algorithm whichincorporates techniques from several inductive logic programming systemsand acquires unbounded patterns that include constraints on the words,part-of-speech tags, and semantic classes present in the filler and thesurrounding text. We present encouraging experimental results on twodomains.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-048.pdf,
48,1999,Learning,"A Simple, Fast, and Effective Rule Learner","William W. Cohen and Yoram Singer, AT&T Labs - Research","We describe SLIPPER, a new rule learner that generates rulesets byrepeatedly boosting a simple, greedy, rule-builder. The ensemble ofrules created by SLIPPER is compact and comprehensible, like therulesets built by other rule learners. This is made possible by imposingappropriate constraints on the rule-builder, and by use of arecently-proposed generalization of Adaboost called confidence-ratedboosting. In spite of its relative simplicity, SLIPPER is highlyscalable, and an effective learner. Experimentally, SLIPPER scales noworse than O(nlogn), where n is the number of examples, and on a set of32 benchmark problems, SLIPPER achieves lower error rates than RIPPER 20times, and lower error rates than C4.5rules 22 times.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-049.pdf,
49,1999,Learning,Monte Carlo Localization: Efficient Position Estimation for Mobile Robots,"Dieter Fox, Carnegie Mellon University; Wolfram Burgard, University of Bonn; Frank Dellaert and Sebastian Thrun, Carnegie Mellon University","This paper presents a new, highly efficient algorithm for mobile robotlocalization, called Monte Carlo Localization. Mobile robot localizationhas been recognized as one of the most important problems in mobilerobotics. Our algorithm is a version of Markov localization, a family ofprobabilistic approaches that have recently been applied with greatpractical success. However, previous approaches were eithercomputationally extremely cumbersome (such as grid-based approaches thatrepresent the state space by high-resolution 3D grids), or had to resortto extremely coarse-grained resolution. Our approach is computationallyefficient while retaining the ability to represent (almost) arbitrarydistributions. It applies highly efficient sampling-based methods forapproximating probability distributions. This approach placescomputation exactly where needed. The number of samples is adaptedon-line, thereby invoking large sample sets only when needed. Empiricalresults illustrate that Monte Carlo Localization is an extremelyefficient on-line algorithm, characterized by better accuracy and anorder of magnitude lower computation and memory requirement whencompared to previous approaches. It is also much easier to implement.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-050.pdf,
50,1999,Learning,Detecting Feature Interactions from Accuracies of Random Feature Subsets,"Thomas R. Ioerger, Texas A&M University","We present a method of improving sound source separation usingvision. The sound source separation is an essential function toaccomplish auditory scene understanding by separating stream of soundsgenerated from multiple sound sources. By separating a stream of sounds,recognition process, such as speech recognition, can simply work on asingle stream, not mixed sound of several speakers. The performance isknown to be improved by using stereo/binaural microphone and microphonearray which provides spatial information for separation. However, thesemethods still have more than 20 degree of positional ambiguities. Inthis paper, we further added visual information to provide more specificand accurate position information. As a result, separation capabilitywas drastically improved. In addition, we found that the use ofapproximate direction information drastically improve object trackingaccuracy of a simple vision system, which in turn improves performanceof the auditory system. We claim that the integration of vision andauditory inputs improves performance of tasks in each perception, suchas sound source separation and object tracking, by bootstrapping.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-051.pdf,
51,1999,Learning,Simulation-Based Inference for Plan Monitoring,"Neal Lesh, MERL - A Mitsubishi Electric Research Laboratory, and James Allen, University of Rochester","The dynamic execution of plans in uncertain domains requires the abilityto infer likely current and future world states from past observations.This task can be cast as inference on Dynamic Belief Networks (DBNs) butthe resulting networks are difficult to solve with exact methods. Weinvestigate and extend simulation algorithms for approximate inferenceon Bayesian networks and a propose a new algorithm, calledRewind/Replay, for generating a set of simulations weighted by theirlikelihood given past observations. We validate our algorithm on a DBNcontaining thousands of variables, which models the spread of wildfire.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-052.pdf,
52,1999,Learning,Selective Sampling for Nearest Neighbor Classifiers,"Michael Lindenbaum, Shaul Markovich, and Dmitry Rusakov, Technion - Israel Institute of Technology","In the passive, traditional, approach to learning, the informationavailable to the learner is a set of classified examples, which arerandomly drawn from the instance space. In many applications, however,the initial classification of the training set is a costly process, andan intelligently selection of training examples from unlabeled data isdone by an active learner. This paper proposes a lookahead algorithm forexample selection and addresses the problem of active learning in thecontext of nearest neighbor classifiers. The proposed approach relies onusing a random field model for the example labeling, which implies adynamic change of the label estimates during the sampling process. Theproposed selective sampling algorithm was evaluated empirically onartificial and real data sets. The experiments show that the proposedmethod outperforms other methods in most cases.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-053.pdf,
53,1999,Learning,Toward a Theoretical Understanding of Why and When Decision Tree Pruning Algorithms Fail,"Tim Oates and David Jensen, University of Massachusetts","Recent empirical studies revealed two surprising pathologies of severalcommon decision tree pruning algorithms. First, tree size is often alinear function of training set size, even when additional treestructure yields no increase in accuracy (Oates and Jensen 1997).Second, building trees with data in which the class label and theattributes are independent often results in large trees (Oates andJensen 1998. In both cases, the pruning algorithms fail to control treegrowth as one would expect them to. We explore this behaviortheoretically by constructing a statistical model of reduced errorpruning (Quinlan 1987). The model explains why and when the pathologiesoccur, and makes predictions about how to lessen their effects. Thepredictions are operationalized in a variant of reduced error pruningthat is shown to control tree growth far better than the originalalgorithm. Finally, we argue that several other common pruningtechniques can be viewed within the same framework, thus explainingtheir pathological behavior as well.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-054.pdf,
54,1999,Learning,Feature Selection for Ensembles,"David W. Opitz, University of Montana","The traditional motivation behind feature selection algorithms is tofind the best subset of features for a task using one particularlearning algorithm. Given the recent success of ensembles, however, weinvestigate the notion of ensemble feature selection. This task isharder than traditional feature selection in that one not only needs tofind features germane to the learning task and learning algorithm, butone also needs to find a set of feature subsets that will promotedisagreement among the ensemble’s classifiers. In this paper, we presentan ensemble feature selection approach that is based on geneticalgorithms. Though conceptually simple, our algorithm shows improvedperformance over the popular and powerful ensemble approaches of Baggingand Ada-boosting and demonstrates the utility of ensemble featureselection.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-055.pdf,
55,1999,Learning,Efficient Exploration for Optimizing Immediate Reward,"Dale Schuurmans, University of Waterloo and Lloyd Greenwald, Drexel University","We consider the problem of learning an effective behavior strategy fromreward. Although much studied, the issue of how to use prior knowledgeto scale optimal behavior learning up to real-world problems remains animportant open issue. We investigate the inherent data-complexity ofbehavior-learning when the goal is simply to optimize immediate reward.Although easier than reinforcement learning where one must also copewith state dynamics, immediate reward learning is still a common problemand is fundamentally harder than supervised learning. For optimizingimmediate reward, prior knowledge can be expressed either as a bias onthe space of possible reward models, or a bias on the space of possiblecontrollers. We investigate the two paradigmatic learning approaches ofindirect (reward-model) learning and direct-control learning, and showthat neither uniformly dominates the other in general. Model-basedlearning has the advantage of generalizing reward experiences acrossstates and actions, but direct-control learning has the advantage offocusing only on potentially optimal actions and avoiding learningirrelevant world details. Both strategies can be strongly advantageousin different circumstances. We introduce hybrid learning strategiesthat combine the benefits of both approaches, and uniformly improvetheir learning efficiency.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-056.pdf,
56,1999,Model-Based Reasoning,Towards Diagram Processing: A Diagrammatic Information System,"Michael Anderson, University of Hartford","We advocate the development of an agent capable of processingdiagrammatic information directly in all its forms. In the same way thatwe will require intelligent agents to be conversant with naturallanguage, we will expect them to be fluent with diagrammatic informationand its processing. We present a methodology to this end, detail adiagrammatic information system that shows the merit of this line ofresearch, and evaluate this system to motivate its future extensions.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-057.pdf,
57,1999,Model-Based Reasoning,Influence-Based Model Decomposition,"Christopher Bailey-Kellogg, Dartmouth College, and Feng Zhao, Xerox Palo Alto Research Center","Recent rapid advances in MEMS and information processing technology haveenabled a new generation of AI robotic systems -- so-called Smart Mattersystems -- that are sensor rich and physically embedded. These systemsrange from decentralized control systems that regulate buildingtemperature (smart buildings) to vehicle on-board diagnostic and controlsystems that interrogate large amounts of sensor data. One of the coretasks in the construction and operation of these Smart Matter systems isto synthesize optimal control policies using data rich models for thesystems and environment. Unfortunately, these models may containthousands of coupled real-valued variables and are prohibitivelyexpensive to reason about using traditional optimization techniques suchas neural nets and genetic algorithms. This paper introduces a generalmechanism for automatically decomposing a large model into smallersubparts so that these subparts can be separately optimized and thencombined. The mechanism decomposes a model using an influence graph thatrecords the coupling strengths among constituents of the model. Thispaper demonstrates the mechanism in an application of decentralizedoptimization for a temperature regulation problem. Performance data hasshown that the approach is much more efficient than the standarddiscrete optimization algorithms and achieves comparable accuracy.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-058.pdf,
58,1999,Model-Based Reasoning,Model-Based Support for Mutable Parametric Design Optimization,"Ravi Kapadia and Gautam Biswas, Vanderbilt University","Traditional methods for parametric design optimization assume that therelationships between performance criteria and design variables areknown algebraic functions with fixed coefficients (that correspond touser preferences). However, performance criteria may be dynamic, i.e.,the functions and/or coefficients may depend on input tasks and run timebehavior. We present a framework to support parametric, dynamic, designoptimization using model-based reasoning techniques that derive eventmodels to represent the effects of the system’s parameters on thematerial that flows through it. Next, we use these models toautomatically discover relations between the system’s design variablesand its optimization criteria dynamically. We then present an algorithmthat searches for ""optimal"" designs by employing sensitivity analysistechniques on the derived relations.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-059.pdf,
59,1999,Model-Based Reasoning,Qualifying the Expressivity/Efficiency Tradeoff: Reformation-Based Diagnosis,"Helmut Prendinger and Mitsuru Ishizuka, University of Tokyo","This paper presents an approach to model-based diagnosis that firstcompiles a first-order system description to a propositionalrepresentation, and then solves the diagnostic problem as a linearprogramming instance. Relevance reasoning is employed to isolate partsof the system that are related to certain observation types and toeconomically instantiate the theory, while methods from operationsresearch offer promising results to generate near-optimal diagnosesefficiently.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-060.pdf,
60,1999,Natural Language and Information Retrieval,The Role of Lexicalization and Pruning for Base Noun Phrase Grammars,"Claire Cardie and David Pierce, Cornell University","This paper explores the role of lexicalization and pruning of grammarsfor base noun phrase identification. We modify the original framework ofCardie & Pierce (1998) to extract lexicalized treebank grammars thatassign a score to each potential noun phrase based upon both thepart-of-speech tag sequence and the word sequence of the phrase. Weevaluate the modified framework on the ""simple"" and ""complex"" base NPcorpora of the original study. As expected, we find that lexicalizationdramatically improves the performance of the unpruned treebank grammars;however, for the simple base noun phrase data set, the lexicalizedgrammar performs below the unlexicalized, but pruned, grammar of theoriginal base NP study, suggesting that lexicalization is not criticalfor recognizing very simple, relatively unambiguous constituents.Somewhat surprisingly, we also find that error-driven pruning improvesthe performance of the probabilistic, lexicalized base noun phrasegrammars by up to 1.0% recall and 0.4% precision, and does so even usingthe original pruning strategy that fails to distinguish the effects oflexicalization. This result may have implications for many probabilisticgrammar-based approaches to problems in natural language processing:error-driven pruning is a remarkably robust method for improving theperformance of probabilistic and non-probabilistic grammars alike.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-061.pdf,
61,1999,Natural Language and Information Retrieval,Two Dimensional Generalization in Information Extraction,"Joyce Yue Chai, IBM T. J. Watson Research Center; Alan W. Biermann, Duke University; Curry I. Guinn, Research Triangle Institute","In a user-trained information extraction system, the cost of creatingthe rules for information extraction can be greatly reduced bymaximizing the effectiveness of user inputs. If the user specifies oneexample of a desired extraction, our system automatically tries avariety of generalizations of this rule including generalizations of theterms and permutations of the ordering of significant words. Wheremodifications of the rules are successful, those rules are incorporatedinto the extraction set. The theory of such generalizations and ameasure of their usefulness is described.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-062.pdf,
62,1999,Natural Language and Information Retrieval,Combining Collaborative Filtering with Personal Agents for Better Recommendations,"Nathaniel Good, J. Ben Schafer, Joseph A. Konstan, Al Borchers, Badrul Sarwar, Jon Herlocker, and John Riedl, University of Minnesota","Information filtering agents and collaborative filtering both attempt toalleviate information overload by identifying which items a user willfind worthwhile. Information filtering (IF) focuses on the analysis ofitem content and the development of a personal user interest profile.Collaborative filtering (CF) focuses on identification of other userswith similar tastes and the use of their opinions to recommend items.Each technique has advantages and limitations that suggest that the twocould be beneficially combined. This paper shows that a CF framework canbe used to combine personal IF agents and the opinions of a community ofusers to produce better recommendations than either agents or users canproduce alone. It also shows that using CF to create a personalcombination of a set of agents produces better results than eitherindividual agents or other combination mechanisms. One key implicationof these results is that users can avoid having to select among agents;they can use them all and let the CF framework select the best ones forthem.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-063.pdf,
63,1999,Natural Language and Information Retrieval,Application-Embedded Retrieval from Distributed Free-Text Collections,"Vladimir A. Kulyukin, DePaul University","A framework is presented for application-embedded information retrievalfrom distributed free-text collections. An application’s usage issampled by an embedded information retrieval system. Samples areconverted into queries to distributed collections. Retrieval is adjustedthrough sample size and structure, anydata indexing, and dual spacefeedback. The framework is investigated with a retrieval systemembedded in a text processor.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-064.pdf,
64,1999,Natural Language and Information Retrieval,Towards Multidocument Summarization by Reformulation: Progress and Prospects,"Kathleen R. McKeown, Judith L. Klavans, Vasileios Hatzivassiloglou, Regina Barzilay, and Eleazar Eskin, Columbia University","By synthesizing information common to retrieved documents,multi-document summarization can help users of information retrievalsystems to find relevant documents with a minimal amount of reading. Weare developing a multi-document summarization system to automaticallygenerate a concise summary by identifying and synthesizing similaritiesacross a set of related documents. Our approach is unique in itsintegration of machine learning and statistical techniques to identifysimilar paragraphs, shallow analysis and comparison to identify similarphrases within paragraphs, and language generation to reformulate thewording of the summary. Our evaluation of system components shows thatour use of learning over multiple extracted linguistic features is moreeffective than information retrieval approaches at identifying similartext units for summarization and that it is possible to generate afluent summary that conveys similarities among documents even when fullsemantic interpretations of the input text are not available.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-065.pdf,
65,1999,Natural Language and Information Retrieval,An Automatic Method for Generating Sense Tagged Corpora,"Rada Mihalcea and Dan I. Moldovan, Southern Methodist University","The unavailability of very large corpora with semantically disambiguatedwords is a major limitation in text processing research. For example,statistical methods for word sense disambiguation of free text are knownto achieve high accuracy results when large corpora are available todevelop context rules, to train and test them. This paper presents anovel approach to automatically generate arbitrarily large corpora forword senses. The method is based on (1) the information provided inWordNet, used to formulate queries consisting of synonyms or definitionsof word senses, and (2) the information gathered from Internet usingexisting search engines. The method was tested on 120 word senses and aprecision of 91% was observed.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-066.pdf,
66,1999,Natural Language and Information Retrieval,Selecting Text Spans for Document Summaries: Heuristics and Metrics,"Vibhu Mittal and Mark Kantrowitz, Just Research; Jade Goldstein and Jaime Carbonell, Carnegie Mellon University","Human-quality text summarization systems are difficult to design, andeven more difficult to evaluate, in part because documents can differalong several dimensions, such as length, writing style and lexicalusage. Nevertheless, certain cues can often help suggest the selectionof sentences for inclusion in a summary. This paper presents ouranalysis of news-article summaries generated by sentence selection.Sentences are ranked for potential inclusion in the summary using aweighted combination of statistical and linguistic features. This paperanalyzes some of the potential linguistic features -- derived from ananalysis of news-wire summaries -- for relative effectiveness. Toevaluate these features we use a modified version of precision-recallcurves, with a baseline derived from a theoretical analysis of text-spanoverlap based on random selection. We illustrate our discussions withempirical results showing the importance of discussing evaluationresults in the context of both corpus characteristics and compressionratios.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-067.pdf,
67,1999,Natural Language and Information Retrieval,Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping,"Ellen Riloff, University of Utah and Rosie Jones, Carnegie Mellon University","Information extraction systems usually require two dictionaries: asemantic lexicon containing domain-specific phrases and a dictionary ofextraction patterns for the domain. We present a multi-levelbootstrapping algorithm for building both the semantic lexicon andextraction patterns simultaneously. As input, our technique requiresonly unannotated training texts and a handful of ""seed words"" for acategory. We use a ""mutual bootstrapping"" technique to alternatelyselect the best extraction pattern for the category and bootstrap itsextractions into the semantic lexicon, which is the basis for selectingthe next extraction pattern. To make this approach more robust, we add asecond level of bootstrapping (""meta-bootstrapping"") that retains onlythe most reliable lexicon entries produced by mutual bootstrapping andthen restarts the process. We evaluated this multi-level bootstrappingtechnique on a collection of corporate web pages and a corpus ofterrorism news articles. The algorithm produced high-qualitydictionaries for several semantic categories, and the dictionariesproved to be useful for extracting information from new web pages.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-068.pdf,
68,1999,Natural Language and Information Retrieval,Feature Selection in SVM Text Categorization,"Hirotoshi Taira, NTT Communication Science Labs, and Masahiko Haruno, ATR Human Information Processing Research Labs","This paper investigates the effect of prior feature selection in SupportVector Machine (SVM) text categorization. The input space was graduallyincreased by mutual information (MI) filtering and part-of-speech (POS)filtering, which determine the portion of words that are appropriate forSVM learning from the information-theoretic and linguistic perspectives,respectively. The common results for both filtering are that 1) theoptimal number of features was completely different among categories,and 2) the average performance for categories was best when all of thewords were used. In addition, the comparison of two experimentsclarifies that 3) POS filtering consistently outperforms MI filtering,which indicates that SVMs cannot find irrelevant parts-of-speech. Theseresults suggest a simple strategy to utilize a full number of words thatare picked up by a rough filtering technique like part-of-speechtagging.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-069.pdf,
69,1999,Natural Language and Information Retrieval,Automatic Construction of Semantic Lexicons for Learning Natural Language Interfaces,"Cynthia A. Thompson, Stanford University and Raymond J. Mooney, University of Texas","This paper describes a system, WOLFIE (WOrd Learning From InterpretedExamples), that acquires a semantic lexicon from a corpus of sentencespaired with semantic representations. The lexicon learned consists ofwords paired with meaning representations. WOLFIE is part of anintegrated system that learns to parse novel sentences into semanticrepresentations, such as logical database queries. Experimental resultsare presented demonstrating WOLFIE’s ability to learn useful lexiconsfor a database interface in four different natural languages. Thelexicons learned by WOLFIE are compared to those acquired by acomparable system developed by Siskind (1996).",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-070.pdf,
70,1999,Planning,Theory for Coordinating Concurrent Hierarchical Planning Agents Using Summary Information,"Bradley J. Clement and Edmund H. Durfee, University of Michigan","Interacting agents that interleave planning, plan coordination, and planexecution for hierarchical plans (e.g. HTNs or procedures for PRS)should reason about abstract plans and their concurrent execution beforethey are fully refined. Poor decisions made at abstract levels can leadto costly backtracking or even failure. We claim that better decisionsrequire information at abstract levels that summarizes the preconditionsand effects that must or may apply when a plan is refined. Here weformally characterize concurrent hiera chical plans and a method forderiving summary information for them, and we illustrate how summaryconditions can be used to coordinate the concurrent interactions ofplans at different levels of abstraction. The properties of summaryconditions and rules determining what interactions can or might holdamong asynchronously executing plans are proven to support theconstruction of sound and complete coordination mechanisms forconcurrent hierarchical planning agents.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-071.pdf,
71,1999,Planning,Fast Planning through Greedy Action Graphs,"Alfonso Gerevini and Ivan Serina, Univeritá di Brescia","Domain-independent planning is a notoriously hard search problem.Several systematic search techniques have been proposed in the contextof various formalisms. However, despite their theoretical completeness,in practice these algorithms are incomplete because for many problemsthe search space is too large to be (even partially) explored. In thispaper we propose a new search method in the context of Blum and Furst’splanning graph approach, which is based on local search. Local searchtechniques are incomplete, but in practice they can efficiently solveproblems that are unsolvable for current systematic search methods. Weintroduce three heuristics to guide the local search (Walkplan, Tabuplanand T-Walkplan), and we propose two methods for combining local andsystematic search. Our techniques are implemented in a system calledGPG, which can be used for both plan-generation and plan-adaptationtasks. Experimental results show that GPG can efficiently solve problemsthat are very hard for current planners based on planning graphs.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-072.pdf,
72,1999,Planning,Control Knowledge in Planning: Benefits and Tradeoffs,"Yi-Cheng Huang and Bart Selman, Cornell University; Henry Kautz, AT&T Labs - Research","Recent new planning paradigms, such as Graphplan and Satplan, have beenshown to outperform more traditional domain-independent planners. Aninteresting aspect of these planners is that they do not incorporatedomain specific control knowledge, but instead rely on efficientgraph-based or propositional representations and advanced searchtechniques. An alternative approach has been proposed in the TLPlansystem. TLPlan is an example of a powerful planner incorporatingdeclarative control specified in temporal logic formulas. We show howthese control rules can be parsed into Satplan. Our empirical resultsshow more than an order of magnitude speed up. We also provide adetailed comparison with TLPlan, and show how the search strategies inTLPlan lead to efficient plans in terms of the number of actions butwith little or no parallelism. The Satplan and Graphplan formalisms onthe other hand do find highly parallel plans, but are less effective insequential domains. We believe our results enhance our understanding ofthe various tradeoffs in planning technology.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-073.pdf,
73,1999,Planning,A Framework for Recognizing Multi-Agent Action from Visual Evidence,"Stephen S. Intille and Aaron F. Bobick, MIT Media Laboratory","A framework for representing and visually recognizing complexmulti-agent action is presented. Motivated by work in model-based objectrecognition and designed for the recognition of action from uncertainvisual evidence, the representation has three components: (1) temporalstructure descriptions representing the temporal relationships betweenagent goals, (2) belief networks for representing and recognizingindividual agent goals from visual evidence, and (3) belief networksautomatically generated from the temporal structure descriptions thatuse low-order temporal relationships between detected goals to supportthe recognition of the complex action in the presence of uncertainty. Wedescribe our current work on recognizing American football plays fromnoisy trajectory data.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-074.pdf,
74,1999,Planning,State-Space Planning by Integer Optimization,"Henry Kautz, AT&T Shannon Labs; Joachim P. Walser, AT&T Shannon Labs and i2 Technologies","This paper describes ILP-PLAN, a framework for solving AI planningproblems represented as integer linear programs. ILP-PLAN extends theplanning as satisfiability framework to handle plans with resources,action costs, and complex objective functions. We show that challengingplanning problems can be effectively solved using both traditionalbranch and bound IP solvers and efficient new integer local searchalgorithms. ILP-PLAN can find better quality solutions for a set of hardbenchmark logistics planning problems than had been found by any earliersystem.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-075.pdf,
75,1999,Planning,Using Planning Graphs for Solving HTN Planning Problems,"Amnon Lotem, Dana S. Nau, and James A. Hendler, University of Maryland","In this paper we present the GraphHTN algorithm, a hybrid planningalgorithm that does Hierarchical Task-Network (HTN) planning using acombination of HTN-style problem reduction and Graphplan-styleplanning-graph generation. We also present experimental resultscomparing GraphHTN with ordinary HTN decomposition (as implemented inthe UMCP planner) and ordinary Graphplan search (as implemented in theIPP planner). Our experimental results show that (1) the performance ofHTN planning can be improved significantly by using planning graphs, and(2) that planning with planning graphs can be sped up by exploiting HTNcontrol knowledge.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-076.pdf,
76,1999,Planning,On the Undecidability of Probabilistic Planning and Infinite-Horizon Partially Observable Markov Decision Problems,"Omid Madani, University of Washington; Steve Hanks, Harlequin Inc; Anne Condon, University of Wisconsin","We investigate the computability of problems in probabilistic planningand partially observable infinite-horizon Markov decision processes. The undecidability of the string-existence problem for probabilisticfinite automata is adapted to show that the following problem of planexistence in probabilistic planning is undecidable: given aprobabilistic planning problem, whether there exists a plan with successprobability exceeding a desirable threshold. Analogous policy-existenceproblems for partially observable infinite-horizon Markov decisionprocesses under discounted and undiscounted total reward models,average-reward models, and state-avoidance models are all shown to beundecidable. The results apply to corresponding approximation problemsas well.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-077.pdf,
77,1999,Planning,Contingent Planning Under Uncertainty via Stochastic Satisfiability,"Stephen M. Majercik and Michael L. Littman, Duke University","We describe how to map the problem of contingent planning in aprobabilistic propositional domain to two different probabilisticsatisfiability problems. In the first approach, a set of Booleanvariables encode the contingent plan and a second set the probabilisticoutcome of the plan--the satisfiability problem is to find the settingof the plan variables that maximizes the probability of satisfactionwith respect to the outcome variables. This is equivalent to theE-MAJSAT problem. A difficulty with this approach (C-MAXPLAN) is thatthe efficiency with which the resulting satisfiability problem is solveddepends critically on the contingent-plan representation, for whichthere are many possible choices. A second approach is to intermingleplan variables and outcome variables in the formula so values for planvariables can be chosen conditionally based on observable values ofoutcome variables. This approach, while equivalent to a satisfiabilityproblem called S-SAT from a higher complexity class, has the virtue ofproviding substantially more direct problem encodings. We report resultsusing a preliminary implementation of the S-SAT approach (ZANDER), whichis competitive with existing planners on a variety of problems.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-078.pdf,
78,1999,Planning,On the Utility of Plan-Space (Causal) Encodings,"Amol D. Mali and Subbarao Kambhampati, Arizona State University","Recently, casting planning as propositional satisfiability has beenshown to be a very promising technique for plan synthesis. It has beenclaimed that SAT encodings for planning problems can be derived fromeach of the traditional refinement planning paradigms. Althoughencodings based both on state-space planning and on plan-space (causal)planning have been proposed, most implementations and trade-offevaluations primarily use state-based encodings. This is surprisinggiven both the prominence of plan-space planners in traditionalplanning, as well as the recent claim that lifted versions of causalencodings provide the smallest encodings. In this paper we attempt asystematic analytical and empircial comparison of plan-space (causal)encodings and state-space encodings. We start by characterizing a largespectrum of plan-space encodings, and provide several encodings that aremuch smaller than those previously proposed. We then show that thesmallest causal encodings cannot be smaller in size than the smalleststate-based encodings. We shall show that the ""lifting"" transformationdoes not affect this relation. Finally, we will present some empiricalresults that demonstrate that the relative encoding sizes are indeedcorrelated with the hardness of solving them. We end with a discussionon why it is reasonable that the primacy of traditional plan-spaceplanners over state-space planners does not carry over to theirrespective SAT encodings.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-079.pdf,
79,1999,Planning,Anytime Coordination for Progressive Planning Agents,"Abdel-Illah Mouaddib, CRIL-IUT de Lens-Université d'Artois","We address in this paper the problem of coordinating resource-boundedagents under time constraints in a dynamic environment. The agentsociety we deal with consists of coordinated agents each of which has agoal to achieve before a deadline and new agents can asynchronouslyappear to achieve time-constrained goals and to coordinate their planswith the already coordinated agent society. Agents use progressiveplanning that adapt the detail of their local plans according to localdeadlines and available resources. The plan consists of a hierarchy ofpartial plans where each partial plan satisfies a part of the goal. Insuch environments, constructing a complete plan and then coordinating itwith other agents doesn’t guarantee that the planning and coord-nationoperations will finish before the given deadline. What we propose is ananytime coordination that allows an agent to return a coordinated planat any time by using series of partial planning followed by acoordination until the complete plan is constructed and coordinated orthe deadline is met. This progressive plan merging operation is assessedin a resource allocation problem.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-080.pdf,
80,1999,Planning,Generating Qualitatively Different Plans through Metatheoretic Biases,"Karen L. Myers and Thomas J. Lee, SRI International","Current methods for generating qualitatively different plans are eitherbased on simple randomization of planning decisions and cannot guaranteemeaningful differences among generated plans, or require extensive userinvolvement to drive the system into different sections of the overallplan space. This paper presents a cost-effective method forautomatically generating qualitatively different plans that is rooted inthe creation of Biases, which focus the planner towards solutions withcertain attributes. Biases are derived from analysis of a DomainMetatheory and enforced through compilation into preferences overplanning decisions. Users can optionally direct the planner into desiredregions of the plan space by designating aspects of the metatheory thatshould be used for bias generation. Experimental results are providedthat validate the effectiveness of biases for reliably generating arange of plans with meaningful semantic differences.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-081.pdf,
81,1999,Planning,"Conditional, Probabilistic Planning: A Unifying Algorithm and Effective Search Control Mechanisms","Nilufer Onder and Martha E. Pollack, University of Pittsburgh","Several recent papers describe algorithms for generating conditionaland/or probabilistic plans. In this paper, we synthesize this work, andpresent a unifying algorithm that incorporates and clarifies the maintechniques that have been developed in the previous literature. Ouralgorithm decouples the search-control strategy for conditional and/orprobabilistic planning from the underlying plan-refinement process. Asimilar decoupling has proven to be very useful in the analysis ofclassical planning algorithms, and we show that it can be at least asuseful here, where the search-control decisions are even more crucial.Previous probabilistic/conditional planners have been severely limitedby the fact that they do not know how to handle failure points toadvantage. We show how a principled selection of failure points can beperformed within the framework our algorithm. We also describe and showthe effectiveness of additional heuristics. We describe our implementedsystem called Mahinur and experimentally demonstrate that our methodsproduce efficiency improvements of several orders of magnitude.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-082.pdf,
82,1999,Planning,CPlan: A Constraint Programming Approach to Planning,"Peter van Beek and Xinguang Chen, University of Alberta","Constraint programming, a methodology for solving difficultcombinatorial problems by representing them as constraint satisfactionproblems, has shown that a general purpose search algorithm based onconstraint propagation combined with an emphasis on modeling can solvelarge, practical scheduling problems. Given the success of constraintprogramming on scheduling problems and the similarity of scheduling toplanning, the question arises, would a constraint programming approachwork as well in planning? In this paper, we present evidence that aconstraint programming approach to planning does indeed work well andhas the advantage in terms of time and space efficiency over the currentstate-of-the-art planners.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-083.pdf,
83,1999,Planning,Total Order Planning Is More Efficient than We Thought,"Vincent Vidal and Pierre Régnier, IRIT, Paul Sabatier University","In this paper, we present VVPLAN, a planner based on a classical statespace search algorithm. The language used for domain and problemrepresentation is ADL (Pednault 1989). We have compared VVPLAN to UCPOP(Penberthy and Weld 1992)(Weld 1994), a planner that admits the samerepresentation language. Our experiments prove that such an algorithm isoften more efficient than a planner based on a search in the space ofpartial plans. This result is achieved as soon as we introduce inVVPLANs algorithm a loop test relating to previously visited states. Inparticular domains, VVPLAN can also outperform IPP (Koehler et al.1997), which makes a planning graph analysis as GRAPHPLAN. We presenthere the details of our comparison with UCPOP, the results we obtain andour conclusions.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-084.pdf,
84,1999,Planning,Cooperative Plan Identification: Constructing Concise and Effective Plan Descriptions,"R. Michael Young, North Carolina State University","Intelligent agents are often called upon to form plans that direct theirown or other agents’ activities. For these systems, the ability todescribe plans to people in natural ways is an essential aspect of theirinterface. In this paper, we present the Cooperative Plan Identification(CPI) architecture, a computational model that generates concise,effective textual descriptions of plan data structures. The modelincorporates previous theoretical work on the comprehension of plandescriptions, using a generate-and-test approach to perform efficientsearch through the space of candidate descriptions. We describe anempirical evaluation of the CPI architecture in which subjects followinginstructions produced by the CPI architecture performed their tasks withfewer execution errors and achieved a higher percentage of their tasks'goals than did subjects following instructions produced by alternativemethods.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-085.pdf,
85,1999,Planning,Exploiting Symmetry in the Planning-Graph via Explanation-Guided Search,"Terry Zimmerman and Subbarao Kambhampati, Arizona State University","We present a method for exploting the sym-metry in the planning-graphstructure of Graphplan algorithm to improve its backward search. Themain insight underlying our method is that due to the inherent symmetryof the planning-graph the backward search conducted at level k + 1 ofthe graph is es-sentially a replay of the search conducted at theprevious level k with certain well-defined extensions. Our methodconsists of main-taining a pilot explanation structure capturing thefailures encountered at previous levels of the search, and using it inan intelligent way to guide the search at the newer levels. The standardEBL and DDB techniques can be employed to control the size of the pilotex-planation. The technique has been imple-mented in the EGBG system,and we present a preliminary empirical study.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-086.pdf,
86,1999,Robotics,An Integrated System for Multi-Rover Scientific Exploration,"Tara Estlin, Alexander Gray, Tobias Mann, Gregg Rabideau, Rebecca Castaño, Steve Chien, and Eric Mjolsness, Jet Propulsion Laboratory","This paper describes an integrated system for coordinating multiplerover behavior with the overall goal of collecting planetary surfacedata. The Multi-Rover Science Exploration system integrates conceptsfrom machine learning with planning and scheduling to perform autonomousscientific exploration by cooperating rovers. The integrated systemutilizes a novel machine learning clustering component to analyzescience data and direct new science activities. A planning andscheduling system is employed to generate rover plans for achievingscience goals and to coordinate activities among rovers. We describeeach of these components and discuss some of the key integration issuesthat arose during development and influenced both system design andperformance. Theme: (AI Integrated Systms) New syntheses that bringtogether work in sub-disciplines of AI toward the creation of completesystems (e.g. architectural frameworks, learning and planning, etc.)",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-087.pdf,
87,1999,Robotics,Integrated Natural Spoken Dialogue System of Jijo-2 Mobile Robot for Office Services,"Toshihiro Matsui and Hideki Asoh, Electrotechnical Laboratory; John Fry, Stanford University; Youichi Motomura, Futoshi Asano, Takio Kurita, Isao Hara, and Nobuyuki Otsu, Electrotechnical Laboratory","Our Jijo-2 mobile robot, whose purpose is to provide office services,such as answering queries about people’s location, route guidance, anddelivery tasks, is expected to conduct natural spoken conversation withthe office dwellers. This paper describes dialogue technologiesimplemented on our Jijo-2 office robot, i.e. noise-free voiceacquisition system by a microphone array, inference of under-specifiedreferents and zero pronouns using the attentional states, andcontext-sensitive construction of semantic frames from fragmentedutterances. The behavior of the dialogue system integrated with thesound source detection, navigation, and face recognition vision isdemonstrated in real dialogue examples in a real office.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-088.pdf,
88,1999,Robotics,Gesture-Based Interaction with a Pet Robot,"Milyn C. Moy, MIT Artificial Intelligence Laboratory / Oracle Corporation","Unlike conventional robots, a pet robot is autonomous and capable ofexhibiting animal-like behaviors, including emotional ones, as itinteracts with people and objects surrounding it. As pet robots becomemore integrated into humans’ everyday lives, a more natural way ofcommunicating with them will be necessary. Similarly, for a pet robot toperceive humans’ intentions and communicate with people moreeffectively, it needs to be able to understand human gestures and bodylanguage. In this paper, we present an extensible, real-time,vision-based communication system that interprets 2D dynamic handgestures in complex environments. This system uses both motion and colorinformation to segment the hand from the cluttered background, withoutthe use of special hand markers. The location of the hand issubsequently tracked in real-time as the human makes the gesture. Basedon the hand’s trajectory information, the gesture is interpreted andtranslated into a command for the robot. We implemented our system onYuppy, a pet robot prototype. Currently we can navigate Yuppy inunstructured environments using hand gestures.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-089.pdf,
89,1999,Robotics,Continuous Categories for a Mobile Robot,"Michael T. Rosenstein and Paul R. Cohen, University of Massachusetts","Autonomous agents make frequent use of knowledge in the form ofcategories -- categories of objects, human gestures, web pages, and soon. This paper describes a way for agents to learn such categories forthemselves through interaction with the environment. In particular, thelearning algorithm transforms raw sensor readings into clusters of timeseries that have predictive value to the agent. We address severalissues related to the use of an uninterpreted sensory apparatus and showspecific examples where a Pioneer 1 mobile robot interacts with objectsin a cluttered laboratory setting.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-090.pdf,
90,1999,Satisfiability,Distance-SAT: Complexity and Algorithms,"Olivier Bailleux and Pierre Marquis, CRIL, Université d'Artois","In many AI fields, the problem of finding out a solution which is asclose as possible to a given configuration has to be faced. This paperaddresses this problem in a propositional framework. The decisionproblem Distance-SAT that consists in determining whether apropositional CNF formula admits a model that disagrees with a givenpartial interpretation on at most d variables, is introduced. Thecomplexity of Distance-SAT is investigated. Like its restriction SAT,Distance-SAT is NP-complete. However, Distance-SAT is shown somewhatmore difficult than SAT, in the sense that the fragments for which SATis tractable are not necessarily fragments for which Distance-SAT istractable. Two algorithms based on the well-known Davis/Putnam searchprocedure are presented so as to solve Distance-SAT. Their empiricalevaluation enables deriving firm conclusions about their respectiveperformance, and to relate the difficulty of Distance-SAT with thedifficulty of SAT from the practical side.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-091.pdf,
91,1999,Satisfiability,Beyond NP: The QSAT Phase Transition,"Ian P. Gent and Toby Walsh, University of Strathclyde","We show that phase transition behaviour similar to that observed inNP-complete problems like random 3-SAT occurs in PSPACEcomplete problemslike random QSAT. Most of the differences in phase transition behaviourthat Cadoli et al report for random QSAT problems (for instance, nofixed point and no easy-hard-easy pattern) are largely due to thepresence of trivially unsatisfiable problems. Once they are removed, wesee behaviour more familiar from SAT and other NP-complete domains.There are, however, some differences. Problems with short clauses show alarge gap between worst case behaviour and median, and theeasy-hard-easy pattern is restricted to higher percentiles of searchcost. We compute the ""constrainedness"" of QSAT problems, and use this topredict the location of phase transitions. We conjecture that thesepredictions are less accurate than in NP-complete problems because ofthe super-exponential size of the state space, and of the weakness offirst moment methods in complexity classes above NP. Finally, we predictthat similar phase transition behaviour will occur in otherPSPACE-complete problems like planning and game playing.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-092.pdf,
92,1999,Satisfiability,Morphing: Combining Structure and Randomness,"Ian P. Gent, University of Strathclyde; Holger H. Hoos, University of British Columbia; Patrick Prosser and Toby Walsh, University of Strathclyde","We introduce a mechanism called ""morphing"" for introducing structure orrandomness into a wide variety of problems. We illustrate the usefulnessof morphing by performing several different experimental studies. Thesestudies identify the impact of a ""small-world"" topology on the cost ofcoloring graphs, of asymmetry on the cost of finding the optimal TSPtour, and of the dimensionality of space on the cost of finding theoptimal TSP tour. We predict that morphing will find many other uses.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-093.pdf,
93,1999,Satisfiability,On the Run-Time Behaviour of Stochastic Local Search Algorithms for SAT,"Holger H. Hoos, University of British Columbia","Stochastic local search (SLS) algorithms for the propositionalsatisfiability problem (SAT) have been successfully applied to solvesuitably encoded search problems from various domains. One drawback ofthese algorithms is that they are usually incomplete. We refine thenotion of incompleteness for stochastic decision algorithms byintroducing the notion of ""probabilistic asymptotic completeness"" (PAC)and prove for a number of well-known SLS algorithms whether or not theyhave this property. We also give evidence for the practical impact ofthe PAC property and show how to achieve the PAC property andsignificantly improved performance in practice for some of the mostpowerful SLS algorithms for SAT, using a simple and general techniquecalled ""random walk extension.""",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-094.pdf,
94,1999,Satisfiability,Initial Experiments in Stochastic Satisfiability,"Michael L. Littman, Duke University","This paper looks at the rich intersection between satisfibility problemsand probabilistic models, opening the door for the use of satisfiabilityapproaches in probabilistic domains. A generic stochastic satisfiabilityproblem is examined, which can function for probabilistic domains as Satdoes for deterministic domains. The paper defines aDavis-Putnam-Logemann-Loveland-style procedure for solving stochasticsatisfiability prob- lems, and reports on a preliminary empiricalexploration of the complexity of the algorithm for a collection ofrandomly generated probabilistic problems. The results exhibit thefamiliar easy-hardest-hard pattern for the diffculty of random Satformulae. Special cases of the stochastic satisfiability problem lie indifferent complexity classes, and one counterintuitive result is that thecomputational complexity and the empirical complexity of the problemsexamined do not track each other exactly|problems in the hardestcomplexity class are not the hardest to solve.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-095.pdf,
95,1999,Satisfiability,Trap Escaping Strategies in Discrete Lagrangian Methods for Solving Hard Satisfiability and Maximum Satisfiability Problems,"Zhe Wu and Benjamin W. Wah, University of Illinois, Urbana Champaign","In this paper, we present an improved local-search method based ondiscrete Lagrange multipliers for solving difficult SAT problems.Although a basic discrete Lagrangian method (DLM) can solve most of theDIMACS SAT benchmarks efficiently, a few of the large SAT benchmarkshave eluded solutions by any local-search methods today. Thesedifficultbenchmarks generally have many traps that attract local-searchtrajectories. To this end, we propose to identify their existence whenany change to a variable will cause the resulting Lagrangian value toincrease. Using the hanoi4 and par-16-1 benchmarks, we illustrate thatsome unsatisfied clauses are trapped more often than others. Since it istoo difficult to remember explicitly all the traps encountered during asearch, we propose a new strategy to remember these traps implicitly bygiving larger increases to Lagrange multipliers of unsatisfied clausesthat are trapped more often. We illustrate the benefit of this newupdate strategy by solving some of most difficult SAT benchmarks in theDIMACS archive (hanoi4, hanoi4-simple, par16-1 to par16-5, f2000, andpar32-1-c).",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-096.pdf,
96,1999,Scheduling,Scheduling Alternative Activities,"J. Christopher Beck, ILOG, S.A. and Mark S. Fox, University of Toronto","In realistic scheduling problems, there may be choices among resourcesor among process plans. We formulate a constraint-based representationof alternative activities to model problems containing such choices. Weextend existing constraint-directed scheduling heuristic commitmenttechniques and propagators to reason directly about the fact that anactivity does not necessarily have to exist in a final schedule.Experimental results show that an algorithm using a novel texture-basedheuristic commitment technique together with extended edge-findingpropagators achieves the best overall performance of the techniquestested.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-097.pdf,
97,1999,Scheduling,Algorithms Performance and Problem Structure for Flow-Shop Scheduling,"Jean-Paul Watson, Laura Barbulescu, Adele E. Howe, and L. Darrell Whitley, Colorado State UniversitySearch","Test suites for many domains often fail to model features present inreal-world problems. For the permutation flow-shop sequencing problem(PFSP), the most popular test suite consists of problems whose featuresare generated from a single uniform random distribution. Syntheticgeneration of problems with characteristics present in real-worldproblems is a viable alternative. We compare the performance of severalcompetitive algorithms on problems produced with such a generator. Wefind that, as more realistic characteristics are introduced, theperformance of a state-of-the-art algorithm degrades rapidly: faster andless complex stochastic algorithms provide superior performance. Ourempirical results show that small changes in problem structure orproblem size can influence algorithm performance. We hypothesize thatthese performance differences may be partially due to differences insearch space topologies; we show that structured problems producetopologies with performance plateaus. Algorithm sensitivity to problemcharacteristics suggests the need to construct test suites morerepresentative of real-world applications.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-098.pdf,
98,1999,Scheduling,Using Probabilistic Knowledge and Simulation to Play Poker,"Darse Billings, Lourdes Peña, Jonathan Schaeffer, and Duane Szafron, University of Alberta","Until recently, artificial intelligence researchers who use games astheir experimental testbed have concentrated on games of perfectinformation. Many of these games have been amenable to so-calledbrute-force search techniques. In contrast, games of imperfectinformation, such as bridge and poker, contain hidden knowledge makingsimilar search techniques impractical. This paper describes recentprogress in developing a high-performance poker-playing program. Theadvances come in two forms. First, we introduce a new betting strategythat returns a probabilistic betting decision, a probability triple,that gives the likelihood of a fold, call or raise occurring in a givensituation. This routine unifies all the expert knowledge used in theprogram, does a better job of representing the type of decision makingneeded to play strong poker, and improves the way information ispropagated throughout the program. Second, real-time simulations areused to compute the expected values of betting decisions. The programgenerates an instance of the missing data, subject to any constraintsthat have been learned, and then simulates the rest of the game todetermine a numerical result. By repeating this a sufficient number oftimes, a statistically meaningful sample can be obtained to be used inthe program’s decision-making process. Experimental results show thatthese enhancements each represent major advances in the strength ofcomputer poker programs.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-099.pdf,
99,1999,Scheduling,A Space-Time Tradeoff for Memory-Based Heuristics,"Robert C. Holte and István T. Hernádvölgyi, University of Ottawa","A memory-based heuristic is a function, h(s), stored in the form of alookup table (pattern database): h(s) is computed by mapping s to anindex and then retrieving the appropriate entry in the table. (Korf97)conjectures that for A* search using memory-based heuristics m*t is aconstant, where m is the size of the heuristic’s lookup table and t issearch time. In this paper we present a method for automaticallygenerating memory-based heuristics and use this to test Korf’sconjecture in a large-scale experiment. The results strongly supportKorf’s conjecture.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-100.pdf,
100,1999,Scheduling,Proverb: The Probabilistic Cruciverbalist,"Greg A. Keim, Noam M. Shazeer, Michael L. Littman, Sushant Agarwal, Catherine M. Cheves, Joseph Fitzgerald, Jason Grosland, Fan Jiang, Shannon Pollard, and Karl Weinmeister, Duke University","We attacked the problem of solving crossword puzzles by computer: givena set of clues and a crossword grid, try to maximize the number of wordscorrectly filled in. In our system, ""expert modules"" specialize insolving specific types of clues, drawing on ideas from informationretrieval, database search, and machine learning. Each expert modulegenerates a (possibly empty) candidate list for each clue, and the listsare merged together and placed into the grid by a centralized solver. Weused a probabilistic representation throughout the system as a commoninterchange language between subsystems and to drive the search for anoptimal solution. Proverb , the complete system, averages 95.3% wordscorrect and 98.1% letters correct in under 15 minutes per puzzle on asample of 370 puzzles taken from the New York Times and several otherpuzzle sources. This corresponds to missing roughly 3 words or 4 letterson a daily 15 x 15 puzzle, making Proverb a better-than-averagecruciverbalist (crossword solver).",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-101.pdf,
101,1999,Scheduling,Value-Update Rules for Real-Time Search,"Sven Koenig, Georgia Institute of Technology and Boleslaw Szymanski, Rensselaer Polytechnic Institute","Real-time search methods have successfully been used to solve a largevariety of search problems but their properties are largely unknown. Inthis paper, we study how existing real-time search methods scale up. Wecompare two real-time search methods that differ only in the updaterules of their values and have been used successfully in the literature:Node Counting, a real-time search method that always moves to thesuccessor state that it has visited the least number of times so far,and Learning Real-Time A*, a subtly different real-time search method.Both real-time search methods seemed to perform equally well in standarddomains from artificial intelligence and robotics. Our formal analysisis therefore very surprising. We show that the performance of NodeCounting can be exponential in the number of states even in undirecteddomains. This solves an open problem from the literature and shows thatthe two real-time search methods do not always perform similarly inundirected domains since the performance of Learning Real-Time A* isknown to be polynomial in the number of states at worst.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-102.pdf,
102,1999,Scheduling,Transposition Table Driven Work Scheduling in Distributed Search,"John W. Romein, Aske Plaat, and Henri E. Bal, Vrije Universiteit; Jonathan Schaeffer, University of Alberta","This paper introduces a new scheduling algorithm for parallelsingle-agent search, transposition table driven work scheduling, thatplaces the transposition table at the heart of the parallel workscheduling. The scheme results in less synchronization overhead, lessprocessor idle time, and less redundant search effort. Measurements on a128-processor parallel machine show that the scheme achievesnearly-optimal performance and scales well. The algorithm performs afactor of 2.0 to 13.7 times better than traditional work-stealing-basedschemes.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-103.pdf,
103,1999,Tractable Reasoning,A Sequential Reversible Belief Revision Method Based on Polynomials,"Salem Benferhat and Didier Dubois, IRIT, Université Paul Sabatier; Odile Papini, LIM, Université de la Méditerranée","This paper deals with iterated belief change and proposes a revisionrule that modifies a plausibility ordering of interpretations in such away that any world where the input observartion holds is more plausiblethat any world where it does not. This change rule makes sense in adynamic context where observations are received, and the newerobservations are considered more plausible than older ones. It is shownhow to encode an epistemic state using polynomials equipped with thelexicographical ordering. This encoding makes it very easy to implementand iterate the revision rule using simple operations on thesepolynomials. Moreover, polynonomials allow to keep track of the sequenceof observations. Lastly, it is shown how to practically compute therevision rule at the syntactical level, when the epistemic state isconcisely represented by a prioritized belief base. Our revision rule isthe most refined one can think of, in accordance with darwiche andPearl’s principles, and thus contrast with the minimal change rulecalled natural belief revision.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-104.pdf,
104,1999,Tractable Reasoning,Point-Based Approaches to Qualitative Temporal Reasoning,"J. Delgrande and A. Gupta, Simon Fraser University; T. Van Allen, University of Alberta","We address the general problem of efficient, qualitative, point-basedtemporal reasoning over a set of operations and their correspondingalgorithms. We consider general reasoners tailored for temporal domainsthat exhibit a particular structure and introduce a general reasonerbased on the series parallel graph reasoner of Delgrande and Gupta. Thisreasoner is also an extension of the TimeGraph reasoner of Gerevini andSchubert. Test results indicate that when there is some underlyingstructure in the data, our reasoner performs better than otherapproaches. When there is no underlying structure in the data, ourreasoner performs about the same as the simple approaches for queryanswering, although compile times are higher.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-105.pdf,
105,1999,Tractable Reasoning,Querying Temporal Constraint Networks in PTIME,"Manolis Koubarakis, University of Athens and Spiros Skiadopoulos, National Technical University of Athens","We start with the assumption that temporal knowledge usually captured byconstraint networks can be represented and queried more effectively byusing the scheme of indefinite constraint databases proposed byKoubarakis. Although query evaluation in this scheme is in general ahard computational problem, we demonstrate that there are severalinteresting cases where query evaluation can be done in PTIME. Thesetractability results are original and subsume previous results by vanBeek, Brusoni, Console and Terenziani.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-106.pdf,
106,1999,Tractable Reasoning,Polarity Guided Tractable Reasoning,"Zbigniew Stachniak, York University","Non-clausal refinement of Boolean Constraint Propagation inferenceprocedure for classical logic, called P-BCP, is introduced within a newknowledge representational formalism of polarized formulas. P-BCP issound, incomplete, and linear time inference procedure. It is shown thatP-BCP can be adopted for tractable reasoning in a number ofnon-classical logics (including some modal and finitely-valued logicalsystems).",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-107.pdf,
107,1999,Vision,"Content-Based Retrieval from Medical Image Databases: A Synergy of Human Interaction, Machine Learning and Computer Vision","C. Brodley, A. Kak, C. Shyu, and J. Dy, Purdue University; L. Broderick, University of Wisconsin Hospital; A. M. Aisen, Indiana University Medical Center","Content-based image retrieval (CBIR) refers to the ability to retrieveimages on the basis of image content. Given a query image, the goal of aCBIR system is to search the database and return the n most visuallysimilar images to the query image. In this paper, we describe anapproach to CBIR for medical databases that relies on human input,machine learning and computer vision. Specifically, we applyexpert-level human interaction for solving that aspect of the problemwhich cannot yet be automated, we use computer vision for only thoseaspects of the problem to which it lends itself best -- imagecharacterization -- and we employ machine learning algorithms to allowthe system to be adapted to new clinical domains. We present empiricalresults for the domain of high resolution computed tomography (HRCT) ofthe lung. Our results illustrate the efficacy of a human-in-the-loopapproach to image characterization and the ability of our approach toadapt the retrieval process to new clinical domains through theapplication of machine learning algorithms.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-108.pdf,
108,1999,Vision,Using Vision to Improve Sound Source Separation,"Yukiko Nakagawa and Hiroshi G. Okuno, Japan Science and Technology Corporation; Hiroaki Kitano, Japan Science and Technology Corporation and Sony Computer Science","We present a method of improving sound source separation usingvision. The sound source separation is an essential function toaccomplish auditory scene understanding by separating stream of soundsgenerated from multiple sound sources. By separating a stream of sounds,recognition process, such as speech recognition, can simply work on asingle stream, not mixed sound of several speakers. The performance isknown to be improved by using stereo/binaural microphone and microphonearray which provides spatial information for separation. However, thesemethods still have more than 20 degree of positional ambiguities. Inthis paper, we further added visual information to provide more specificand accurate position information. As a result, separation capabilitywas drastically improved. In addition, we found that the use ofapproximate direction information drastically improve object trackingaccuracy of a simple vision system, which in turn improves performanceof the auditory system. We claim that the integration of vision andauditory inputs improves performance of tasks in each perception, suchas sound source separation and object tracking, by bootstrapping.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-109.pdf,
109,1999,AAAI-99 Intelligent Systems Demos,Sensible Agents: Demonstration of Dynamic Configuration of Agent Organizations for Responsive Planning Operations,"K. S. Barber, A. Goel, D. Han, J. Kim, T. H. Liu, C. E. Martin, and R. McKay, The University of Texas","Decisions rarely occur in isolation, and decision makers must often respond to dynamic and unexpected events. A decision-maker must consider not only its own possible actions but also the possible behaviors and the resources of others who may either assist with planning and execution, accidentally interfere, or maliciously interfere. Dynamic Adaptive Autonomy (DAA) is the fundamental technology of Sensible Agents that permits a decision-making agent (responsible for planning and execution) to react, adjust, and respond to unpredictable environments. Sensible Agents can (1) assess current and potential interaction styles for planning, and (2) optimize planning frameworks by adjusting these styles. To address these issues, dynamic configuration of decision-making agent organizations is a must. Some specific research that has contributed to flexible, adaptive multi-agent coordination includes partial global planning (Durfee and Lesser, 1987), organizational self-design (Ishida et al., 1992), TEAMS flexible teamwork (Tambe, 1997), RETSINA matchmaking (Sycara and Pannu, 1998), and organizational fluidity (Glance and Huberman, 1993). However, these techniques do not specifically adapt agent planning-interaction styles.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-127.pdf,
110,1999,AAAI-99 Intelligent Systems Demos,The Disciple Integrated Shell and Methodology for Rapid Development of Knowledge-Based Agents,"Mihai Boicu, Kathryn Wright, Dorin Marcu, Seok Won Lee, Michael Bowman, and Gheorghe Tecuci, George Mason University","The Disciple Learning Agent Shell (Disciple-LAS) is anintegrated set of modules for rapid development of practicalend-to-end knowledge-based agents, by domain experts,with limited assistance from knowledge engineers. Disciple-LASand its associated agent building methodology arepresented in (Tecuci et al. 1999). Therefore, in this paper,we introduce two very different agents developed withDisciple-LAS, to show its applicability to a wide range ofdomains. Then we introduce the different modules that arepart of Disciple-LAS, and present their use in the agentbuilding process. Finally we summarize the solutionsproposed by the Disciple approach to some of the issuesthat have been found to be limiting factors in developingknowledge-based agents.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-128.pdf,
111,1999,AAAI-99 Intelligent Systems Demos,"SMILE: Structural Modeling, Inference, and Learning Engine and GeNIe: A Development Environment for Graphical Decision-Theoretic Models","Marek J. Druzdzel, University of Pittsburgh","SMILE(Structural Modeling, Inference, and Learning Engine)is a fully portable library of C++ classes implementinggraphical decision-theoretic methods, such as Bayesian networksand influence diagrams, directly amenable to inclusion in intelligent systems. Its Windows user interface, Genie isa versatile and user-friendly development environment forgraphical decision-theoretic models. Both modules, developedat the Decision Systems Laboratory, University of Pittsburgh,have been made available to the community in July1998 at http://www2.sis.pitt.edu/~genie and have over 1,200users worldwide (as of April 1999). This document summarizesthe basic features of Genie and Smile.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-129.pdf,
112,1999,AAAI-99 Intelligent Systems Demos,Knowledge Base Discovery Tool*,"Erik Eilerts, Kathleen Lossau, Christopher York, Austin Info Systems, Inc.","The Knowledge Base Discovery Tool (KBDT) is a suite of tools and components to improve the indexing of and search for documents. KBDT extracts and displays content from documents and builds knowledge indexes based on meaning, rather than keywords. KBDT uses the indexes to perform more intelligent searches. It also includes visualization technology to display relevant results using multi-media, rather than plain text. This paper describes prototypes of two tools in this suite that use components for searching, extraction, and display of requested information. The tools are the Knowledge Base Editor and the Intelligent Information Retrieval Engine.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-130.pdf,
113,1999,AAAI-99 Intelligent Systems Demos,TRIPS: The Rochester Interactive Planning System,"George Ferguson and James F. Allen, University of Rochester","This demonstration showcases TRIPS, The Rochester Interactive Planning System, an intelligent, collaborative, conversational planning assistant. TRIPS collaborates with the user using both spoken dialogue andgraphical displays to solve problems in a transportation logistics domain. In our demonstrations, users are encouraged to sit down and try the system, with only rudimentary guidance from us. For further information, including QuickTime movies of the system in ac-tion, please visit our website at the URL listed above.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-131.pdf,
114,1999,AAAI-99 Intelligent Systems Demos,A Natural-Language Speech Interface Constructed Entirely as a Set of Executable Specifications,"R. A. Frost, University of Windsor","SpeechNet is a collection of speech-accessible hyperlinked objects called sihlos. Sihlos are deployed over the Internet and are accessed by remote speech browsers. When a speech browser accesses a sihlo, it begins by downloading a grammar file which is used to configure the browser in order to achieve high recognition accuracy. Sihlos are hyperlinked in a manner that is similar to the linking of html pages. SpeechNet provides non-visual access to knowledge which is analogous to visual access provided by the web. One of the sihlos can answer thousands of spoken pseudo-natural-language questions about the solar system. This sihlo has been constructed entirely as a set of executable specifications of the language that it can process.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-132.pdf,
115,1999,AAAI-99 Intelligent Systems Demos,A System for the Semantic Interpretation of Unrestricted Domains using WordNet,"Fernando Gomez, University of Central Florida and Carlos Segami, Barry University","In this demonstration, we show an algorithm for the semantic interpretation of unrestricted texts. The algorithm presents a solution for the following interpretation problems: determination of the meaning of the verb, identification of thematic roles and adjuncts, and attachments of prepositional phrases (PPs).",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-133.pdf,
116,1999,AAAI-99 Intelligent Systems Demos,"DIPLOMAT: Compiling Prioritized Default Rules into Ordinary Logic Programs, for E-Commerce Applications","Benjamin N. Grosof, IBM T.J. Watson Research Center","Rules promise to be widely useful in Internet electronic commerce. Declarative prioritized defaultrule knowledge representations offer the advantage of handling con icts that arise in updating rule sets, but have as yet had little practical deployment. DIPLOMAT is a Java librarythat embodies a new approach to the implementation of such prioritized default rules: to compile them into ordinary logic programs (LP’s) cf. pure Prolog. We apply the approach to a newlygeneralized version of courteous LP’s, a semantically attractive and computationally tractableform of prioritized default rules. Compilation enables courteous LP’s functionality to be addedmodularly to ordinary LP rule engines, via a preprocessor, with tractable computational overhead.This takes a long step towards actual deploymentof prioritized-default knowledge representation incommercially fielded technology and applications.We give in the demo storyboard an automatedexample e-commerce application scenario: inferencing in a 70-rule courteous LP that representspersonalized pricing and promotions on a bookstore’s Web storefront.The extended version of this paper, available as an IBM Research Report, containsthe demo storyboard and technical details.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-134.pdf,
117,1999,AAAI-99 Intelligent Systems Demos,Solving Crosswords with Proverb,"Michael L. Littman, Greg A. Keim, and Noam M. Shazeer, Duke University","We attacked the problem of solving crossword puzzles by computer: Given a set of clues and a crossword grid, try to maximize the number of words correctly filled in. Proverb , the probabilistic cruciverbalist, separates the problem into two, more familiar subproblems: candidate generation and grid filling. In candidate generation, each clue is treated as a type of query to an information retrieval system, and relevant words of the correct length are returned along with confidence scores. In grid filling, the candidate words are fit into the puzzle grid to maximize an overall confidence score using a combination of ideas from beliefnetwork inference and constraint satisfaction. For our demonstration, we will have an interactive version of the candidate-generation process available via the web, and will also give people an opportunity to go head-to-head against Proverb in solving complete puzzles.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-135.pdf,
118,1999,AAAI-99 Intelligent Systems Demos,Worldwide Aeronautical Route Planner,"Charles B. McVey, David P. Clements, Barton C. Massey, and Andrew J. Parkes, University of Oregon","We consider the common problem of calculating routes from a starting point to a destination through a given space. This process typically involves discretizing the navigational space into a graph of intermediate waypoints linked together through transitions. A search for a solution that fits desired criteria can then be performed. Typical criteria include: minimum distance, minimum transit time, minimum fuel use, and maximum agent safety. Our work in this area focuses on the rapid determination of minimal fuel routes for aircraft to fly from any source point to any destination point on the earth. The Worldwide Aeronautical Route Planner (WARP) is our prototype demonstration of technology developed to perform optimal real-time (under one minute per route) flight planning. WARP uses high-fidelity aircraft flight models, standard rules of flight operation, actual time-dependent worldwide weather data, and a variant of A* (Multi-Pass A*) which retains A*’s completeness and optimality properties. WARP discovers the flight plan that guarantees minimal use of fuel. Typical routes are generated by WARP in under thirty seconds, with fuel savings on the order of one to eight percent compared to great circle (minimum distance) routes.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-136.pdf,
119,1999,AAAI-99 Intelligent Systems Demos,Authoring New Material in a Reading Tutor that Listens,"Jack Mostow and Gregory Aist, Carnegie Mellon University","Project LISTEN’s Reading Tutor helps children learn to read by providing assisted practice in reading connected text. A key goal is to provide assistance for reading any English text entered by students or adults. This live demonstration shows how the Reading Tutor helps users enter and narrate stories, and then helps children read them. Areas: intelligent interfaces, computer-aided instruction, dialog, speech recognition.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-137.pdf,
120,1999,AAAI-99 Intelligent Systems Demos,Demonstration of Rational Communicative Behavior in Coordinated Defense,"Sanguk Noh and Piotr J. Gmytrasiewicz, University of Texas at Arlington","The primary goal of our demonstration is to showresults we obtained on communication among artificial and human agents interacting in a simulated air-defense domain. For artificial agents, we advocate a decision-theoretic message selection mechanism which maximizes the expected utility of the communicative actions. Thus, the agents compute the expected utility of alternative communicative behaviors, and execute the one with the highest value. Following the principle of maximizing the expected utility, our agents are intended to be rational in their communicative behavior; they send only the most valuable messages, and never send messages they consider to be damaging given the circumstances at hand.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-138.pdf,
121,1999,AAAI-99 Intelligent Systems Demos,Automated Team Analysis,"Taylor Raines, Milind Tambe, and Stacy Marsella, University of Southern California","We have created an agent for analyzing and improving synthetic teams. The agent is built in a bottom-up fashion using little specific domain knowledge. In lieu of extensive domain knowledge, data mining and inductive learning techniques are used in an attempt to isolate the key issues determining the successes or failures of these teams. This approach has been applied to the RoboCup domain, with a current focus on analyzing shots on goal and with future plans for assists, passing, and general teamwork.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-139.pdf,
122,1999,AAAI-99 Intelligent Systems Demos,eMediator: A Next Generation Electronic Commerce Server,"Tuomas Sandholm, Washington University","eMediator , a next generation electronic commerceserver,demonstrates ways in which AI, algorithmic support, gametheoretic incentive engineering, and GUI design can jointlyimprove the efficiency of ecommerce. The first component,eAuctionHouse , is a configurable auction house that supports alarge variety of parameterizable auction types. It supportsgeneralized combinatorial auctions with new algorithms for winnerdetermination. It also allows bidding via graphically drawnprice-quantity graphs. It has an expert system for helping theuser decide which auction type to use. Finally, it supportsmobile software agents that bid optimally on the user’s behalfbased on game theoretic analyses. The second component,eCommitter , is a leveled commitment contract optimizer. Inautomated negotiation systems consisting of self-interestedagents, contracts have traditionally been binding. Leveledcommitment contracts, i.e. contracts where each party can decommitby paying a predetermined penalty|were recently shown to improvePareto efficiency even if agents rationally decommit in Nashequilibrium using in ated thresholds on how good their outsideoffers must be before they decommit. eCommitter solves the Nashequilibrium thresholds. Furthermore, it optimizes the contractprice and decommitment penalties themselves.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-140.pdf,
123,1999,AAAI-99 Intelligent Systems Demos,MailCat: An Intelligent Assistant for Organizing E-Mail,Richard B. Segal and Jeffrey O. Kephart,"MailCat is an intelligent assistant that helps users organizetheir e-mail into folders. It uses a text classifier to learneach user’s mailling habits. MailCat uses what it learns topredict the three folders in which the user is most likely toplace each incoming message. It then provides shortcut buttons tofile each message into one of these three folders. When one ofMailCat’s predictions is correct, the effort required to file amessage is reduced to a single button click.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-141.pdf,
124,1999,AAAI-99 Intelligent Systems Demos,"HIKE (HPKB Integrated Knowledge Environment) -- A Query Interface and Integrated Knowledge Environment for HPKB","Barbara H. Starr, Vinay K. Chaudhri, Boris Katz, Benjamin Good, and Jerome Thomere","This demonstration is based upon the results of a research project sponsored by the Defense Advance Research Projects Agency (DARPA), called High Performance Knowledge Bases (HPKB). The demonstrated portion of HPKB follows a question-answering paradigm. The integrated architecture developed at Science Applications International Corporation (SAIC), called the HPKB Integrated Knowledge Environment (HIKE) is introduced. Following this, the components involved in the demonstration, which include a natural language understanding system, a first order theorem prover, and a knowledge server are briefly described. The demonstration effectively illustrates the use of both a graphical user interface and a natural language interface to query a first order theorem prover with similar results.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-142.pdf,
125,1999,AAAI-99 Intelligent Systems Demos,Intelligent Agents in Computer Games,"Michael van Lent, John Laird, Josh Buckman, Joe Hartford, Steve Houchard, Kurt Steinkraus, and Russ Tedrake, University of Michigan","As computer games become more complex and consumers demand more sophisticated computer controlled opponents, game developers are required to place a greater emphasis on the artificial intelligence aspects of their games. Our experience developing intelligent air combat agents for DARPA has suggested a number of areas of AI research that are applicable to computer games. Research in areas such as intelligent agent architectures, knowledge representation, goal-directed behavior and knowledge reusability are all directly relevant to improving the intelligent agents in computer games. The Soar/Games project at the University of Michigan Artificial Intelligence Lab has developed an interface between Soar (Laird, Newell, and Rosenbloom 1987) and the commercial computer games Quake II and Descent 3. Techniques from each of the research areas mentioned above have been used in developing intelligent opponents in these two games.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-143.pdf,
126,1999,Robot Competition and Exhibition,Sensor Based Coverage of Unknown Environment for Land Mine Detection,"Ercan Acar, Morgan Simmons, Michael Rosenblatt, Maayan Roth, Mary Berna, Yonatan Mittlefehldt and Howie Choset, Carnegie Mellon University",This paper introduces a sensor based coverage algorithm and an overview of a mobile robot system for demining. The algorithm is formulated in terms of critical points which are the points where the topology of an environment changes. We developed a provably complete coverage algorithm which makes a robot pass over all possible points of an unknown environment.,https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-144.pdf,
127,1999,Robot Competition and Exhibition,A Natural Interface and Unified Skills for a Mobile Robot,"William Adams, Dennis Perzanowski, and Alan C. Schultz, Naval Research Laboratory","Our research is aimed at developing an independent, cooperative, autonomous agent. Toward this end, we are working on two areas: a natural interface for interacting with the robot, and the basic underlying skills for navigating in previously unknown environments.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-145.pdf,
128,1999,Robot Competition and Exhibition,Kansas State Robotics,"Frank Blecha, Tim Beese, Damon Kuntz, Jonathan Cameron, David Sexton, and David Gustafson, Kansas State University","The Computing and Information Sciences Department at Kansas State University has developed a software control laboratory for the purpose of exposing undergraduate students to the problems of developing software on real, moving equipment. The equipment in the laboratory consists of two Nomad200 robots and two Scout robots from Nomadic Technology, Inc. The main use of the equipment is in a capstone, two-semester software engineering sequence. In this course, selected teams of students develop software to control the robot in tasks such as maze running, object identification or environment mapping. In the last few AAAI robotic contests, the tasks have been similar to projects in the course.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-146.pdf,
129,1999,Robot Competition and Exhibition,Web-Based Mobile Robot Simulator,"Dan Stormont, Utah State University","Many roboticists rely on simulation during the early phases of developing navigation algorithms for their autonomous mobile robots. While many commercial robots now come with robust development environments that include visual simulators, these tools aren’t available to robotics researchers who are working with a custom-built robot or who have not yet determined which commercial robot will satisfy their requirements. Even researchers using one of the commercial development environments will have difficulty sharing their simulation results with colleagues or others who do not have access to the commercial development tools. Believing that the ability to share simulation results visually with the greatest number of people would be an important capability to have led to the development of the web-based simulation approach described in this paper.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-147.pdf,
130,1999,1999 SIGART/AAAI Doctoral Consortium,Elaboration Tolerance of Logical Theories,"Eyal Amir, Stanford University","We consider the development and modification oflogical theories (e.g., commonsense theories). During development of such knowledge bases (KBs) a knowledge engineer makes some design and modeling choices. These decisions may later force the KB to undergo some redesign and rewriting when new knowledge needs to be integrated. We then say that the KB lacks Elaboration Tolerance. McCarthy illustrated this problem using example elaborations for the toy problem of the Missionaries and Cannibals.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-148.pdf,
131,1999,1999 SIGART/AAAI Doctoral Consortium,Approximation Algorithms for Solving Cost Observable Markov Decision Processes,"Valentina Bayer, Oregon State University",Designing approximation algorithms to solve problems that have partial observability is the focus of this research. The model we propose (Cost Observable Markov Decision Processes or COMDPs) associates costs with obtaining information about the current state. The COMDP’s actions are of two kinds: world actions and observation actions.,https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-149.pdf,
132,1999,1999 SIGART/AAAI Doctoral Consortium,Using Formal Meta-Data Descriptions for Automated Ecological Modeling,"Virginia V. B. Biris Brilhante, University of Edinburgh","We observe that property descriptions of ecological data (ecological meta-data), such as functional, temporal and spatial relations between variables, seem to be cognitively close to the concepts and reasoning used by model designers. Can the process of linking ecological meta-data to model design be automated? We aim to answer this question by: (1) developing a formal language for expressing ecological metadata; (2) building a logic-based formalisation of connections between the meta-data descriptions and model design; and (3) semi-automating model design endorsed by meta-data descriptions.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-150.pdf,
133,1999,1999 SIGART/AAAI Doctoral Consortium,Modeling Higher Cognitive Functions with Hebbian Cell Assemblies,"Marcin Chady, University of Birmingham",The objective of this work is to develop a model of higher cognitive behaviour using the connectionist paradigm.,https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-151.pdf,
134,1999,1999 SIGART/AAAI Doctoral Consortium,Learning Form-Meaning Mappings for Language,"Nancy Chang, University California, Berkeley and International Computer Science Institute","The proposed thesis research addresses two of the main obstacles to building agents that communicate using natural language: the need for richer representations of linguistic constructions that incorporate aspects of conceptual knowledge, context and goals; and the need for a principled approach to the automatic ac- quisition of such structures from examples. More generally, it explores the idea that patterns that arise in language are inextricably linked with and motivated by patterns of meaning and experience. This view, along with empirical evidence suggesting that linguistic knowledge at all levels can be characterized as mappings between form and meaning, serves as the basis for a computational model of the acquisition of simple phrasal and clausal constructions.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-152.pdf,
135,1999,1999 SIGART/AAAI Doctoral Consortium,Development of a Methodology and Software Shell for the Automatic Generation of Intelligent Tutoring Systems from Existing Generic Task-Based Expert Systems,"Eman M. El-Sheikh, Michigan State University","This research proposes a novel approach to developing an intelligent tutoring system shell that will generate tutoring systems for a wide range of domains. The goal is to develop an ITS authoring environment that interacts with any generic task-based expert system, and to produce a tutoring system fo9r the domain knowledge represented in that system.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-153.pdf,
136,1999,1999 SIGART/AAAI Doctoral Consortium,Towards Bounded Optimal Meta-Level Control: A Case Study,"Daishi Harada, University of California, Berkeley","Suppose we allow the controller to perform arbitrary search, and to base its control on the backed up information. To do this, we need to make decisions about the following: the order in which search nodes are expanded, and when to stop searching and actually ""commit"" to a control. The approach that we take is to view these decisions as the meta-level control problem. With some care in the formulation, it can be seen that a solution to this meta-level control problem will provide us with a bounded optimal controller. We would like to solve this problem by using algorithms from reinforcement learning.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-154.pdf,
137,1999,1999 SIGART/AAAI Doctoral Consortium,Execution Monitoring and Diagnosis in Multi-Agent Environments,"Gal A. Kaminka, University of Southern California","We investigate a novel complementary paradigm for multi-agent monitoring and diagnosis. Socially-Attentive Monitoring (SAM) focuses on monitoring the social relationships between the agents as they are executing their tasks, and uses models of multiple agents and their relationships in monitoring and diagnosis.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-155.pdf,
138,1999,1999 SIGART/AAAI Doctoral Consortium,Corpus-Based Induction of Lexical Representation and Meaning,"Maria Lapata, University of Edinburgh","The acquisition of linguistic knowledge, i.e., the identification, extraction, and encoding of linguistic information in a corpus, has been one of the main motivations for data-driven approaches to natural language. Methods have been developed for the acquisition of, for instance, parts of speech, noun compounds, collocations, support verbs, subcategorization frames, phrase structure rules, selectional restrictions and sense induction for an overview). Drawing on this body of research, I am investigating the acquisition of lexical semantic knowledge from corpora, thereby addressing the logical problem of language acquisition, one of the fundamental issues in linguistics and cognitive science.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-156.pdf,
139,1999,1999 SIGART/AAAI Doctoral Consortium,Data Driven Profiling of Dynamic System Behavior Using Hidden Markov Model Based Combined Unsupervised and Supervised Classification,"Cen Li, Vanderbilt University","Dynamic systems are often best characterized by a combination of static and temporal features, with the static features describing time-invariant properties of the system, and the temporal features capturing dynamic aspects of the system. Our goal is to construct context based temporal behavior models of dynamic systems using information from both types of features. Our dynamic system profiling framework consists of three main steps: (i) model generation, (ii) model validation, and (iii) model interpretation. Model generation step can be further decomposed into two components: (ia) temporal model generation, and (ib) context generation.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-157.pdf,
140,1999,1999 SIGART/AAAI Doctoral Consortium,Planning under Uncertainty via Stochastic Satisfiability,"Stephen M. Majercik, Duke University","A probabilistic propositional planning problem can be solved by converting it to a stochastic satisfiability problem and solving that problem instead. I have developed three planners that use this approach: maxplan , c-maxplan , and zander . maxplan , which assumes complete unobservability, converts a dynamic belief network representation of the planning problem to an instance of a stochastic satisfiability problem called E-Majsat . maxplan then solves that problem using a modified version of the Davis-Putnam-Logemann-Loveland (DPLL) procedure for determining satisfiability along with time-ordered splitting and memoization.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-158.pdf,
141,1999,1999 SIGART/AAAI Doctoral Consortium,Applying Supervised Learning to Real-World Problems,"Dragos D. Margineantu, Oregon State University","The last years have seen machine learning methods applied to an increasing variety of application problems such as: language, handwriting and speech processing, document classification, knowledge discovery in databases, industrial process control and diagnosis, fraud and intrusion detection, image analysis and many others. Our work starts from the realization that most of these problems require significant reformulation before learning algorithms can be applied, and in many cases, existing algorithms require modifications before being applied to a problem.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-159.pdf,
142,1999,1999 SIGART/AAAI Doctoral Consortium,Modeling Prosody Automatically in Concept-to-Speech Generation,"Shimei Pan, Columbia University","My thesis emphasizes investigation and establishment of systematic methodologies for automatic prosody modeling using corpus analysis. Prosody modeling in most previous CTS systems employs handcrafted rules, with little evaluation of the overall performance of the rules. By systematically employing different machine learning techniques on a speech corpus, I am able to automatically model prosody for a given domain. Another focus of my thesis is on system architecture. There are two concerns when designing a CTS system: modularity and extensibility. The goal is to design a exible CTS system so that new prosody generators, natural language generators and speech realization systems can be incorporated without requiring major changes to the existing system. Designing a CTS system to facilitate multimedia synchronization is another focus of this research.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-160.pdf,
143,1999,1999 SIGART/AAAI Doctoral Consortium,A Bayesian Approach to Object Identification,"Hanna Pasula, University of California, Berkeley","There are many real world domains where an agent can observe the world state only partially and intermittently, using noisy sensors. Merely keeping track of the objects present in such a system is non-trivial. The problem may be complicated further if the system dynamics are not fully known or unpredictable, so that some on-line learning is necessary. Ihave been working on a principled approach to state estimation and prediction under these realistic conditions. So far, I have focused mostly on object identification, deciding if some newly observed object is the same as a previously observed one. The work has been applied to the surveillance of a large metropolitan freeway system.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-161.pdf,
144,1999,1999 SIGART/AAAI Doctoral Consortium,Over-Constrained Systems,"Hana Rudová, Masaryk University","Standard methods for solving over-constrained problems apply constraint preferences for definition of optimal solution. There are, however, over-constrained problems with partially or even completely ordered variables and this ordering creates natural preferences for given problem. I developed a new constraint solving environment, where these preferences (variables’ annotations) dependent on variable occurence in constraint are applied.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-162.pdf,
145,1999,1999 SIGART/AAAI Doctoral Consortium,Reasoning about Sensing Actions and Reactivity,"Son Cao Tran, University of Texas at El Paso",This thesis focuses on the problem of reasoning about sensing actions and the relationship between action theory and reactive control.,https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-163.pdf,
146,1999,Student Abstracts,Applying Genetic Algorithms to Pronoun Resolution,"Donna K. Byron and James F. Allen, University of Rochester","Many pronoun resolution algorithms work by calculating the most salient candidate antecedent. However, many factors affect salience, for example being the syntactic subject or the most frequently mentioned item, and these factors must be combined into an aggregate salience score. One technique is to assign weights for each factor representing the amount by which that factor impacts the overall salience, and the candidate antecedent which accumulates the most weight is selected. Previous authors assigned weights heuristically (cf. Mitkov 1998). By using a genetic algorithm to select the weights, our program beats baseline techniques, and can be customized for each language domain.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-164.pdf,
147,1999,Student Abstracts,Automatic Sample-by-Sample Model Selection Between Two Off-the-Shelf Classifiers,"Steve P. Chadwick, University of Texas at Dallas","If one could predict which of two classifiers will correctly classify a particular sample, then one could use the better classifier. Continuing this selection process throughout the data set should result in improved accuracy over either classifier alone. Fortunately, scalar measures which relate to the degree of confidence that we have in a classification can be computed for most common classifiers. Some examples of confidence measures are distance from a linear discriminant separating plane, distance to the nearest neighbor, distance to the nearest unlike neighbor, and distance to the center of correctly classified training data. We propose to apply discriminant analysis to the confidence measures, producing a rule which determines when one classifier is expected to be more accurate than the other.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-165.pdf,
148,1999,Student Abstracts,Structural Knowledge Discovery in Chemical and Spatio-Temporal Databases,"Ravindra N. Chittimoori, Jesus A. Gonzalez, and Lawrence B. Holder, University of Texas at Arlington","Most current knowledge discovery systems use only attribute-value information. But relational information between objects is also important to the knowledge hidden in today’s databases. Two such domains are chemical structures and domains where objects are related in space and time. Inductive Logic Programming (ILP) discovery systems handle relational data, but require data to be expressed as a subset of first-order logic. We are investigating the application of the graph-based relational discovery system Subdue in structural domains.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-166.pdf,
149,1999,Student Abstracts,Learning Design Guidelines by Theory Refinement,"Jacob Eisenstein, Stanford University","We add adaptation to an existing piece of automatic design software: the TIMM module of the MOBI-D user- interface design environment. MOBI-D maintains explicit, formal representations of the abstract and concrete sides of the interface. TIMM automates the mappings between the abstract domain objects and concrete presentation elements, using a decision tree.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-167.pdf,
150,1999,Student Abstracts,Using Neural Networks in Agent Teams to Speed Up Solution Discovery for Hard Multi-Criteria Problems,"Shaun Gittens, University of Maryland; Richard Goodwin, Jayant Kalagnanam, and Sesh Murthy, IBM T.J. Watson Research Center","The framework we use, called the Asynchronous Team (A-Team) architecture, deploys teams of optimizing agents to evolve population(s) of candidate solutions to instances of hard MC problems in order to develop very good solutions. In this framework, agents embody specific heuristics geared to create, modify, or destroy any of a number of possible solutions to a problem instance.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-168.pdf,
151,1999,Student Abstracts,OBDD-Based Planning with Real-Valued Variables in Non-Deterministic Environments,"A. Goel and K. S. Barber, University of Texas at Austin","We are developing a planner that can efficiently handle non-determinism and real variables using neither relative values nor explicit enumeration. In doing so, we are leveraging tools and representations from planning and logic synthesis for computer-aided verification.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-169.pdf,
152,1999,Student Abstracts,Expectation-Based Learning in Design,"Dan L. Grecu and David C. Brown, Worcester Polytechnic Institute","Design problems typically have a very large number of problem states, many of which cannot be anticipated at the onset of the design. Some design problem states are characterized by as many as hundreds of parameters. Given these amounts of uncertainty and information, AI design systems faced with learning tasks cannot know from the beginning what needs to be learned, and whether these needs will remain the same. In this abstract we describe how LEAD (Learning Expectations in Agent-based Design), a multi-agent system for parametric and configuration design, addresses these challenges in design learning.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-170.pdf,
153,1999,Student Abstracts,A Framework for Problem Solving Activities in Multi-Agent Systems,"D. C. Han, T. H. Liu, and K. S. Barber, University of Texas at Austin","The basic research issues in multi-agent systems (MAS) include problem decomposition, task distribution, communication, plan synthesis, coordination, conflict resolution, and organization design. For practical implementation, there is a need for an integrated framework that can help MAS designers to select appropriate techniques for building their specific systems. Difficulties in the integration of techniques for each of these issues is due to the interdependencies among the issues themselves. We propose a framework that describes the activities that occur during problem solving. This framework is based upon the premise that meta-level reasoning about the agents’ activities adds flexibility to each agent, allowing them to adjust to changes in their environments or operating conditions.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-171.pdf,
154,1999,Student Abstracts,Robot Navigation with a Polar Neural Map,"Michail G. Lagoudakis, Duke University, and Anthony S. Maida, University of Southwestern Louisiana","Neural maps have been recently proposed as an alternative method for mobile robot path planning. However, these proposals are mostly theoretical and are primarily concerned with biological plausibility. Our purpose is to investigate their applicability on real robots.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-172.pdf,
155,1999,Student Abstracts,Comparison of Clustering Metrics and Unsupervised Learning Algorithms on Genome-Wide Gene Expression Level Data,"Sonia Leach, Brown University; Lawrence Hunter, National Cancer Institute; David Landsman, National Center for Biotechnology Information","With the recent availability of genome-wide DNA sequence information, biologists are left with the overwhelming task of identifying the biological role of every gene in an organism. Technological advances now provide fast and efficient methods to monitor, on a genomic scale, the patterns of gene expression in response to a stimulus, lending key insight about a gene’s function. With this wealth of information comes the need to organize and analyze the data. One natural approach is to group together genes with similar patterns of expression. Several alternatives have been proposed for both the similarity metric and the clustering algorithm. However, these studies used a specific metric-clustering algorithm pair. In our work, we aim to provide a more systematic investigation into the various metric and clustering algorithm alternatives. We also offer two methods to handle missing data.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-173.pdf,
156,1999,Student Abstracts,Knowledge Base Revision through Exception-Driven Discovery and Learning,"Seok Won Lee and Gheorghe Tecuci, George Mason University","We are enhancing Disciple by developing a mixed-initiative multistrategy approach to KB revision that will result in an extended and domain-adapted ontology, as well as a set of rules with fewer (if any) exceptions. We are developing two classes of KB revision methods, a class of local methods and a class of global methods.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-174.pdf,
157,1999,Student Abstracts,Autonomous Discovery in Empirical Domains,"Gary Livingston and Bruce G. Buchanan, University of Pittsburgh","We have tested a hypothesis that the agenda-based architecture used in AM (Lenat 1982) can be adapted to perform autonomous discovery in empirical domains. Our preliminary evaluation of our adaptation, HAMB (Heuristic, Autonomous Model Builder), suggests that the architecture is practical and sufficient for empirical discovery. HAMB was able to make many discoveries and rediscoveries from the domain of macromolecule crystal-growing experiments (Gililand 1987).",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-175.pdf,
158,1999,Student Abstracts,Learning in Broker Agent,"Xiaocheng Luan, Yun Peng, and Timothy Finin, University of Maryland Baltimore County","One of the common ways to achieve interoperability among the autonomous agents is to use a broker agent (or a facilitator). Simple broker agents provide match-making services based on the capability information volunteered by individual agents and the (recommendation) request. The problem is, even with a very good agent capability description language and a powerful match-making mechanism, if the actual capability information volunteered by each individual agent is not accurate, it won’t be of much help. Given that the autonomous agents might be written by different people, at different time, and for different purpose, this is likely to occur. This work is an attempt to solve such problems by incorporating learning into broker agents so that the broker agents can capture more accurate information about the capabilities of individual agents.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-176.pdf,
159,1999,Student Abstracts,Text Compression as a Test for Artificial Intelligenc,"Matthew V. Mahoney, Florida Institute of Technology","It is shown that optimal text compression is a harder problem thanartificial intelligence as defined by Turing’s (1950) imitationgame; thus compression ratio on a standard benchmark corpuscould be used as an objective and quantitative alternative test forAI.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-177.pdf,
160,1999,Student Abstracts,Externalizing Internal State,"Amol D. Mali, Arizona State University","Current autonomous robots that are highly reactive are not significantly intelligent and the robots that are significantly intelligent are not highly reactive. The previous research has concentrated on modifications to internal computational structures of robots, ignoring the modifications to external environments (which can preserve both intelligence and reactivity). This work is the first to formalize the modification of an environment that externalizes the internal states.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-178.pdf,
161,1999,Student Abstracts,Hybrid Propositional Encodings of Planning,"Amol D. Mali, Arizona State University","Casting planning as propositional satisfiability has been recently shown to be a very promising technique of plan synthesis. Some challenges, one of which is the de- velopment of hybrid propositional encodings (that com- bine the important notions from the existing encodings) have also been posed to the community. The existing encodings are either entirely based only on the plan space planning (also known as ""causal"" or ""least com- mitment"" or ""partial order"" planning) or only on the state space planning. To answer this challenge, we have developed several hybrid encodings.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-179.pdf,
162,1999,Student Abstracts,Causal Discovery from Population-Based Infant Birth and Death Records,"Subramani Mani and Gregory F. Cooper, University of Pittsburgh",The most useful explanation of a phenomenon is of- ten a description of the underlying causal processes (Salmon 1998). This is particularly true in the domain of medicine where identification of the causal factors of a disease in uence treatment planning and develop- ment ofintervention strategies for disease prevention and control. The study described here focuses on causal discovery from observational data related to infant mor- tality in the United States.,https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-180.pdf,
163,1999,Student Abstracts,Interacting with a Pet Robot Using Hand Gestures,"Milyn C. Moy, MIT Artificial Intelligence Lab and Oracle Corporation","This work focuses on the real-time, visual interpretation of 2D dynamic hand gestures in complex environments. Our goal is to enable humans to communicate and interact with Yuppy, a pet robot being developed at the MIT AI Lab. The gesture lexicon consists of a set of 2D gesture classes (primitives) that include linear (vertical, horizontal, and diagonal) as well as circular (clockwise and counterclockwise) gestures.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-181.pdf,
164,1999,Student Abstracts,Active Learning for Hierarchical Wrapper Induction,"Ion Muslea, Steve Minton, and Craig Knoblock, University of Southern California","As an alternative to manually writing extraction rules, we created STALKER, which is a wrapper induction algorithm that learns high-accuracy extraction rules. The major novelty introduced by STALKER is the concept of hierarchical wrapper induction: the extraction of the relevant data is performed in a hierarchical manner based on the embedded catalog tree (ECT), which is a user-provided description of the information to be extracted.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-182.pdf,
165,1999,Student Abstracts,Decision-Theoretic Layered Robotic Control Architecture,"Gilbert Peterson and Diane J. Cook, University of Texas at Arlingto","One of the current methods for developing task control software for robots is a layering approach. This approach generally consists of a symbolic planner, a task sequencer, and a behavioral robotic controller. The task sequencer is responsible for taking a command from an abstract plan and selecting which robot level actions and behaviors to execute. This representation leads to a robust functioning software control for a robot and a single task. When the robot must be reconfigured for a new task, elements must be added to the sequencer, and behaviors to the behavioral controller. We are currently developing a decision-theoretic planner to function as the planning and sequencing layers for the architecture. It is our expectation that using a decision-theoretic planner as the sequencer will reduce the amount of work to reconfigure for a new task.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-183.pdf,
166,1999,Student Abstracts,Learning of Compositional Hierarchies by Data-Driven Chunking,"Karl Pfleger, Stanford University","Compositional hierarchies (CHs), layered structures of part-of relationships, underlie many forms of data, and rep-resentations involving these structures lie at the heart of much of AI. Despite this importance, methods for learning CHs from data are scarce. We present an unsupervised technique for learning CHs by an on-line, bottom-up chunking process. At any point, the induced structure can make predictions about new data.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-184.pdf,
167,1999,Student Abstracts,A Representation Reducing Approach to Scientific Discovery,"Joseph Phillips, University of Michigan","The proliferation of sensors and the ease of large dataset maintenance have given many scientists more data than can be analyzed by traditional means. Computers have long been used to help scientists calculate. Science, however, is more than calculating. Science at least also involves hypothesis generation and testing, planning, and integrating prior knowledge with new ideas. Artificial intelligence (AI) and database (DB) technologies have grown to the point where they may be able to help scientists in more meaningful ways. We investigate a principled approach to semi-automated knowledge discovery in databases (KDD) for integrated scientific discovery and the rationale for this approach.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-185.pdf,
168,1999,Student Abstracts,Minimal Cost Complexity Pruning of Meta-Classifiers,"Andreas L. Prodromidis and Salvatore J. Stolfo, Columbia University","This extended abstract describes a pruning algorithm that is independent of the combining scheme and is used for discarding redundant classifiers without degrading the overall predictive performance of the pruned meta- classififier. To determine the most effective base classifiers, the algorithmtakes advantage of the minimal cost-complexity pruning method of the CART learning algorithm which guarantees to find the best (with respect to misclassification cost) pruned tree of a specific size (number of terminal nodes) of an initial unpruned decision tree.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-186.pdf,
169,1999,Student Abstracts,Comparison of Second-Order Polynomial Model Selection Methods: An Experimental Survey,"Grace W. Rumantir, Monash University","This abstract gives an overview of the work described in (Rumantir 1999). The paper compares some of the most commonly cited model selection criteria that claim to have the mechanism to balance between model complexity and goodness of t. The model chosen by any of the methods is claimed to be a parsimonious description of the data at hand, therefore has predictive power for future data.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-187.pdf,
170,1999,Student Abstracts,Learning State Features from Policies to Bias Exploration in Reinforcement Learning,"Bryan Singer and Manuela Veloso, Carnegie Mellon University","When given several problems to solve in some domain, a standard reinforcement learner learns an optimal policy from scratch for each problem. This seems rather unfortunate in that one might expect some domain-specific information to be present in the solution to one problem for solving the next problem. Using this information would improve the reinforcement learner’s performance. However, policies learned by standard reinforcement learning techniques are often very dependent on the exact states, rewards, and state transitions in the particular problem. Therefore, it is infeasible to directly apply a learned policy to new problems, and so several approaches have been and are being investigated to find structure, abstraction, generalization, and/or policy reuse in reinforcement learning. Within our line of research, we describe each state in terms of local features, assuming that these state features together with the learned policies can be used to abstract out the domain characteristics from the specific layout of states and rewards of a particular problem. When given a new problem to solve, this abstraction is used as an exploration bias to improve the rate of convergence of a reinforcement learner.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-188.pdf,
171,1999,Student Abstracts,Investigating the Effect of Relevance and Reachability Constraints on SAT Encodings of Planning,"Biplav Srivastava, Arizona State University","Recently, satisfiability (SAT) techniques have been shown to be more efficient at extracting solutions from a planning graph in Graphplan than the standard backward search. Graphplan gains efficiency from forward propagation and backward use of mutual exclusion constraints. The utility of SAT techniques for solution extraction raises two important questions: (a) Are the mutual exclusion constraints equally useful for so-lution extraction with SAT encodings? (b) If so, are there additional types of propagated constraints that can benefit them even more? Our ongoing research investigates these two questions.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-189.pdf,
172,1999,Student Abstracts,Learning to Handle Inconsistency for Multi-Source Integration,"Sheila Tejada, Craig A. Knoblock, and Steven Minton, University of Southern California","The goal of this research is to be able to create mapping constructs so that an information broker, like Ariadne, can use it to properly integrate data from inconsistent sources in an intelligent and efficient manner.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-190.pdf,
173,1999,Student Abstracts,Learning Rewrite Rules to Improve Plan Quality,"Muhammad Afzal Upal, University of Alberta",This paper presents a system called REWRITE that automatically learns rewrite rules. REWRITE has three main components. The first is a partial-order causal-link planner (POP). The second component does the analytic work of identifying the replacing and to-be-replaced action sequences. The third component is a case library of plan-rewrite rules.,https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-191.pdf,
174,1999,Student Abstracts,Word Sense Disambiguation for Information Retrieval,"Ozlem Uzuner, Boris Katz, and Deniz Yuret, MIT Artificial Intelligence Laboratory","Despite their increasing importance as data retrieval tools, most Information Retrieval (IR) systems are deficient in precision and recall. Lack of disambiguation power is one reason for the poor performance of these systems. Correctly disambiguating and expanding a query with intended synonyms before retrieval may improve the performance. We use the local context of a word to identify its sense. In our case, the local context of a word is the ordered list of words from the closest content word on each side of the target word up to the target word which is expressed as a placeholder.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-192.pdf,
175,1999,Invited Talk,Game Playing: The Next Moves,"Susan L. Epstein, Hunter College","Computer programs now play many board games as well or better than the most expert humans. Human players, however, learn, plan, allocate resources, and integrate multiple streams of knowledge. This paper highlights recent achievements in game playing, describes some cognitively-oriented work, and poses three related challenge problems for the AI community.",https://aaai.org/Library/AAAI/1999/../../../Papers/AAAI/1999/AAAI99-193.pdf,
