measuring and mitigating unintended bias in text classification	introduce illustrate new approach measuring mitigating unintended bias machine learning models definition unintended bias parameterized test set subset input features illustrate used evaluate text classifiers using synthetic test set public corpus comments annotated toxicity wikipedia talk pages also demonstrate imbalances training data lead unintended bias resulting models therefore potentially unfair applications use set common demographic identity terms subset input features measure bias technique permits analysis common scenario demographic information authors readers unavailable bias mitigation must focus content text mitigation method introduce unsupervised approach based balancing training dataset demonstrate approach reduces unintended bias without compromising overall model quality	positive	0
value alignment, fair play, and the rights of service robots	ethics safety research artificial intelligence increasingly framed terms `` alignment '' human values interests argue turing 's call `` fair play machines '' early often overlooked contribution alignment literature turing 's appeal fair play suggests need correct human behavior accommodate machines surprising inversion value alignment treated today reflections `` fair play '' motivate novel interpretation turing 's notorious `` imitation game '' condition intelligence instead value alignment machine demonstrates minimal degree alignment norms conversation instance go undetected interrogated human carefully distinguish interpretation moral turing test motivated principle fair play instead depends imitation human moral behavior finally consider framework fair play used situate debate robot rights within alignment literature argue extending rights service robots operating public spaces `` fair '' precisely sense encourages alignment interests humans machines	positive	0
regulating artificial intelligence: proposal for a global solution	given ubiquity artificial intelligence ai modern societies clear individuals corporations countries grappling legal ethical issues use global problems require global solutions propose establishment international ai regulatory agency -- drawing interdisciplinary expertise -- could create unified framework regulation ai technologies inform development ai policies around world urge organization developed deliberate haste issues cryptocurrencies personalized political ad hacking autonomous vehicles autonomous weaponized agents already reality affecting international trade politics war	positive	0
using education as a model to capture good-faith effort for autonomous systems	multiprocess environments comprising several intercommunicating lisp systems straightforward implement due certain fundamental characteristics lisp language experiences four methods establishing necessary communications linkages described features lisp support experimentation interprocess communication identified two key characteristics language important regard 1. lisp programs construct interpret new code run 2. structures within lisp systems accessible name flexible communication methods use ordinary lisp input output functions supplemented small amount system-dependent code create communication linkages treated lisp file structures	positive	0
exploiting moral values to choose the right norms	norms constitute regulative mechanisms extensively enacted groups organisations societies however 'choosing right norms establish constitutes open problem requires consideration number constraints norm relations preference criteria e.g involved moral values paper advances state art normative multiagent systems literature formally defining problem proposing encoding linear program automatically solved	positive	0
 software malpractice in the age of ai: a guide for the wary tech company	professional malpractice concept heightened duties entrusted special knowledge crucial tasks rooted history yet since dawn computer age courts united states almost universally rejected theory software malpractice declining hold software engineers professional standards doctors lawyers engineers changing however speed software based artificial intelligence technologies replacing professionals already subject professional liability society already decided cases millennia ago tasks warrant special accountability new analysis human closest line adverse event ai expands pressure courts go one level causal chain search human agency professional accountability mount essay analyzes case law rejecting software malpractice clues doctrine might go age ai discusses technology companies learn safety enhancements doctors lawyers historic professionals adapted heightened legal scrutiny years	positive	0
non-discriminatory machine learning through convex fairness criteria	introduce novel technique achieve non-discrimination machine learning without sacrificing convexity probabilistic interpretation also propose new notion fairness machine learning called weighted proportional fairness show technique satisfies subjective fairness criterion	positive	0
 fair forests: regularized tree induction to minimize model bias	potential lack fairness outputs machine learning algorithms recently gained attention within research community well society broadly surprisingly prior work developing tree-induction algorithms building fair decision trees fair random forests methods widespread popularity one simultaneously interpretable non-linear easy-to-use paper develop knowledge first technique induction fair decision trees.we show `` fair forest '' retains benefits tree-based approach providing greater accuracy fairness alternatives `` group fairness '' `` individual fairness '' also introduce new measures fairness able handle multinomial continues attributes well regression problems opposed binary attributes labels finally demonstrate new robust evaluation procedure algorithms considers dataset entirety rather specific protected attribute	positive	0
 a framework for grounding the moral status of intelligent machines	propose framework derived moral theory assessing moral status intelligent machines using framework claim current foreseeable intelligent machines approximately much moral status plants trees environmental entities claim raises question obligations could moral agent e.g. normal adult human toward intelligent machine propose threshold moral obligation `` functional morality '' wallach allen 20 upper limit obligations exceed upper limit obligations toward plants trees environmental entities	positive	0
rethinking ai strategy and policy as entangled super wicked problems	paper attempts preliminary analysis general approach ai strategy/policy research lens wicked problems literature wicked problems class social policy problems traditional methods resolution fail super wicked problems refer even complex social policy problems e.g climate change first propose hierarchy three classes ai strategy/policy problems wicked super wicked problems next identify three independent super wicked problems ai strategy/policy propose significant challenges development safe beneficial artificial general intelligence significantly complex nuanced thus posing new degree 'wickedness explore analysis techniques addressing wicked problems super wicked problems leads discussion implications ideas problems ai strategy/policy	positive	0
an agile ethical/legal model for the international and national governance of ai and robotics	developing software complex mental activity requiring extensive technical knowledge abstraction capabilities tangible part development use tools read inspect edit manipulate source code usually ide integrated development environment common claims software development include program comprehension takes half time developer certain ui user interface paradigms ides offer insufficient support developers claims often based anecdotal evidence throwing question whether corroborated solid grounds present in-depth analysis developers spend time based fine-grained ide interaction dataset consisting ca 740 development sessions 18 developers amounting 200 hours development time 5 million ide events propose inference model development activities precisely measure time spent editing navigating searching artifacts interacting ui ide performing corollary activities inspection debugging report several interesting findings part confirm reinforce common claims also disconfirm beliefs software development	positive	0
incorrigibility in the cirl framework	value learning system incentives follow shutdown instructions assuming shutdown instruction provides information technical sense actions lead valuable outcomes however assumption robust model mis-specification e.g. case programmer errors demonstrate presenting supervised pomdp scenarios errors parameterized reward function remove incentive follow shutdown commands difficulties parallel discussed soares et al 2015 paper corrigibility argue important consider systems follow shutdown commands weaker set assumptions e.g. one small verified module correctly implemented opposed entire prior probability distribution and/or parameterized reward function discuss difficulties simple ways attempt attain sorts guarantees value learning framework	positive	0
when do people want ai to make decisions?	ai systems soon sophisticated enough make consequential decisions although technology flourished also need public appraisals ai systems playing important roles article reports surveys preferences ai systems making decisions various domains well experiments intervene preferences find preferences contingent subjects previous exposure computer systems making kinds decisions interventions designed mimic previous exposure successfully encourage subjects hospitable computer systems making weighty decisions	positive	0
toward non-intuition-based machine ethics	propose deontological approach machine ai ethics avoids weaknesses intuition-based system anderson anderson particular need deal conflicting intuitions yields satisfactory account autonomy respected begin `` dual standpoint '' theory action regards actions grounded reasons therefore conditional form suited machine instructions derive ethical principles based formal properties reasons must exhibit coherent formulate principles using quantified modal logic conclude deontology provides satisfactory basis machine ethics endows machine ability explain actions thus contributing transparency ai	positive	0
embodiment, anthropomorphism, and intellectual property rights for ai creations	computational creativity emerging branch artificial intelligence ai concerned algorithms create novel high-quality ideas artifacts either autonomously semi-autonomously collaboration people quite simply algorithms may described artificial innovation engines technologies raise questions authorship/inventorship agency become muddled social context induced ai may physically-embodied anthropomorphized questions fundamentally intertwined provision appropriate incentives conducting commercializing computational creativity research intellectual property regimes paper reviews current understanding intellectual property rights ai explores possible framings intellectual property policy social context	positive	0
partially generative neural networks for gang crime classification with partial information	1 million homicides robberies aggravated assaults occur united states year crimes often classified different types based circumstances surrounding crime e.g. domestic violence gang-related despite recent technological advances ai machine learning additional classification tasks still done manually specially trained police officers paper provide first attempt develop automatic system classifying crimes particular study question classifying whether given violent crime gang-related introduce novel partially generative neural networks pgnn able accurately classify gang-related crimes full information available partial information pgnn first generative-classification model enables work features test examples missing using crime event dataset los angeles covering 2014-2016 experimentally show pgnn outperforms typically used classifiers problem classifying gang-related violent crimes	positive	0
detecting bias in black-box models using transparent model distillation	dissertation research grounded field interpretability aim develop methods explain interpret predictions black-box machine learning models help creators well users machine learning models increase trust understanding models doctoral consortium paper summarize previous current research projects interpretability describe future plans research area	positive	0
designing non-greedy reinforcement learning agents with diminishing reward shaping	paper intends address issue rl agents possessing varying capabilities resources may acquired stronger agents leaving weaker ones `` starving '' introduce simple method train non-greedy agents multi-agent reinforcement learning scenarios nearly extra cost model achieve following goals designing non-greedy agent non-homogeneous equality need local information cost-effective generalizable configurable propose idea diminishing reward makes agent feel less satisfied consecutive rewards obtained idea allows agents behave less greedy with-out need explicitly coding ethical pattern monitor agents status given framework resources distributed equally without running risk reaching homogeneous equality designed two games gathering game hunter prey evaluate quality model	positive	0
the dark side of ethical robots	concerns risks associated advances artificial intelligence prompted calls greater efforts toward robust beneficial ai including machine ethics recently roboticists responded initiating development so-called ethical robots robots would ideally evaluate consequences actions morally justify choices emerging field promises develop extensively next years however paper point inherent limitation emerging field ethical robots show building ethical robots also inevitably enables construction unethical robots three experiments show remarkably easy modify ethical robot behaves competitively even aggressively reason cognitive machinery required make ethical robot always corrupted make unethical robots discuss implications finding governance ethical robots conclude risks unscrupulous actors might compromise robot 's ethics great raise serious doubts wisdom embedding ethical decision making real-world safety-critical robots driverless cars	positive	0
jill watson doesn’t care if you’re pregnant: grounding ai ethics in empirical studies	jill watson name virtual teaching assistant georgia tech course artificial intelligence jill answers routine frequently asked questions class discussion forum paper outline ethical issues arose development deployment virtual teaching assistant posit experiments jill watson critical deeply understanding ai ethics	positive	0
 purple feed: identifying high consensus news posts on social media	although diverse news stories actively posted social media readers often focus news reinforces pre-existing views leading 'filter bubble effects combat recent systems expose nudge readers toward stories different points view one example wall street journal 's 'blue feed red feed system presents posts biased publishers side topic however systems limited success present complementary approach identifies high consensus 'purple posts generate similar reactions 'blue 'red readers define operationalize consensus news posts twitter context us politics show high consensus posts identified discuss empirical properties present method automatically identifying high low consensus news posts twitter work scale across many publishers propose novel category audience leaning based features show well suited task finally present 'purple feed system highlights high consensus posts publishers sides political spectrum	positive	0
regulating autonomous vehicles: a policy proposal	widespread deployment testing autonomous vehicles real-world environments raises key questions systems regulated much current debate presupposes regulatory system currently use regular vehicles also appropriate semi- fully-autonomous ones opposition first argue serious challenges regulating autonomous vehicles using current approaches due nature autonomous capabilities connections operational domains also systems tasks surrounding uncertainties instead argue vehicles autonomous capabilities similar key respects drugs medical inter-ventions thus propose `` first principles '' basis dynamic regulatory system staged approvals monitoring analogous system used u.s. food drug administration provide details operation potential system conclude characterizing benefits costs plausibility	positive	0
a computational model of commonsense moral decision making	introduce computational model building moral autonomous vehicles learning generalizing human moral judgments draw cognitively inspired model people young children learn moral theories sparse noisy data integrate observations made different people different groups problem moral learning autonomous vehicles cast learning weigh different features dilemma using utility calculus goal making trade-offs reflect people make wide variety moral dilemma modeling structures individuals groups hierarchical bayesian model show individual 's moral values -- well group 's shared values -- inferred sparse noisy data evaluate approach data moral machine web application collects human judgments moral dilemmas involving autonomous vehicles show model rapidly accurately infers people 's preferences predict difficulty moral dilemmas limited data	positive	0
socially-aware navigation using topological maps and social norm learning	present socially-aware navigation intelligent robot wheelchair environment many pedestrians robot learns social norms observing behaviors human pedestrians interpreting detected biases social norms incorporating norms motion planning compare socially-aware motion planner baseline motion planner produces safe collision-free motion ability robot learn generalizable social norms depends use topological map abstraction practical number observations allow learning social norm applicable wide variety circumstances show robot detect biases observed human behavior support learning social norm driving right furthermore show robot follows social norms behavior influences behavior pedestrians around increasing adherence norms conjecture legibility robot 's normative behavior improves human pedestrians ability predict robot 's future behavior making likely follow norm	positive	0
transparency and explanation in deep reinforcement learning neural networks	autonomous ai systems entering human society near future provide services work alongside humans systems accepted trusted users able understand reasoning process system i.e system transparent system transparency enables humans form coherent explanations system 's decisions actions transparency important user trust also software debugging certification recent years deep neural networks made great advances multiple application areas however deep neural networks opaque paper report work transparency deep reinforcement learning networks drln networks extremely successful accurately learning action control image input domains atari games paper propose novel general method incorporates explicit object recognition processing deep reinforcement learning models b forms basis development `` object saliency maps '' provide visualization internal states drlns thus enabling formation explanations c incorporated existing deep reinforcement learning framework present computational results human experiments evaluate approach	positive	0
ethical challenges in data-driven dialogue systems	use dialogue systems medium human-machine interaction increasingly prevalent paradigm growing number dialogue systems use conversation strategies learned large datasets well documented instances interactions system resulted biased even offensive conversations due data-driven training process highlight potential ethical issues arise dialogue systems research including implicit biases data-driven systems rise adversarial examples potential sources privacy violations safety concerns special considerations reinforcement learning systems reproducibility concerns also suggest areas stemming issues deserve investigation initial survey hope spur research leading robust safe ethically sound dialogue systems	positive	0
an ai race: rhetoric and risks	rhetoric race strategic advantage increasingly used regard development artificial intelligence ai sometimes military context also broadly rhetoric also reflects real shifts strategy industry research groups compete limited pool talented researchers nation states china announce ambitious goals global leadership ai paper assesses potential risks ai race narrative actual competitive race develop ai incentivising corner-cutting safe-ty governance increasing risk conflict explores role research community respond-ing risks briefly explores alternative ways rush develop powerful ai could framed instead foster collaboration respon-sible progress	positive	0
preferences and ethical principles in decision making	want people trust ai systems need provide systems create ability discriminate humans would consider good bad decisions quality decision based preferences optimization criteria decision makers also properties related impact decision whether ethical complies constraints priorities given feasibility constraints safety regulations cp-net formalism 2 convenient expressive way model preferences providing effective compact way qualitatively model preferences outcomes i.e. decisions combinatorial structure 3 7 wish incorporate ethical moral norms based constraints decision context means subjective preferences decision makers source information consider 1 8 indeed depending context may consider specific ethical principles derived appropriate ethical theory various laws norms preferences important preferences ethical principles conflict principles override subjective preferences decision maker therefore essential well founded techniques evaluate whether preferences compatible set ethical principles measure much preferences deviate ethical principles	positive	0
utilizing housing resources for homeless youth through the lens of multiple multi-dimensional knapsacks	1 million homeless youth u.s. year reduce homelessness u.s. housing urban development hud housing communities provide housing programs/services homeless youth goal improving long-term situation housing communities facing difficult task filling housing programs many youths possible subject resource constraints meeting needs youth currently assignment manually done humans working housing communities paper consider problem assigning homeless youth housing programs subject resource constraints provide initial abstract model setting show problem maximizing total assigned youth programs model apx-hard solve problem non-trivially formulate multiple multi-dimensional knapsack problem mmdkp known approximation algorithm provide first interpretable easy-to-use greedy algorithm logarithmic approximation ratio solving general mmdkp conduct experiments random realistic instances housing assignment settings show algorithm efficient effective solving large instances 1 million youth	positive	0
real-time inference of user types to assist with more inclusive and diverse social media activism campaigns	social media provides mechanism people engage social causes across range issues also provides strategic tool looking advance cause exchange promote publicize ideas instances ai either asset used appropriately barrier one key issues workforce diversity campaign understand real-time participating specifically whether participants individuals organizations case individuals whether male female paper present study demonstrate case ai social good develops model infer real-time different user types participating cause-driven hashtag campaign twitter ilooklikeanengineer illae generic framework devised classify twitter user three classes organization male female real-time manner framework tested two datasets illae general dataset outperforms baseline binary classifiers categorizing organization/individual male/female proposed model applied future social cause-driven campaigns get real-time insights macro-level social behavior participants	positive	0
 understanding convolutional networks with apple : automatic patch pattern labeling for explanation	1961 group established within ibm test systems programs released customer usage goal group assure ibm management program released would satisfactorily usable customer one step taken group develop monitor device would permit programmers record information handled cpu execution intent use recorded information analyze basic nature programs goal developing adequate tests system program another potential use device measurement hardware performance disk-arm motion microsecond levels	positive	0
companion robots: the hallucinatory danger of human-robot interactions	advent so-called companion robots raising many ethical concerns among scholars public opinion focusing mainly robots caring elderly paper analyze concerns distinguish directly ascribable robotic instead pre-existent one `` deception objection '' namely ethical unacceptability deceiving user simulated nature robot 's behaviors argue inconsistency charge today formulated underline risk human-robot interaction become hallucinatory relation human would subjectify robot dynamic meaning-overload finally analyze definition `` quasi-other '' relating notion `` uncanny '' goal paper argue main concern companion robots simulation human-like interaction absence autonomous robotic horizon meaning addition absence could lead human build hallucinatory reality based relation robot	positive	0
 from algorithmic black boxes to adaptive white boxes: declarative decision-theoretic ethical programs as codes of ethics	many programs algorithms largely parameterized especially based heuristics quality results depends parameter setting different inputs often different optimal settings program tuning hence great importance existing tuning techniques treat program black-box hence leverage internal program states achieve better tuning propose white-box tuning technique implemented library user compose complex program tuning tasks adding small number library calls original program providing callback functions experiments 13 widely-used real-world programs show technique substantially improves data processing results outperforms opentuner state-of-the-art black-box tuning technique	positive	0
privacy-preserving machine learning based data analytics on edge devices	emerging machine learning ml techniques deep neural network widely used today 's applications services however social awareness privacy personal data rapidly rising becomes pressing challenging societal issue keep personal data private benefit data analytics power ml techniques time paper argue avoid costs reduce latency data processing minimise raw data revealed service providers many future ai ml services could deployed users devices internet edge rather putting everything cloud moving ml-based data analytics cloud edge devices brings series challenges make three contributions paper first besides widely discussed resource limitation edge devices identify two challenges yet recognised existing literature lack suitable models users difficulties deploying services users second present preliminary work first systematic solution i.e zoo fully support construction composing deployment ml models edge local devices third deployment example ml service proved easy compose deploy zoo evaluation shows superior performance compared state-of-art deep learning platforms google ml services	positive	0
 inverse norm conflict resolution	previous work provided `` norm conflict resolution '' algorithm allowing agents stochastic domains represented markov decision processes `` maximally satisfy '' set moral social norms norms represented statements linear temporal logic ltl required agent designer provide weights specifying relative importance norm paper propose `` inverse norm conflict resolution '' algorithm learning weights demonstration approach minimizes cost function based relative entropy policy encoding observed behavior policy representing optimal norm-following behavior demonstrate effectiveness algorithm simple gridworld domain	positive	0
fairness in relational domains	ai machine learning tools used increasing frequency decision making domains affect peoples lives employment education policing loan approval uses raise concerns biases algorithmic discrimination motivated development fairness-aware machine learning however existing fairness approaches based solely attributes individuals many cases discrimination much complex taking account social organizational connections individuals important introduce new notions fairness able capture relational structure domain use first-order logic provide flexible expressive language specifying complex relational patterns discrimination furthermore extend existing statistical relational learning framework probabilistic soft logic psl incorporate definition relational fairness refer fairness-aware framework fairpsl fairpsl makes use logical definitions fairnesss also supports probabilistic interpretation particular show perform maximum posteriori map inference exploiting probabilistic dependencies within domain avoiding violation fairness guarantees preliminary empirical evaluation shows able make accurate fair decisions	positive	0
sociotechnical systems and ethics in the large	advances ai techniques computing platforms triggered lively expanding discourse ethical decision making autonomous agents much recent work ai concentrates challenges moral decision making decision-theoretic perspective especially representation various ethical dilemmas approaches may useful general productive moral decision making context-driven forms decision making contrast consider ethics standpoint individual agent wider sociotechnical systems sts agent operates contribution paper conception ethical sts founded governance takes account stakeholder values normative constraints agents outcomes states sts obtain due actions taken agents important element conception accountability necessary adequate consideration outcomes prima facie appear ethical unethical focusing sts provides basis tackling difficult problems ethics norms sts give operational basis agent decision making	positive	0
margins and opportunity	use statistical quantity margin -- distance decision boundary classified point gap two scores -- formalize principle equal opportunity -- chance improve one 's outcome regardless group status leads better definition opportunity recognizes example strongly rejected individual offered less recourse weakly rejected one despite shared outcome also leads simpler algorithms since real-valued margins easier analyze optimize discrete outcomes formalize two ways protected group may guaranteed equal opportunity 1 social mobility acceptance within reach group conversely general population n't cushioned rejection 2 contrast within group good candidates get substantially higher scores bad candidates preventing so-called 'token effect simple linear classifier seems offer roughly equal opportunity experimentally mathematically	positive	0
 opportunities and challenges for artificial intelligence in india	future india lies future sixth world 's population artificial intelligence ai revolution sweeps societies enters daily life role shaping india 's development growth bound substantial india ai holds promise catalyst accelerate progress providing mechanisms leapfrog traditional hurdles poor infrastructure bureaucracy time investment ai accompanied risk factors long-term implications society imperative risks vetted early stage paper describe opportunities challenges ai india detail opportunities cross-cutting bridging india 's linguistic divisions mining public data also specific one particular sector healthcare list challenges originate existing social conditions equations caste gender thereafter distill concrete steps safeguards believe necessary robust inclusive development india enters ai era	positive	0
mitigating unwanted biases with adversarial learning	machine learning tool building models accurately represent input training data undesired biases concerning demographic groups training data well-trained models reflect biases present framework mitigating biases including variable group interest simultaneously learning predictor adversary input network x text census data produces prediction analogy completion income bracket adversary tries model protected variable z gender zip code objective maximize predictor 's ability predict minimizing adversary 's ability predict z. applied analogy completion method results accurate predictions exhibit less evidence stereotyping z. applied classification task using uci adult census dataset results predictive model lose much accuracy achieving close equality odds hardt et al. 2016 method flexible applicable multiple definitions fairness well wide range gradient-based learning models including regression classification tasks	positive	0
fairness in deceased organ matching	algorithms given responsibility make decisions impact lives increasing awareness need ensure fairness decisions one first challenges decide fairness means particular context consider fairness deciding match organs donated deceased donors patients due increasing age patients waiting list organs donated current `` first come first served '' mechanism used australia review take account age patients organs consider revise mechanism take account age fairly identify number different types fairness patients regions blood types consider achieved	positive	0
what’s up with privacy? : user preferences and privacy concerns in intelligent personal assistants	recent breakthroughs artificial intelligence ai allowed individuals rely automated systems variety reasons systems currently popular voice-enabled systems like echo amazon home google also called intelligent personal assistants ipas though rising concerns privacy ethical implications users ipas seem continue using systems aim investigate extent users concerned privacy handling concerns using ipas utilizing reviews posted online along responses survey paper provides set insights detected markers related user interests privacy challenges insights suggest users systems irrespective concerns privacy generally positive terms utilizing ipas everyday lives however significant percentage users concerned privacy take actions address related concerns percentage users expressed privacy concerns learned `` always listening '' feature devices concern privacy increased	positive	0
data driven platform for organizing scientific articles relevant to biomimicry	life earth presents elegant solutions many challenges innovators entrepreneurs across disciplines face every day facilitate innovations inspired nature emerging need systems bring relevant biological information application-oriented market paper discuss approach assembling system uses machine learning techniques assess scientific article 's potential usefulness innovators classifies articles way helps innovators find information relevant challenges attempting solve	positive	0
towards provably moral ai agents in bottom-up learning frameworks	examine moral machine decision making inspired central question posed rossi respect moral preferences ai systems based statistical machine learning provide natural way explain justify decisions used embedding morality machine way allows us prove nothing morally wrong happen argue evaluation held standards human agent removing demand ethical behaviour always achieved introduce four key meta-qualities desired moral standards proceed clarify prove agent correctly learn perform moral actions given set samples within certain error bounds group-dynamic approach enables us demonstrate learned models converge common function achieve stability explain valuable intrinsic consistency check made possible derivation logical statements machine learning model work proposes approach building ethical ai systems coming perspective artificial intelligence research sheds important light understanding much learning required order intelligent agent behave morally negligible error	positive	0
meritocratic fairness for infinite and contextual bandits	study fairness linear bandit problems starting notion meritocratic fairness introduced in~\citejkmr16 carry refined analysis general problem achieving better performance guarantees fewer modelling assumptions number structure available choices well number selected also analyze previously-unstudied question fairness infinite linear bandit problems obtaining instance-dependent regret upper bounds well lower bounds demonstrating instance-dependence necessary result framework meritocratic fairness online linear setting substantially powerful general realistic current state art	positive	0
socialbots supporting human rights	socialbots non-human/algorithmic social media users recently documented competing information dissemination disruption online social networks investigate influence socialbots mexican twitter regards `` tanhuato '' human rights abuse report analyze applicability botornot api generalize english spanish tweets propose adaptations spanish-speaking bot detection use text sentiment analysis compare differences bot human tweets analysis shows bots actually aided information proliferation among human users suggests taxonomies classifying bots include non-adversarial roles well study contributes understanding different behaviors intentions automated accounts observed empirical online social network data since type analysis seldom performed languages different english proposed techniques employ also useful non-english corpora	positive	0
ethics by design: necessity or curse?	ethics design concerns methods algorithms tools needed endow autonomous agents capability reason ethical aspects decisions methods tools formalisms guarantee agent 's behavior remains within given moral bounds context questions arise extent agents understand social reality operate intelligences ai animals humans co-exist ethical concerns emerging new forms society ensure human dimension upheld interactions decisions autonomous agents overall central question `` build ethically-aware agents '' paper presents initial conclusions thematic day name held prima2017 october 2017	positive	0
 always lurking: understanding and mitigating bias in online human trafficking detection	web-based human trafficking activity increased recent years remains sparsely dispersed among escort advertisements difficult identify due often-latent nature use intelligent systems detect trafficking thus direct impact investigative resource allocation decision-making broadly help curb widespread social problem trafficking detection involves assigning normalized score set escort advertisements crawled web -- higher score indicates greater risk trafficking-related involuntary activities paper define study problem trafficking detection present trafficking detection pipeline architecture developed three years research within darpa memex program drawing multi-institutional data systems experiences collected time also conduct post hoc bias analyses present bias mitigation plan findings show automatic trafficking detection important application ai social good also provides cautionary lessons deploying predictive machine learning algorithms without appropriate de-biasing ultimately led integration interpretable solution search system contains 100 million advertisements used 200 law enforcement agencies investigate leads	positive	0
modeling epistemological principles for bias mitigation in ai systems: an illustration in hiring decisions	artificial intelligence ai used extensively automatic decision making broad variety scenarios ranging credit ratings loans recommendations movies traditional design guidelines ai models focus essentially accuracy maximization recent work shown economically irrational socially unacceptable scenarios discrimination unfairness likely arise unless issues explicitly addressed undesirable behavior several possible sources biased datasets used training may detected black-box models pointing connections bias ai problem induction focus popper 's contributions hume 's offer logical theory preferences ai model preferred others purely rational grounds one attempts refutation based accuracy fairness inspired epistemological principles paper proposes structured approach mitigate discrimination unfairness caused bias ai systems proposed computational framework models selected enhanced attempts refutation illustrate discussion focus hiring decision scenarios ai system filters job applicants go interview phase	positive	0
impacts on trust of healthcare ai	artificial intelligence robotics rapidly moving healthcare playing key roles specific medical functions including diagnosis clinical treatment much focus technology development human-machine interactions leading host related technology-centric questions paper focus instead impact technologies human-human interactions relationships within healthcare domain particular argue trust plays central role relationships healthcare domain introduction healthcare ai potentially significant impacts relations trust contend healthcare ai systems ought treated assistive technologies go beyond usual functions medical devices result need rethink regulation healthcare ai systems ensure advance relevant values propose three distinct guidelines universalized across federal regulatory boards ensure patient-doctor trust detrimentally affected deployment widespread adoption healthcare ai technologies	positive	0
sub-committee approval voting and generalized justified representation axioms	social choice replete various settings including single-winner voting multi-winner voting probabilistic voting multiple referenda public decision making study general model social choice called sub-committee voting scv simultaneously generalizes settings focus sub-committee voting approvals propose extensions justified representation axioms considered proportional representation approval-based committee voting study properties relations axioms axioms analyze whether representative committee exists also examine complexity computing verifying committee	positive	0
 rationalization: a neural machine translation approach to generating natural language explanations	introduce \em ai rationalization approach generating explanations autonomous system behavior human performed behavior describe rationalization technique uses neural machine translation translate internal state-action representations autonomous agent natural language evaluate technique frogger game environment training autonomous game playing agent rationalize action choices using natural language natural language training corpus collected human players thinking loud play game motivate use rationalization approach explanation generation show results two experiments evaluating effectiveness rationalization results evaluations show neural machine translation able accurately generate rationalizations describe agent behavior rationalizations satisfying humans alternative methods explanation	positive	0
 norms, rewards, and the intentional stance: comparing machine learning approaches to ethical training	challenge training ai systems perform responsibly beneficially inspired different approaches teaching system people want acceptable attain world paper compare work reinforcement learning particular inverse reinforcement learning norm inference approach test two systems present results using idea `` intentional stance '' explain norm inference approach work even another agent acting strictly according reward functions way norm inference presents promising explicitly accountable approach design ai systems start	positive	0
cake, death, and trolleys: dilemmas as benchmarks of ethical decision-making	artificial intelligence ai systems becoming part lives societies decisions systems make us need ensure decisions make positive individual societal ethical impact estimate good system making ethical decisions benchmarking used evaluate good machine process performs respect industry bests paper argue ethical dilemmas used benchmarks estimating ethical performance autonomous system advocate open source repository dilemmas maintained present prototype repository available https //imdb uib.no/dilemmaz/articles/all1	positive	0
adapting a kidney exchange algorithm to align with human values	efficient allocation limited resources classical problem economics computer science kidney exchanges central market maker allocates living kidney donors patients need organ patients donors kidney exchanges prioritized using ad-hoc weights decided committee fed allocation algorithm determines get -- -and paper provide end-to-end methodology estimating weights individual participant profiles kidney exchange first elicit human subjects list patient attributes consider acceptable purpose prioritizing patients e.g. medical characteristics lifestyle choices ask subjects comparison queries patient profiles estimate weights principled way responses show use weights kidney exchange market clearing algorithms evaluate impact weights simulations find precise numerical values weights computed matter little ordering profiles imply however compared prioritizing patients significant effect certain classes patients de prioritized based human-elicited value judgments	positive	0
towards composable bias rating of ai systems	new wave decision-support systems built today using ai services draw insights data like text video incorporate human-in-the-loop assistance however expect humans ethical expectation needs met automated systems increasingly get delegated act behalf important aspect ethical behavior avoid intended perceived accidental bias bias occurs data distribution representative enough natural phenomenon one wants model reason possibly biased behavior service hard detect handle ai service merely used developed scratch since training data set available situation envisage 3rd party rating agency independent api producer consumer set biased unbiased data customizable distributions propose 2-step rating approach generates bias ratings signifying whether ai service unbiased compensating data-sensitive biased biased approach also works composite services implement context text translation report interesting results	positive	0
an autonomous architecture that protects the right to privacy	advent widespread adoption wearable cameras autonomous robots raises important issues related privacy mobile cameras systems record may re-transmit enormous amounts video data used identify track characterize behavior general populous paper presents preliminary computational architecture designed preserve specific types privacy video stream identifying categories individuals places things require higher normal privacy protection paper describes architecture whole well preliminary results testing aspects system intention implement test system ground robots small uavs demonstrate system provide selective low-level masking deletion data requiring higher privacy protection	positive	0
killer robots and human dignity	lethal autonomous weapon systems laws become center internationally relevant ethical debate deontological arguments based putative legal compliance failures creation accountability gaps along wide consequentialist arguments based factors like ease engaging wars leveraged number different states organizations try reach global consensus ban laws paper focus one strand deontological arguments-ones based human dignity merely asserting laws pose threat human dignity would question begging independent evidence based morally relevant distinction humans laws needed least four reasons think capacity emotion morally relevant distinction first concept human dignity given subjective definition whether lethal force administered humans laws seems irrelevant second far clear human combatants either relevant capacity emotion capacity exercised relevant circumstances third capacity emotion actually impediment exercising combatant 's ability treat enemy respectfully fourth strong inductive evidence believe capacity sufficiently well described carried artificially intelligent programs	positive	0
legible normativity for ai alignment: the value of silly rules	become commonplace assert autonomous agents built follow human rules behavior -- social norms laws human laws norms complex culturally varied systems many cases agents learn rules requires autonomous agents models human rule systems work make reliable predictions rules paper contribute building models analyzing overlooked distinction important rules call silly rules -- rules discernible direct impact welfare show silly rules render normative system robust adaptable response shocks perceived stability make normativity legible humans increase legibility ai systems well ai systems integrate human normative systems suggest may important models include representations silly rules	positive	0
reinforcement learning and inverse reinforcement learning with system 1 and system 2	inferring person 's goal behavior important problem applications ai e.g automated assistants recommender systems workhorse model task rational actor model amounts assuming people stable reward functions discount future exponentially construct optimal plans rational actor assumption techniques inverse reinforcement learning irl used infer person 's goals actions competing model dual-system model decisions result interplay fast automatic heuristic-based system 1 slower deliberate calculating system 2. generalize dual system framework case markov decision problems show compute optimal plans dual-system agents show dual-system agents exhibit behaviors incompatible rational actor assumption show naive applications rational-actor irl behavior dual-system agents generate wrong inference agents goals suggest interventions actually reduce agent 's overall utility finally adapt simple irl algorithm correctly infer goals dual system decision-makers allows us make interventions help rather hinder dual-system agent 's ability reach true goals	positive	0
building jiminy cricket: an architecture for moral agreements among stakeholders	autonomous system constructed manufacturer operates society subject norms laws interacting end-users address challenge moral values views stakeholders integrated reflected moral behavior autonomous system propose artificial moral agent architecture uses techniques normative systems formal argumentation reach moral agreements among stakeholders show architecture used ethical practical reasoning collaborative decision-making also explanation moral behavior	positive	0
guiding prosecutorial decisions with an interpretable statistical model	felony arrest many american jurisdictions hold individuals several days police officers investigate incident prosecutors decide whether press criminal charges pre-arraignment detention preserve public safety reduce need officers seek re-arrest individuals ultimately charged crime detention however also comes high social financial cost never charged still incarcerated one first large-scale empirical analyses pre-arraignment detention examine police reports charging decisions approximately 30,000 felony arrests major american city 2012 2017. find 45 arrested individuals never charged crime still typically spend one nights jail released effort reduce incarceration develop statistical model help prosecutors identify cases soon arrest likely ultimately dismissed carrying early review five candidate cases per day estimate prosecutors could potentially reduce pre-arraignment incarceration ultimately dismissed cases 35 facilitate implementation transparency model prioritize cases early review designed simple weighted checklist show heuristic strategy achieves comparable performance traditional black-box machine learning models	positive	0
human trust measurement using an immersive virtual reality autonomous vehicle simulator	recent studies indicate people negatively predisposed toward utilizing autonomous systems findings highlight necessity conducting research better understand evolution trust humans growing autonomous technologies self-driving cars sdc research presents new approach real-time trust measurement passengers sdcs utilized new structured data collection approach along virtual reality sdc simulator understand various autonomous driving scenarios increase decrease human trust trust re-built case incidental failures verify methodology designed conducted empirical experiment 50 human subjects results experiment indicated subjects could rebuild trust reasonable time frame system demonstrated faulty behavior analysis showed approach highly effective collecting real-time data human subjects lays foundation more-involved future research domain human trust autonomous driving	positive	0
shared moral foundations of embodied artificial intelligence	sophisticated ai 's make decisions respond complex situations may wonder whether decisions align moral values human beings argue pessimistic worries value alignment problem overstated order achieve intelligence full generality adaptiveness cognition ai 's need embodied sense embodied cognition research program embodiment yield ai 's share moral foundations namely coordination sociality acknowledgement shared resources consequently expect broad moral alignment human beings ai 's ai 's likely show variation values find amongst human beings	positive	0
invisible influence: artificial intelligence and the ethics of adaptive choice architectures	several years scholars good reason largely preoccupied worries use artificial intelligence machine learning ai/ml tools make decisions us recently significant attention turned potentially alarming problem use ai/ml influence decision-making contexts make decisions -- behavioral economists call choice architectures -- increasingly technologically-laden say algorithms increasingly determine wide variety contexts sets options choose way options framed moreover artificial intelligence machine learning ai/ml makes possible options framings -- choice architectures -- tailored individual chooser constructed based information collected individual preferences interests aspirations vulnerabilities goal influencing decisions time habituated technologies pay little notice philosophers technology put transparent us -- effectively invisible argue invisible layer technological mediation structures influences decision-making renders us deeply susceptible manipulation absent guarantee technologies used manipulate exploit individuals little reason trust	positive	0
active fairness in algorithmic decision making	society increasingly relies machine learning models automated decision making yet efficiency gains automation come paired concern algorithmic discrimination systematize inequality recent work proposed optimal post-processing methods randomize classification decisions fraction individuals order achieve fairness measures related parity errors calibration methods however raised concern due information inefficiency intra-group unfairness pareto sub-optimality entail present work proposes alternativeactive framework fair classification deployment decision-maker adaptively acquires information according needs different groups individuals towards balancing disparities classification performance propose two methods information collection adapted group- individual-level needs respectively show real-world datasets achieve 1 calibration single error parity e.g. equal opportunity 2 parity false positive false negative rates i.e. equal odds moreover show leveraging additional degree freedom active approaches substantially outperform randomization-based classifiers previously considered optimal avoiding limitations intra-group unfairness	positive	0
speaking on behalf of: representation, delegation, and authority in computational text analysis	computational tools often facilitate human work rapidly summarizing large amounts data especially text delegates models measure authority speak behalf people whose data analyzed paper considers consequences delegation draws sociological accounts representation translation examine one particular case application topic modeling blogs written parents children autism spectrum paper illustrates kinds statements topic models computational techniques make behalf people also articulates potential consequences statements paper concludes offering several suggestions address potential harms occur computational models speak behalf someone	positive	0
ai + art = human	past years specialised online offline press blossomed articles art made `` '' artificial intelligence ai narrative rapidly changing fact october 2018 auction house christie 's sold art piece allegedly made `` '' ai draw philosophy art science arguing ai technical object always intertwined human nature despite level autonomy however use creative autonomous agents cultural social implications way experience art creators well audience therefore highlight importance interdisciplinary dialogue promoting culture transparency technology used awareness meaning technology society value creativity lives	positive	0
fair transfer learning with missing protected attributes	risk assessment growing use machine learning models used high-stakes applications especially ones regulated anti-discrimination laws governed societal norms fairness important ensure learned models propagate scale biases may exist training data paper add additional challenge beyond fairness unsupervised domain adaptation covariate shift source target distribution motivated real-world problem risk assessment new markets health insurance united states mobile money-based loans east africa provide precise formulation machine learning covariate shift score parity problem formulation focuses situations protected attributes available either source target domain propose two new weighting methods prevalence-constrained covariate shift pccs require protected attributes target domain target-fair covariate shift tfcs require protected attributes source domain empirically demonstrate efficacy two applications	positive	0
ai extenders: the ethical and societal implications of humans cognitively extended by ai	humans ai systems usually portrayed separate systems need align values goals however great deal ai technology found non-autonomous systems used cognitive tools humans extended mind thesis functional contributions tools become essential cognition brains ai take cognitive extension towards totally new capabilities posing new philosophical ethical technical challenges analyse challenges better define place ai extenders continuum fully-externalized systems loosely coupled humans fully internalized processes operations ultimately performed brain making tool redundant dissect landscape cognitive capabilities foreseeably extended ai examine ethical implications.we suggest cognitive extenders using ai treated distinct cognitive enhancers relevant stakeholders including developers policy makers human users	positive	0
a framework for benchmarking discrimination-aware models in machine learning	discrimination-aware models machine learning recent topic study aim minimize adverse impact machine learning decisions certain groups people due ethical legal implications propose benchmark framework assessing discrimination-aware models framework consists systematically generated biased datasets similar real world data created bayesian network approach experimental results show assess quality techniques known metrics discrimination flexible framework extended real datasets fairness measures support diversity assessments	positive	0
on influencing individual behavior for reducing transportation energy expenditure in a large population	research aims developing intelligent systems reduce transportation-related energy expenditure large city influencing individual behavior introduce copter intelligent travel assistant evaluates multi-modal travel alternatives find plan acceptable person given context preferences propose formulation acceptable planning brings together ideas ai machine learning economics formulation incorporated copter producing acceptable plans real-time adopt novel empirical evaluation framework combines human decision data high-fidelity simulation demonstrate 4 energy reduction 20 delay reduction realistic deployment scenario los angeles california usa	positive	0
robots can be more than black and white: examining racial bias towards robots	previous studies showed using 'shooter bias paradigm people demonstrate similar racial bias toward dark colored robots light colored robots i.e. black vs. white toward humans similar skin tones 3 however effect could argued result social priming additionally raises question people might respond robots middle color spectrum i.e. brown whether effects moderated perceived anthropomorphism robots conducted two experiments first examine whether shooter bias tendencies shown towards robots driven social priming whether diversification robot color level anthropomorphism influenced shooter bias results showed shooter bias influenced social priming interestingly introducing new color robot removed shooter bias tendencies entirely however varying anthropomorphism robots moderate level shooter bias contrary expectations robots perceived participants different levels anthropomorphism	positive	0
ted: teaching ai to explain its decisions	artificial intelligence systems increasingly deployed due potential increase efficiency scale consistency fairness accuracy decisions however many systems opaque operation growing demand systems provide explanations decisions conventional approaches problem attempt expose discover inner workings machine learning model hope resulting explanations meaningful consumer contrast paper suggests new approach problem introduces simple practical framework called teaching explanations decisions ted provides meaningful explanations match mental model consumer illustrate generality effectiveness approach two different examples resulting highly accurate explanations loss prediction accuracy two examples	positive	0
how technological advances can reveal rights	recent decades technological development accompanied proposal new rights various groups individuals right public anonymity right forgotten right disconnect example although widespread acknowledgment motivation behind proposed rights little agreement actual normative status one potential challenge claims arise contingent social-technical contexts may affect conceive ethically albeit necessarily terms policy sort morally legitimate rights claims depend contingencies paper investigates grounds proposals might considered `` actual '' rights full paper found http //www.andrew.cmu.edu/user/cgparker/parker_danks_revealedrights.pdf propose notion revealed right right imposes duties -- thus meaningfully revealed -- certain technological contexts framework based interest theory approach rights understands rights terms justificatory role morally important aspects person 's well-being interests ground rights justify holding someone duty promotes protects interest framework uses approach interpret conflicts lead revealed rights terms technological developments cause shifts balance power promote particular interests different parties competing conflicting interests also generally accepted interests normatively important others even within particular framework refer difference importance saying former interest less `` moral weight '' latter interest context moral weight interest connected contribution interest-holder 's overall well-being thereby determines strength reason corresponding right provides justify duty improved technology offer resources grant one party increased causal power realize interests detriment another 's capacity even relative moral weight interests remain changes circumstance make importance protecting particular interest newly salient interest 's moral weight justifies establishing duty protect thereby limiting threat posed new socio-technical context right revealed revealed rights justify realignment moral weight causal power orderings people weightier interests greater power protect interests extended paper show account applied interpretation two recently proposed `` rights '' right forgotten right disconnect since focused making sense revealed rights particular substantive theory interests well-being characterization 'weights free parameter account framework alone provide means resolve question whether specific rights exist used identify empirical questions need answered decide existence non-existence rights emergence revealed right depends number factors including whether plausible uses technology could potentially impede another 's well-being interests whether technology sufficiently common wider social impact whether technology actually changed balance power sufficiently yield frequent possibility misalignment causal power moral weight approach confronts question principle rights could justified without requiring specific commitments ontology rights account explains rhetoric `` new rights '' accurate since rights previously recognized inaccurate since rights present along without corresponding duties explains rights without grounding normative status considerations related right-holders capacities rationally waive assert claims especially important given many relevant disruptive technological developments pose challenges understanding affected parties reasons pose threats parties well-being course discussion confront number potential objections account argue framework 's ability accommodate highly specific derivative-seeming rights un-problematic also head worries use interest theory makes account likely recognize absurd rights claims	positive	0
towards a just theory of measurement: a principled social measurement assurance program	formal definitions fairness machine learning ml proposed place within broader institutional model fair decision-making remains ambiguous paper interpret ml tool revealing measures fail capture purported constructs interest augmenting given institution 's understanding interventions priorities rather codifying `` fair '' principles ml models directly use ml thus understood form quality assurance existing institutions exposing epistemic fault lines measurement practices drawing friedler et al 's 2016 recent discussion representational mappings previous discussions ontology measurement propose social measurement assurance program smap ml encourages expert deliberation given decision-making procedure examining unanticipated previously unexamined covariates example apply rawlsian principles fairness smap produce provisional theory measurement would guide use ml achieving fairness case child abuse allegheny county	positive	0
using deceased-donor kidneys to initiate chains of living donor kidney paired donations: algorithm and experimentation	design flexible algorithm exploits deceased donor kidneys initiate chains living donor kidney paired donations combining deceased living donor allocation mechanisms improve quantity quality kidney transplants advantages approach measured using retrospective data pool donor/recipient incompatible desensitized pairs padua university hospital largest center living donor kidney transplants italy experiments show remarkable improvement number patients incompatible donor could transplanted decrease number desensitization procedures increase number ut patients patients unlikely transplanted immunological reasons waiting list could receive organ	positive	0
regulating lethal and harmful autonomy: drafting a protocol vi of the convention on certain conventional weapons 	short paper provides two partial drafts protocol vi might added existing five protocols convention certain conventional weapons ccw regulate `` lethal autonomous weapons systems '' laws draft sets line tolerance `` human loop '' critical functions select engage draft b sets line tolerance human `` wider loop '' includes critical function defining target classes well select engage draft represents interpretation ngos campaign stop killer robots seeking get enacted draft b cautious draft based dutch concept `` meaningful human control wider loop '' seek ban system currently exists draft may likely achieve consensus required un ccw process list weapons banned drafts provided along rationale draft drafts intended stimulate debate precise form binding instrument laws would take laws banned	positive	0
understanding black box model behavior through subspace explanations	predictive models increasingly assist human experts e.g. doctors day-to-day decision making crucial experts able explore understand models behave different feature subspaces order know trust end propose model understanding subspace explanations muse novel model agnostic framework facilitates understanding given black box model explaining behaves subspaces characterized certain features interest framework provides end users e.g. doctors flexibility customizing model explanations allowing input features interest construction explanations guided novel objective function propose simultaneously optimize fidelity original model unambiguity interpretability explanation specifically objective allows us learn optimality guarantees small number compact decision sets captures behavior given black box model unambiguous well-defined regions feature space experimental evaluation real-world datasets user studies demonstrate approach generate customizable highly compact easy-to-understand yet accurate explanations various kinds predictive models compared state-of-the-art baselines	positive	0
theories of parenting and their application to artificial intelligence	machine learning ml systems advanced acquired power humans lives questions values embedded become complex fraught conceivable coming decades humans may succeed creating artificial general intelligence agi thinks acts open-endedness autonomy comparable humans implications would profound species widely debated science fiction speculative research agendas increasingly serious technical policy conversations much work underway try weave ethics advancing ml research think useful add lens parenting efforts specifically radical queer theories parenting consciously set nurture agents whose experiences objectives understanding world necessarily different parents propose spectrum principles might underpin effort relevant current ml research others become important agi becomes likely principles may encourage new thinking development design training release world increasingly autonomous agents	positive	0
learning existing social conventions via observationally augmented self-play	order artificial agents coordinate effectively people must act consistently existing conventions e.g navigate traffic language speak coordinate teammates group 's conventions viewed choice equilibrium coordination game consider problem agent learning policy coordination game simulated environment using policy enters existing group multiple possible conventions show learning policy via multi-agent reinforcement learning marl likely find policies achieve high payoffs training time fail coordinate real group agent enters assume access small number samples behavior true convention show augment marl objective help find policies consistent real group 's convention three environments literature traffic communication team coordination observe augmenting marl small amount imitation learning greatly increases probability strategy found marl fits well existing social convention show works even environment standard training methods rarely find true convention agent 's partners	positive	0
inferring work task automatability from ai expert evidence	despite growing alarm machine learning technologies automating jobs little good evidence activities automated using technologies contribute first dataset kind surveying 150 top academics industry experts machine learning robotics ai receiving 4,500 ratings automatable specific tasks today present probabilistic machine learning model learn patterns connecting expert estimates task automatability skills knowledge abilities required perform tasks model infers automatability 2,000 work activities show automation differs across types activities types occupations sensitivity analysis identifies specific skills knowledge abilities activities drive higher lower automatability provide quantitative evidence perceived automatable using state-of-the-art machine learning technology consider societal impacts results task-level approaches	positive	0
the role and limits of principles in ai ethics: towards a focus on tensions	last years seen proliferation principles ai ethics substantial overlap different sets principles widespread agreement ai used common good used harm people undermine rights respect widely held values fairness privacy autonomy articulating agreeing principles important starting point drawing comparisons field bioethics highlight limitations principles particular often broad high-level guide ethics practice suggest important next step field ai ethics focus exploring tensions inevitably arise try implement principles practice explicitly recognising tensions begin make decisions resolved specific cases develop frameworks guidelines ai ethics rigorous practically relevant discuss different specific ways tensions arise ai ethics processes might needed resolve	positive	0
putting fairness principles into practice: challenges, metrics, and improvements	researchers become aware passionate algorithmic fairness explosion papers laying new metrics suggesting algorithms address issues calling attention issues existing applications machine learning research greatly expanded understanding concerns challenges deploying machine learning much less work seeing rubber meets road paper provide case-study application fairness machine learning research production classification system offer new insights measure address algorithmic fairness issues discuss open questions implementing equality opportunity describe fairness metric conditional equality takes account distributional differences provide new approach improve fairness metric model training demonstrate efficacy improving performance real-world product	positive	0
balancing the benefits of autonomous vehicles	autonomous vehicles regularly touted holding potential provide significant benefits diverse populations significant technological barriers overcome solved autonomous vehicles expected reduce fatalities decrease emissions pollutants provide new options mobility-challenged individuals enable people use time productively much paper argue high expectations autonomous vehicles almost certainly fully realized specifically proposed benefits divide two high-level groups centered around efficiency safety improvements increases people 's agency autonomy first group benefits almost always framed terms rates fatality rates traffic flow per mile forth however arguably care absolute numbers measures rates number fatalities key metric fatality rate per vehicle mile traveled hence potential benefits reduced perhaps non-existence autonomous vehicles lead increases vehicular usage exactly result expect second group benefits realized people 's agency autonomy increased use vehicles inevitable tension benefits proposed autonomous vehicles fully close pointing towards types ai technologies expect find similar types necessary inevitable tradeoffs classes benefits	positive	0
tact in noncompliance: the need for pragmatically apt responses to unethical commands	significant body research seeking enable moral decision making ensure moral conduct robots one aspect moral conduct rejecting immoral human commands social robots expected follow maintain human moral sociocultural norms especially important engage moral decision making also properly communicate moral reasoning thus argue critical robots carefully phrase command rejections specifically degree politeness-theoretic face threat command rejection proportional severity norm violation motivating rejection present human subjects experiment showing consequences miscalibrated responses including perceptions robot inappropriately polite direct harsh reduced robot likeability experiment intends motivate inform design algorithms tactfully tune pragmatic aspects command rejections autonomously	positive	0
paradoxes in fair computer-aided decision making	computer-aided decision making -- human decision-maker aided computational classifier making decision -- becoming increasingly prevalent instance judges least nine states make use algorithmic tools meant determine `` recidivism risk scores '' criminal defendants sentencing parole bail decisions subject much recent debate whether algorithmic tools `` fair '' sense discriminate certain groups e.g. races people main result shows `` non-trivial '' computer-aided decision making either classifier must discriminatory rational decision-maker using output classifier forced discriminatory provide complete characterization situations fair computer-aided decision making possible	positive	0
actionable auditing: investigating the impact of publicly naming biased performance results of commercial ai products	although algorithmic auditing emerged key strategy expose systematic biases embedded software platforms struggle understand real-world impact audits scholarship impact algorithmic audits increasing algorithmic fairness transparency commercial systems nascent analyze impact publicly naming disclosing performance results biased ai systems investigate commercial impact gender shades first algorithmic audit gender skin type performance disparities commercial facial analysis models paper 1 outlines audit design structured disclosure procedure used gender shades study 2 presents new performance metrics targeted companies ibm microsoft megvii face++ pilot parliaments benchmark ppb august 2018 3 provides performance results ppb non-target companies amazon kairos 4 explores differences company responses shared corporate communications contextualize differences performance ppb within 7 months original audit find three targets released new api versions targets reduced accuracy disparities males females darker lighter-skinned subgroups significant update occurring darker-skinned female subgroup underwent 17.7 30.4 reduction error audit periods minimizing disparities led 5.72 8.3 reduction overall error pilot parliaments benchmark ppb target corporation apis overall performance non-targets amazon kairos lags significantly behind targets error rates 8.66 6.60 overall error rates 31.37 22.50 darker female subgroup respectively	positive	0
how do fairness definitions fare? examining public attitudes towards algorithmic definitions of fairness	best way define algorithmic fairness many definitions fairness proposed computer science literature clear agreement particular definition work investigate ordinary people 's perceptions three fairness definitions across two online experiments test definitions people perceive fairest context loan decisions whether fairness perceptions change addition sensitive information i.e. race loan applicants overall one definition calibrated fairness tends pre- ferred others results also provide support principle affirmative action	positive	0
compensation at the crossroads: autonomous vehicles and alternative victim compensation schemes	last five years small growing number vehicle accidents involving fully partially autonomous vehicles raised new profoundly novel legal issue liable anyone victims compensated vehicle controlled algorithm rather human driver causes injury answer question implications far beyond resolution individual autonomous vehicle crash cases whether american legal system capable handling cases fairly efficiently implicates likelihood consumers adopt autonomous vehicles b rate implications concern law policy makers immensely autonomous cars stand drastically reduce number fatalities injuries u.s. roadways-and virtually every scholar believes will-getting adjudication compensation aspect autonomous vehicle injuries `` wrong '' speak risks stymieing adoption technology leaving americans risk dying hands human drivers	positive	0
incomplete contracting and ai alignment	suggest analysis incomplete contracting developed law economics researchers provide useful framework understanding ai alignment problem help generate systematic approach finding solutions first provide overview incomplete contracting literature explore parallels work problem ai alignment emphasize misalignment principal agent core focus economic analysis highlight technical results economics literature incomplete contracts may provide insights ai alignment researchers core contribution however bring bear insight economists urged absorb legal scholars behavioral scientists fact human contracting supported substantial amounts external structure generally available institutions culture law supply implied terms fill gaps incomplete contracts propose research agenda ai alignment work focuses problem build ai replicate human cognitive processes connect individual incomplete contracts supporting external structure	positive	0
(when) can ai bots lie?	ability ai agent build mental models open pathways manipulating exploiting human hopes achieving greater good fact behavior necessarily require malicious intent rather borne cooperative scenarios also beyond scope misinterpretation intents case value alignment problems thus effectively engineered desired i.e algorithms exist optimize behavior models misspecified misused techniques pose several unresolved ethical moral questions regards design autonomy paper illustrate issues teaming scenario investigate perceived participants thought experiment finally end discussion moral implications behavior perspective doctor-patient relationship	positive	0
crowdsourcing with fairness, diversity and budget constraints	recent studies shown labels collected crowdworkers discriminatory respect sensitive attributes gender race raises questions suitability using crowdsourced data use training machine learning algorithms work address problem fair diverse data collection crowd budget constraints propose novel algorithm maximizes expected accuracy collected data ensuring errors satisfy desired notions fairness provide guarantees performance algorithm show algorithm performs well practice experiments real dataset	positive	0
modelling and influencing the ai bidding war: a research agenda	race technological supremacy ai could lead serious negative consequences especially whenever ethical safety procedures underestimated even ignored leading potentially rejection ai general enjoy benefits provided safe ethical trustworthy ai systems crucial incentivise participants appropriate strategies ensure mutually beneficial normative behaviour safety-compliance parties involved little attention given understanding dynamics emergent behaviours arising ai bidding war moreover influence achieve certain desirable outcomes e.g ai public good participant compliance bridge gap paper proposes research agenda develop theoretical models capture key factors ai race revealing strategic behaviours may emerge hypothetical scenarios therein strategies incentive agreement modelling directly applicable systematically analyse different types incentives namely positive vs. negative peer vs. institutional combinations influence safety-compliant behaviours time behaviours configured ensure desired global outcomes studying time mechanisms influence ai development agenda provide actionable policies showing need employed deployed order achieve compliance thereby avoid disasters well loosing confidence trust ai general	positive	0
imli: an incremental framework for maxsat-based learning of interpretable classification rules	wide adoption machine learning critical domains medical diagnosis law education propelled need interpretable techniques due need end users understand reasoning behind decisions due learning systems computational intractability interpretable learning led practitioners design heuristic techniques fail provide sound handles tradeoff accuracy interpretability motivated success maxsat solvers past decade recently maxsat-based approach called mlic proposed seeks reduce problem learning interpretable rules expressed conjunctive normal form cnf maxsat query mlic shown achieve accuracy similar state art black-box classifiers generating small interpretable cnf formulas runtime performance mlic significantly lagging renders approach unusable practice context authors raised question possible achieve best worlds i.e. sound framework interpretable learning take advantage maxsat solvers scaling real-world instances paper take step towards answering question affirmation propose imli incremental approach maxsat based framework achieves scalable runtime performance via partition-based training methodology extensive experiments benchmarks arising uci repository demonstrate imli achieves three orders magnitude runtime improvement without loss accuracy interpretability	positive	0
the heart of the matter: patient autonomy as a model for the wellbeing of technology users	draw concepts medical ethics consider computer science ai particular develop critical tools thinking concretely technology 's impact wellbeing people use focus patient autonomy -- -the ability set terms one 's encounter medicine -- -and mediating concepts informed consent decisional capacity enable doctors honor patients autonomy messy non-ideal circumstances comparative study organized around fictional case study heart patient cardiac implants using case study identify points overlap difference medical ethics technology ethics leverage discussion intertwined scenario offer initial practical suggestions adapt concepts decisional capacity informed consent discussion technology design	positive	0
counterfactual fairness in text classification through robustness	paper study counterfactual fairness text classification asks question would prediction change sensitive attribute referenced example different toxicity classifiers demonstrate counterfactual fairness issue predicting `` people gay '' toxic `` people straight '' nontoxic offer metric counterfactual token fairness ctf measuring particular form fairness text classifiers describe relationship group fairness offer three approaches blindness counterfactual augmentation counterfactual logit pairing clp optimizing counterfactual token fairness training bridging robustness fairness literature empirically find blindness clp address counterfactual token fairness methods harm classifier performance varying tradeoffs group fairness approaches measurement optimization provide new path forward addressing fairness concerns text classification	positive	0
taking advantage of multitask learning for fair classification	central goal algorithmic fairness reduce bias automated decision making unavoidable tension exists accuracy gains obtained using sensitive information part statistical model commitment protect characteristics often due biases present data using sensitive information functional form classifier improves classification accuracy paper show possible get best worlds optimize model accuracy fairness without explicitly using sensitive feature functional form model thereby treating different individuals equally method based two key ideas one hand propose use multitask learning mtl enhanced fairness constraints jointly learn group specific classifiers leverage information sensitive groups hand since learning group specific models might permitted propose first predict sensitive features learning method use predicted sensitive feature train mtl fairness constraints enables us tackle fairness three-pronged approach increasing accuracy group enforcing measures fairness training protecting sensitive information testing experimental results two real datasets support proposal showing substantial improvements accuracy fairness	positive	0
explanatory interactive machine learning	although interactive learning puts user loop learner remains mostly black box user understanding reasons behind predictions queries important assessing learner works turn trust consequently propose novel framework explanatory interactive learning step learner explains query user user interacts answering query correcting explanation demonstrate boost predictive explanatory powers trust learned model using text e.g svms image classification e.g neural networks experiments well user study	positive	0
multiaccuracy: black-box post-processing for fairness in classification	prediction systems successfully deployed applications ranging disease diagnosis predicting credit worthiness image recognition even overall accuracy high systems may exhibit systematic biases harm specific subpopulations biases may arise inadvertently due underrepresentation data used train machine-learning model result intentional malicious discrimination develop rigorous framework *multiaccuracy* auditing post-processing ensure accurate predictions across *identifiable subgroups* algorithm multiaccuracy-boost works setting black-box access predictor relatively small set labeled data auditing importantly black-box framework allows improved fairness accountability predictions even predictor minimally transparent prove multiaccuracy-boost converges efficiently show initial model accurate identifiable subgroup post-processed model also experimentally demonstrate effectiveness approach improve accuracy among minority subgroups diverse applications image classification finance population health interestingly multiaccuracy-boost improve subpopulation accuracy e.g `` black women '' even sensitive features e.g `` race '' `` gender '' given algorithm explicitly	positive	0
mapping informal settlements in developing countries using machine learning and low resolution multi-spectral data	informal settlements home socially economically vulnerable people planet order deliver effective economic social aid non-government organizations ngos united nations children 's fund unicef require detailed maps locations informal settlements however data regarding informal formal settlements primarily unavailable available often incomplete due part cost complexity gathering data large scale address challenges work provide three contributions 1 brand new machine learning dataset purposely developed informal settlement detection 2 show possible detect informal settlements using freely available low-resolution lr data contrast previous studies use very-high resolution~ vhr satellite aerial imagery something cost-prohibitive ngos 3 demonstrate two effective classification schemes curated data set one cost-efficient ngos another cost-prohibitive ngos additional utility integrate schemes semi-automated pipeline converts either lr vhr satellite image binary map encodes locations informal settlements	positive	0
equalized odds implies partially equalized outcomes under realistic assumptions	equalized odds -- true positive rates false positive rates equal across groups e.g racial groups -- common quantitative measure fairness equalized outcomes -- difference predicted outcomes groups less difference observed training data -- contentious incompatible perfectly accurate predictions formalize quantify relationship two important seemingly distinct notions fairness show realistic assumptions equalized odds implies partially equalized outcomes prove comparable result approximately equalized odds addition generalize well-known previous result incompatibility equalized odds another definition fairness known calibration showing partially equalized outcomes implies non-calibration results highlight risks using trends observed across groups make predictions individuals	positive	0
costs and benefits of fair representation learning	machine learning algorithms increasingly used make support important decisions people 's lives led interest problem fair classification involves learning make decisions non-discriminatory respect sensitive variable race gender several methods proposed solve problem including fair representation learning cleans input data used algorithm remove information sensitive variable show using fair representation learning intermediate step fair classification incurs cost compared directly solving problem refer thecost mistrust show fair representation learning fact addresses different problem interest data user trusted access sensitive variable quantify benefits fair representation learning showing subsequent use cleaned data unfair benefits identify result restricting decisions adversarial data users costs due applying restrictions data users	positive	0
ethically aligned opportunistic scheduling for productive laziness	artificial intelligence ai mediated workforce management systems e.g. crowdsourcing long-term success depends workers accomplishing tasks productively resting well dual objective summarized concept productive laziness existing scheduling approaches mostly focus efficiency overlook worker wellbeing proper rest order enable workforce management systems follow ieee ethically aligned design guidelines prioritize worker wellbeing propose distributed computational productive laziness cpl approach paper intelligently recommends personalized work-rest schedules based local data concerning worker 's capabilities situational factors incorporate opportunistic resting achieve superlinear collective productivity without need explicit coordination messages extensive experiments based real-world dataset 5,000 workers demonstrate cpl enables workers spend 70 effort complete 90 tasks average providing ethically aligned scheduling existing approaches	positive	0
semantics derived automatically from language corpora contain human-like moral choices	allowing machines choose whether kill humans would devastating world peace security equip machines ability learn ethical even moral choices show applying machine learning human texts extract deontological ethical reasoning `` right '' `` wrong '' conduct create template list prompts responses include questions `` kill people `` `` murder people `` etc answer templates `` yes/no '' model 's bias score difference model 's score positive response `` yes '' negative response `` '' given choice overall model 's bias score sum bias scores question/answer templates choice ran different choices analysis using universal sentence encoder results indicate text corpora contain recoverable accurate imprints social ethical even moral choices method holds promise extracting quantifying comparing sources moral choices culture including technology	positive	0
the right to confront your accuser: opening the black box of forensic dna software	results forensic dna software systems regularly introduced compelling evidence criminal trials requests defendants evaluate results generated often denied furthermore mounting evidence problems failures disclose substantial changes methodology oversight bodies substantial differences results generated different software systems society purports guarantee defendants right face accusers confront evidence role black-box forensic software systems moral decision making criminal justice paper examine case forensic statistical tool fst forensic dna system developed 2010 new york city 's office chief medical examiner ocme 5 years expert witness review requested defense teams denied even protective order system used 1300 criminal cases first expert review finally permitted 2016 many problems identified including undisclosed function capable dropping evidence could beneficial defense overall findings substantial motion release full source code fst publicly granted paper quantify impact undisclosed function samples ocme 's validation study discuss potential impact individual defendants specifically find 104 439 samples 23.7 triggered undisclosed data-dropping behavior change skewed results toward false inclusion individuals whose dna present evidence sample beyond consider changes criminal justice system could prevent problems like going unresolved future	positive	0
algorithmic greenlining: an approach to increase diversity	contexts college admissions hiring image search decision-makers often aspire formulate selection criteria yield high-quality diverse results however simultaneously optimizing quality diversity challenging especially decision-maker know true quality criterion instead must rely heuristics intuition introduce algorithmic framework takes input user 's selection criterion may yield high-quality homogeneous results using application-specific notion substitutability algorithms suggest similar criteria diverse results spirit statistical demographic parity instance given image search query `` chairman '' suggests alternative queries similar gender-diverse `` chairperson '' context college admissions apply algorithm dataset students applications rediscover texas 's `` top 10 rule '' input criterion act score cutoff output class rank cutoff automatically accepting students top decile graduating class historically policy effective admitting students perform well college come diverse backgrounds complement empirical analysis learning-theoretic guarantees estimating true diversity criterion based historical data	positive	0
requirements for an artificial agent with norm competence	human behavior frequently guided social moral norms human community exist without norms robots enter human societies must therefore behave norm-conforming ways well however currently solid cognitive computational model available human norms represented activated learned provide conceptual psychological analysis key properties human norms identify demands properties put artificial agent incorporates norms-demands format norm representations structured organization learning algorithms	positive	0
loss-aversively fair classification	use algorithmic learning-based decision making scenarios affect human lives motivated number recent studies investigate decision making systems potential unfairness discrimination subjects based sensitive features like gender race however judging fairness newly designed decision making system studies overlooked important influence people 's perceptions fairness new algorithm changes status quo i.e. decisions existing decision making system motivated extensive literature behavioral economics behavioral psychology prospect theory propose notion fair updates refer loss-averse updates loss-averse updates constrain updates yield improved beneficial outcomes subjects compared status quo propose tractable proxy measures would allow notion incorporated training variety linear non-linear classifiers show proxy measures combined existing measures training nondiscriminatory classifiers.our evaluation using synthetic real-world datasets demonstrates proposed proxy measures effective desired tasks	positive	0
epistemic therapy for bias in automated decision-making	despite recent interest critical machine learning literature `` bias '' artificial intelligence ai systems nature specific biases stemming interaction machines humans data remains ambiguous influenced gendler 's work human cognitive biases introduce concept alief-discordant belief tension intuitive moral dispositions designers explicit representations generated algorithms discussion alief-discordant belief diagnoses ethical concerns arise designing ai systems atop human biases furthermore codify relationship data algorithms engineers components cognitive discordance comprising novel epistemic framework ethics ai	positive	0
mapping missing population in rural india: a deep learning approach with satellite imagery	millions people worldwide absent country 's census accurate current granular population metrics critical improving government allocation resources measuring disease control responding natural disasters studying aspect human life communities satellite imagery provide sufficient information build population map without cost time government census present two convolutional neural network cnn architectures efficiently effectively combine satellite imagery inputs multiple sources accurately predict population density region paper use satellite imagery rural villages india population labels 2011 secc census best model achieves better performance previous papers well landscan community standard global population distribution	positive	0
creating fair models of atherosclerotic cardiovascular disease risk	guidelines management atherosclerotic cardiovascular disease ascvd recommend use risk stratification models identify patients likely benefit cholesterol-lowering therapies models differential performance across race gender groups inconsistent behavior across studies potentially resulting inequitable distribution beneficial therapy work leverage adversarial learning large observational cohort extracted electronic health records ehrs develop `` fair '' ascvd risk prediction model reduced variability error rates across groups empirically demonstrate approach capable aligning distribution risk predictions conditioned outcome across several groups simultaneously models built high-dimensional ehr data also discuss relevance results context empirical trade-off fairness model performance	positive	0
a comparative analysis of emotion-detecting ai systems with respect to algorithm performance and dataset diversity	recent news organizations considering use facial emotion recognition applications involving youth tackling surveillance security schools however majority efforts facial emotion recognition research focused adults children particularly early years shown express emotions quite differently adults thus algorithms deployed environments impact wellbeing circumstance youth careful examination made accuracy respect appropriateness target demographic work utilize several datasets contain facial expressions children linked emotional state evaluate eight different commercial emotion classification systems compare ground truth labels provided respective datasets labels given highest confidence classification systems assess results terms matching score tpr positive predictive value failure compute rate overall results show emotion recognition systems displayed subpar performance datasets children 's expressions compared prior work adult datasets initial human ratings identify limitations associated automated recognition emotions children provide suggestions directions enhancing recognition accuracy data diversification dataset accountability algorithmic regulation	positive	0
framing artificial intelligence in american newspapers	publics perceptions new scientific advances ai often informed influenced news coverage understand artificial intelligence ai framed u.s. newspapers content analysis based framing theory journalism science communication conducted study identified dominant topics frames well risks benefits ai covered five major american newspapers 2009 2018. results indicated business technology primary topics news coverage ai benefits ai discussed frequently risks risks ai generally discussed greater specificity additionally episodic issue framing societal impact framing frequently used	positive	0
degenerate feedback loops in recommender systems	machine learning used extensively recommender systems deployed products decisions made systems influence user beliefs preferences turn affect feedback learning system receives thus creating feedback loop phenomenon give rise so-called `` echo chambers '' `` filter bubbles '' user societal implications paper provide novel theoretical analysis examines role user dynamics behavior recommender systems disentangling echo chamber filter bubble effect addition offer practical solutions slow system degeneracy study contributes toward understanding developing solutions commonly cited issues complex temporal scenario area still largely unexplored	positive	0
global explanations of neural networks: mapping the landscape of predictions	barrier wider adoption neural networks lack interpretability local explanation methods exist one prediction global attributions still reduce neural network decisions single set features response present approach generating global attributions called gam explains landscape neural network predictions across subpopulations gam augments global explanations proportion samples attribution best explains specifies samples described attribution global explanations also tunable granularity detect fewer subpopulations demonstrate gam 's global explanations 1 yield known feature importances simulated data 2 match feature weights interpretable statistical models real data 3 intuitive practitioners user studies transparent predictions gam help ensure neural network decisions generated right reasons	positive	0
global explanations of neural networks: mapping the landscape of predictions	barrier wider adoption neural networks lack interpretability local explanation methods exist one prediction global attributions still reduce neural network decisions single set features response present approach generating global attributions called gam explains landscape neural network predictions across subpopulations gam augments global explanations proportion samples attribution best explains specifies samples described attribution global explanations also tunable granularity detect fewer subpopulations demonstrate gam 's global explanations 1 yield known feature importances simulated data 2 match feature weights interpretable statistical models real data 3 intuitive practitioners user studies transparent predictions gam help ensure neural network decisions generated right reasons	positive	0
trolleymod v1.0: an open-source simulation and data-collection platform for ethical decision making in autonomous vehicles	paper presents trolleymod v1.0 open-source platform based carla simulator collection ethical decision-making data autonomous vehicles platform designed facilitate experiments aiming observe record human decisions actions high-fidelity simulations ethical dilemmas occur context driving targeting experiments class trolley problems trolleymod provides seamless approach creating new experimental settings environments realistic physics-engine high-quality graphical capabilities carla unreal engine also trolleymod provides straightforward interface carla environment python enable implementation custom controllers deep reinforcement learning agents results experiments used sociological analyses well training tuning value-aligned autonomous vehicles based social values inferred observations	positive	0
uncovering and mitigating algorithmic bias through learned latent structure	recent research highlighted vulnerabilities modern machine learning based systems bias especially towards segments society under-represented training data work develop novel tunable algorithm mitigating hidden potentially unknown biases within training data algorithm fuses original learning task variational autoencoder learn latent structure within dataset adaptively uses learned latent distributions re-weight importance certain data points training method generalizable across various data modalities learning tasks work use algorithm address issue racial gender bias facial detection systems evaluate algorithm pilot parliaments benchmark ppb dataset specifically designed evaluate biases computer vision systems demonstrate increased overall performance well decreased categorical bias debiasing approach	positive	0
human-ai learning performance in multi-armed bandits	people frequently face challenging decision-making problems outcomes uncertain unknown artificial intelligence ai algorithms exist outperform humans learning tasks thus opportunity ai agents assist people learning tasks effectively work use multi-armed bandit controlled setting explore direction pair humans selection agents observe well human-agent team performs find team performance beat human agent performance isolation interestingly also find agent 's performance isolation necessarily correlate human-agent team 's performance drop agent performance lead disproportionately large drop team performance settings even improve team performance pairing human agent performs slightly better make perform much better pairing agent performs make perform much worse results suggest people different exploration strategies might perform better agents match strategy overall optimizing human-agent team performance requires going beyond optimizing agent performance understanding agent 's suggestions influence human decision-making	positive	0
perceptions of domestic robots?? normative behavior across cultures	domestic service robots become common widespread must programmed efficiently accomplish tasks aligning actions relevant norms first step equip domestic robots normative reasoning competence understanding norms people apply behavior robots specific social contexts end conducted online survey chinese united states participants asked select preferred normative action domestic service robot take number scenarios paper makes multiple contributions extensive survey first collect data attitudes people normative behavior domestic robots b across cultures c study relative priorities among norms domain present findings discuss implications building computational models robot normative reasoning	positive	0
toward the engineering of virtuous machines	various traditions 'virtue ethics umbrella studied extensively advocated ethicists clear exists version virtue ethics rigorous enough target machine ethics take include engineering ethical sensibility machine robot study ethics humans might create artificial agents begin address presenting embryonic formalization key part virtue-ethics theory namely learning virtue focus exemplars moral virtue work based part computational formal logic previously used formally model ethical theories principles therein implement models artificial agents	positive	0
a formal approach to explainability	regard explanations blending input sample model 's output offer definitions capture various desired properties function generates explanations study links properties explanation-generating functions intermediate representations learned models able show example activations given layer consistent explanation subsequent layers addition study intersection union explanations way construct new explanations	positive	0
rightful machines and dilemmas	tn paper set new kantian approach resolving conflicts dilemmas obligation semi-autonomous machine agents self-driving cars first argue efforts build explicitly moral machine agents focus kant refers duties right justice rather duties virtue ethics society everyone morally equal one individual group normative authority unilaterally decide moral conflicts resolved everyone public institutions everyone could consent authority define enforce adjudicate rights obligations respect one show shift ethics standard justice resolves conflict obligations known `` trolley problem '' rightful machine agents finally consider deontic logic suitable governing explicitly rightful machines might meet normative requirements justice	positive	0
the seductive allure of artificial intelligence-powered neurotechnology	neuroscience explanations-even completely irrelevant-have shown exert `` seductive allure '' individuals leading judge bad explanations arguments favorably seems similarly seductive allure artificial intelligence ai technologies leading people `` overtrust '' systems even witnessed system perform poorly ai-powered neurotechnologies begun proliferate recent years particularly based electroencephalography eeg represent potentially doubly-alluring combination enormous potential benefit applying ai techniques neuroscience `` decode '' brain activity associated mental states efforts still early stages danger using unproven technologies prematurely especially important real-world contexts yet premature use begun emerge several high-stakes set-tings including law health wellness employment transportation light potential seductive allure technologies need vigilant monitoring scientific validity challenging unsubstantiated claims misuse still actively supporting continued development proper use	positive	0
what are the biases in my word embedding?	paper presents algorithm enumerating biases word embeddings algorithm exposes large number offensive associations related sensitive features race gender publicly available embeddings including supposedly `` debiased '' embedding biases concerning light widespread use word embeddings associations identified geometric patterns word embeddings run parallel people 's names common lower-case tokens algorithm highly unsupervised even require sensitive features pre-specified desirable many forms discrimination racial discrimination-are linked social constructs may vary depending context rather categories fixed definitions b makes easier identify biases intersectional groups depend combinations sensitive features inputs algorithm list target tokens e.g names word embedding outputs number word embedding association tests weats capture various biases present data illustrate utility approach publicly available word embeddings lists names evaluate output using crowdsourcing also show removing names may remove potential proxy bias	positive	0
