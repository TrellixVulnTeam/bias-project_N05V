,conference_year,category,title,author,abstract,download_url,keywords
0,2005,Contents,Cross-Lingual Bootstrapping of Semantic Lexicons: The Case of FrameNet,"Sebastian Pado, Mirella Lapata","This paper considers the problem of unsupervised semantic lexicon acquisition. We introduce a fully automatic approach which exploits parallel corpora, relies on shallow text properties, and is relatively inexpensive. Given the English FrameNet lexicon, our method exploits word alignments to generate frame candidate list for new languages, which are subsequently pruned automatically using a small set of linguistically motivated filters. Evaluation shows that our approach can produce high-precision multilingual FrameNet lexicons without recourse to bilingual dictionaries or deep syntactic and semantic analysis.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-172.pdf,Subjects: 13. Natural Language Processing; 11.2 Ontologies
1,2005,Contents,Word Sense Disambiguation with Semi-Supervised Learning,"Thanh Phong Pham, Hwee Tou Ng, Wee Sun Lee",Content Area:  14. Natural Language Processing & Speech Recognition,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-173.pdf,Subjects: 13. Natural Language Processing
2,2005,Contents,Robust Textual Inference via Learning and Abductive Reasoning,"Rajat Raina, Andrew Y. Ng, Christopher D. Manning","We present a system for textual inference (the task of inferring whether a sentence follows from another text) that uses learning and a logical-formula semantic representation of the text. More precisely, our system begins by parsing and then transforming sentences into a logical formula-like representation similar to the one used by (Harabagiu et al., 2000). An abductive theorem prover then tries to find the minimum ``cost'' set of assumptions necessary to show that one statement follows from the other. These costs reflect how likely different assumptions are, and are learned automatically using information from syntactic/semantic features and from linguistic resources such as WordNet. If one sentence follows from the other given only highly plausible, low cost assumptions, then we conclude that it can be inferred. Our approach can be viewed as combining statistical machine learning and classical logical reasoning, in the hope of marrying the robustness and scalability of learning with the preciseness and elegance of logical theorem proving. We give experimental results from the recent PASCAL RTE 2005 challenge competition on recognizing textual inferences, where a system using this inference algorithm achieved the highest confidence weighted score.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-174.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
3,2005,Contents,Exploiting Subjectivity Classification to Improve Information Extraction,"Ellen Riloff, Janyce Wiebe, William Phillips","Information extraction (IE) systems are prone to false hits for a variety of reasons and we observed that many of these false hits occur in sentences that contain subjective language (e.g., opinions, emotions, and sentiments). Motivated by these observations, we explore the idea of using subjectivity analysis to improve the precision of information extraction systems. In this paper, we describe an IE system that uses a subjective sentence classifier to filter its extractions. We experimented with several different strategies for using the subjectivity classifications, including an aggressive strategy that discards all extractions found in subjective sentences and more complex strategies that selectively discard extractions. We evaluated the performance of these different approaches on the MUC-4 terrorism data set. We found that indiscriminately filtering extractions from subjective sentences was overly aggressive, but more selective filtering strategies improved IE precision with minimal recall loss.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-175.pdf,Subjects: 13. Natural Language Processing
4,2005,Contents,Dependency Parsing with Dynamic Bayesian Network,"Virginia Savova, Leonid Peshkin",Exact parsing with finite state automata is deemed inapropriate because of the unbounded non-locality languages overwhelmingly exhibit. We propose a way to structure the parsing task in order to make it amenable to local classification methods. This allows us to build a Dynamic Bayesian Network which uncovers the syntactic dependency structure of English sentences. Experiments with the Wall Street Journal demonstrate that the model successfully learns from labeled data.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-176.pdf,Subjects: 13. Natural Language Processing; 4. Cognitive Modeling
5,2005,Contents,Spotting Subsequences matching a HMM using the Average Observation Probability Criteria with application to Keyword Spotting,Marius C Silaghi,"This paper addresses the problem of detecting keywords in unconstrained speech. The proposed algorithms search for the speech segment maximizing the average observation probability along the most likely path in the hypothesized keyword model. As known, this approach (sometimes referred to as sliding model method) requires a relaxation of the begin/endpoints of the Viterbi matching, as well as a time normalization of the resulting score. This makes solutions complex (i.e., LN2/2 basic operations for keyword HMM models with L states and utterances with N frames). We present here two alternative (quite simple and efficient) solutions to this problem. a) First we provide a method that finds the optimal segmentation according to the criteria of maximizing the average observation probability. It uses Dynamic Programming as a step, but does not require scoring for all possible begin/endpoints. While the worst case remains O(LN2), this technique converged in at most 3(L+2)N basic operations in each experiment for two very different applications. b) The second proposed algorithm does not provide a segmentation but can be used for the decision problem of whether the utterance should be classified as containing the keyword or not (provided a predefined threshold on the acceptable average observation probability). This allows the algorithm to be even faster, with fix cost of (L+2)N.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-177.pdf,Subjects: 18. Speech Understanding; 15.7 Search
6,2005,Activity and Plan Recognition,Multiple-Goal Recognition in a Wireless Environment,"Xiaoyong Chai, Qiang Yang","Inferring a user’s high-level goals from low-level sensor readings has been drawing increasing attention from both AI and Pervasive Computing communities recently. A common assumption made by most approaches is that a user has a single goal in mind or aims to achieve several goals sequentially. However, in real-world environments, a user often has multiple goals concurrently carried out and a single action can serve as a step towards multiple goals. In this paper, we formulate the multiple-goal recognition problem and exemplify it in an indoor environment where an RF-based wireless network is available. We propose a recognition algorithm based on a dynamic model set and show how goal models evolve over time among pre-defined states to perform recognition. Experiments with real data demonstrate that our method can accurately and efficiently recognize multiple goals in a user’s trace.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-001.pdf,Subjects: 3.4 Probabilistic Reasoning
7,2005,Activity and Plan Recognition,A Variational Learning Algorithm for the Abstract Hidden Markov Model,"Jeff Johns, Sridhar Mahadevan","We present a fast algorithm for learning the parameters of the abstract hidden Markov model, a type of hierarchical activity recognition model. Learning using exact inference scales poorly as the number of levels in the hierarchy increases; therefore, an approximation is required for large models. We demonstrate that variational inference is well suited to solve this problem. Not only does this technique scale, but it also offers a natural way to leverage the context specific independence properties inherent in the model via the fixed point equations. Experiments confirm that the variational approximation significantly reduces the time necessary for learning while estimating parameter values that can be used to make reliable predictions.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-002.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
8,2005,Activity and Plan Recognition,Large-Scale Localization from Wireless Signal Strength,"Julia Letchner, Dieter Fox, Anthony LaMarca","Knowledge of the physical locations of mobile devices such as laptops or PDA’s is becoming increasingly important with the rise of location-based services such as specialized web search, navigation, and social network applications; furthermore, location information is a key foundation for high-level activity inferencing. In this paper we propose a novel technique for accurately estimating the locations of mobile devices and their wearers from wireless signal strengths. Our technique estimates time-varying device locations on a spatial connectivity graph whose outdoor edges correspond to streets and whose indoor edges represent hallways, staircases, elevators, etc. Use of a hierarchical Bayesian framework for learning a signal strength sensor model allows us not only to achieve higher accuracy than existing approaches, but to overcome many of their limitations. In particular, our technique is able to (1) seamlessly integrate new access points into the model, (2) make use of negative information (not detecting an access point), and (3) bootstrap a sensor model from sparse training data. Experiments demonstrate various properties of our system.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-003.pdf,Subjects: 1. Applications; 3.4 Probabilistic Reasoning
9,2005,Activity and Plan Recognition,Unsupervised Activity Recognition Using Automatically Mined Common Sense,"Danny Wyatt, Matthai Philipose, Tanzeem Choudhury","A fundamental difficulty in recognizing human activities is obtaining the labeled data needed to learn models of those activities. Given emerging sensor technology, however, it is possible to view activity data as a stream of natural language terms. Activity models are then mappings from such terms to activity names, and may be extracted from text corpora such as the web. We show that models so extracted are sufficient to automatically produce labeled segmentations of activity data with an accuracy of 42% over 26 activities, well above the 3.8% baseline. The segmentation so obtained is sufficient to bootstrap learning, with accuracy of learned models increasing to 52%. To our knowledge, this is the first human activity inferencing system shown to learn from sensed activity data with no human intervention per activity learned, even for labeling.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-004.pdf,Subjects: 5. Common Sense Reasoning; 12. Machine Learning and Discovery
10,2005,Activity and Plan Recognition,Activity Recognition through Goal-Based Segmentation,"Jie Yin, Dou Shen, Qiang Yang, Ze-Nian Li","A major issue in activity recognition in a sensor network is how to automatically segment the low-level signal sequences in order to optimize the probabilistic recognition models for goals and activities. Past efforts have relied on segmenting the signal sequences by hand, which is both time-consuming and error-prone. In our view, segments should correspond to atomic human activities that enable a goal-recognizer to operate optimally; the two are intimately related. In this paper, we present a novel method for building probabilistic activity models at the same time as we segment signal sequences into motion patterns. We model each motion pattern as a linear dynamic model and the transitions between motion patterns as a Markov process conditioned on goals. Our EM learning algorithm simultaneously learns the motion-pattern boundaries and probabilistic models for goals and activities, which in turn can be used to accurately recognize activities in an online phase. A major advantage of our algorithm is that it can reduce the human effort in segmenting and labeling signal sequences. We demonstrate the effectiveness of our algorithm using the data collected in a real wireless environment.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-005.pdf,Subjects: 3.4 Probabilistic Reasoning
11,2005,Agents / Multiagent Systems,Team Member Reallocation via Tree Pruning,"Noa Agmon, Gal A Kaminka, Sarit Kraus","This paper considers the task reallocation problem, where k agents are to be extracted from a coordinated group of N agents in order to perform a new task. The interaction between the team members and the cost associated with this interaction are represented by a weighted graph. Consider a group of N robots organized in a formation, the graph is the monitoring graph which represents the sensorial capabilities of the robots, i.e., which robot can sense the other and at what cost. Following this example, the team member reallocation problem this paper deals with is the extraction of k robots from the group in order to acquire a new target, while minimizing the cost of the interaction of the remaining group. In general, the method proposed here shifts the utility from the team member itself to the interaction between the members, and calculates the reallocation according to this interaction utility. We found that this can be done optimally by a deterministic polynomial time algorithm under several constraints, the first constraint is that k = O(log N). We describe several other domains in which this method is applicable.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-000.pdf,Subjects: 7.1 Multi-Agent Systems; 9.2 Computational Complexity
12,2005,Agents / Multiagent Systems,Efficient No-Regret Multiagent Learning,"Bikramjit Banerjee, Jing Peng","We present new results on the efficiency of no-regret algorithms in the context of multiagent learning. We use a known approach to augment a large class of no-regret algorithms to allow stochastic sampling of actions and observation of scalar reward of only the action played. We show that the average actual payoffs of the resulting learner gets (1) close to the best response against (eventually) stationary opponents, (2) close to the asymptotic optimal payoff against opponents that play a converging sequence of policies, and (3) close to at least a dynamic variant of minimax payoff against arbitrary opponents, with a high probability in polynomial time. In addition the polynomial bounds are shown to be significantly better than previously known bounds. Furthermore, we do not need to assume that the learner knows the game matrices and can observe the opponents’ actions, unlike previous work.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-007.pdf,Subjects: 7.1 Multi-Agent Systems; 12.1 Reinforcement Learning
13,2005,Agents / Multiagent Systems,Solving DisCSPs with Penalty Driven Search,"Muhammed Basharu, Ines Arana, Hatem Ahriz","We introduce the Distributed, Penalty-driven Local search algorithm (DisPeL) for solving Distributed Constraint Satisfaction Problems. DisPeL is a novel distributed iterative improvement algorithm which escapes local optima by the use of both temporary and incremental penalties and a tabu-like no-good store. We justify the use of these features and provide empirical results which demonstrate the competitiveness of the algorithm.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-008.pdf,Subjects: 15.2 Constraint Satisfaction; 7. Distributed AI
14,2005,Agents / Multiagent Systems,Coordination and Adaptation in Impromptu Teams,"Michael Bowling, Peter McCracken","Coordinating a team of autonomous agents is one of the major challenges in building effective multiagent systems. Many techniques have been devised for this problem, and coordinated teamwork has been demonstrated even in highly dynamic and adversarial environments. A key assumption of these techniques, though, is that the team members are developed together as a whole. In many multiagent scenarios, this assumption is violated. We study the problem of coordination in impromptu teams, where a team is composed of independent agents each unknown to the others. The team members have their own skills, models, strategies, and coordination mechanisms, and no external organization is imposed upon them. In particular, we propose two techniques, one adaptive and one predictive, for coordinating a single agent that joins an unknown team of existing agents. We experimentally evaluate these mechanisms in the robot soccer domain, while introducing useful baselines for evaluating the performance of impromptu teams. We show some encouraging success while demonstrating this is a very fertile area of research.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-009.pdf,Subjects: 7.1 Multi-Agent Systems; 17. Robotics
15,2005,Agents / Multiagent Systems,Robust and Self-Repairing Formation Control for Swarms of Mobile Agents,"Jimming Cheng, Winston Cheng, Radhika Nagpal","We describe a decentralized algorithm for coordinating a swarm of identically-programmed mobile agents to spatially self-aggregate into arbitrary shapes using only local interactions. Our approach, called SHAPEBUGS, generates a consensus coordinate system by agents continually performing local trilaterations, and achieves shape formation by simultaneously allowing agents to disperse within the defined 2D shape using a Contained Gas Model. This approach has several novel features (1) agents can easily aggregate into arbitrary user-specified shapes, using a formation process that is independent of the number of agents (2) the system automatically adapts to influx and death of agents, as well as accidental displacement. We show that the consensus coordinate system is robust and provides reasonable accuracy in the face of significant sensor and movement error.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-010.pdf,Subjects: 7. Distributed AI; 7.1 Multi-Agent Systems
16,2005,Agents / Multiagent Systems,An Extended Protocol for Multiple-Issue Concurrent Negotiation,"Jiangbo Dang, Michael N. Huhns",Content Area:  1. Agents/Multiagent Systems,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-011.pdf,Subjects: 7.1 Multi-Agent Systems
17,2005,Agents / Multiagent Systems,The Semantics of Potential Intentions,"Xiaocong Fan, John Yen","The SharedPlans theory provides an axiomatic framework of collaborative plans based on four types of intentional attitudes. However, there still lacks an adequate semantics for the potential intention operators. In this paper, we give a formal semantics to potential intentions, and examine models that can validate various relations between beliefs, intentions, and potential intentions.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-012.pdf,Subjects: 9.4 Philosophical Foundations; 7. Distributed AI
18,2005,Agents / Multiagent Systems,Agent-Organized Networks for Multi-Agent Production and Exchange,"Matthew Gaston, Marie desJardins","As multi-agent systems grow in size and complexity, social networks that govern the interactions among the agents will directly impact system behavior at the individual and collective levels. Examples of such large-scale, networked multi-agent systems include peer-to-peer networks, distributed information retrieval, and agent-based supply chains. One way of dealing with the uncertain and dynamic nature of such environments is to endow agents with the ability to modify the agent social network by autonomously adapting their local connectivity structure. In this paper, we present a framework for agent-organized networks (AONs) in the context of multi-agent production and exchange, and experimentally evaluate the feasibility and efficiency of specific AON strategies. We find that decentralized network adaptation can significantly improve organizational performance. Additionally, we analyze several properties of the resulting network structures and consider their relationship to the observed increase in organizational performance.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-013.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
19,2005,Agents / Multiagent Systems,Supporting Collaborative Activity,"Meirav Hadad, Gilad Armon-Kest, Gal A. Kaminka, Sarit Kraus","This paper presents a model---SharedActivity---for collaborative agents acting in a group. The model suggests mental states for agents with different levels of cooperation and permits the formation of groups in which members increase individual benefits. Unlike previous models, the model covers group member behavior where group members do not have a joint goal, but act collaboratively. The model defines key components of a collaborative activity and provides a platform for supporting such activity. We studied the behavior of the model in a simulation environment. Results show how the benefit attained by cooperation is influenced by the complexity of the environment, the number of group members, and the social dependencies between the members. The results demonstrate that the model covers social behavior both in settings previously addressed, as well as in novel settings.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-014.pdf,Subjects: 7.1 Multi-Agent Systems
20,2005,Agents / Multiagent Systems,Multiple Agent Event Detection and Representation in Videos,"Asaad Hakeem, Mubarak Shah","We propose a novel method to detect events involving multiple agents in a video and to learn their structure in terms of temporally related chain of sub-events. The proposed method has three significant contributions over existing frameworks. First, in order to learn the event structure from training videos, we present the concept of a video event graph, which is composed of temporally related sub-events. Using the video event graph, we automatically encode the event dependency graph. The event dependency graph is the learnt event model that depicts the frequency of occurrence of conditionally dependent sub-events. Second, we pose the problem of event detection in novel videos as clustering the maximally correlated sub-events, and use normalized cuts to determine these clusters. The principal assumption made in this work is that the events are composed of highly correlated chain of sub-events, that have high weights (association) within the cluster and relatively low weights (disassociation) between clusters. These weights (between sub-events) are the likelihood estimates obtained from the event models. Last, we recognize the importance of representing the variations in the temporal order of sub-events, occurring in an event, and encode the probabilities directly into our representation. We show results of our learning, detection, and representation of events for videos in the meeting, surveillance, and railroad monitoring domains.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-015.pdf,Subjects: 7.1 Multi-Agent Systems; 19. Vision
21,2005,Agents / Multiagent Systems,Anyone But Him: The Complexity of Precluding an Alternative,"Edith Hemaspaandra, Lane A. Hemaspaandra, J&ouml;rg Rothe","Preference aggregation in a multiagent setting is a central issue in both human and computer contexts. In this paper, we study in terms of complexity the vulnerability of preference aggregation to destructive control. That is, we study the ability of an election&#8217;s chair to, through such mechanisms as voter/candidate addition/suppression/partition, ensure that a particular candidate (equivalently, alternative) does not win. And we study the extent to which election systems can make it impossible, or computationally costly (NP-complete), for the chair to execute such control. Among the systems we study---plurality, Condorcet, and approval voting---we find cases where systems immune or computationally resistant to a chair choosing the winner nonetheless are vulnerable to the chair blocking a victory. Beyond that, we see that among our studied systems no one system offers the best protection against destructive control. Rather, the choice of a preference aggregation system will depend closely on which types of control one wishes to be protected against. We also find concrete cases where the complexity of or susceptibility to control varies dramatically based on the choice among natural tie-handling rules.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-016.pdf,Subjects: 9.2 Computational Complexity; 7.1 Multi-Agent Systems
22,2005,Agents / Multiagent Systems,Towards Model-Based Diagnosis of Coordination Failures,"Meir Kalech, Gal A.","With increasing deployment of multi-agent and distributed systems, there is an increasing need for failure diagnosis systems. While successfully tackling key challenges in multi-agent settings, model-based diagnosis has left open the diagnosis of coordination failures, where failures often lie in the boundaries between agents, and thus the inputs to the model - with which the diagnoser simulates the system to detect discrepancies - are not known. However, it is possible to diagnose such failures using a model of the coordination between agents. This paper formalizes model-based coordination diagnosis, using two coordination primitives (concurrence and mutual exclusion). We define the consistency-based and abductive diagnosis problems within this formalization, and show that both are NP-Hard by mapping them to other known problems.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-017.pdf,Subjects: 1.5 Diagnosis; 7.1 Multi-Agent Systems
23,2005,Agents / Multiagent Systems,Flexible Teamwork in Behavior-Based Robots,"Gal A. Kaminka, Inna Frenkel","A key challenge in deploying teams of robots in real-world applications is to automate the control of teamwork, such that the designer can focus on the taskwork. Existing teamwork architectures seeking to address this challenge are monolithic, in that they commit to interaction protocols at the architectural level, and do not allow the designer to mix and match protocols for a given task. We present BITE, a behavior-based teamwork architecture that automates collaboration in physical robots, in a distributed fashion. BITE separates task behaviors that control a robot’s interaction with its task, from interaction behaviors that control a robot’s interaction with its teammates. This distinction provides for flexibility and modularity in terms of the interactions used by teammates to collaborate effectively. It also allows BITE to synthesize and significantly extend existing teamwork architectures. BITE also incorporates key lessons learned in applying multi-agent teamwork architectures in physical robot teams. We present empirical results from experiments with teams of Sony AIBO robots executing BITE, and discuss the lessons learned.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-018.pdf,Subjects: 7.1 Multi-Agent Systems; 17. Robotics
24,2005,Agents / Multiagent Systems,Coordinating Agile Systems through the Model-Based Execution of Temporal Plans,"Thomas Leaute, Brian C. Williams","Agile autonomous systems are emerging, such as unmanned aerial vehicles (UAVs), that must robustly perform tightly coordinated time-critical missions; for example, military surveillance or search-and-rescue scenarios. In the space domain, execution of temporally flexible plans has provided an enabler for achieving the desired coordination and robustness. We address the challenge of extending plan execution to under-actuated systems that are controlled indirectly through the setting of continuous state variables. Our solution is a novel model-based executive that takes as input a temporally flexible state plan, specifying intended state evolutions, and dynamically generates a near-optimal control sequence. To achieve optimality and safety, the executive plans into the future, framing planning as a disjunctive programming problem. To achieve robustness to disturbances and tractability, planning is folded within a receding horizon, continuous planning framework. Key to performance is a problem reduction method based on constraint pruning. We benchmark performance through a suite of UAV scenarios using a hardware-in-the-loop testbed.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-019.pdf,Subjects: 1.11 Planning; 3.5 Qualitative Reasoning
25,2005,Agents / Multiagent Systems,Controversial Users Demand Local Trust Metrics: An Experimental Study on Epinions.com Community,"Paolo Massa, Paolo Avesani.","In today’s connected world it is possible and very common to interact with unknown people, whose reliability is unknown. Trust Metrics are a recently proposed technique for answering questions such as ""Should I trust this user?"". However, most of the current research assumes that every user has a global quality score and that the goal of the technique is just to predict this correct value. We show, on data from a real and large user community, Epinions.com, that such an assumption is not realistic because there is a significant portion of what we call controversial users, users who are trusted and distrusted by many. A global agreement about the trustworthiness value of these users cannot exist. We argue, using computational experiments, that the existence of controversial users (a normal phenomena in societies) demands Local Trust Metrics, techniques able to predict the trustworthiness of an user in a personalized way, depending on the very personal view of the judging user.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-020.pdf,Subjects: 7.1 Multi-Agent Systems; 8. Enabling Technologies
26,2005,Agents / Multiagent Systems,Modeling Human Behavior for Virtual Training Systems,"Yohei Murakami, Yuki Sugimoto, Toru Ishida","Constructing highly realistic agents is essential if agents are to be employed in virtual training systems. In training for collaboration based on face-to-face interaction, the generation of emotional expressions is one key. In training for guidance based on one-to-many interaction such as direction giving for evacuations, emotional expressions must be supplemented by diverse agent behaviors to make the training realistic. To reproduce diverse behavior, we characterize agents by using a various combinations of operation rules instantiated by the user operating the agent. To accomplish this goal, we introduce a user modeling method based on participatory simulations. These simulations enable us to acquire information observed by each user in the simulation and the operating history. Using these data and the domain knowledge including known operation rules, we can generate an explanation for each behavior. Moreover, the application of hypothetical reasoning, which offers consistent selection of hypotheses, to the generation of explanations allows us to use otherwise incompatible operation rules as domain knowledge. In order to validate the proposed modeling method, we apply it to the acquisition of an evacuee’s model in a fire-drill experiment. We successfully acquire a subject’s model corresponding to the results of an interview with the subject.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-021.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
27,2005,Agents / Multiagent Systems,Networked Distributed POMDPs: A Synthesis of Distributed Constraint and POMDPs,"Ranjit Nair, Pradeep Varakantham, Milind Tambe, Makoto Yokoo","In many real-world multiagent applications such as distributed sensor nets, a network of agents is formed based on each agent’s limited interactions with a small number of neighbors. While distributed POMDPs capture the real-world uncertainty in multiagent domains, they fail to exploit such locality of interaction. Distributed constraint optimization (DCOP) captures the locality of interaction but fails to capture planning under uncertainty. This paper present a new model synthesized from distributed POMDPs and DCOPs, called Networked Distributed POMDPs (ND-POMDPs). Exploiting network structure enables us to present two novel algorithms for ND-POMDPs: a distributed policy generation algorithm that performs local search and a systematic policy search that is guaranteed to reach the global optimal.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-022.pdf,Subjects: 7.1 Multi-Agent Systems
28,2005,Agents / Multiagent Systems,New Approaches to Optimization and Utility Elicitation in Autonomic Computing,"Relu Patrascu, Craig Boutilier,Rajarshi Das,Jeffrey O. Kephart,Gerald Tesauro,William E. Walsh","Autonomic (self-managing) computing systems face the critical problem of resource allocation to different computing elements. Adopting a recent model, we view the problem of provisioning resources as involving utility elicitation and optimization to allocate resources given imprecise utility information. In this paper, we propose a new algorithm for regret-based optimization that performs significantly faster than that proposed in earlier work. We also explore new regret-based elicitation heuristics that are able to find near-optimal allocations while requiring a very small amount of utility information from the distributed computing elements. Since regret-computation is intensive, we compare these to the more tractable Nelder-Mead optimization technique w.r.t. amount of utility information required.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-023.pdf,Subjects: 15.5 Decision Theory; 7.1 Multi-Agent Systems
29,2005,Agents / Multiagent Systems,An Ecological Approach to Agent Population Management,"Maxim D. Peysakhov, Robert N. Lass, William C. Regli, Moshe Kam","The problem of maintaining a desired number of mobile agents on a network is not trivial, especially if what is required is a completely decentralized solution. Decentralized control makes a system more robust and less susceptible to partial failures. The problem of agent population management is exacerbated on wireless ad hoc networks where host mobility can result in significant changes in the network size and topology. System stability is also of critical importance. This paper analyzes the stability of a previously proposed ecology-inspired approach to agent population management, and proposes improvements. The stability of the new ecology based strategy is proved theoretically, and the clusions are verified with a set of experiments.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-024.pdf,Subjects: 7.1 Multi-Agent Systems
30,2005,Agents / Multiagent Systems,Distributing Coalitional Value Calculations among Cooperative Agents,"Talal Rahwan, Nicholas R. Jennings","The process of forming coalitions of software agents generally requires calculating a value for every possible coalition which indicates how beneficial that coalition would be if it was formed. Now, since the number of possible coalitions increases exponentially with the number of agents involved, having one agent calculate all the values is inefficient. Given this, we present a novel algorithm for distributing this calculation among agents in cooperative environments. Specifically, by using our algorithm, each agent is assigned some part of the calculation such that the agents’ shares are exhaustive and disjoint. Moreover, the algorithm is decentralized, requires no communication between the agents, and has minimal memory requirements. To evaluate the effectiveness of our algorithm we compare it with the only other algorithm available in the literature (due to Shehory and Kraus). This shows that for the case of 25 agents, the distribution process of our algorithm took 0.00037% of the time, the values were calculated using 0.000006% of the memory, the calculation redundancy was reduced from 477826101 to 0, and the total number of bytes sent between the agents dropped from 674047872 to 0 (note that for larger numbers of agents, these improvements become exponentially better).",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-025.pdf,Subjects: 7. Distributed AI; 7.1 Multi-Agent Systems
31,2005,Agents / Multiagent Systems,Cooperative Exploration in the Electronic Marketplace,"David Sarne, Sarit Kraus","In this paper we study search strategies of agents that represent buyer agents’ coalitions in electronic marketplaces. The representative agents operate in environments where numerous potential complex opportunities can be found. Each opportunity is associated with several different terms and conditions thus differing from other opportunities by its value for the coalition. Given a search cost, the goal of the representative agent is to find the best set of opportunities which fulfills the coalition’s demands with the maximum overall utility, to be divided among the coalition members. Given the option of side-payments, this strategy will always be preferred by all coalition members (thus no conflict of interests), regardless of the coalition’s payoff division protocol. We analyze the incentive to form such coalitions and extract the optimal search strategy for their representative agents, with a distinction between operating in B2C and C2C markets. Based on our findings we suggest efficient algorithms to be used by the representative agents for calculating their strategy and the appropriate derived expected utilities. A computational-based example is given, illustrating the achieved performance as a function of the heterogeneity level of the coalition’s members.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-026.pdf,Subjects: 7.1 Multi-Agent Systems
32,2005,Agents / Multiagent Systems,Solving the Auction-Based Task Allocation Problem in an Open Environment,"David Sarne, Sarit Kraus","In this paper we analyze the process of allocating tasks to self-interested agents in uncertain changing open environments. The allocator in our model is responsible for the performance of dynamically arriving tasks using a second price reverse auction as the allocation protocol. Since the agents are self-interested (i.e. each agent attempts to maximize its own revenue), previous models concerning cooperative agents aiming for a joint goal are not applicable. Thus the main challenge is to identify a set of equilibrium strategies - a stable solution where no agent can benefit from changing its strategy given the other agents’ strategies - for any specific environmental settings. We formulate the model and discuss the difficulty in extracting the agents’ equilibrium strategies directly from the model’s equations. Consequently we propose an efficient algorithm to accurately approximate the agents’ equilibrium strategies. A comparative illustration through simulation of the system performance in a closed and open environments is given, emphasizing the advantage of the allocator operating in the latter environment, reaching results close to those obtained by a central enforceable allocation.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-027.pdf,Subjects: 7.1 Multi-Agent Systems
33,2005,Agents / Multiagent Systems,Profit Sharing Auction,"Sandip Sen, Teddy Candale, Susnata Basak","Auctions are a class of multi-party negotiation protocols. Classical auctions try to maximize social welfare by selecting the highest bidder as the winner. If bidders are rational, this ensures that the sum of profits for all bidders and the seller is maximized. In all such auctions, however, only the winner and the seller make any profit. We believe that ``social welfare distribution"" is a desired goal of any multi-party protocol. In the context of auctions, this goal translates into a rather radical proposal of profit sharing between all bidders and the seller. We propose a Profit Sharing Auction (PSA) where a part of the selling price paid by the winner is paid back to the bidders. The obvious criticism of this mechanism is the incentive for the seller to share its profit with non-winning bidders. We claim that this loss can be compensated by attracting more bidders to such an auction, resulting in an associated increase in selling price. We run several sets of experiments where equivalent items are concurrently sold at a First Price Sealed Bid, a Vickrey, and a PSA auction. A population of learning bidders repeatedly choose to go to one of these auctions based on their valuation for the good being auctioned and their learned estimates of profits from these auctions. Results show that sellers make more or equivalent profits by using PSA as compared to the classical auctions. Additionally, PSA always attracts more bidders, which might create auxiliary revenue streams, and a desirable lower variability in selling prices. Interestingly then, a rational seller has the incentive to share profits and offer an auction like PSA which maximizes and distributes social welfare.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-028.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
34,2005,Agents / Multiagent Systems,OAR: A Formal Framework for Multi-Agent Negotiation,"Jiaying Shen, Ingo Weber, Victor Lesser","In Multi-Agent systems, agents often need to make decisions about how to interact with each other when negotiating over task allocation. In this paper, we present OAR, a formal framework to address the question of how the agents should interact in an evolving environment in order to achieve their different goals. The traditional categorization of self-interested and cooperative agents is unified by adopting a utility view. We illustrate mathematically that the degree of cooperativeness of an agent and the degree of its self-directness are not directly related. We also show how OAR can be used to evaluate different negotiation strategies and to develop distributed mechanisms that optimize the performance dynamically. This research demonstrates that sophisticated probabilistic modeling can be used to understand the behaviors of a system with complex agent interactions.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-029.pdf,Subjects: 7.1 Multi-Agent Systems; 15.3 Control
35,2005,Agents / Multiagent Systems,Tool Use for Autonomous Agents,"Robert St. Amant, Alexander B. Wood","The intelligent use of tools is a general and important human competence that AI research has not yet examined in depth. Other fields have studied the topic, however, with results we can compile into a broad characterization of habile (tool-using) agents. In this paper we give an overview of research on the use of physical tools, using this information to motivate the development of artificial habile agents. Specifically, we describe how research goals and methods in animal cognition overlap with those in artificial intelligence. We argue that analysis of activities of tool-using agents offers an informative way to evaluate intelligence.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-030.pdf,Subjects: 9.4 Philosophical Foundations; 17. Robotics
36,2005,Agents / Multiagent Systems,Observation-Based Model for BDI-Agents,"Kaile Su, Abdul Sattar, Kewen Wang, Xiangyu Luo, Guido Governatori Vineet Padmanabhan$","We present a new computational model of BDI-agents, called the observation-based BDI-model. The key point of this BDI-model is to express agents’ beliefs, desires and intentions as a set of runs(computing paths), which is exactly a system in the interpreted system model, a well-known agent model due to Halpern and his colleagues. Our BDI-model is computationally grounded in that we are able to associate the BDI-agent model with a computer program, and formulas, involving agents’ beliefs, desires (goals) and intentions, can be understood as properties of program computations. We present a sound and complete proof system with respect to our BDI-model and explore how symbolic model checking techniques can be applied to model checking BDI-agents. In order to make our BDI-model more flexible and practically realistic, we generalize it so that agents can have multiple sources of beliefs, goals and intentions.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-031.pdf,Subjects: 7.1 Multi-Agent Systems; 1.6.1 Automated Device Modeling
37,2005,Agents / Multiagent Systems,Stable Service Placement on Dynamic Peer-to-Peer Networks: A Heuristic for the Distributed k-Center Problem,"Evan A. Sultanik, William C. Regli","The proliferation of wireless networks has underscored the need for systems capable of coping with sporadic network connectivity. The restriction of communication to neighboring hosts makes determining the global state especially difficult, if not impractical. This paper addresses the problem of coordinating the positions of an arbitrary number of services, encapsulated by mobile agents, in a dynamic peer-to-peer network. The agents’ collective goal is to minimize the distance between hosts and services, even if the topology is changing constantly. We propose a distributed algorithm to efficiently calculate the stationary distribution of the network. This can be used as a hill climbing heuristic for agents to find near-optimal locations at which to provide services. Finally, we show that the agent-based hill climbing approach is temporally-stable relative to the instantaneous optimum.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-032.pdf,Subjects: 7. Distributed AI; 7.1 Multi-Agent Systems
38,2005,Analogical and Case-Based Reasoning,Analogical Learning of VIsual/Conceptual Relationships in Sketches,"Kenneth D. Forbus, Jeffrey Usher, Emmett Tomai",This paper explores the use of analogy to learn about properties of sketches. Sketches often convey conceptual relationships between entities via the visual relationships between their depictions in the sketch. Understanding these conventions is an important part of adapting to a user. This paper describes how learning by accumulating examples can be used to make suggestions about such relationships in new sketches. We describe how sketches are being used in Companion Cognitive Systems to illustrate one context in which this problem arises. We describe how existing cognitive simulations of analogical matching and retrieval are used to generate suggestions for new sketches based on analogies with prior sketches. Two experiments provide evidence as to the accuracy and coverage of this technique.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-033.pdf,Subjects: 12. Machine Learning and Discovery; 4. Cognitive Modeling
39,2005,Analogical and Case-Based Reasoning,Solving Everyday Physical Reasoning Problems by Analogy Using Sketches,"Matthew Klenk, Ken Forbus, Emmett Tomai, Hyeonkyeong Kim, and Brian Kyckelhahn","Understanding common sense reasoning about the physical world is one of the goals of qualitative reasoning research. This paper describes how we combine qualitative mechanics and analogy to solve everyday physical reasoning problems posed as sketches. The problems are drawn from the Bennett Mechanical Comprehension Test, which is used to evaluate technician candidates. We discuss sketch annotations, which define conceptual quantities in terms of visual measurements, how modeling decisions are made by analogy, and how analogy can be used to frame comparative analysis problems. Experimental results support the plausibility of this approach.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-034.pdf,Subjects: 3.5 Qualitative Reasoning; 5. Common Sense Reasoning
40,2005,Analogical and Case-Based Reasoning,Complexity-Guided Case Discovery for Case Based Reasoning,"Stewart Massie, Susan Craw, Nirmalie Wiratunga",The distribution of cases in the case base is critical to the performance of a Case Based Reasoning system. The case author is given little support in the positioning of new cases during the development stage of a case base. In this paper we argue that classification boundaries represent important regions of the problem space. They are used to identify locations where new cases should be acquired. We introduce two complexity-guided algorithms which use a local complexity measure and boundary identification techniques to actively discover cases close to boundaries. The ability of these algorithms to discover new cases that significantly improve the accuracy of case bases is demonstrated on five public domain classification datasets.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-035.pdf,Subjects: 3.1 Case-Based Reasoning; 10. Knowledge Acquisition
41,2005,Analogical and Case-Based Reasoning,Interactive Knowledge Validation and Query Refinement in CBR,"Monica H Ou, Geoff A W West, Mihai Lazarescu, Chris Clay","In most case-based reasoning (CBR) systems there has been little research done on validating new knowledge, specifically on how previous knowledge differs from current knowledge as a result of conceptual change. This paper proposes two methods that enable the domain expert, who is non-expert in artificial intelligence (AI), to interactively supervise the knowledge validation process in a CBR system, and to enable dynamic updating of the system, to provide the best diagnostic questions. The first method is based on formal concept analysis which involves a graphical representation and comparison of the concepts, and a summary description highlighting the conceptual differences. We propose a dissimilarity metric for measuring the degree of variation between the previous and current concepts when a new case is added to the knowledge base. The second method involves determining unexpected classification-based association rules to form critical questions as the knowledge base gets updated.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-036.pdf,Subjects: 3.1 Case-Based Reasoning; 1.7 Expert Systems
42,2005,Analogical and Case-Based Reasoning,Competence Driven Case-Base Mining,"Rong Pan, Qiang Yang, Junfeng Pan, Lei Li","We present a novel algorithm for extracting a high-quality case base from raw data while preserving and sometimes improving the competence of case-based reasoning. We extend the framework of Smyth and Keane’s case-deletion policy with two additional features. First, we build a case base using a statistical distribution that is mined from the input data so that the case-base competence can be preserved or even increased for future problems. Second, we introduce a nonlinear transformation of the data set so that the case-base sizes can be further reduced while ensuring that the competence be preserved and even increased. We show that Smyth and Keane’s deletion-based algorithm is sensitive to noisy cases, and that our solution solves this problem more satisfactorily. We show the theoretical foundation and empirical evaluation on several data sets.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-037.pdf,Subjects: 3.1 Case-Based Reasoning; 11. Knowledge Representation
43,2005,Analogical and Case-Based Reasoning,A Domain-Independent System for Case-Based Task Decomposition without Domain Theories,"Ke Xu, Hector Munoz-Avila","We propose using domain-independent task decomposition techniques for situations in which cases are the sole or the main source for domain knowledge. Our work is motivated by project planning domains, where hierarchical cases are readily available, but neither a planning domain theory nor case adaptation knowledge is available. We present DInCaD (Domain-Independent System for Case-Based Task Decomposition), a system that encompasses case retrieval, refinement, and reuse, following from the idea of reusing generalized cases to solve new problems. DInCaD consists of a case refinement procedure that reduces case over-generalization, and a similarity criterion that takes advantage of the refinement to improve case retrieval precision. We will analyze the properties of the system, and present an empirical evaluation.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-038.pdf,Subjects: 3.1 Case-Based Reasoning; 1.11 Planning
44,2005,Auctions and Market-Based Systems,Mechanism Design for Single-Value Domains,"Moshe Babaioff, Ron Lavi: Elan Pavlov","n ``Single-Value domains'', each agent has the same private value for all desired outcomes. We formalize this notion and give new examples for such domains, including a ``SAT domain'' and a ``single-value combinatorial auctions'' domain. We study two informational models: where the set of desired outcomes is public information (the ``known'' case), and where it is private information (the ``unknown'' case). Under the ``known'' assumption, we present several truthful approximation mechanisms. Additionally, we suggest a general technique to convert any bitonic approximation algorithm for an unweighted domain (where agent values are either zero or one) to a truthful mechanism, with only a small approximation loss. In contrast, we show that even positive results from the ``unknown single minded combinatorial auctions'' literature fail to extend to the ``unknown'' single-value case. We give a characterization of truthfulnessin this case, demonstrating that the difference is subtle and surprising.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-039.pdf,Subjects: 7.1 Multi-Agent Systems
45,2005,Auctions and Market-Based Systems,Combinatorial Auctions with k-wise Dependent Valuations,"Vincent Conitzer, Tuomas Sandholm, Paolo Santi","We analyze the computational and communication complexity of combinatorial auctions from a new perspective: the degree of interdependency between the items for sale in the bidders’ preferences. Denoting by Gk the class of valuations displaying up to k-wise dependencies, we consider the hierarchy G1 < G2 < ... < Gm, where m is the number of items for sale. We show that the minimum non-trivial degree of interdependency (2-wise dependency) is sufficient to render NP-hard the problem of computing the optimal allocation (but we also exhibit a restricted class of such valuations for which computing the optimal allocation is easy). On the other hand, bidders’ preferences can be communicated efficiently (i.e., exchanging a polynomial amount of information) as long as the interdependencies between items are limited to sets of cardinality up to k, where k is an arbitrary constant. The amount of communication required to transmit the bidders’ preferences becomes super-polynomial (under the assumption that only value queries are allowed) when interdependencies occur between sets of cardinality g(m), where g(m) is an arbitrary function such that g(m) goes to infinity as m goes to infinity. We also consider approximate elicitation, in which the auctioneer learns, asking polynomially many value queries, an approximation of the bidders’ actual preferences.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-040.pdf,Subjects: 7.1 Multi-Agent Systems
46,2005,Auctions and Market-Based Systems,Expressive Negotiation in Settings with Externalities,"Vincent Conitzer, Tuomas Sandholm","In recent years, certain formalizations of combinatorial negotiation settings, most notably combinatorial auctions, have become an important research topic in the AI community. A pervasive assumption has been that of no externalities: the agents deciding on a variable (such as whether a trade takes place between them) are the only ones affected by how this variable is set. To date, there has been no widely studied formalization of combinatorial negotiation settings with externalities. In this paper, we introduce such a formalization. We show that in a number of key special cases, it is NP-complete to find a feasible nontrivial solution (and therefore the maximum social welfare is completely inapproximable). However, for one important special case, we give an algorithm which converges to the solution with the maximal concession by each agent (in a linear number of rounds for utility functions that decompose into piecewise constant functions). Maximizing social welfare, however, remains NP-complete even in this setting. We also demonstrate a special case which can be solved in polynomial time by linear programming.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-041.pdf,Subjects: 7.1 Multi-Agent Systems
47,2005,Auctions and Market-Based Systems,A New Strategy-Proof Greedy-Allocation Combinatorial Auction Protocol and its Extension to Open Ascending Auction Protocol,"Takayuki Ito, Makoto Yokoo, Shigeo Matsubara, Atsushi Iwasaki","This paper proposes a new combinatorial auction protocol called Average-Max-Minimal-Bundle (AM-MB) protocol. The characteristics of the AM-MB protocol are as follows: (i) it is strategyproof, i.e., truth-telling is a dominant strategy, (ii) the computational overhead is very low, since it allocates bundles greedily thereby avoiding an explicit combinatorial optimization problem, and (iii) it can obtain higher social surplus and revenue than can the Max-Minimal-Bundle (M-MB) protocol, which also satisfies (i) and (ii). Furthermore, this paper extends the AM-MB protocol to an open ascending-price protocol in which straightforward bidding is an ex-post Nash equilibrium.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-042.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
48,2005,Auctions and Market-Based Systems,Approximating Revenue-Maximizing Combinatorial Auctions,"Anton Likhodedov, Tuomas Sandholm","Designing revenue-maximizing combinatorial auctions (CAs) is a recognized open problem in mechanism design. It is unsolved even for two bidders and two items for sale. Rather than attempting to characterize the optimal auction, we focus on designing approximations (suboptimal auction mechanisms which yield high revenue). Our approximations belong to the family of virtual valuations combinatorial auctions (VVCA). VVCA is a Vickrey-Clarke-Groves (VCG) mechanism run on virtual valuations that are linear transformations of the bidders’ real valuations. We pursue two approaches to constructing approximately optimal CAs. The first is to construct a VVCA with worst-case and average-case performance guarantees. We give a logarithmic approximation auction for basic important special cases of the problem: 1) limited supply of items on sale with additive valuations and 2) unlimited supply. The second approach is to search the parameter space of VVCAs in order to obtain high-revenue mechanisms for the general problem. We introduce a series of increasingly sophisticated algorithms that use economic insights to guide the search and thus reduce the computational complexity. Our experiments demonstrate that in many cases these algorithms perform almost as well as the optimal VVCA, yield a substantial increase in revenue over the VCG mechanism and drastically outperform the straightforward algorithms in run-time.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-043.pdf,Subjects: 7.1 Multi-Agent Systems; 1. Applications
49,2005,Automated Reasoning,The Achilles’ Heel of QBF,"Carlos Ansotegui, Carla P. Gomes, Bart Selman","In recent years we have seen significant progress in the area of Boolean satisfiability (SAT) solving and its applications. As a new challenge, the community is now moving to investigate whether similar advances can be made in the use of Quantified Boolean Formulas (QBF). QBF provides a natural framework for capturing problem solving and planning in multi-agent settings. However, contrarily to single-agent planning, which can be effectively formulated as SAT, we show that a QBF approach to planning in a multi-agent setting leads to significant unexpected computational difficulties. We identify as a key difficulty of the QBF approach the fact that QBF solvers often end up exploring a much larger search space than the natural search space of the original problem. This is in contrast to the experience with SAT approaches. We also show how one can alleviate these problems by introducing two special QBF formulations and a new QBF solution strategy. We present experiments that show the effectiveness of our approach in terms of a significant improvement in performance compared to earlier work in this area. Our work also provides a general methodology for formulating adversarial scenarios in QBF.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-044.pdf,Subjects: 3. Automated Reasoning
50,2005,Automated Reasoning,Combining Stochastic and Greedy Search in Hybrid Estimation,"Lars J Blackmore, Stanislav Funiak, Brian Williams","Techniques for robot monitoring and diagnosis have been developed that perform state estimation using probabilistic hybrid discrete/continuous models. Exact inference in hybrid dynamic systems is, in general, intractable. Approximate algorithms are based on either 1) greedy search, as in the case of k-best enumeration or 2) stochastic search, as in the case of Rao-Blackwellised Particle Filtering (RBPF). In this paper we propose a new method for hybrid state estimation. The key insight is that stochastic and greedy search methods, taken together, are often particularly effective in practice. The new method combines the stochastic methods of RBPF with the greedy search of k-best in order to create a method that is effective for a wider range of estimation problems than the individual methods alone. We demonstrate this robustness on a simulated acrobatic robot, and show that this benefit comes at only a small performance penalty.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-045.pdf,Subjects: 1.5 Diagnosis; 3.4 Probabilistic Reasoning
51,2005,Automated Reasoning,Propositional Fragments for Knowledge Compilation and Quantified Boolean Formulae,"Sylvie Coste-Marquis, Daniel Le Berre, Florian Letombe, Pierre Marquis","Several propositional fragments have been considered so far as target languages for knowledge compilation and used for improving computational tasks from major AI areas (like inference, diagnosis and planning); among them are the (quite influential) ordered binary decision diagrams, prime implicates, prime implicants, ``formulae'' in decomposable negation normal form. On the other hand, the validity problem QBF for Quantified Boolean Formulae (QBF) has been acknowledged for the past few years as an important issue for AI, and many solvers have been designed for this purpose. In this paper, the complexity of restrictions of {\sc qbf} obtained by imposing the matrix of the input QBF to belong to such propositional fragments is identified. Both tractability and intractability results (PSPACE-completeness) are obtained.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-046.pdf,Subjects: 3. Automated Reasoning
52,2005,Automated Reasoning,Axiom Schemata as Metalevel Axioms: Model Theory,"Timothy L. Hinrichs, Michael R. Genesereth",Logicians frequently use axiom schemata to encode (potentially infinite) sets of sentences with particular syntactic form. In this paper we examine a first-order language in which it is possible to write expressions that both describe sentences and assert the truth of the sentences so described. The effect of adding such expressions to a knowledge base is the same as directly including the set of described sentences.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-047.pdf,Subjects: 3. Automated Reasoning; 11. Knowledge Representation
53,2005,Automated Reasoning,On Compiling System Models for Faster and More Scalable Diagnosis,"Jinbo Huang, Adnan Darwiche","Knowledge compilation is one of the more traditional approaches to model-based diagnosis, where a compiled system model is obtained in an off-line phase, and then used to efficiently answer diagnostic queries on-line. The choice of a suitable representation for the compiled model is critical to the success of this approach, and two of the main proposals have been Decomposable Negation Normal Form (DNNF) and Ordered Binary Decision Diagram (OBDD). The contribution of this paper is twofold. First, we show that in the current state of the art, DNNF dominates OBDD in efficiency and scalability for some typical diagnostic tasks. This result is based on a step-by-step comparison of the complexities of diagnostic algorithms for DNNF and OBDD, together with a known succinctness relation between the two representations. Second, we present a tool for model-based diagnosis, which is based on a state-of-the-art DNNF compiler and our implementations of DNNF diagnostic algorithms. We demonstrate the efficiency of this tool against recent results reported on diagnosis using OBDD.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-048.pdf,Subjects: 1. Applications; 1.5 Diagnosis
54,2005,Automated Reasoning,A Discourse Planning Approach to Virtual Cinematography for Narratives,"Arnav Jhala, R Michael Young","As the complexity of narrative-based virtual environments grows, the need for effective communication of information to the users of these systems increase. Effective camera control for narrative-oriented virtual worlds involves decision making at three different levels: choosing cinematic geometric composition, choosing the best camera parameters for conveying affective information, and choosing camera shots and transitions to maintain rhetorical coherence. We propose a camera planning system that mirrors the film production pipeline; we describe our formalization of film idioms used to communicate affective information. Our representation of idioms captures their hierarchical nature, represents the causal motivation for selection of shots, and provides a way for the system designer to specify the ranking of candidate shot sequences.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-049.pdf,Subjects: 6.4 Virtual Reality; 13.1 Discourse
55,2005,Automated Reasoning,Dependency-Directed Reconsideration: Belief Base Optimization for Truth Maintenance Systems,"Frances L. Johnson, Stuart C. Shapiro","We define reconsideration, a non-prioritized belief change operation on a finite set of base beliefs. Reconsideration is a hindsight belief change repair that eliminates negative effects caused by the order of previously executed belief change operations. Beliefs that had previously been removed are returned to the base if there no longer are valid reasons for their removal. This might result in less preferred beliefs being removed, and additional beliefs being returned. The end product is an optimization of the belief base, converting the results of a series of revisions to the very base that would have resulted from a batch revision performed after all base beliefs were entered/added. Reconsideration can be done by examining the entire set of all base beliefs (both currently believed and retracted) --- or, if the believed base is consistent, by examining all retracted beliefs for possible return. This, however, is computationally expensive. We present a more efficient, TMS-friendly algorithm, dependency-directed reconsideration (DDR), which can produce the same results by examining only a dynamically determined subset of base beliefs that are actually affected by changes made since the last base optimization process. DDR is an efficient, anytime, belief base optimizing algorithm that eliminates operation order effects.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-050.pdf,Subjects: 15.1 Belief Revision; 3.3 Nonmonotonic Reasoning
56,2005,Automated Reasoning,Diagnosis as Approximate Belief State Enumeration for Probabilistic Concurrent Constraint Automata,"Oliver B. Martin, Michel D. Ingham, Brian C. Williams","As autonomous spacecraft and other robotic systems grow increasingly complex, there is a pressing need for capabilities that more accurately monitor and diagnose system state while maintaining reactivity. Mode estimation addresses this problem by reasoning over declarative models of the physical plant, represented as a factored variant of Hidden Markov Models (HMMs), called Probabilistic Concurrent Constraint Automata (PCCA). Previous mode estimation approaches track a set of most likely PCCA state trajectories, enumerating them in order of trajectory probability. Although Best-First Trajectory Enumeration (BFTE) is efficient, ignoring the additional trajectories that lead to the same state can significantly underestimate the true state probability and result in misdiagnosis. This paper introduces an innovative belief approximation technique, called Best-First Belief State Enumeration (BFBSE), that addresses this limitation by computing estimate probabilities directly from the HMM belief state update equations. Theoretical and empirical results show that BFBSE significantly increases estimator accuracy, uses less memory, and requires less computation time when enumerating a moderate number of estimates for the approximate belief state of subsystem sized models.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-051.pdf,Subjects: 1.5 Diagnosis; 3.4 Probabilistic Reasoning
57,2005,Automated Reasoning,Model-Based Monitoring and Diagnosis of Systems with Software-Extended Behavior,"Tsoline Mikaelian, Brian C. Williams, Martin Sachenbacher","Model-based diagnosis has largely operated on hardware systems. However, in most complex systems today, hardware is augmented with software functions that influence the system’s behavior. In this paper, hardware models are extended to include the behavior of associated embedded software, resulting in more comprehensive diagnoses. Prior work introduced probabilistic, hierarchical, constraint-based automata (PHCA) to allow the uniform and compact encoding of both hardware and software behavior. This paper focuses on PHCA-based monitoring and diagnosis to ensure the robustness of complex systems. We introduce a novel approach that frames diagnosis over a finite time horizon as a soft constraint optimization problem (COP), allowing us to leverage an extensive body of efficient solution methods for COPs. The solutions to the COP correspond to the most likely evolutions of the complex system. We demonstrate our approach on a vision-based rover navigation system, and models of the SPHERES and Earth Observing One spacecraft.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-052.pdf,Subjects: 1.5 Diagnosis; 3.4 Probabilistic Reasoning
58,2005,Automated Reasoning,Recommender Systems: Attack Types and Strategies,"Michael P. O'Mahony, Neil J. Hurley, Guenole C. M. Silvestre","In the research to date, the performance of recommender systems has been extensively evaluated across various dimensions. Increasingly, the issue of robustness against malicious attack is receiving attention from the research community. In previous work, we have shown that knowledge of certain domain statistics is sufficient to allow successful attacks to be mounted against recommender systems. In this paper, we examine the extent of domain knowledge that is actually required and find that, even when little such knowledge is known, it remains possible to mount successful attacks.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-053.pdf,Subjects: 3. Automated Reasoning; 1.10 Information Retrieval
59,2005,Automated Reasoning,Compact Propositional Encoding of First-Order Theories,"Deepak Ramachandran, Eyal Amir","In this paper we present polynomial-time algorithms that translate First-Order Logic (FOL) theories to smaller propositional encodings than achievable before in polynomial time. For example, we can sometimes reduce the number of propositions to $O(|P|+|C|)$, or $O(|P|^k\cdot \log |P|)$, for $|P|$ predicates of arity $k$ and $|C|$ constant symbols. The guarantee depends on availability of some graphical structure in the FOL representation. Our algorithms accept all FOL theories, and preserve soundness and completeness (sometimes requiring the Domain Closure Assumption). Our experiments show significant speedup in inference with a SAT solver on real-world problems. Our results address a common approach that translates inference and decision problems that originate in FOL into propositional logic, later applying efficient SAT solvers. Standard translation techniques result in very large propositional encodings ($O(|P||C|^k)$ for predicates of arity $k$) that are often infeasible to solve. This approach scales up inference for many objects, and has potential applications in planning, probabilistic reasoning and formal verification.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-054.pdf,Subjects: 3. Automated Reasoning; 3. Automated Reasoning
60,2005,Automated Reasoning,Identifying Direct Causal Effects in Linear Models,Jin Tian,"This paper deals with the problem of identifying direct causal effects in recursive linear structural equation models. Using techniques developed for graphical causal models, we show that a model can be decomposed into a set of submodels such that the identification problem can be solved independently in each submodel. We provide a new identification method that identifies causal effects by solving a set of algebraic equations.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-055.pdf,Subjects: 3.4 Probabilistic Reasoning; 9.1 Causality
61,2005,Constraint Satisfaction and Satisfiability,Old Resolution Meets Modern SLS,"A. Anbulagan, Duc Nghia Pham, John Slaney, Abdul Sattar","Recent work on Stochastic Local Search (SLS) for the SAT and CSP domains has shown the importance of a dynamic (non-markovian) strategy for weighting clauses in order to escape from local minima. In this paper, we improve the performance of two best contemprorary clause weighting solvers, PAWS and SAPS, by integrating a propositional resolution procedure. We also extend the work to AdaptNovelty+, the best non-weighting SLS solver in the GSAT/WalkSAT series. One outcome is that our systems can solve some highly structured problems such as quasigroup existence and parity learning problems which were previously thought unsuitable for local search and which are completely out of reach of traditional solvers such as GSAT. Here we present empirical results showing that for a range of random and real-world benchmark problems, resolution-enhanced SLS solvers clearly outperform the alternatives.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-056.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
62,2005,Constraint Satisfaction and Satisfiability,CSP Properties for Quantified Constraints: Definitions and Complexity,"Lucas Bordeaux, Marco Cadoli, Toni Mancini","Quantified constraints and Quantified Boolean Formulae are typically much more difficult to reason with than classical constraints, because quantifier alternation makes the simple, classical notion of solution inappropriate. As a consequence, even such essential CSP properties as consistency or substitutability are not completely understood in the quantified case. In this paper, we show that most of the properties which are used by solvers for CSP can be generalized to Quantified CSP. We propose a systematic study of the relations which hold between these properties, as well as complexity results regarding the decision of these properties. Finally, and since these problems are typically intractable, we generalise the approach used in CSP and propose weakenings of these notions based on locality, which allow for a tractable, albeit incomplete detecting of these properties.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-057.pdf,Subjects: 15.2 Constraint Satisfaction; 9.2 Computational Complexity
63,2005,Constraint Satisfaction and Satisfiability,Constrained Decision Diagrams,"Kenil C.K. Cheng, Roland H.C. Yap","A general n-ary constraint is usually represented explicitly as a set of its solution tuples, which may need exponential space. In this paper, we introduce a new representation for general n-ary constraints called Constrained Decision Diagram (CDD). CDD generalizes BDD-style representations and the main feature is that it combines constraint reasoning/consistency techniques with a compact data structure. We present an application of CDD for recording all solutions of a conjunction of constraints. Instead of an explicit representation, we can implicitly encode the solutions by means of constraint propagation. Our experiments confirm the scalability and demonstrate that CDDs can drastically reduce the space needed over explicit and ZBDD representations.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-058.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
64,2005,Constraint Satisfaction and Satisfiability,Finding Diverse and Similar Solutions in Constraint Programming,"Emmanuel Hebrard, Brahim Hnich, Barry O'Sullivan, Toby Walsh","It is useful in a wide range of situations to find solutions which are diverse (or similar) to each other. We therefore define a number of different classes of diversity and similarity problems. For example, what is the most diverse set of solutions of a constraint satisfaction problem with a given cardinality? We first determine the computational complexity of these problems. We then propose a number of practical solution methods, some of which use global constraints for enforcing diversity (or similarity) between solutions. Empirical evaluation on a number of problems show promising results.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-059.pdf,Subjects: 15.2 Constraint Satisfaction; 9.2 Computational Complexity
65,2005,Constraint Satisfaction and Satisfiability,Weighted Super Solutions for Constraint Programs,"Alan Holland, Barry O'Sullivan","Super solutions to constraint programs guarantee that if a limited number of variables lose their values, repair solutions can be found by modifying a bounded number of assignments. However, in many application domains the classical super solutions framework is not expressive enough since it only reasons about the number of breaks in a solution and the number of changes that are necessary to find a repair. For example, in combinatorial auctions we may wish to guarantee that we can always find a repair solution whose revenue exceeds some threshold while limiting the cost associated with forming such a repair. In this paper we present the weighted super solution framework that involves two important extensions. Firstly, the set of variables that may lose their values is determined using a probabilistic approach enabling us to find repair solutions for assignments that are most likely to fail. Secondly, we include a mechanism for reasoning about the cost of repair. The proposed framework has been successfully used to find robust solutions to combinatorial auctions.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-060.pdf,Subjects: 15.2 Constraint Satisfaction
66,2005,Constraint Satisfaction and Satisfiability,Generating Hard Satisfiable Formulas by Hiding Solutions Deceptively,"Haixia Jia, Cristopher Moore, Doug Strain.","To test incomplete search algorithms for constraint satisfaction problems such as 3-SAT, we need a source of hard, but satisfiable, benchmark instances. A simple way to do this is to choose a random truth assignment A, and then choose clauses randomly from among those satisfied by A. However, this method tends to produce easy problems, since the majority of literals point toward the ""hidden"" assignment A. Last year, Achlioptas, Jia and Moore proposed a problem generator that cancels this effect by hiding both A and its complement. While the resulting formulas appear to be just as hard for DPLL algorithms as random 3-SAT formulas with no hidden assignment, they can be solved by WalkSAT in only polynomial time. Here we propose a new method to cancel the attraction to A, by choosing a clause with t > 0 literals satisfied by A with probability proportional to q^t for some q < 1. By varying q, we can generate formulas whose variables have no bias, i.e., which are equally likely to be true or false; we can even cause the formula to ""deceptively"" point away from A. We present theoretical and experimental results suggesting that these formulas are exponentially hard both for DPLL algorithms and for incomplete algorithms such as WalkSAT.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-061.pdf,Subjects: 15.2 Constraint Satisfaction; 9.2 Computational Complexity
67,2005,Constraint Satisfaction and Satisfiability,Generalized NoGoods in CSPs,"George Katsirelos, Fahiem Bacchus","Although nogood learning in CSPs and clause learning in SAT are formally equivalent, nogood learning has not been as successful a technique in CSP solvers as clause learning has been for SAT solvers. We show that part of the reason for this discrepancy is that nogoods in CSPs (as standardly defined) are too restrictive. In this paper we demonstrate that these restrictions can be lifted so that a CSP solver can learn more general and powerful nogoods. Nogoods generalized in this manner yield a provably more powerful CSP solver. We also demonstrate how generalized nogoods facilitate learning useful nogoods from global constraints. Finally, we demonstrate empirically that generalized nogoods can yield significant improvements in performance.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-062.pdf,Subjects: 15.2 Constraint Satisfaction
68,2005,Constraint Satisfaction and Satisfiability,Neighborhood Interchangeability and Dynamic Bundling for Non-Binary Finite CSPs,"Anagh Lal, Berthe Y. Choueiry, Eugene C. Freuder","Neighborhood Interchangeability (NI) identifies the equivalent values in the domain of a variable of a Constraint Satisfaction Problem (CSP) by considering only the constraints that directly apply to the variable. Freuder described an algorithm for efficiently computing NI values in binary CSPs. In this paper, we show that the generalization of this algorithm to non-binary CSPs is not straightforward, and introduce an efficient algorithm for computing NI values in the presence of non-binary constraints. Further, we show how to interleave this mechanism with search for solving CSPs, thus yielding a dynamic bundling strategy. While the goal of dynamic bundling is to produce multiple robust solutions, we empirically show that it does not increase (but significantly decreases) the cost of search.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-063.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
69,2005,Constraint Satisfaction and Satisfiability,A Fast Arc Consistency Algorithm for n-ary Constraints,"Olivier Lhomme, Jean-Charles Regin","The GAC-Scheme has become a popular general purpose algorithm for solving n-ary constraints, although it may scan an exponential number of supporting tuples. In this paper, we develop a major improvement of this scheme. When searching for a support, our new algorithm is able to skip over a number of tuples exponential in the arity of the constraint by exploiting knowledge about the current domains of the variables. We demonstrate the effectiveness of the method for large table constraints.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-065.pdf,Subjects: 15.2 Constraint Satisfaction
70,2005,Constraint Satisfaction and Satisfiability,Quick Shaving,Olivier Lhomme,"Arc-consistency plays such a key role in constraint programming for solving real life problems that it is almost the only algorithm used for reducing domains. There are a few specific problems for which a stronger form of propagation, often called shaving, is more efficient. Nevertheless, in many cases, shaving at each node of the search tree is not worth doing: arc-consistency filtering is much faster, and the additional domain reductions inferred by shaving do not pay off. In this paper, we propose a new kind of shaving called QuickShaving, which is guided by the search. As QuickShaving may infer some additional domain reductions compared with arc-consistency, it can improve the search for a solution by an exponential ratio. Moreover, the advantage of QuickShaving is that in practice, unlike a standard form of shaving, the additional domain reductions deduced by QuickShaving come at a very low overhead compared with arc-consistency.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-064.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
71,2005,Constraint Satisfaction and Satisfiability,DC-SSAT: A Divide-and-Conquer Approach to Solving Stochastic Satisfiability Problems Efficiently,"Stephen M. Majercik, Byron Boots","We present DC-SSAT, a sound and complete divide-and-conquer algorithm for solving stochastic satisfiability (SSAT) problems that outperforms the best existing algorithm for solving such problems (ZANDER) by several orders of magnitude with respect to both time and space. DC-SSAT achieves this performance by dividing the SSAT problem into subproblems based on the structure of the original instance, caching the viable partial assignments (VPAs) generated by solving these subproblems, and using these VPAs to construct the solution to the original problem. DC-SSAT does not save redundant VPAs and each VPA saved is necessary to construct the solution. Furthermore, DC-SSAT builds a solution that is already human-comprehensible, allowing it to avoid the costly solution rebuilding phase in ZANDER. As a result, DC-SSAT is able to solve problems using, typically, 1-2 orders of magnitude less space than ZANDER, allowing DC-SSAT to solve problems ZANDER cannot solve due to space constraints. And, in spite of its more parsimonious use of space, DC-SSAT is typically 1-2 orders of magnitude faster than ZANDER. We describe the DC-SSAT algorithm and present empirical results comparing its performance to that of ZANDER on a set of SSAT problems.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-066.pdf,Subjects: 15.2 Constraint Satisfaction; 3.4 Probabilistic Reasoning
72,2005,Constraint Satisfaction and Satisfiability,A Constraint Satisfaction Approach to Geospatial Reasoning,"Martin Michalowski, Craig A. Knoblock","The large number of data sources on the Internet can be used to augment and verify the accuracy of geospatial sources, such as gazetteers and annotated satellite imagery. Data sources such as satellite imagery, maps, gazetteers and vector data have been traditionally used in geographic information systems (GIS), but nontraditional geospatial data, such as online phone books and property records are more difficult to relate to imagery. In this paper, we present a novel approach to combining extracted information from imagery, road vector data, and online data sources. We represent the problem of identifying buildings in satellite images as a constraint satisfaction problem (CSP) and use constraint programming to solve it. We apply this technique to real-world data sources in El Segundo, CA and our experimental evaluation shows how this approach can accurately identify buildings when provided with both traditional and nontraditional data sources.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-067.pdf,Subjects: 3. Automated Reasoning; 15.2 Constraint Satisfaction
73,2005,Constraint Satisfaction and Satisfiability,A Framework for Representing and Solving NP Search Problems,"David G. Mitchell, Eugenia Ternovska","NP search and decision problems occur widely in AI, and a number of general-purpose methods for solving them have been developed. The dominant approaches include propositional satisfiability (SAT), constraint satisfaction problems (CSP), and answer set programming (ASP). Here, we propose a declarative constraint programming framework which we believe combines many strengths of these approaches, while addressing weaknesses in each of them. We formalize our approach as a model extension problem, which is based on the classical notion of extension of a structure by new relations. A parameterized version of this problem captures NP. We discuss properties of the formal framework intended to support effective modelling, and prospects for effective solver design.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-068.pdf,Subjects: 9.3 Mathematical Foundations; 9.2 Computational Complexity
74,2005,Constraint Satisfaction and Satisfiability,Generation of Hard Non-Clausal Random Satisfiability Problems,"Juan A. Navarro, Andrei Voronkov",We present the results from experiments with a new family of random formulas for the satisfiability problem. Our proposal is a generalisation of the random k-SAT model that introduces non-clausal formulas and exhibits interesting features such as experimentally observed sharp phase transition and the easy-hard-easy pattern. The experimental results provide some insights on how the use of different clausal translations can affect the performance of satisfiability solving algorithms. We also expect our model to provide diverse and challenging benchmarks for developers of SAT procedures for non-clausal formulas.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-069.pdf,Subjects: 15.2 Constraint Satisfaction
75,2005,Constraint Satisfaction and Satisfiability,"Anytime, Complete Algorithm for Finding Utilitarian Optimal Solutions to STPPs","Bart Peintner, Martha E. Pollack","We present a simple greedy algorithm and a novel complete algorithm for finding utilitarian optimal solutions to Simple Temporal Problems with Preferences. Unlike previous algorithms, ours does not restrict preference functions to be convex. We present experimental results showing that (1) a single iteration of the greedy algorithm produces high-quality solutions, (2) multiple iterations, bounded by the square of the number of constraints, produce near-optimal solutions, and (3) our complete, memory-boundable algorithm has compelling anytime properties and outperforms a branch-andbound algorithm.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-070.pdf,Subjects: 3.6 Temporal Reasoning; 15.2 Constraint Satisfaction
76,2005,Constraint Satisfaction and Satisfiability,"Superstabilizing, Fault-containing Distributed Combinatorial Optimization","Adrian Petcu, Boi Faltings","Self stabilization in distributed systems is the ability of a system to respond to transient failures by eventually reaching a legal state, and maintaining it afterwards. This makes such systems particularly interesting because they can tolerate faults, and are able to cope with dynamic environments. We propose the first self stabilizing mechanism for distributed combinatorial optimization, which works on general networks and stabilizes in a state corresponding to the optimal solution of the optimization problem. Our algorithm is based on dynamic programming, and requires a linear number of messages to find the optimal solution in the absence of faults. We show how our algorithm can be made super-stabilizing, in the sense that while transiting from one stable state to the next, our system preserves the assignments from the previous optimal state, until the new optimal solution is found. We offer equal bounds for the stabilization and the superstabilization time. Furthermore, we describe a general scheme for fault containment and fast response time upon low impact failures. Multiple, isolated failures are handled effectively. To show the merits of our approach we report on experiments with practical sized distributed meeting scheduling problems in a multiagent system.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-071.pdf,Subjects: 15.2 Constraint Satisfaction; 7. Distributed AI
77,2005,Constraint Satisfaction and Satisfiability,SAT-based Versus CSP-based Constraint Weighting for Satisfiability,"Duc Nghia Pham, John Thornton, Abdul Sattar, Abdelraouf Ishtaiwi","Recent research has focused on bridging the gap between the satisfiability (SAT) and constraint satisfaction problem (CSP) formalisms. One approach has been to develop a many-valued SAT formula (MV-SAT) as an intermediate paradigm between SAT and CSP, and then to translate existing highly efficient SAT solvers to the MV-SAT domain. Experimental results have shown this approach can achieve significant improvements in performance compared with the traditional SAT and CSP approaches. In this paper, we follow a different route, developing SAT solvers that can automatically recognise CSP structure hidden in SAT encodings. This allows us to look more closely at how constraint weighting can be implemented in the SAT and CSP domains. Our experimental results show that a SAT-based approach to handle weights, together with CSP-based approach to variable instantiation, is superior to other combinations of SAT and CSP-based approaches. A further experiment on the round robin scheduling problem indicates that this many-valued constraint weighting approach outperforms other state-of-the-art solvers.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-072.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
78,2005,Constraint Satisfaction and Satisfiability,Constraint-Based Preferential Optimization,"Steve Prestwich, Francesca Rossi, Kristen Brent Venable, Toby Walsh","We first show that the optimal and undominated outcomes of an unconstrained (and possibly cyclic) CP-net are the solutions of a set of hard constraints. We then propose a new algorithm for finding the optimal outcomes of a constrained CP-net which makes use of hard constraint solving. Unlike previous algorithms, this new algorithm works even with cyclic CP-nets. In addition, the algorithm is not tied to CP-nets, but can work with any preference formalism which produces a preorder over the outcomes. We also propose an approximation method which weakens the preference ordering induced by the CP-net, returning a larger set of outcomes, but provides a significant computational advantage. Finally, we describe a weighted constraint approach that allows to find good solutions even when optimals do not exist.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-073.pdf,Subjects: 15.2 Constraint Satisfaction; 11. Knowledge Representation
79,2005,Constraint Satisfaction and Satisfiability,SymChaff: A Structure-Aware Satisfiability Solver,Ashish Sabharwal,"We present a novel low-overhead framework for encoding and utilizing structural symmetry in propositional satisfiability algorithms (SAT solvers). We use the notion of complete multi-class symmetry and demonstrate the efficacy of our technique through a solver SymChaff that achieves exponential speedup by using simple tags in the specification of problems from both theory and practice. Efficient implementations of DPLL-based SAT solvers are routinely used in areas as diverse as planning, scheduling, design automation, model checking, verification, testing, and algebra. A natural feature of many application domains is the presence of symmetry, such as that amongst all trucks at a certain location in logistics planning and all wires connecting two switch boxes in an FPGA circuit. Many of these problems turn out to have a concise description in many-sorted first order logic. This description can be easily specified by the problem designer and almost as easily inferred automatically. SymChaff, an extension of the popular SAT solver zChaff, uses information obtained from the ""sorts"" in the first order logic constraints to create symmetry sets that are used to partition variables into classes and to maintain and utilize symmetry information dynamically. Current approaches designed to handle symmetry include: (A) symmetry breaking predicates (SBPs), (B) pseudo-Boolean solvers with implicit representation for counting, (C) modifications of DPLL that handle symmetry dynamically, and (D) techniques based on ZBDDs. SBPs are prohibitively many, often large, and expensive to compute for problems such as the ones we report experimental results for. Pseudo-Boolean solvers are provably exponentially slow in certain symmetric situations and their implicit counting representation is not always appropriate. Suggested modifications of DPLL either work on limited global symmetry and are difficult to extend, or involve expensive algebraic group computations. Finally, techniques based on ZBDDs often do not compare well even with ordinary DPLL-based solvers. SymChaff addresses and overcomes most of these limitations.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-074.pdf,Subjects: 15.2 Constraint Satisfaction; 1.11 Planning
80,2005,Constraint Satisfaction and Satisfiability,Performing Bayesian Inference by Weighted Model Counting,"Tian Sang, Paul Beame, Henry Kautz","Over the past decade general satisfiability testing algorithms have proven to be surprisingly effective at solving a wide variety of constraint satisfaction problem, such as planning and scheduling. Solving such NP-complete tasks by compilation to SAT has turned out to be an approach that is of both practical and theoretical interest. Recently, it has been shown that state of the art SAT algorithms can be efficiently extended to the harder task of counting the number of models (satisfying assignments) of a formula, by employing a technique called component caching. This paper begins to investigate the question of whether compilation to model-counting could be a practical technique for solving real-world #P-complete problems, in particular Bayesian inference. We describe an efficient translation from Bayesian networks to weighted model counting, extend the best model-counting algorithms to weighted model counting, develop an efficient method for computing all marginals in a single counting pass, and evaluate the approach on computationally challenging reasoning problems.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-075.pdf,Subjects: 15.2 Constraint Satisfaction; 3.4 Probabilistic Reasoning
81,2005,Game Theory and Economic Models,A Generalized Strategy Eliminability Criterion and Computational Methods for Applying It,"Vincent Conitzer, Tuomas Sandholm","We define a generalized strategy eliminability criterion for bimatrix games that considers whether a given strategy is eliminable relative to given dominator & eliminee subsets of the players’ strategies. We show that this definition spans a spectrum of eliminability criteria from strict dominance (when the sets are as small as possible) to Nash equilibrium (when the sets are as large as possible). We show that checking whether a strategy is eliminable according to this criterion is coNP-complete (both when all the sets are as large as possible and when the dominator sets each have size 1). We then give an alternative definition of the eliminability criterion and show that it is equivalent using the Minimax Theorem. We show how this alternative definition can be translated into a mixed integer program of polynomial size with a number of (binary) integer variables equal to the sum of the sizes of the eliminee sets, implying that checking whether a strategy is eliminable according to the criterion can be done in polynomial time, given that the eliminee sets are small. Finally, we study using the criterion for iterated elimination of strategies.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-076.pdf,Subjects: 7.1 Multi-Agent Systems; 1.8 Game Playing
82,2005,Game Theory and Economic Models,Fast and Compact: A Simple Class Of Congestion Games,"Samuel Ieong, Robert McGrew, Eugene Nudelman, Yoav Shoham, Qixiang Sun","We study a simple, yet rich subclass of congestion games that we call singleton games. These games are exponentially more compact than general congestion games. In contrast with some other compact subclasses, we show tractability of many natural game-theoretic questions, such as finding a sample or optimal Nash equilibrium. For best- and better-response dynamics, we establish polynomial upper and lower bounds on the rate of convergence and present experimental results. We also consider a natural generalization of singleton games and show that many tractability results carry over.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-077.pdf,Subjects: 7.1 Multi-Agent Systems; 9.2 Computational Complexity
83,2005,Game Theory and Economic Models,Mixed-Integer Programming Methods for Finding Nash Equilibria,"Tuomas Sandholm, Andrew Gilpin, Vincent Conitzer","We present, to our knowledge, the first mixed integer program (MIP) formulations for finding Nash equilibria in games (specifically, two-player normal form games). We study different design dimensions of search algorithms that are based on those formulations. Our MIP Nash algorithm outperforms Lemke-Howson but not Porter-Nudelman-Shoham (PNS) on GAMUT data. We argue why experiments should also be conducted on games with equilibria with medium-sized supports only, and present a methodology for generating such games. On such games MIP Nash drastically outperforms PNS but not Lemke-Howson. Certain MIP Nash formulations also yield anytime algorithms for epsilon-equilibrium, with provable bounds. Another advantage of MIP Nash is that it can be used to find an optimal equilibrium (according to various objectives). The prior algorithms can be extended to that setting, but they are orders of magnitude slower.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-078.pdf,Subjects: 7.1 Multi-Agent Systems; 15.7 Search
84,2005,Game Theory and Economic Models,Approximate Strategic Reasoning through Hierarchical Reduction of Large Symmetric Games,"Michael P. Wellman, Daniel M. Reeves, Kevin M. Lochner, Shih-Fen Cheng, and Rahul Suri","To deal with exponential growth in the size of a game with the number of agents, we propose an approximation based on a hierarchy of reduced games. The reduced game achieves savings by restricting the number of agents playing any strategy to fixed multiples. We validate the idea through experiments on randomly generated local-effect games. An extended application to strategic reasoning about a complex trading scenario motivates the approach, and demonstrates methods for game-theoretic reasoning over incompletely-specified games at multiple levels of granularity.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-079.pdf,Subjects: 7.1 Multi-Agent Systems
85,2005,Game Theory and Economic Models,Coalitional Games in Open Anonymous Environments,"Makoto Yokoo, Vincent Conitzer, Tuomas Sandholm, Naoki Ohta, Atsushi Iwasaki","Coalition formation is a key aspect of automated negotiation among self-interested agents. In order for coalitions to be stable, a key question that must be answered is how the gains from cooperation are to be distributed. Various solution concepts (such as the Shapley value, core, least core, and nucleolus) have been proposed. In this paper, we demonstrate how these concepts are vulnerable to various kinds of manipulations in open anonymous environments such as the Internet. These manipulations include submitting false names (one acting as many), collusion (many acting as one), and the hiding of skills. To address these threats, we introduce a new solution concept called the anonymity-proof core, which is robust to these manipulations. We show that the anonymity-proof core is characterized by certain simple axiomatic conditions. Furthermore, we show that by relaxing these conditions, we obtain a concept called the least anonymity-proof core, which is guaranteed to be non-empty. We also show that computational hardness of manipulation may provide an alternative barrier to manipulation.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-080.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
86,2005,Human-Computer Interaction,Mathematical Domain Reasoning Tasks in Natural Language Tutorial Dialog on Proofs,"Christoph Benzmueller, Quoc Bao Vo","We study challenges that are imposed to mathematical domain reasoning in the context of natural language tutorial dialog on mathematical proofs. The focus is on proof step evaluation: (i) How can mathematical domain reasoning support the resolution of ambiguities and underspecified parts in proof steps uttered by a student? (ii) How can mathematical domain reasoning support the evaluation of a proof step with respect to the criteria soundness, granularity, and relevance?",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-081.pdf,Subjects: 6. Computer-Human Interaction; 3. Automated Reasoning
87,2005,Human-Computer Interaction,Real-Time Classification of Electromygraphic Signals for Robotic Control,"Beau Crawford, Kai Miller, Pradeep Shenoy, Rajesh P.N. Rao","Advances in bioengineering have led to increasingly sophisticated prosthetic devices for amputees and paralyzed individuals. Control of such devices necessitates real-time classification of biosignals, e.g., electromyographic (EMG) signals recorded from intact muscles. In this paper, we show that a 4-degrees-of-freedom robotic arm can be controlled in real-time using non-invasive surface EMG signals recorded from the forearm. The innovative features of our system include a physiologically- informed selection of forearm muscles for recording EMG signals, intelligent choice of hand gestures for easy classification, and fast, simple feature extraction from EMG signals. Our selection of gestures is meant to intuitively map to appropriate degrees of freedom in the robotic arm. These design decisions allow us to build fast accurate classifiers online, and control a 4-DOF robotic arm in real- time. In a study involving 3 subjects, we achieved accuracies of 92- 98% on an 8-class classification problem using linear SVMs. These classifiers can be learned on-line in under 10 minutes, including data collection and training. Our study also analyzes the issues and tradeoffs involved in designing schemes for robotic control using EMG. Finally, we present details of online experiments where subjects successfully solved tasks of varying complexity using EMG to control the robotic arm.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-082.pdf,Subjects: 8. Enabling Technologies; 6.3 User Interfaces
88,2005,Human-Computer Interaction,A Decision Theoretic Model for Stress Recognition and User Assistance,"Wenhui Liao, Weihong Zhang, Zhiwei Zhu, Qiang Ji","We present a general unified probabilistic decisiontheoretic model based on Influence Diagrams for simultaneously modeling both user stress recognition and user assistance. Stress recognition is achieved through dynamic probabilistic inference from the available sensory data from multiple-modality sources. User assistance is automatically achieved by balancing the benefits of improving user performance and the costs of performing user assistance. In addition, a non-invasive real-time system is built to validate the proposed framework. Utilizing the evidences from four modalities (physical appearance features, physiological measures, user performance and behavioral data), the system can successfully recognize human stress and provide timely and appropriate assistance in a task-specific environment.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-083.pdf,Subjects: 6. Computer-Human Interaction; 4. Cognitive Modeling
89,2005,Human-Computer Interaction,On the Evaluation of Dynamic Critiquing: A Large-Scale User Study,"Kevin McCarthy, Lorraine McGinty, Barry Smyth, James Reilly","Critiquing is an important form of feedback in conversational recommender systems. However, in these systems the user is usually limited to critiquing a single product feature at a time. Recently dynamic critiquing has been proposed to address this shortcoming, by automatically generating compound critiques over multiple features that may be presented to the user at recommendation time. To date a number of different versions of dynamic critiquing have been evaluated in isolation, and with reference to artificial users. In this paper we bring together the main flavors of dynamic critiquing and perform a large-scale comparative evaluation as part of an extensive real-user trial. This evaluation reveals some interesting facts about the way real users interact with critique-based recommenders.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-084.pdf,Subjects: 3.1 Case-Based Reasoning; 6.3 User Interfaces
90,2005,Human-Computer Interaction,Optimal Recommendation Sets: Covering Uncertainty over User Preferences,"Bob Price, Paul Messinger","We propose an approach to recommendation systems that optimizes over possible sets of recommended alternatives in a decision-theoretic manner. Our approach selects the alternative set that maximizes the expected valuation of the user’s choice from the recommended set. The set-based optimization explicitly recognizes the opportunity for passing residual uncertainty about preferences back to the user to resolve. Implicitly, the approach chooses a set with a diversity of alternatives that optimally covers the uncertainty over possible user preferences. The approach can be used with several preference representations, including utility theory, qualitative preferences models, and informal scoring. We develop a specific formulation for multi-attribute utility theory, which we call maximization of expected max (MEM). We go on to show that this optimization is NP-complete (when user preferences are described by discrete distributions) and suggest two efficient methods for approximating it. These approximations have complexity of the same order as the traditional k-max operator and, for both synthetic and real-world data, perform better than the approach of recommending the k-individually best alternatives (which is not a surprise) and very close to the optimum set (which is less expected).",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-085.pdf,Subjects: 15.5 Decision Theory; 6.3 User Interfaces
91,2005,Human-Computer Interaction,Goal-Directed Site-Independent Recommendations from Passive Observations,"Tingshao Zhu, Russ Greiner, Gerald Haeubl, Kevin Jewell, Bob Price","This paper introduces a novel method to find Web pages that satisfy the user’s current information need. The method infers the user’s need from the content of the pages the user has visited and the actions the user has applied to these pages. Unlike content-based systems that attempt to learn a user’s long-term interests, our system learns user-independent patterns of behavior that identify the user’s current information need, based on his/her current browsing session, then uses this information to suggest specific pages intended to address this need. Our system learns these behavior patterns from labeled data collected during a five-week user study, involving over one hundred participants working on their day-to-day tasks. We tested this learned model in a second phase of this same study, and found that this model can effectively identify the information needs of new users as they browse previously unseen pages, and that we can use this information to help them find relevant pages.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-086.pdf,Subjects: 6. Computer-Human Interaction; 1.10 Information Retrieval
92,2005,Knowledge Acquisition and Engineering,An Analysis of Procedure Learning by Instruction,Jim Blythe,"Many useful planning tasks are handled by plan execution tools, such as PRS, that expand procedure definitions and keep track of several interacting goals and tasks. Learning by instruction is a promising approach to help users modify the definitions of the procedures. However, the impact of the set of possible instructions on the performance of such systems is not well understood. We develop a framework in which instruction templates may be characterized in terms of syntactic transforms on task definitions, and use it to explore the properties of coverage, ambiguity and efficiency in the set of instructions that are understood by an implemented task learning system. We determine what kind of ambiguity is affected by the instruction set, and show how context-dependent interpretation can increase efficiency and coverage without increasing ambiguity.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-087.pdf,Subjects: 10. Knowledge Acquisition; 1.11 Planning
93,2005,Knowledge Acquisition and Engineering,An Analysis of Knowledge Collected from Volunteer Contributors,"Timothy Chklovski, Yolanda Gil","A new generation of intelligent applications can be enabled by broad-coverage repositories of knowledge. One emerging approach to constructing such repositories is proactive knowledge collection from large numbers of volunteer contributors. In this paper, we study the coverage and quality of a representative collection of part-of information contributed by volunteers. We analyze growth of coverage over time, redundancy of the collected knowledge, and the effect of the coverage and redundancy on the quality of the collection. We also present initial comparisons with collections created by ontology engineering and text extraction approaches. Our analysis reveals that redundancy of contribution helps identify high quality statements, but that some of the statements also have overly high redundancy, drawing contributor effort away from areas where they are needed more. We suggest possible ways to address these issues in future collection efforts.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-088.pdf,Subjects: 10. Knowledge Acquisition; 11. Knowledge Representation
94,2005,Knowledge Representation and Reasoning,Integrating Description Logics and Action Formalisms: First Results,"Franz Baader, Carsten Lutz, Maja Milicic, Ulrike Sattler, Frank Wolter","We propose an action formalism that is based on description logics (DLs) and may be viewed as an instance of the Situation Calculus (SitCalc). In particular, description logic concepts can be used for describing the state of the world, and the pre- and post-conditions of actions. The main advantage of such a combination is that, on the one hand, the expressive power for describing world states and conditions is higher than in other decidable fragments of the SitCalc, which are usually propositional. On the other hand, in contrast to the full SitCalc, effective reasoning is still possible. In this paper, we perform a detailed investigation of how the choice of the DL influences the complexity of the standard reasoning tasks executability and projection in the corresponding action formalism. We also discuss semantic and computational problems in natural extensions of our framework.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-089.pdf,Subjects: 11.1 Description Logics; 9.2 Computational Complexity
95,2005,Knowledge Representation and Reasoning,Using SAT and Logic Programming to Design Polynomial-Time Algorithms for Planning in Non-Deterministic Domains,"Chitta Baral, Thomas Eiter, Jicheng Zhao","We show that a Horn SAT and logic programming approach to obtain polynomial time algorithms for problem solving can be fruitfully applied to finding plans for various kinds of goals in a non-deterministic domain. We particularly focus on finding weak, strong, and strong cyclic plans for planning problems, as they are the most studied ones in the literature. We describe new algorithms for these problems and show how non-monotonic logic programming can be used to declaratively compute strong cyclic plans. As a further benefit, preferred plans among alternative candidate plans may be singled out this way. We give complexity results for weak, strong, and strong cyclic planning. Finally, we briefly discuss some of the kinds of goals in non-deterministic domains for which the approach in the paper can be used.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-090.pdf,Subjects: 11. Knowledge Representation; 1.11 Planning
96,2005,Knowledge Representation and Reasoning,Hybrid Possibilistic Networks,"Salem Benferhat, Salma Smaoui","Possibilistic networks are important tools for dealing with uncertain pieces of information. For multiply-connected networks, it is well known that the inference process is a hard problem. This paper studies a new representation of possibilistic networks, called hybrid possibilistic networks. The uncertainty is no longer represented by local conditional possibility distributions, but by their compact representations which are possibilistic knowledge bases. We show that the inference algorithm in hybrid networks is strictly more efficient than the ones of standard propagation algorithm.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-091.pdf,Subjects: 3.5 Qualitative Reasoning
97,2005,Knowledge Representation and Reasoning,Practical First-Order Argumentation,"Philippe Besnard, Anthony Hunter",There are many frameworks for modelling argumentation in logic. They include a formal representation of individual arguments and techniques for comparing conflicting arguments. A problem with these proposals is that they do not consider arguments for and against first-order formulae. We present a framework for first-order logic argumentation based on argument trees that provide a way of exhaustively collating arguments and counter-arguments. A difficulty with first-order argumentation is that there may be many arguments and counterarguments even with a relatively small knowledgebase. We propose rationalizing the arguments under consideration with the aim of reducing redundancy and highlighting key points.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-092.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
98,2005,Knowledge Representation and Reasoning,Prioritized Component Systems,"Gerhard Brewka, Ilkka Niemel&auml;, Miros&#322;aw Truszczy&#324;ski","We introduce a flexible framework to specify problem solutions (outcomes) and preferences among them. The proposal combines ideas from answer-set programming (ASP), answer-set optimization (ASO) and CP-nets. The problem domain is structured into components. ASP techniques are used to specify values of components, as well as global (inter-component) constraints among these values. ASO methods are used to describe preferences among the values of a component and CP-net techniques to represent inter-component dependencies and corresponding preferences.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-093.pdf,Subjects: 11. Knowledge Representation; 3.5 Qualitative Reasoning
99,2005,Knowledge Representation and Reasoning,DL-Lite: Tractable Description Logics for Ontologies,"Diego Calvanese, Giuseppe De Giacomo, Domenico Lembo, Maurizio Lenzerini, Riccardo Rosati","We propose a new Description Logic, called DL-Lite, specifically tailored to capture basic ontology languages, while keeping low complexity of reasoning. Reasoning here means not only computing subsumption between concepts, and checking satisfiability of the whole knowledge base, but also answering complex queries (in particular, conjunctive queries) over the set of instances maintained in secondary storage. We show that in DL-Lite the usual DL reasoning tasks are polynomial in the size of the TBox, and query answering is polynomial in the size of the ABox (i.e., in data complexity). To the best of our knowledge, this is the first result of polynomial data complexity for query answering over DL knowledge bases. A notable feature of our logic is to allow for a separation between TBox and ABox reasoning during query evaluation: the part of the process requiring TBox reasoning is independent of the ABox, and the part of the process requiring access to the ABox can be carried out by an SQL engine, thus taking advantage of the query optimization strategies provided by current DBMSs.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-094.pdf,Subjects: 11.1 Description Logics; 11.2 Ontologies
100,2005,Knowledge Representation and Reasoning,An Axiomatic Account of Formal Argumentation,"Martin Caminada, Leila Amgoud","Argumentation theory has become an important topic in the field of AI. The basic idea is to construct arguments in favor and against a statement, to select the ''acceptable'' ones and, finally, to determine whether the statement can be accepted or not. Dung’s elegant account of abstract argumentation may have caused some to believe that defining an argumentation formalism is simply a matter of determining how arguments and their defeat relation can be constructed from a given knowledge base. Unfortunately, things are not that simple; many straightforward instantiations of Dung’s theory can lead to very unintuitive results, as is discussed in this paper. 	 In order to avoid such anomalies, in this paper we are interested in defining some rules, called rationality postulates or axioms, that govern the well definition of an argumentation system. In particular, we define two important rationality postulates that any system should satisfy: the consistency and the closeness of the results returned by that system. We then provide a relatively easy way in which these quality postulates can be warranted by our argumentation system.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-095.pdf,Subjects: 3.5 Qualitative Reasoning; 3.3 Nonmonotonic Reasoning
101,2005,Knowledge Representation and Reasoning,Merging Argumentation Systems,"Sylvie Coste-Marquis, Caroline Devred, Sébastien Konieczny, Marie-Christine Lagasquie-Schiex, Pierre Marquis","In this paper, we address the problem of deriving sensible information from a collection of argumentation systems coming from different agents. A general framework for merging argumentation systems from Dung’s theory of argumentation is presented. Each argumentation system gives both a set of arguments and the way they interact (i.e. attack or non-attack) according to the corresponding agent. The aim is to define the argument system (or the set of argument systems) that best represents the group. Our framework is general enough to handle the case when agents do not share the same set of arguments. Merging argumentation systems is shown as a valuable approach for defining (sets of) arguments acceptable by the group.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-096.pdf,Subjects: 11. Knowledge Representation; 15.1 Belief Revision
102,2005,Knowledge Representation and Reasoning,DD-PREF: A Language for Expressing Preferences Over Sets,"Marie desJardins, Kiri L. Wagstaff","In many application domains, it is useful to be able to represent and reason about a user’s preferences over sets of objects. We present a representation language, DD-PREF (for Diversity and Depth PREFerences), for specifying the desired diversity and depth of sets of objects where each object is represented as a vector of feature values. A strong diversity preference for a particular feature indicates that the user would like the set to include objects whose values are evenly dispersed across the range of possible values for that feature. A strong depth preference for a feature indicates that the user is interested in specific target values or ranges. Diversity and depth are complementary, but are not necessarily opposites. We define an objective function that, when maximized, identifies the subset of objects that best satisfies a statement of preferences in DD-PREF. Exhaustively searching the space of all possible subsets is intractable for large problem spaces; therefore, we also present an efficient greedy algorithm for generating preferred object subsets. We demonstrate the expressive power of DD-PREF and the performance of our greedy algorithm by encoding and applying qualitatively different preferences for multiple tasks on a blocks world data set. Finally, we provide experimental results for a collection of Mars rover images, demonstrating that we can successfully capture individual preferences of different users, and use them to retrieve high-quality image subsets.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-097.pdf,Subjects: 11. Knowledge Representation; 8. Enabling Technologies
103,2005,Knowledge Representation and Reasoning,Cumulative Effects of Concurrent Actions on Numeric-Valued Fluents,"Esra Erdem, Alfredo Gabaldon","We propose a situation calculus formalization of action domains that include numeric-valued fluents (so-called additive or measure fluents) and concurrency. Our approach allows formalizing concurrent actions whose effects increment/decrement the value of additive fluents. For describing indirect effects, we employ mathematical equations in a manner that is inspired by recent work on causality and structural equations.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-098.pdf,Subjects: 5. Common Sense Reasoning; 11. Knowledge Representation
104,2005,Knowledge Representation and Reasoning,Only-Knowing: Taking It Beyond Autoepistemic Reasoning,"Gerhard Lakemeyer, Hector J. Levesque","The idea of only-knowing a collection of sentences has been previously shown to have a close connection with autoepistemic logic. Here we propose a more general account of only-knowing that captures not only autoepistemic logic but default logic as well. This allows us not only to study the properties of default logic in terms of an underlying model of belief, but also the relationship among different forms of nonmonotonic reasoning, all within a classical monotonic logic characterized semantically in terms of possible worlds.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-099.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
105,2005,Knowledge Representation and Reasoning,Tractable Reasoning in First-Order Knowledge Bases with Disjunctive Information,"Yongmei Liu, Hector J. Levesque","This work proposes a new methodology for establishing the tractability of a reasoning service that deals with expressive first-order knowledge bases. It consists of defining a logic that is weaker than classical logic and that has two properties: first, the entailment problem can be reduced to the model checking problem for a small number of characteristic models; and second, the model checking problem itself is tractable for formulas with a bounded number of variables. We show this methodology in action for the reasoning service previously proposed by Liu, Lakemeyer and Levesque for dealing with disjunctive information. They show that their reasoning is tractable in the propositional case and decidable in the first-order case. Here we apply the methodology and prove that the reasoning is also tractable in the first-order case if the knowledge base and the query both use a bounded number of variables.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-100.pdf,Subjects: 11. Knowledge Representation; 3. Automated Reasoning
106,2005,Knowledge Representation and Reasoning,Knowledge Integration for Description Logics,"Thomas Meyer, Kevin Lee, Richard Booth","Description logic reasoners are able to detect incoherences (such as logical inconsistency and concept unsatisfiability) in knowledge bases, but provide little support for resolving them. We propose to recast techniques for propositional inconsistency management into the description logic setting. We show that the additional structure afforded by description logic statements can be used to refine these techniques. Our focus in this paper is on the formal semantics for such techniques, although we do provide high-level decision procedures for the knowledge integration strategies discussed.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-101.pdf,Subjects: 15.1 Belief Revision; 11.1 Description Logics
107,2005,Knowledge Representation and Reasoning,Analysis of Strategic Knowledge in Back of the Envelope Reasoning,"Praveen K Paritosh, Kenneth D. Forbus","Back of the envelope (BotE) reasoning involves generating quantitative answers in situations where exact data and models are unavailable and where available data is often incomplete and/or inconsistent. A rough estimate generated quickly is more valuable and useful than a detailed analysis, which might be unnecessary, impractical, or impossible because the situation does not provide enough time, information, or other resources to perform one. Such reasoning is a key component of commonsense reasoning about everyday physical situations. We present an implemented system, BotE-Solver, that can solve about a dozen estimation questions like ""What is the annual cost of healthcare in USA?"" from different domains using a library of strategies and the Cyc knowledge base. BotE-Solver is a general-purpose problem solving framework that uses strategies represented as suggestions, and keeps track of problem solving progress in an AND/OR tree. A key contribution of this paper is a knowledge level analysis [Newell, 1982] of the strategic knowledge used in BotE reasoning. We present a core collection of seven powerful estimation strategies that provides broad coverage for such problem solving. We hypothesize that this is the complete set of back of the envelope problem solving strategies. We present twofold support for this hypothesis: 1) an empirical analysis of all problems (n=44) on Force and Pressure, Rotation and Mechanics, Heat, and Astronomy from Clifford Swartz’s ""Back-of-the-Envelope Physics"" [Swartz, 2003], and 2) an analysis of strategies used by BotE-Solver.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-102.pdf,Subjects: 5. Common Sense Reasoning; 3.5 Qualitative Reasoning
108,2005,Knowledge Representation and Reasoning,Generalized Link Properties for Expressive E-Connections of Description Logics,"Bijan Parsia, Bernardo Cuenca Grau","E-Connections are a robust framework for combining in a decidable way several families of decidable logics, including Description Logics (DLs), Modal Logics, and many logics of time and space. E-Connections have also proved to be useful for supporting modular, distributed modeling such as is becoming common on the Semantic Web. In this paper, we present an extension to E-Connections of DLs that provides more flexibility in the way link properties can be defined and used in a combination of ontologies. We also provide means for defining transitive relations across domains and for simulating some of the expressivity of the transitive closure operator. Finally, we provide a tableau-based decision procedure for two relevant E-Connection languages involving the influential DLs SHIQ, SHOQ and SHIO, which are at the basis of the Web Ontology Language (OWL)",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-103.pdf,Subjects: 11.1 Description Logics; 11.2 Ontologies
109,2005,Knowledge Representation and Reasoning,Functional Specification of Probabilistic Process Models,Avi Pfeffer,"Agents that handle complex processes evolving over a period of time need to be able to monitor the state of the process. Since the evolution of a process is often stochastic, this requires probabilistic monitoring of processes. A probabilistic process modeling language is needed that can adequately capture our uncertainty about the process execution. We present a language for describing probabilistic process models. This language is functional in nature, and the paper argues that a functional language provides a natural way to specify process models. %The paper presents the language features that allow the description of %processes that execute over time and processes with state. In our framework, processes have both states and values. Processes may execute sequentially or in parallel, and we describe two alternative forms of parallelism. An inference algorithm is presented that constructs a dynamic Bayesian network, containing a variable for every subprocess that is executed during the course of executing a process. We present a detailed example demonstrating the naturalness of the language.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-104.pdf,Subjects: 3.4 Probabilistic Reasoning; 3.6 Temporal Reasoning
110,2005,Knowledge Representation and Reasoning,Diagnosing Terminologies,Stefan Schlobach,"We present a framework for the debugging of logically contradicting terminologies, which is based on traditional model-based diagnosis. To study the feasibility of this highly general approach we prototypically implemented the hitting set algorithm presented in (Reiter 1987), and applied it in three different scenarios. First, we use a Description Logic reasoning system as a black-box to determine (necessarily maximal) conflict sets. Then we use our own non-optimized DL reasoning engine to produce small, and a specialized algorithm to determine minimal conflict sets. In a number of experiments we show that the first method already fails for relatively small terminologies. However, based on small, or minimal conflict sets, we can often calculate diagnoses in reasonable time.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-105.pdf,Subjects: 11.1 Description Logics; 1.5 Diagnosis
111,2005,Knowledge Representation and Reasoning,Issues in Reasoning about Interaction Networks in Cells: Necessity of Issues in Reasoning about Interaction Networks in Cells: Necessity of Event Ordering Knowledge,"Nam Tran, Chitta Baral, Carron Shankland","In this paper we discuss several representation issues that we came across while modelling molecular interactions in cells of living organisms. One of the issues was that the triggering of events inside cells, an important modelling component, are not necessarily immediate, leading to multiple evolution models in the absence of additional information. Second, often an action or a trigger at one level of granularity of representation can be elaborated and refined. We show the problem that existing representation and modelling formalisms have in dealing with the above issues. We then present an action language which builds up on a previous language, and has the ability to express event ordering knowledge. We show that our language is able to adequately address the above-mentioned issues.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-106.pdf,Subjects: 11. Knowledge Representation
112,2005,Knowledge Representation and Reasoning,A Theory of Forgetting in Logic Programming,"Kewen Wang, Abdul Sattar, Kaile Su","The study of forgetting for reasoning has attracted considerable attention in AI. However, much of the work on forgetting, and other related approaches such as independence, irrelevance and novelty, has been restricted to the classical logics. This paper describes a detailed theoretical investigation of the notion of forgetting in the context of logic programming. We first provide a semantic definition of forgetting under the answer sets for extended logic programs. We then discuss the desirable properties and some motivating examples. An important result of this study is an algorithm for computing the result of forgetting in a logic program. Furthermore, we present a modified version of the algorithm and show that the time complexity of the new algorithm is polynomial with respect to the size of the given logic program if the size of certain rules is fixed. We show how the proposed theory of forgetting can be used to characterize the logic program updates. %We show %that the proposed theory of forgetting provides a general %framework for the reasoning tasks such as merging, update and %revision of logic programs.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-107.pdf,Subjects: 3. Automated Reasoning; 3.3 Nonmonotonic Reasoning
113,2005,Logic Programming,Reasoning about Intended Actions,"Chitta Baral, Michael Gelfond","In most research on reasoning about actions and reasoning about narratives one either reasons about hypothetical execution of actions, or about actions that actually occurred. In this paper we develop a high level language that allows the expression of intended or planned action sequences. Unlike observed action occurrences, planned or intended action occurrences may not actually take place. But often when they do not take place, they persist, and happen at an opportune future time. We give the syntax and semantics for expressing such intentions. We then give a logic programming axiomatization and show the correspondence between the semantics of a description in the high level language, and the answer sets of the corresponding logic programming axiomatization. We illustrate the application of our formalism with respect to reasoning about trips.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-108.pdf,Subjects: 11. Knowledge Representation
114,2005,Logic Programming,Strong and Uniform Equivalence in Answer-Set Programming: Characterizations and Complexity Results for the Non-GroundCase,"Thomas Eiter, Michael Fink, Hans Tompits, Stefan Woltran","Recent research in nonmonotonic logic programming under the answer-set semantics focuses on different notions of equivalence. In particular, strong and uniform equivalence are proposed as useful tools for optimizing (parts of) a logic program. Whereas most previous research in this direction addressed only ground logic programs (i.e., programs without variables), in this paper, we deal with the more general case of non-ground programs. More specifically, we discuss languages with both finite and infinite vocabularies and provide semantical characterizations capturing the essence of equivalence, generalizing the concepts of SE-models and UE-models, respectively, as originally introduced for propositional programs. We furthermore show that, for infinite vocabularies, uniform equivalence between disjunctive programs is undecidable, and we provide decidability results and precise complexity bounds for strong equivalence, for both finite and infinite vocabularies, and for uniform equivalence for finite vocabularies, thereby correcting a previous complexity bound for strong equivalence from the literature.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-109.pdf,Subjects: 9.2 Computational Complexity; 3.3 Nonmonotonic Reasoning
115,2005,Logic Programming,Properties of Programs with Monotone and Convex Constraints,"Lengning Liu, Miroslaw Truszczynski","We study properties of programs with monotone and convex constraints. We extend to these formalisms concepts and results from normal logic programming. They include tight programs and Fages Lemma, program completion and loop formulas, and the notions of strong and uniform equivalence with their characterizations. Our results form an abstract account of properties of some recent extensions of logic programming with aggregates, especially the formalism of smodels.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-110.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
116,2005,Logic Programming,A Unified Framework for Representing Logic Program Updates,"Yan Zhang, Norman Foo","As a promising formulation to represent and reason about agents’ dynamic behavious, logic program updates have been considerably studied recently. While similarities and differences between various approaches were discussed and evaluated by researchers, there is a lack of method to represent different logic program update approaches under a common framework. In this paper, we continue our study on a general framework for logic program conflict solving based on notions of strong and weak forgettings. We show that all major logic program update approaches can be transformed into our framework, under which each update approach becomes a specific conflict solving case with certain constraints. We also investigate related computational properties for these transformations.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-111.pdf,Subjects: 11. Knowledge Representation; 15.1 Belief Revision
117,2005,Machine Learning,Robust Supervised Learning,James Bagnell,"Supervised machine learning techniques developed in the Probably Approximately Correct, Maximum A Posteriori, and Structural Risk Minimiziation frameworks typically make the assumption that the test data a learner is applied to is drawn from the same distribution as the training data. In various prominent applications of learning techniques, from robotics to medical diagnosis to process control, this assumption is violated. We consider a novel framework where a learner may influence the test distribution in a bounded way. From this framework, we derive an efficient algorithm that acts as a wrapper around a broad class of existing supervised learning algorithms while guarranteeing more robust behavior under changes in the input distribution.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-112.pdf,Subjects: 12. Machine Learning and Discovery; 15.3 Control
118,2005,Machine Learning,Weighted One-Against-All,"Alina Beygelzimer, John Langford, Bianca Zadrozny","The one-against-all reduction from multiclass classification to binary classification is a standard technique used to solve multiclass problems with binary classifiers. We show that modifying this technique in order to optimize its error transformation properties results in a superior technique, both experimentally and theoretically. This algorithm can also be used to solve a more general classification problem: multi-label classification, which is the same as multiclass classification except that it allows multiple correct labels for a given example.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-113.pdf,Subjects: 12. Machine Learning and Discovery; 9.3 Mathematical Foundations
119,2005,Machine Learning,Optimal Efficient Learning Equilibrium: Imperfect Monitoring in Symmetric Games,"Ronen Brafman, Moshe Tennenholtz","Efficient Learning Equilibrium (ELE) is a natural solution concept for multi-agent encounters with incomplete information. It requires the learning algorithms themselves to be in equilibrium for any game selected from a set of (initially unknown) games. In an optimal ELE, the learning algorithms would efficiently obtain the surplus the agents would obtain in an optimal Nash equilibrium of the initially unknown game which is played. The crucial part is that in an ELE deviations from the learning algorithms would become non-beneficial after polynomial time, although the game played is initially unknown. While appealing conceptually, the main challenge for establishing learning algorithms based on this concept is to isolate general classes of games where an ELE exists. Unfortunately, it has been shown that while an ELE exists for the setting in which each agent can observe all other agents’ actions and payoffs, an ELE does not exist in general when the other agents’ payoffs cannot be observed. In this paper we provide the first positive results on this problem, constructively proving the existence of an optimal ELE for the class of symmetric games where an agent can not observe other agents’ payoffs.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-114.pdf,Subjects: 7.1 Multi-Agent Systems; 12. Machine Learning and Discovery
120,2005,Machine Learning,Discovering Domain-Specific Composite Kernels,"Tom Briggs, Tim Oates","Kernel-based data mining algorithms, such as Support Vector Machines, project data into high-dimensional feature spaces, wherein linear decision surfaces correspond to non-linear decision surfaces in the original feature space. Choosing a kernel amounts to choosing a high-dimensional feature space, and is thus a crucial step in the data mining process. Despite this fact, and as a result of the difficulty of establishing that a function is a positive definite kernel, only a few standard kernels (e.g. polynomial and Gaussian) are typically used. We propose a method for searching over a space of kernels for composite kernels that are guaranteed to be positive definite, and that are tuned to produce a feature space appropriate for a given dataset. Composite kernel functions are easily interpreted by humans, in contrast to the output of other work on kernel tuning. Empirical results demonstrate that our method often finds composite kernels that yield higher classification accuracy than the standard kernels.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-115.pdf,Subjects: 12. Machine Learning and Discovery
121,2005,Machine Learning,A Comparison of Novel and State-of-the-Art Polynomial Bayesian Network Learning Algorithms,"Laura E. Brown, Ioannis Tsamardinos, Constantin F. Aliferis","Learning the most probable a posteriori Bayesian network from data has been shown to be an NP-Hard problem and typical state-of-the-art algorithms are exponential in the worst case. However, an important open problem in the field is to identify the least restrictive set of assumptions and corresponding algorithms under which learning the optimal network becomes polynomial. In this paper, we present a technique for learning the skeleton of a Bayesian network, called Polynomial Max-Min Skeleton (PMMS), and compare it with Three Phase Dependency Analysis, another state-of-the-art polynomial algorithm. This analysis considers both the theoretical and empirical differences between the two algorithms, and demonstrates PMMS’s advantages in both respects. When extended with a greedy hill-climbing Bayesian-scoring search to orient the edges, the novel algorithm proved more time efficient, scalable, and accurate in quality of reconstruction than most state-of-the-art Bayesian network learning algorithms. The results show promise of the existence of polynomial algorithms that are provably correct under minimal distributional assumptions.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-116.pdf,Subjects: 12. Machine Learning and Discovery
122,2005,Machine Learning,Reducing Labeling Effort for Structured Prediction Tasks,"Aron Culotta, Andrew McCallum","A common obstacle preventing the rapid deployment of supervised machine learning algorithms is the lack of labeled training data. This is particularly expensive to obtain for structured prediction tasks, where each training instance may have multiple, interacting labels, all of which must be correctly annotated for the instance to be of use to the learner. Traditional active learning addresses this problem by optimizing the order in which the examples are labeled to increase learning efficiency. However, this approach does not consider the difficulty of labeling each example, which can vary widely in structured prediction tasks. For example, the labeling predicted by a partially trained system may be easier to correct for some instances than for others. We propose a new active learning paradigm which reduces not only how many instances the annotator must label, but also how difficult each instance is to annotate. The system also leverages information from partially correct predictions to efficiently solicit annotations from the user. We validate this active learning framework in an interactive information extraction system, reducing the total number of annotation actions by 22%.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-117.pdf,Subjects: 12. Machine Learning and Discovery; 6. Computer-Human Interaction
123,2005,Machine Learning,Towards Learning Stochastic Logic Programs From Proof-Banks,"Luc De Raedt, Kristian Kersting, Sunna Torge","Stochastic logic programs combine ideas from probabilistic grammars with the expressive power of definite clause logic; as such they can be considered as an extension of probabilistic context-free grammars. Motivated by an analogy with learning tree-bank grammars, we study how to learn stochastic logic programs from proof-trees. Using proof-trees as examples imposes strong logical constraints on the structure of the target stochastic logic program. These constraints can be integrated in the least general generalization (lgg) operator, which is employed to traverse the search space. Our implementation employs a greedy search guided by the maximum likelihood principle and failure-adjusted maximization. We also report on a number of simple experiments that show the promise of the approach.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-118.pdf,Subjects: 12. Machine Learning and Discovery
124,2005,Machine Learning,Incremental Estimation of Discrete Hidden Markov Models Based on a New Backward Procedure,"German Florez-Larrahondo, Susan Bridges, Eric A. Hansen","We address the problem of learning discrete hidden Markov models from very long sequences of observations. Incremental versions of the Baum-Welch algorithm that approximate the &beta;-values used in the backward procedure are commonly used for this problem, since their memory complexity is independent of the sequence length. We introduce an improved incremental Baum-Welch algorithm with a new backward procedure that pproximates the &beta;-values based on a one-step lookahead in the training sequence. We justify the new approach analytically, and report empirical results that show it converges faster than previous incremental algorithms.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-119.pdf,Subjects: 12. Machine Learning and Discovery; 12.1 Reinforcement Learning
125,2005,Machine Learning,A Hybrid Generative/Discriminative Approach to Semi-Supervised Classifier Design,"Akinori Fujino, Naonori Ueda, Kazumi Saito","Semi-supervised classifier design that simultaneously utilizes both labeled and unlabeled samples is a major research issue in machine learning. Existing semi-supervised learning methods belong to either generative or discriminative approaches. This paper focuses on probabilistic semi-supervised classifier design and presents a hybrid approach to take advantage of the generative and discriminative approaches. Our formulation considers a generative model trained on labeled samples and a newly introduced bias correction model. Both models belong to the same model family. The proposed hybrid model is constructed by combining both generative and bias correction models based on the maximum entropy principle. The parameters of the bias correction model are estimated by using training data, and combination weights are estimated so that labeled samples are correctly classified. We use naive Bayes models as the generative models to apply the hybrid approach to text classification problems. In our experimental results on three text data sets, we confirmed that the proposed method significantly outperformed pure generative and discriminative methods when the classification performances of the both methods were comparable.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-120.pdf,Subjects: 12. Machine Learning and Discovery
126,2005,Machine Learning,Discriminative Model Selection for Belief Net Structures,"Yuhong Guo, Russ Greiner","Bayesian belief nets (BNs) are often used for classification tasks, typically to return the most likely class label for a specified instance. Many BN-learners, however, attempt to find the BN that maximizes a different objective function --- viz., likelihood, rather than classification accuracy --- typically by first using some model selection criterion to identify an appropriate graphical structure, then finding good parameters for that structure. This paper considers a number of possible criteria for selecting the best structure, both generative (ie, based on likelihood; BIC, BDe) and discriminative (ie, Conditional BIC (CBIC), resubstitution Classification Error (CE) and Bias2+Variance (BV) ). We empirically compare these criteria against a variety of different ``correct BN structures'', both real-world and synthetic, over a range of complexities. We also explore different ways to set the parameters, dealing with two issues: (1) Should we seek the parameters that maximize likelihood versus the ones that maximize conditional likelihood? (2) Should we use (i) the entire training sample first to learn the best parameters and then to evaluate the models, versus (ii) only a partition for parameter estimation and another partition for evaluation (cross-validation)? Our results show that the discriminative BV model selection criterion is one of the best measures for identifying the optimal structure, while the discriminative CBIC performs poorly; that we should use the parameters that maximize likelihood; and that it is typically better to use cross-validation here.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-121.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
127,2005,Machine Learning,Transforming Between Propositions and Features: Bridging the Gap,"Daniel T. Halstead, Kenneth D. Forbus","It is notoriously difficult to simultaneously deal with both probabilistic and structural representations in A.I., particularly because probability necessitates a uniform representation of the training examples. In this paper, we show how to build fully-specified probabilistic models from arbitrary propositional case descriptions about terrorist activities. Our method facilitates both reasoning and learning. Our solution is to use structural analogy to build probabilistic generalizations about those cases. We use these generalizations as a framework for mapping the structural representations, which are well-suited for reasoning, into features, which are well-suited for learning, and back again. Finally, we demonstrate how probabilistic generalizations are an excellent bridge for joining reasoning and learning by using them to perform a traditional machine learning technique, Bayesian network modeling, over arbitrarily high order structural data about terrorist actions, and further, we discuss how this might be used to facilitate automatic knowledge acquisition.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-122.pdf,Subjects: 3.4 Probabilistic Reasoning
128,2005,Machine Learning,Effective Short-Term Opponent Exploitation in Simplified Poker,"Bret Hoehn, Finnegan Southey, Robert C. Holte, Valeriy Bulitko","Uncertainty in poker stems from two key sources, the shuffled deck and an adversary whose strategy is unknown. One approach is to find a pessimistic game theoretic solution (i.e. a Nash equilibrium), but human players have idiosyncratic weaknesses that can be exploited if a model of their strategy can be learned by observing their play. However, games against humans last for at most a few hundred hands so learning must be fast to be effective. We explore two approaches to opponent modelling in the context of Kuhn poker, a small game for which game theoretic solutions are known. Parameter estimation and expert algorithms are both studied. Experiments demonstrate that, even in this small game, convergence to maximally exploitive solutions in a small number of hands is impractical, but that good (i.e. better than Nash or breakeven) performance can be achieved in a short period of time. Finally, we show that amongst a set of strategies with equal game theoretic value, in particular the set of Nash equilibrium strategies, some are preferable because they speed learning of the opponent’s strategy by exploring it more effectively.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-123.pdf,Subjects: 1.8 Game Playing; 12. Machine Learning and Discovery
129,2005,Machine Learning,Non-Stationary Policy Learning in 2-player Zero Sum Games,"Steven Jensen, Daniel Boley, Maria Gini, Paul Schrater","A key challenge in multiagent environments is the construction of agents that are able to learn while acting in the presence of other agents that are simultaneously learning and adapting. These domains require on-line learning methods without the benefit of repeated training examples, as well as the ability to adapt to the evolving behavior of other agents in the environment. The difficulty is further exacerbated when the agents are in an adversarial relationship, demanding that a robust (i.e. winning) non-stationary policy be rapidly learned and adapted. We propose an on-line sequence learning algorithm, ELPH, based on a straightforward entropy pruning technique that is able to rapidly learn and adapt to non-stationary policies. We demonstrate the performance of this method in a non-stationary learning environment of adversarial zero-sum matrix games.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-124.pdf,Subjects: 12. Machine Learning and Discovery
130,2005,Machine Learning,nFOIL: Integrating Naive Bayes and FOIL,"Niels Landwehr, Kristian Kersting, Luc De Raedt","We present the system nFOIL. It tightly integrates the naive Bayes learning scheme with the inductive logic programming rule-learner FOIL. In contrast to previous combinations, which have employed naive Bayes only for post-processing the rule sets, nFOIL employs the naive Bayes criterion to directly guide its search. Experimental evidence shows that nFOIL performs better than both its base line algorithm FOIL or the post-processing approach, and is at the same time competitive with more sophisticated approaches.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-125.pdf,Subjects: 12. Machine Learning and Discovery
131,2005,Machine Learning,Using Modified Lasso Regression to Learn Large Undirected Graphs in a Probabilistic Framework,"Fan Li, Yiming Yang","Learning the structures of large undirected graphs with thousands of nodes from data has been an open challenge. In this paper, we use graphical Gaussian model (GGM) as the underlying model and propose a novel ARD style Wishart prior for the precision matrix of the GGM, which encodes the graph structure we want to learn. With this prior, we can get the MAP estimation of the precision matrix by solving (a modified version of) Lasso regressions and achieve a sparse solution. We use our approach to learn genetic regulatory networks from genome-wide expression microarray data and protein-binding location analysis data. Evaluated on the basis of consistency with the GO annotations, the experiments show that our approach has a much better performance than the clustering-based approaches and BN learning approaches in discovering gene regulatory modules.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-126.pdf,Subjects: 12. Machine Learning and Discovery; 15.7 Search
132,2005,Machine Learning,The Regularized EM Algorithm,"Haifeng Li, Keshu Zhang, Tao Jiang","The EM algorithm heavily relies on the interpretation of observations as incomplete data but it does not have any control on the uncertainty of missing data. To effectively reduce the uncertainty of missing data, we present a regularized EM algorithm that penalizes the likelihood with the mutual information between the missing data and the incomplete data (or the conditional entropy of the missing data given the observations). The proposed method maintains the advantage of the conventional EM algorithm, such as reliable global convergence, low cost per iteration, economy of storage, and ease of programming. We also apply the regularized EM algorithm to fit the finite mixture model. Our theoretical analysis and experiments show that the new method can efficiently fit the models and effectively simplify over-complicated models.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-127.pdf,Subjects: 12. Machine Learning and Discovery
133,2005,Machine Learning,Semi-Supervised Sequence Modeling with Syntactic Topic Models,Wei Li,"Although there has been significant previous work on semi-supervised learning for classification, there has been relatively little in sequence modeling. This paper presents an approach that leverages recent work in manifold-learning on sequences to discover word clusters from language data, including both syntactic classes and semantic topics. From unlabeled data we form a smooth, low-dimensional feature space, where each word token is projected based on its underlying role as a function or content word. We then use this projection as additional input features to a linear-chain conditional random field trained on limited labeled training data. On standard part-of-speech tagging and Chinese word segmentation data sets we show as much as 14\% error reduction due to the unlabeled data, and also statistically-significant improvements over a related semi-supervised sequence tagging method due to Miller et al.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-128.pdf,Subjects: 12. Machine Learning and Discovery; 13. Natural Language Processing
134,2005,Machine Learning,Giving Advice about Preferred Actions to Reinforcement Learners Via Knowledge-Based Kernel Regression,"Richard Maclin, Jude Shavlik, Lisa Torrey, Trevor Walker, Edward Wild","We present a novel formulation for providing advice to a reinforcement learner that employs support-vector regression as its function approximator. Our new method extends a recent advice-giving technique, called Knowledge-Based Kernel Regression (KBKR), that accepts advice concerning a single action of a reinforcement learner. In KBKR, users can say that in some set of states, an action’s value should be greater than some linear expression of the current state. In our new technique, which we call Preference KBKR (Pref-KBKR), the user can provide advice in a more natural manner by recommending that some action is preferred over another in the specified set of states. Specifying preferences essentially means that users are giving advice about policies rather than Q values, which is a more natural way for humans to present advice. We present the motivation for preference advice and a proof of the correctness of our extension to KBKR. In addition, we show empirical results that our method can make effective use of advice on a novel reinforcement-learning task, based on the RoboCup simulator, which we call Breakaway. Our work demonstrates the significant potential of advice-giving techniques for addressing complex reinforcement learning problems, while further demonstrating the use of support-vector regression for reinforcement learning.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-129.pdf,Subjects: 12. Machine Learning and Discovery; 12.1 Reinforcement Learning
135,2005,Machine Learning,Distribution-Free Learning of Bayesian Network Structure in Continuous Domains,Dimitris Margaritis,"In this paper we present a method for learning the structure of Bayesian networks (BNs) without making any assumptions on the probability distribution of the domain. This is mainly useful for continuous domains, where there is little guidance and many choices for the parametric distribution families to be used for the local conditional probabilities of the Bayesian network, and only a few have been examined analytically. We therefore focus on BN structure learning in continuous domains. We address the problem by developing a conditional independence test for continuous variables, which can be readily used by any existing independence-based BN structure learning algorithm. Our test is non-parametric, making no assumptions on the distribution of the domain. We also provide an effective and computationally efficient method for calculating it from data. We demonstrate the learning of the structure of graphical models in continuous domains from real-world data, to our knowledge for the first time using independence-based methods and without distributional assumptions. We also experimentally show that our test compares favorably with existing statistical approaches which use prediscretization, and verify desirable properties such as statistical consistency.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-130.pdf,Subjects: 12. Machine Learning and Discovery
136,2005,Machine Learning,Online Query Relaxation via Bayesian Causal Structures Discovery,"Ion Muslea, Thomas J. Lee","We introduce a novel algorithm, TOQR, for relaxing failed queries over databases, that is, over-constrained DNF queries that return an empty result. TOQR uses a small dataset to discover the implicit relationships among the domain attributes, and then it exploits this domain knowledge to relax the failed query. TOQR starts with a relaxed query that does not include any constraint, and it tries to add to it as many as possible of the original constraints or their relaxations. The order in which the constraints are added is derived from the domain’s causal structure, which is learned by applying the TAN algorithm to the small training dataset. Our experiments show that TOQR clearly outperforms other approaches: even when trained on a handful of examples, it successfully relaxes more that 97% of the failed queries; furthermore, TOQR’s relaxed queries are highly similar to the original failed query.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-131.pdf,Subjects: 12. Machine Learning and Discovery
137,2005,Machine Learning,Redescription Mining: Structure Theory and Algorithms,"Laxmi Parida, Naren Ramakrishnan","We introduce a new data mining problem---redescription mining---that unifies considerations of conceptual clustering, constructive induction, and logical formula discovery. Redescription mining begins with a collection of sets, views it as a propositional vocabulary, and identifies clusters of data that can be defined in at least two ways using this vocabulary. The primary contributions of this paper are conceptual and theoretical: (i) we formally study the space of redescriptions underlying a dataset and characterize their intrinsic structure, (ii) we identify impossibility as well as strong possibility results about when mining redescriptions is feasible, (iii) we present several scenarios of how we can custom-build redescription mining solutions for various biases, and (iv) we outline how many problems studied in the larger machine learning community are really special cases of redescription mining. By highlighting its broad scope and relevance, we aim to establish the importance of redescription mining and make the case for a thrust in this new line of research.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-132.pdf,Subjects: 12. Machine Learning and Discovery
138,2005,Machine Learning,Spectral Clustering of Biological Sequence Data,"William Pentney, Marina Meila","In this paper, we apply spectral techniques to clustering biological sequence data that has proved more difficult to cluster effectively. For this purpose, we have to (1) extend spectral clustering algorithms to deal with asymmetric affinities, like the alignment scores used in the comparison of biological sequences, and (2) devise a hierarchical algorithm that can handle many clusters with imbalanced sizes robustly. We present an algorithm for clustering asymmetric affinity data, and demonstrate the performance of this algorithm at recovering the higher levels of the Structural Classification of Proteins (SCOP) on a data base of highly conserved subsequences.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-133.pdf,Subjects: 12. Machine Learning and Discovery; 12.2 Scientific Discovery
139,2005,Machine Learning,Enhanced Direct Linear Discriminant Analysis for Feature Extraction on High Dimensional Data,"A. K. Qin, S. Y. M. Shi, P. N. Suganthan, M. Loog","We present an enhanced direct linear discriminant analysis (EDLDA) solution to effectively and efficiently extract discriminatory features from high dimensional data. The EDLDA integrates two types of class-wise weighting terms in estimating the average within-class and between-class scatter matrices in order to relate the resulting Fisher criterion more closely to the minimization of classification error. Furthermore, the extracted discriminant features are weighted by mutual information between features and class labels. Experimental results on four biometric datasets demonstrate the promising performance of the proposed method.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-134.pdf,Subjects: 12. Machine Learning and Discovery; 19. Vision
140,2005,Machine Learning,A Maximum Likelihood Framework for Integrating Taxonomies,"Suju Rajan, Kunal Punera , Joydeep Ghosh","Many approaches have been proposed for the problem of mapping categories (classes)from a source taxonomy to classes in a master taxonomy. Most of these techniques, however, ignore the hierarchical structure of the taxonomies. In this paper, we propose a maximum likelihood based framework which exploits the hierarchical structure to obtain a more natural mapping between the source classes and the master taxonomy. Furthermore, unlike previous work, our technique also inserts source classes into appropriate places of the master hierarchy creating new categories if required. We evaluate our approach on text and hyperspectral datasets.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-000.pdf,Subjects: 12. Machine Learning and Discovery; 11.2 Ontologies
141,2005,Machine Learning,Constraint-Based Entity Matching,"Warren Shen, Xin Li, AnHai Doan","Entity matching is the problem of deciding if two given mentions in the data, such as ""Helen Hunt"" and ""H. M. Hunt"", refer to the same real-world entity. Numerous solutions have been developed, but they have not considered in depth the problem of exploiting integrity constraints that frequently exist in the domains. Examples of such constraints include ""a mention with age two cannot match a mention with salary 200K"" and ""if two paper citations match, then their authors are likely to match in the same order"". In this paper we describe a probabilistic solution to entity matching that exploits such constraints to improve matching accuracy. At the heart of the solution is a generative model that takes into account the constraints during the generation process, and provides well-defined interpretations of the constraints. We describe a novel combination of EM and relaxation labeling algorithms that efficiently learns the model, thereby matching mentions in an unsupervised way, without the need for annotated training data. Experiments on several real-world domains show that our solution can exploit constraints to significantly improve matching accuracy, by 3-12 percent F-1, and that the solution scales up to large data sets.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-136.pdf,Subjects: 12. Machine Learning and Discovery
142,2005,Machine Learning,Discriminative Training of Markov Logic Networks,"Parag Singla, Pedro Domingos","Many machine learning applications require a combination of probability and first-order logic. Markov logic networks (MLNs) accomplish this by attaching weights to first-order clauses, and viewing these as templates for features of Markov networks. Model parameters (i.e., clause weights) can be learned by maximizing the likelihood of a relational database, but this can be quite costly and lead to suboptimal results for any given prediction task. In this paper we propose a discriminative approach to training MLNs, one which optimizes the conditional likelihood of the query predicates given the evidence ones, rather than the joint likelihood of all predicates. We extend Collins’s (2002) voted perceptron algorithm for HMMs to MLNs by replacing the Viterbi algorithm with a weighted satisfiability solver. Experiments on entity resolution and link prediction tasks show the advantages of this approach compared to generative MLN training, as well as compared to purely probabilistic and purely logical approaches.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-137.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
143,2005,Machine Learning,Representing Conditional Independence Using Decision Trees,"Jiang Su, Harry Zhang","While the representation of decision trees is fully expressive theoretically, it has been observed that traditional decision trees has the replication problem. This problem makes decision trees to be large and learnable only when sufficient training data are available. In this paper, we present a new representation model, conditional independence trees (CITrees), to tackle the replication problem from probability perspective. We propose a novel algorithm for learning CITrees. Our experiments show that CITrees outperform naive Bayes, C4.5, TAN, and AODE significantly in classification accuracy.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-138.pdf,Subjects: 15.6 Decision Trees; 12. Machine Learning and Discovery
144,2005,Machine Learning,Value Functions for RL-Based Behavior Transfer: A Comparative Study,"Matthew E. Taylor, Peter Stone, Yaxin Liu","Temporal difference (td) learning methods have become popular reinforcement learning techniques in recent years. td methods, relying on function approximators to generalize learning to novel situations, have had some experimental successes and have been shown to exhibit some desirable properties in theory, but have often been found slow in practice. This paper presents methods for further generalizing across tasks, thereby speeding up learning, via a novel form of behavior transfer. We compare learning on a complex task with three function approximators, a CMAC, a neural network, and an RBF, and demonstrate that behavior transfer works well with all three. Using behavior transfer, agents are able to learn one task and then markedly reduce the time it takes to learn a more complex task. Our algorithms are fully implemented and tested in the RoboCup-soccer keepaway domain.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-139.pdf,Subjects: 12.1 Reinforcement Learning; 7.1 Multi-Agent Systems
145,2005,Machine Learning,Online Resource Allocation Using Decompositional Reinforcement Learning,Gerald Tesauro,"This paper considers a novel application domain for reinforcement learning: that of ""autonomic computing,"" i.e. self-managing computing systems. RL is applied to an online resource allocation task in a distributed multi-application computing environment with independent time-varying load in each application. The task is to allocate servers in real time so as to maximize the sum of performance-based expected utility in each application. This task may be treated as a composite MDP, and to exploit the problem structure, a simple localized RL approach is proposed, with better scalability than previous approaches. The RL approach is tested in a realistic prototype data center comprising real servers, real HTTP requests, and realistic time-varying demand. This domain poses a number of major challenges associated with live training in a real system, including: the need for rapid training, exploration that avoids excessive penalties, and handling complex, potentially non-Markovian system effects. The early results are encouraging: in overnight training, RL performs as well as or slightly better than heavily researched model-based approaches derived from queuing theory.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-140.pdf,Subjects: 12.1 Reinforcement Learning; 1. Applications
146,2005,Machine Learning,Inducing Hierarchical Process Models in Dynamic Domains,"Ljupco Todorovski, Will Bridewell, Oren Shiran, Pat Langley","Research on inductive process modeling combines background knowledge with time-series data to construct explanatory models, but previous work has placed few constraints on search through the model space. We present an extended formalism that organizes process knowledge in a hierarchical manner, and we describe HIPM, a system that carries out constrained search for hierarchical process models. We report experiments that suggest this approach produces more accurate and plausible models with less effort. We conclude by discussing related research and directions for future work.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-141.pdf,Subjects: 12.2 Scientific Discovery
147,2005,Machine Learning,Software Testing by Active Learning for Commercial Games,"Gang Xiao, Finnegan Southey, Robert C. Holte, Dana Wilkinson","As software systems have become larger, exhaustive testing has become increasingly onerous. This has rendered statistical software testing and machine learning techniques increasingly attractive. Drawing from both of these, we present an active learning framework for blackbox software testing. The active learning approach samples input/output pairs from a blackbox and learns a model of the system’s behaviour. This model is then used to select new inputs for sampling. This framework has been developed in the context of commercial video games, complex virtual worlds with high-dimensional state spaces, too large for exhaustive testing. Beyond its correctness, developers need to evaluate the gameplay of a game, properties such as difficulty. We use the learned model not only to guide sampling but also to summarize the game’s behaviour for the developer to evaluate. We present results from our semi-automated gameplay analysis by machine learning (SAGA-ML) tool applied to Electronics Arts’ FIFA Soccer game.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-142.pdf,Subjects: 12. Machine Learning and Discovery; 1. Applications
148,2005,Machine Learning,Unsupervised and Semi-Supervised Multi-class Support Vector Machines,"Linli Xu, Dale Schuurmans","We present new unsupervised and semi-supervised training algorithms for multi-class support vector machines based on semidefinite programming. Although support vector machines (SVMs) have been a dominant machine learning technique for the past decade, they have generally been applied to supervised learning problems. Developing unsupervised extensions to SVMs has in fact proved to be difficult. In this paper, we present a principled approach to unsupervised SVM training by formulating convex relaxations of the natural training criterion: find a labeling that would yield an optimal SVM classifier on the resulting training data. The problem is hard, but semidefinite relaxations can approximate this objective surprisingly well. While previous work has concentrated on the two-class case, we present a general, multi-class formulation that can be applied to a wider range of natural data sets. The resulting training procedures are computationally intensive, but produce high quality generalization results.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-143.pdf,Subjects: 12. Machine Learning and Discovery
149,2005,Machine Learning,Learning Planning Rules in Noisy Stochastic Worlds,"Luke S. Zettlemoyer, Hanna M. Pasula, Leslie Pack Kaelbling","We present an algorithm for learning a model of the effects of actions in noisy stochastic worlds. We consider learning in a 3D simulated blocks world with realistic physics. To model this world, we develop a planning representation with explicit mechanisms for expressing object reference and noise. We then present a learning algorithm that can create rules while also learning derived predicates, and evaluate this algorithm in the blocks world simulator, demonstrating that we can learn rules that effectively model the world dynamics.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-144.pdf,Subjects: 12. Machine Learning and Discovery; 1.11 Planning
150,2005,Machine Learning,Hidden Naive Bayes,"Harry Zhang, Liangxiao Jiang, Jiang Su","The conditional independence assumption of naive Bayes essentially ignores attribute dependencies and is often violated. On the other hand, although a Bayesian network can represent arbitrary attribute dependencies, learning an optimal Bayesian network from data is intractable. The main reason is that learning the optimal structure of a Bayesian network is extremely time consuming. Thus, a Bayesian model without structure learning is desirable. In this paper, we propose a novel model, called hidden naive Bayes (HNB). In an HNB, a hidden parent is created for each attribute which combines the influences from all other attributes. We present an approach to creating hidden parents using the average of weighted one-dependence estimators. HNB inherits the structural simplicity of naive Bayes and can be easily learned without structure learning. We propose an algorithm for learning HNB based on conditional mutual information. We experimentally test HNB in terms of classification accuracy, using the 36 UCI data sets recommended by Weka, and compare it to naive Bayes, C4.5, SBC, NBTree, CL-TAN, and AODE. The experimental results show that HNB outperforms naive Bayes, C4.5, SBC, NBTree, and CL-TAN, and is competitive with AODE.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-145.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
151,2005,Machine Learning,Finite Sample Error Bound for Parzen Windows,"Peng Zhang, Jing Peng,Norbert Riedel","Parzen Windows as a nonparametric method has been applied to a variety of density estimation as well as classification problems. Similar to nearest neighbor methods, Parzen Windows does not involve learning. While it converges to true but unknown probability densities in the asymptotic limit, there is a lack of theoretical analysis on its performance with finite samples. In this paper we establish a finite sample error bound for Parzen Windows. We first show that Parzen Windows is an approximation to regularized least squares (RLS) methods that have been well studied in statistical learning theory. We then derive the finite sample error bound for Parzen Windows, and discuss the properties of the error bound and its relationship to the error bound for RLS. This analysis provides interesting insight to Parzen Windows as well as the nearest neighbor method from the point of view of learning theory. Finally, we provide empirical results on the performance of Parzen Windows and other methods such as nearest neighbors, RLS and SVMs on a number of real data sets. These results corroborate well our theoretical analysis.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-146.pdf,Subjects: 9.3 Mathematical Foundations; 9. Foundational Issues
152,2005,Machine Perception,Cross-Modal Clustering,Michael H. Coen,"This paper presents a self-supervised algorithm for learning perceptual structures based upon correlations in different sensory modalities. The brain and cognitive sciences have gathered an enormous body of neurological and phenomenological evidence in the past half century that demonstrates the extraordinary degree of interaction between sensory modalities during the course of ordinary perception. This paper presents a new framework for creating artificial perceptual systems inspired by these findings, where the primary architectural motif is the cross-modal transmission of perceptual information to enhance each sensory channel individually. The basic hypothesis underlying this approach is that the world has regularities -- natural laws tend to correlate physical properties -- and biological perceptory systems have evolved to take advantage of this. They share information continually and opportunistically across seemingly disparate perceptual channels, not epiphenomenologically, but rather as a fundamental component of normal perception. It is therefore essential that their artificial counterparts be able to share information synergistically within their perceptual channels, if they are to approach degrees of biological sophistication. This paper is a preliminary step in that direction.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-147.pdf,Subjects: 19.1 Perception; 12. Machine Learning and Discovery
153,2005,Machine Perception,A Computational Model of the Cerebral Cortex,Thomas Dean,"Our current understanding of the primate cerebral cortex (neocortex) and in particular the posterior, sensory association cortex has matured to a point where it is possible to develop a family of graphical models that capture the structure, scale and power of the neocortex for purposes of associative recall, sequence prediction and pattern completion among other functions. Implementing such models using readily available computing clusters is now within the grasp of many labs and would provide scientists with the opportunity to experiment with both hard-wired connection schemes and structure-learning algorithms inspired by animal learning and developmental studies. While neural circuits involving structures external to the neocortex such as the thalamic nuclei are less well understood, the availability of a computational model on which to test hypotheses would likely accelerate our understanding of these circuits. Furthermore, the existence of an agreed-upon cortical substrate would not only facilitate our understanding of the brain but enable researchers to combine lessons learned from biology with state-of-the-art graphical-model and machine-learning techniques to design hybrid systems that combine the best of biological and traditional computing approaches.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-148.pdf,Subjects: 3.4 Probabilistic Reasoning; 4. Cognitive Modeling
154,2005,Machine Perception,Data-Driven MCMC for Learning and Inference in Switching Linear Dynamic Systems,"Sangmin Oh, James M. Rehg, Tucker Balch, Frank Dellaet","Switching Linear Dynamic System (SLDS) models are a popular technique for modeling complex nonlinear dynamic systems. An SLDS has significantly more descriptive power than an HMM, but inference in SLDS models is computationally intractable. This paper describes a novel inference algorithm for SLDS models based on the Data-Driven MCMC paradigm. We describe a new proposal distribution which substantially increases the convergence speed. Comparisons to standard deterministic approximation methods demonstrate the improved accuracy of our new approach. We apply our approach to the problem of learning an SLDS model of the bee dance. Honeybees communicate the location and distance to food sources through a dance that takes place within the hive. We learn SLDS model parameters from tracking data which is automatically extracted from video. We then demonstrate the ability to successfully segment novel bee dances into their constituent parts, effectively decoding the dance of the bees.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-149.pdf,Subjects: 3.4 Probabilistic Reasoning; 19.1 Perception
155,2005,Machine Perception,Function-Based Classification from 3D Data via Generic and Symbolic Models,"Michael Pechuk, Octavian Soldea, Ehud Rivlin","We propose a novel scheme for function-based classification of objects in 3D images. The classification process calls for constructing a generic multi-level hierarchical description of object classes in terms of functional components. Functionality is derived from a large set of geometric attributes and relationships between object parts. Initially, the input range data describing each object instance is segmented, each object part is labeled as one of a few possible primitives, and each group of primitive parts is tagged by a functional symbol. Connections between primitive parts and functional parts at the same level in the hierarchy are labeled as well. Then, the generic multi-level hierarchical description of object classes is built using the functionalities of a number of object instances. During classification, a search through a finite graph using a probabilistic fitness measure is performed to find the best assignment of object parts to the functional structures of each class. An object is assigned to a class providing the highest fitness value. The scheme does not require a-priori knowledge about any class. We tested the proposed scheme on a database of about one thousand different 3D objects. The results show high accuracy in classification.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-150.pdf,Subjects: 19. Vision; 19.1 Perception
156,2005,Machine Perception,Learning Static Object Segmentation from Motion Segmentation,"Michael G. Ross, Leslie Pack Kaelbling","Dividing an image into its constituent objects can be a useful first step in many visual processing tasks, such as object classification or determining the arrangement of obstacles in an environment. Motion segmentation is a rich source of training data for learning to segment objects by their static image properties. Background subtraction can distinguish between moving objects and their surroundings, and the techniques of statistical machine learning can capture information about objects’ shape, size, color, brightness, and texture properties. Presented with a new, static image, the trained model can infer the proper segmentation of the objects present in a scene. The algorithm presented in this work uses the techniques of Markov random field modeling and belief propagation inference, outperforms a standard segmentation algorithm on an object segmentation task, and outperforms a learned boundary detector at determining object boundaries on the test data.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-151.pdf,Subjects: 19. Vision; 12. Machine Learning and Discovery
157,2005,Machine Perception,Semantic Scene Concept Learning by an Autonomous Agent,Weiyu Zhu,"Scene understanding addresses the issue of ""what a scene contains?"" Existing research on scene understanding is typically focused on classifying a scene into classes that are of the same category type. These approaches, although they solve some scene-understanding tasks successfully, in general fail to address the semantics in scene understanding. For example, how does an agent learn the concept label ""red"" and ""ball"" without being told that it is a color or a shape label in advance? To cope with this problem, we have proposed a novel research called semantic scene concept learning. Our proposed approach models the task of scene understanding as a ""multilabeling"" classification problem. Each scene instance perceived by the agent may receive multiple labels coming from different concept categories, where the goal of learning is to let the agent discover the semantic meanings, i.e., the set of relevant visual features, of the scene labels received. Our preliminary experiments have shown the effectiveness of our proposed approach in solving this special intra- and inter- category mixing learning task.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-152.pdf,Subjects: 14. Neural Networks; 12. Machine Learning and Discovery
158,2005,Markov Decision Processes and Uncertainty,A Particle Filtering Based Approach to Approximating Interactive POMDPs,"Prashant Doshi, Piotr J. Gmytrasiewicz","POMDPs provide a principled framework for sequential planning in single agent settings. An extension of POMDPs to multiagent settings, called interactive POMDPs (I-POMDPs), replaces POMDP belief spaces with interactive hierarchical belief systems which represent an agent’s belief about the physical world, about beliefs of the other agent(s), about their beliefs about others’ beliefs, and so on. This modification makes the difficulties of obtaining solutions due to complexity of the belief and policy spaces even more acute. We describe a method for obtaining approximate solutions to I-POMDPs based on particle filtering (PF). We utilize the  interactive PF  which descends the levels of interactive belief hierarchies and samples and propagates beliefs at each level. The interactive PF is able to deal with the belief space complexity, but it does not address the policy space complexity. We provide experimental results and chart future work.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-153.pdf,Subjects: 7.1 Multi-Agent Systems; 1.11 Planning
159,2005,Markov Decision Processes and Uncertainty,Efficient Maximization in Solving POMDPs,"Zhengzhu Feng, Shlomo Zilberstein","We present a simple, yet effective improvement to the dynamic programming algorithm for solving partially observable Markov decision processes. The technique targets the vector pruning operation during the maximization step, a key source of complexity in POMDP algorithms. We identify two types of structures in the belief space and exploit them to reduce significantly the number of constraints in the linear programs used for pruning. The benefits of the new technique are evaluated both analytically and experimentally, showing that it can lead to significant performance improvement. The results open up new research opportunities to enhance the performance and scalability of several POMDP algorithms.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-154.pdf,Subjects: 1.11 Planning; 3.4 Probabilistic Reasoning
160,2005,Markov Decision Processes and Uncertainty,Extending Continuous Time Bayesian Networks,"Karthik Gopalratnam, Henry Kautz, Daniel S. Weld","Continuous-time Bayesian networks (CTBNs), are an elegant modeling language for structured stochastic processes that evolve over continuous time. The CTBN framework is based on homogeneous Markov processes, and defines two distributions with respect to each local variable in the system, given its parents: an exponential distribution over when the variable transitions, and a multinomial over what is the next value. In this paper, we present two extensions to the framework that make it more useful in modeling practical applications. The first extension models arbitrary transition time distributions using Erlang-Coxian approximations, while maintaining tractable learning. We show how the censored data problem arises in learning the distribution, and present a solution based on expectation-maximization initialized by the Kaplan-Meier estimate. The second extension is a general method for reasoning about negative evidence, by introducing updates that assert no observable events occur over an interval of time. Such updates were not defined in the original CTBN framework, and we show show that their inclusion can significantly improve the accuracy of filtering and prediction. We illustrate and evaluate these extensions in two real-world domains, email use and GPS traces of a person traveling about a city.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-155.pdf,Subjects: 3.6 Temporal Reasoning; 3.4 Probabilistic Reasoning
161,2005,Markov Decision Processes and Uncertainty,Planning in Models that Combine Memory with Predictive Representations of State,"Michael R. James, Satinder Singh","Models of dynamical systems based on predictive state representations (PSRs) use predictions of future observations as their representation of state. A main departure from traditional models such as partially observable Markov decision processes (POMDPs) is that the PSR-model state is composed entirely of observable quantities. PSRs have recently been extended to a class of models called memory-PSRs (mPSRs) that use both memory of past observations and predictions of future observations in their state representation. Thus, mPSRs preserve the PSR-property of the state being composed of observable quantities while potentially revealing structure in the dynamical system that is not exploited in PSRs. In this paper, we demonstrate that the structure captured by mPSRs can be exploited quite naturally for stochastic planning based on value-iteration algorithms. In particular, we adapt the incremental-pruning (IP) algorithm defined for planning in POMDPs to mPSRs. Our empirical results show that our modified IP on mPSRs outperforms, in most cases, IP on both PSRs and POMDPs.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-156.pdf,Subjects: 12.1 Reinforcement Learning; 3.4 Probabilistic Reasoning
162,2005,Markov Decision Processes and Uncertainty,Risk-Sensitive Planning with One-Switch Utility Functions: Value Iteration,"Yaxin Liu, Sven Koenig","Decision-theoretic planning with nonlinear utility functions is important since decision makers are often risk-sensitive in high-stake planning situations. One-switch utility functions are an important class of nonlinear utility functions that can model decision makers whose decisions change with their wealth level. We study how to maximize the expected utility of a Markov decision problem for a given one-switch utility function, which is difficult since the resulting planning problem is not decomposable. We first study an approach that augments the states of the Markov decision problem with the wealth level. The properties of the resulting infinite Markov decision problem then allow us to generalize the standard risk-neutral version of value iteration from manipulating values to manipulating functions that map wealth levels to values. We use a probabilistic blocks-world example to demonstrate that the resulting risk-sensitive version of value iteration is practical.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-157.pdf,Subjects: 1.11 Planning; 15.5 Decision Theory
163,2005,Markov Decision Processes and Uncertainty,Samuel Meets Amarel: Automating Value Function Approximation using Global State Space Analysis,Sridhar Mahadevan,"Most work on value function approximation adheres to Samuel’s original design: agents learn a task-specific value function using parameter estimation, where the approximation architecture (e.g, polynomials) is specified by a human designer. This paper proposes a novel framework generalizing Samuel’s paradigm using a coordinate-free approach to value function approximation. Agents learn both representations and value functions by constructing geometrically customized task-independent basis functions that form an orthonormal set for the Hilbert space of smooth functions on the underlying state space manifold. The approach rests on a technical result showing that the space of smooth functions on a (compact) Riemanian manifold has a discrete spectrum associated with the Laplace-Beltrami operator. In the discrete setting, spectral analysis of the graph Laplacian yields a set of geometrically customized basis functions for approximating and decomposing value functions. The proposed framework generalizes Samuel’s value function approximation paradigm by combining it with a formalization of Saul Amarel’s paradigm of representation learning through global state space analysis.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-158.pdf,Subjects: 12.1 Reinforcement Learning; 12. Machine Learning and Discovery
164,2005,Markov Decision Processes and Uncertainty,Error Bounds for Approximate Value Iteration,Rémi Munos,"Approximate Value Iteration (AVI) is an method for solving a Markov Decision Problem by making successive calls to a supervised learning (SL) algorithm. Sequence of value representations Vn are processed iteratively by Vn+1 = A T Vn where T is the Bellman operator and A an approximation operator. Bounds on the error between the performance of the policies induced by the algorithm and the optimal policy are given as a function of weighted L_p-norms (p>=1) of the approximation errors. The results extend usual analysis in L_infinity-norm, and allow to relate the performance of AVI to the approximation power (usually expressed in L_p-norm, for p=1 or 2) of the SL algorithm. We illustrate the tightness of these bounds on an optimal replacement problem.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-159.pdf,Subjects: 12.1 Reinforcement Learning; 9.3 Mathematical Foundations
165,2005,Markov Decision Processes and Uncertainty,Geometric Variance Reduction in Markov Chains. Application to Value Function and Gradient Estimation,Rémi Munos,"We study a sequential variance reduction technique for Monte Carlo estimation of functionals in Markov Chains. The method is based on designing sequential control variates using successive approximations of the function of interest V. Regular Monte Carlo estimates have a variance of O(1/N), where N is the number of samples. Here, we obtain a geometric variance reduction O(r^N) (with r < 1) up to a threshold that depends on the approximation error V - AV, where A is an approximation operator linear in the values. Thus, if V belongs to the right approximation space (i.e. AV=V), the variance decreases geometrically to zero. An immediate application is value function estimation in Markov chains, which may be used for policy evaluation in policy iteration for Markov Decision Processes. Another important domain, for which variance reduction is highly needed, is gradient estimation, that is computing the sensitivity of the performance measure V with respect to some parameter of the transition probabilities. For example, in parametric optimization of the policy, an estimate of the policy gradient is required to perform a gradient optimization method. We show that, using two approximations, the value function and the gradient, a geometric variance reduction is also achieved, up to a threshold that depends on the approximation errors of both of those representations.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-160.pdf,Subjects: 12.1 Reinforcement Learning; 9.2 Computational Complexity
166,2005,Markov Decision Processes and Uncertainty,Modeling Form for On-line Following of Musical Performances,"Bryan Pardo, William Birmingham","Automated musical accompaniment of human performers often requires an agent be able to follow a musical score with similar facility to that of a human performer. Systems described in the literature represent musical scores in a way that assumes no large-scale structural variation of the piece during performance. If the performer deviates from the expected path by skipping or repeating a section, the system may become lost. We describe a way to automatically generate a Markov model from a written score that models the score form, and an on-line algorithm to align a performance to a score. The resulting system can follow performances that take alternate paths through the score without losing its place. We compare the performance of our system to that of sequence-based score followers on a melodic corpus of 98 Jazz melodies. Results show that explicitly representing the branching structure of a score significantly improves score following when the branch a performer may take is unknown beforehand.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-161.pdf,Subjects: 1.1 Art And Music
167,2005,Markov Decision Processes and Uncertainty,Improving Action Selection in MDP’s via Knowledge Transfer,"Alexander A. Sherstov, Peter Stone","Temporal-difference reinforcement learning (RL) has been successfully applied in several domains with large state sets. Large action sets, however, have received considerably less attention. This paper demonstrates the use of knowledge transfer between related tasks to accelerate learning with large action sets. We introduce action transfer, a technique that extracts the actions from the (near-)optimal solution to the first task and uses them in place of the full action set when learning any subsequent tasks. When optimal actions make up a small fraction of the domain’s action set, action transfer can substantially reduce the number of actions and thus the complexity of the problem. However, action transfer between dissimilar tasks can be detrimental. To address this difficulty, we contribute randomized task perturbation (RTP), an enhancement to action transfer that makes it robust to unrepresentative source tasks. We motivate RTP action transfer with a detailed theoretical analysis featuring a formalism of related tasks and a bound on the suboptimality of action transfer. The empirical results in this paper show the potential of RTP action transfer to substantially expand the applicability of RL to problems with large action sets.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-162.pdf,Subjects: 12.1 Reinforcement Learning; 12. Machine Learning and Discovery
168,2005,Markov Decision Processes and Uncertainty,Planning and Execution with Phase Transitions,H&aring;kan L. S. Younes,"We consider a special type of continuous-time Markov decision processes (MDPs) that arise when phase-type distributions are used to model the timing of non-Markovian events and actions. We focus, primarily, on the execution of phase-dependent policies. Phases are introduced into a model to represent relevant execution history, but there is no physical manifestation of phases in the real world. We treat phases as partially observable state features and show how a belief distribution over phase configurations can be derived from observable state features through the use of transient analysis for Markov chains. This results in an efficient method for phase tracking during execution that can be combined with the QMDP value method for POMDPs to make action choices. We also discuss, briefly, how the structure of MDPs with phase transitions can be exploited in structured value iteration with symbolic representation of vectors and matrices.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-163.pdf,Subjects: 1.11 Planning; 3.4 Probabilistic Reasoning
169,2005,Natural Language Processing and Speech Recognition,Scaling Up Word Sense Disambiguation via Parallel Texts,"Yee Seng Chan, Hwee Tou Ng","A critical problem faced by current supervised WSD systems is the lack of manually annotated training data. Tackling this data acquisition bottleneck is crucial, in order to build high accuracy and wide-coverage WSD systems. In this paper, we show that the approach of automatically gathering training examples from parallel texts is scalable to a large set of nouns. We conducted evaluation on the nouns of SENSEVAL-2 English all-words task, using fine-grained sense scoring. Our evaluation shows that training on examples gathered from 680MB of parallel texts achieves accuracy comparable to the best system of SENSEVAL-2 English all-words task, and significantly outperforms the baseline of always choosing sense 1 of WordNet.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-164.pdf,Subjects: 13. Natural Language Processing
170,2005,Natural Language Processing and Speech Recognition,An Inference Model for Semantic Entailment in Natural Language,"Rodrigo de Salvo Braz, Roxana Girju, Vasin Punyakanok, Dan Roth, Mark Sammons",Semantic entailment is the problem of determining if the meaning of a given sentence entails that of another. This is a fundamental problem in natural language understanding that provides a broad framework for studying language variability and has a large number of applications. This paper presents a principled approach to this problem that builds on inducing representations of text snippets into a hierarchical knowledge representation along with a sound optimization-based inferential mechanism that makes use of it to decide semantic entailment. A preliminary evaluation on the PASCAL text collection is presented.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-165.pdf,Subjects: 13. Natural Language Processing
171,2005,Natural Language Processing and Speech Recognition,A Probabilistic Classification Approach for Lexical Textual Entailment,"Oren Glickman, Ido Dagan, Moshe Koppel",The textual entailment task - determining if a given text entails a given hypothesis - provides an abstraction of applied semantic inference. This paper describes first a general generative probabilistic setting for textual entailment. We then focus on the sub-task of recognizing whether the lexical concepts present in the hypothesis are entailed from the text. This problem is recast as one of text categorization in which the classes are the vocabulary words. We make novel use of Naïve Bayes to model the problem in an entirely unsupervised fashion. Empirical tests suggest that the method is effective and compares favorably with state-of-the-art heuristic scoring approaches.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-166.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
172,2005,Natural Language Processing and Speech Recognition,Clustering and Classifying Person Names by Origin,"Fei Huang, Stephan Vogel, Alex Waibel","In natural language processing, information about a person’s geographical origin is an important feature for name entity transliteration and question answering. We propose a language-independent name origin clustering and classification framework. Provided with a small amount of bilingual name translation pairs with labeled origins, we measure origin similarities based on the perplexities of name character language and translation models. We group similar origins into clusters, then train a Bayesian classifier with different features. It achieves 84% classification accuracy with source names only, and 91% with both source and target name pairs. We apply the origin clustering and classification technique to a name transliteration task. The cluster-specific transliteration model dramatically improves the transliteration accuracy from 3.8% to 55%, reducing the transliteration character error rate from 50.3 to 13.5. Adding more unlabeled name pairs to the cluster-specific name transliteration model further improves the transliteration accuracy.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-167.pdf,Subjects: 13. Natural Language Processing; 13.2 Machine Translation
173,2005,Natural Language Processing and Speech Recognition,Learning to Transform Natural to Formal Languages,"Rohit J. Kate, Yuk Wah Wong, Raymond J. Mooney","This paper presents a method for inducing transformation rules that map natural-language sentences into a formal query or command language. The approach assumes a formal grammar for the target representation language and learns transformation rules that exploit the non-terminal symbols in this grammar. The learned transformation rules incrementally map a natural-language sentence or its syntactic parse tree into a parse-tree for the target formal language. Experimental results are presented for two corpora, one which maps English instructions into an existing formal coaching language for simulated RoboCup soccer agents, and another which maps English U.S.-geography questions into a database query language. We show that our method performs overall better and faster than previous approaches in both domains.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-168.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
174,2005,Natural Language Processing and Speech Recognition,Impact of Linguistic Analysis on the Semantic Graph Coverage and Learning of Document Extracts,"Jure Leskovec, Natasa Milic-Frayling, Marko Grobelnik","Automatic document summarization is a problem of creating a document surrogate that adequately represents the full document content. We aim at a summarization system that can replicate the quality of summaries created by humans. In this paper we investigate the machine learning method for extracting full sentences from documents based on the document semantic graph structure. In particular, we explore how the Support Vector Machines (SVM) learning method is affected by the quality of linguistic analyses and the corresponding semantic graph representations. We apply two types of linguistic analysis: (1) a simple part-of-speech tagging of noun phrases and verbs and (2) full logical form analysis which identifies Subject-Predicate-Object triples, and then build the semantic graphs. We train the SVM classifier to identify summary nodes and use these nodes to extract sentences. Experiments with the DUC 2002 and CAST datasets show that the SVM based extraction of sentences does not differ significantly for the simple and the sophisticated syntactic analysis. In both cases the graph attributes used in learning are essential for the classifier performance and the quality of extracted summaries.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-169.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
175,2005,Natural Language Processing and Speech Recognition,Unsupervised Multilingual Word Sense Disambiguation via an Interlingua,"Kornel Marko, Stefan Schulz, Udo Hahn",We present an unsupervised method for resolving word sense ambiguities in one language by using statistical evidence assembled from other languages. It is crucial for this approach that texts are mapped into a language-independent interlingual representation. We also show that the coverage and accuracy resulting from multilingual sources outperform analyses where only monolingual training data is taken into account.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-170.pdf,Subjects: 13. Natural Language Processing; 13.2 Machine Translation
176,2005,Natural Language Processing and Speech Recognition,Supervised Ranking for Pronoun Resolution: Some Recent Improvements,Vincent Ng,"A recently-proposed machine learning approach to reference resolution --- the twin-candidate approach --- has been shown to be more promising than the traditional single-candidate approach. This paper presents a pronoun interpretation system that extends the twin-candidate framework by (1) equipping it with the ability to identify non-referential pronouns, (2) training different models for handling different types of pronouns, and (3) incorporating linguistic knowledge sources that are generally not employed in traditional pronoun resolvers. The resulting system, when evaluated on a standard coreference corpus, outperforms not only the original twin-candidate approach but also a state-of-the-art pronoun resolver.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-171.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
177,2005,Natural Language Processing and Speech Recognition,Cross-Lingual Bootstrapping of Semantic Lexicons: The Case of FrameNet,"Sebastian Pado, Mirella Lapata","This paper considers the problem of unsupervised semantic lexicon acquisition. We introduce a fully automatic approach which exploits parallel corpora, relies on shallow text properties, and is relatively inexpensive. Given the English FrameNet lexicon, our method exploits word alignments to generate frame candidate list for new languages, which are subsequently pruned automatically using a small set of linguistically motivated filters. Evaluation shows that our approach can produce high-precision multilingual FrameNet lexicons without recourse to bilingual dictionaries or deep syntactic and semantic analysis.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-172.pdf,Subjects: 13. Natural Language Processing; 11.2 Ontologies
178,2005,Natural Language Processing and Speech Recognition,Word Sense Disambiguation with Semi-Supervised Learning,"Thanh Phong Pham, Hwee Tou Ng, Wee Sun Lee",Content Area:  14. Natural Language Processing & Speech Recognition,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-173.pdf,Subjects: 13. Natural Language Processing
179,2005,Natural Language Processing and Speech Recognition,Robust Textual Inference via Learning and Abductive Reasoning,"Rajat Raina, Andrew Y. Ng, Christopher D. Manning","We present a system for textual inference (the task of inferring whether a sentence follows from another text) that uses learning and a logical-formula semantic representation of the text. More precisely, our system begins by parsing and then transforming sentences into a logical formula-like representation similar to the one used by (Harabagiu et al., 2000). An abductive theorem prover then tries to find the minimum ``cost'' set of assumptions necessary to show that one statement follows from the other. These costs reflect how likely different assumptions are, and are learned automatically using information from syntactic/semantic features and from linguistic resources such as WordNet. If one sentence follows from the other given only highly plausible, low cost assumptions, then we conclude that it can be inferred. Our approach can be viewed as combining statistical machine learning and classical logical reasoning, in the hope of marrying the robustness and scalability of learning with the preciseness and elegance of logical theorem proving. We give experimental results from the recent PASCAL RTE 2005 challenge competition on recognizing textual inferences, where a system using this inference algorithm achieved the highest confidence weighted score.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-174.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
180,2005,Natural Language Processing and Speech Recognition,Exploiting Subjectivity Classification to Improve Information Extraction,"Ellen Riloff, Janyce Wiebe, William Phillips","Information extraction (IE) systems are prone to false hits for a variety of reasons and we observed that many of these false hits occur in sentences that contain subjective language (e.g., opinions, emotions, and sentiments). Motivated by these observations, we explore the idea of using subjectivity analysis to improve the precision of information extraction systems. In this paper, we describe an IE system that uses a subjective sentence classifier to filter its extractions. We experimented with several different strategies for using the subjectivity classifications, including an aggressive strategy that discards all extractions found in subjective sentences and more complex strategies that selectively discard extractions. We evaluated the performance of these different approaches on the MUC-4 terrorism data set. We found that indiscriminately filtering extractions from subjective sentences was overly aggressive, but more selective filtering strategies improved IE precision with minimal recall loss.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-175.pdf,Subjects: 13. Natural Language Processing
181,2005,Natural Language Processing and Speech Recognition,Dependency Parsing with Dynamic Bayesian Network,"Virginia Savova, Leonid Peshkin",Exact parsing with finite state automata is deemed inapropriate because of the unbounded non-locality languages overwhelmingly exhibit. We propose a way to structure the parsing task in order to make it amenable to local classification methods. This allows us to build a Dynamic Bayesian Network which uncovers the syntactic dependency structure of English sentences. Experiments with the Wall Street Journal demonstrate that the model successfully learns from labeled data.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-176.pdf,Subjects: 13. Natural Language Processing; 4. Cognitive Modeling
182,2005,Natural Language Processing and Speech Recognition,Spotting Subsequences matching a HMM using the Average Observation Probability Criteria with application to Keyword Spotting,Marius C Silaghi,"This paper addresses the problem of detecting keywords in unconstrained speech. The proposed algorithms search for the speech segment maximizing the average observation probability along the most likely path in the hypothesized keyword model. As known, this approach (sometimes referred to as sliding model method) requires a relaxation of the begin/endpoints of the Viterbi matching, as well as a time normalization of the resulting score. This makes solutions complex (i.e., LN2/2 basic operations for keyword HMM models with L states and utterances with N frames). We present here two alternative (quite simple and efficient) solutions to this problem. a) First we provide a method that finds the optimal segmentation according to the criteria of maximizing the average observation probability. It uses Dynamic Programming as a step, but does not require scoring for all possible begin/endpoints. While the worst case remains O(LN2), this technique converged in at most 3(L+2)N basic operations in each experiment for two very different applications. b) The second proposed algorithm does not provide a segmentation but can be used for the decision problem of whether the utterance should be classified as containing the keyword or not (provided a predefined threshold on the acceptable average observation probability). This allows the algorithm to be even faster, with fix cost of (L+2)N.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-177.pdf,Subjects: 18. Speech Understanding; 15.7 Search
183,2005,Natural Language Processing and Speech Recognition,Capturing Expression Using Linguistic Information,"Ozlem Uzuner, Boris Katz","Recognizing similarities between literary works for copyright infringement detection requires evaluating similarity in the expression of content. Copyright law protects expression of content; similarities in content alone are not enough to indicate infringement. Expression refers to the way people convey particular information; it captures both the information and the manner of its presentation. In this paper, we present a novel set of linguistically informed features that provide a computational definition of expression and that enable accurate recognition of individual titles and their paraphrases more than 80% of the time. In comparison, baseline features, e.g., tfidf-weighted keywords, function words, etc., give an accuracy of at most 53%. Our computational definition of expression uses linguistic features that are extracted from POS-tagged text using context-free grammars, without incurring the computational cost of full parsers. The results indicate that informative linguistic features do not have to be computationally prohibitively expensive to extract.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-178.pdf,Subjects: 13. Natural Language Processing; 13.3 Syntax
184,2005,Planning and Scheduling,State Agnostic Planning Graphs and the application to belief-space planning,"William Cushing, Daniel Bryce","Planning graphs have been shown to be a rich source of heuristic information for many kinds of planners. In many cases, planners must compute a planning graph for each element of a set of states. The naive technique enumerates the graphs individually. This is equivalent to solving an all-pairs shortest path problem by iterating a single-source algorithm over each source. We introduce a structure, the state agnostic planning graph, that directly solves the all-pairs problem for the relaxation introduced by planning graphs. The technique can also be characterized as exploiting the overlap present in sets of planning graphs. For the purpose of exposition, we first present the technique in classical planning. The more prominent application of this technique is in belief-space planning, where an optimization results in drastically improved theoretical complexity. Our experimental evaluation quantifies this performance boost, and demonstrates that heuristic belief-space progression planning using our technique is competitive with the state of the art.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-179.pdf,Subjects: 1.11 Planning
185,2005,Planning and Scheduling,Genome Rearrangement and Planning,"Esra Erdem, Elisabeth Tillier","The genome rearrangement problem is to find the most economical explanation for observed differences between the gene orders of two genomes. Such an explanation is provided in terms of events that change the order of genes in a genome. We present a new approach to the genome rearrangement problem, according to which this problem is viewed as the problem of planning rearrangement events that transform one genome to the other. This method differs from the existing ones in that we can put restrictions on the number of events, specify the cost of events with functions, possibly based on the length of the gene fragment involved, and add constraints controlling search. With this approach, we have described genome rearrangements in the action description language ADL, and studied the evolution of Metazoan mitochondrial genomes and the evolution of Campanulaceae chloroplast genomes using the planner TLplan. We have observed that the phylogenies reconstructed using this approach conform with the most widely accepted ones.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-180.pdf,Subjects: 1.11 Planning; 11. Knowledge Representation
186,2005,Planning and Scheduling,Quasi-Monotonic Segmentation of State Variable Behavior for Reactive Control,"Will Fitzgerald, Daniel Lemire, Martin Brooks","Real-world agents must react to changing conditions as they execute planned tasks. Conditions are typically monitored through time series representing state variables. While some predicates on these times series only consider one measure at a time, other predicates, sometimes called episodic predicates, consider sets of measures. We consider a special class of episodic predicates based on segmentation of the the measures into quasi-monotonic intervals where each interval is either quasi-increasing, quasi-decreasing, or quasi-flat. While being scale-based, this approach is also computational efficient and results can be computed exactly without need for approximation algorithms. Our approach is compared to linear spline and regression analysis.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-181.pdf,Subjects: 15.4 Reactive Control; 17. Robotics
187,2005,Planning and Scheduling,Validating Plans in the Context of Processes and Exogenous Events,"Maria Fox, Richard Howey, Derek Long","Complex planning domains push the boundaries of the expressive power of planning domain modelling languages. Recent extensions to the standard planning languages have included expressions for temporal, metric and resource structures. Other work has also considered how process models can be incorporated into domain models. In this paper we consider the problem of expressing and validating models containing events which are triggered as a consequence of the action of physical processes. We focus, primarily, on the validation of plans in the context of exogenous events, discussing the modelling, semantic and implementation issues that arise. Events impact not only on plans but on domain models as a whole and we also consider the problems that arise in considering the validation of event structures in domain models.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-182.pdf,Subjects: 1.11 Planning
188,2005,Planning and Scheduling,Fast Planning in Domains with Derived Predicates: An Approach Based on Rule-Action Graphs and Local Search,"Alfonso Gerevini, Alessandro Saetti, Ivan Serina, Paolo Toninelli","The ability to express ""derived predicates"" in the formalization of a planning domain is both practically and theoretically important. In this paper, we propose an approach to planning with derived predicates where the search space consists of ""Rule-Action Graphs"", particular graphs of actions and rules representing derived predicates. We present some techniques for representing rules and reasoning with them, which are integrated into a method for planning through local search and rule-action graphs. We also propose some new heuristics for guiding the search, and some experimental results illustrating the performance of our approach. Our proposed techniques are implemented in a planner that took part in the fourth International Planning Competition showing good performance in many benchmark problems.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-183.pdf,Subjects: 1.11 Planning
189,2005,Planning and Scheduling,New Admissible Heuristics for Domain-Independent Planning,"Patrik Haslum, Blai Bonet, Hector Geffner","Admissible heuristics are critical for effective domain-independent planning when optimal solutions must be guaranteed. Two useful heuristics are the hm heuristics, which generalize the reachability heuristic underlying the planning graph, and pattern database heuristics. These heuristics, however, have serious limitations: reachability heuristics capture only the cost of critical paths in a relaxed problem, ignoring the cost of other relevant paths, while PDB heuristics, additive or not, cannot accommodate too many variables in patterns, and methods for automatically selecting patterns that produce good estimates are not known. We introduce two refinements of these heuristics: First, the additive hm heuristic which yields an admissible sum of hm heuristics using a partitioning of the set of actions. Second, the constrained PDB heuristic which uses constraints from the original problem to strengthen the lower bounds obtained from abstractions. The new heuristics depend on the way the actions or problem variables are partitioned. We advance methods for automatically deriving additive hm and PDB heuristics from STRIPS encodings. Evaluation shows improvement over existing heuristics in several domains, although, not surprisingly, no heuristic dominates all the others over all domains.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-184.pdf,Subjects: 1.11 Planning
190,2005,Planning and Scheduling,Using Domain-Configurable Search Control for Probabilistic Planning,"Ugur Kuter, Dana Nau","We describe how to improve the performance of MDP planning algorithms by modifying them to use the search-control mechanisms of planners such as TLPlan, SHOP2, and TALplanner. In our experiments, modified versions of RTDP, LRTDP, and Value Iteration were exponentially faster than the original algorithms. On the largest problems the original algorithms could solve, the modified ones were about 10,000 times faster. On another set of problems whose state spaces were more than 14,000 times larger than the original algorithms could solve, the modified algorithms took only about 1/3 second.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-185.pdf,Subjects: 1.11 Planning
191,2005,Planning and Scheduling,Lazy Approximation for Solving Continuous Finite-Horizon MDPs,"Lihong Li, Michael L. Littman","Solving Markov decision processes (MDPs) with continuous state spaces is a challenge due to, among other problems, the well-known curse of dimensionality. Nevertheless, numerous real-world applications such as transportation planning and telescope observation scheduling exhibit a critical dependence on continuous states. Current approaches to continuous-state MDPs include discretizing their transition models. In this paper, we propose and study an alternative, discretizationfree approach we call lazy approximation. Empirical study shows that lazy approximation performs much better than discretization, and we successfully applied this new technique to a more realistic planetary rover planning problem.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-186.pdf,Subjects: 15.3 Control
192,2005,Planning and Scheduling,Prottle: A Probabilistic Temporal Planner,"Iain Little, Douglas Aberdeen, Sylvie Thiebaux.","Planning with concurrent durative actions and probabilistic effects, or probabilistic temporal planning, is a relatively new area of research. The challenge is to replicate the success of modern temporal and probabilistic planners with domains that exhibit an interaction between time and uncertainty. We present a general framework for probabilistic temporal planning in which effects, the time at which they occur, and action durations are all probabilistic. This framework includes a search space that is designed for solving probabilistic temporal planning problems via heuristic search, an algorithm that has been tailored to work with it, and an effective heuristic based on an extension of the planning graph data structure. Prottle is a planner that implements this framework, and can solve problems expressed in an extension of PDDL.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-187.pdf,Subjects: 1.11 Planning; 15.7 Search
193,2005,Planning and Scheduling,Augmenting Disjunctive Temporal Problems with Finite-Domain Constraints,"Michael D. Moffitt, Bart Peintner, Martha E. Pollack","We present a general framework for augmenting instances of the Disjunctive Temporal Problem (DTP) with finite-domain constraints. In this new formalism, the bounds of the temporal constraints become conditional on the finite-domain assignment. This hybridization makes it possible to reason simultaneously about temporal relationships between events as well as their nontemporal properties. We provide a special case of this hybridization that allows reasoning about a limited form of spatial constraints; namely, the travel time induced by the locations of a set of activities. We develop a least-commitment algorithm for efficiently finding solutions to this combined constraint system and provide empirical results demonstrating the effectiveness of our approach.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-188.pdf,Subjects: 3.6 Temporal Reasoning; 15.2 Constraint Satisfaction
194,2005,Planning and Scheduling,Temporal Dynamic Controllability Revisited,"Paul H. Morris, Nicola Muscettola","An important issue for temporal planners is the ability to handle temporal uncertainty. We revisit the question of how to determine whether a given set of temporal requirements are feasible in the light of uncertain durations of some processes. In particular, we consider how best to determine whether a network is Dynamically Controllable, i.e., whether a dynamic strategy exists for executing the network that is guaranteed to satisfy the requirements. Previous work has shown the existence of a pseudo-polynomial algorithm for testing Dynamic Controllability. Here, we simplify the previous framework, and present a strongly polynomial algorithm with a termination criterion based on the structure of the network.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-189.pdf,Subjects: 3.6 Temporal Reasoning; 15.2 Constraint Satisfaction
195,2005,Planning and Scheduling,Exploiting Temporal Flexibility to Obtain High Quality Schedules,"Nicola Policella, Xiaofang Wang, Stephen F. Smith, Angelo Oddi","We consider a schedule optimization problem where each activity to be scheduled has a duration-dependent quality profile, and activity durations must be determined that maximize overall quality within given deadline and resource constraints. To solve this quality maximization problem, prior work has proposed a hybrid search scheme, where a linear programming solver for optimally setting the durations of temporally related activities is embedded within a larger search procedure that incrementally posts sequencing constraints to resolve resource conflicts. Under this approach, dual concerns of establishing feasibility and optimizing quality are addressed in an integrated fashion. In this paper, we propose an alternative approach, where feasibility and optimization concerns are treated separately: first, we establish a resource-feasible partial order schedule, assuming minimum durations for all activities; second, these fixed duration constraints are relaxed and quality optimal durations are determined. Experimental results indicate a tradeoff: when resource capacity constraints are loose, the integrated hybrid approach performs comparably to the separated scheme. However, in problems with tighter capacity constraints we find that separation of concerns enables both better solving capability and higher quality results. Following from these results, we discuss potential synergy between problem objectives of maintaining temporal flexibility and maximizing quality.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-190.pdf,Subjects: 1.12 Scheduling; 15.7 Search
196,2005,Planning and Scheduling,Planning for Stream Processing Systems,"Anton Riabov, Zhen Liu","With the advent of compositional programming models in computer science, applying planning technologies to automatically build workflows for solving large and complex problems in such a paradigm becomes not only technically appealing but also feasible approach. The application areas that will benefit from automatic composition include, among others, Web services, Grid computing and stream processing systems. Although the classical planning formalism is expressive enough to describe planning problems that arise in a large variety of different applications, it can pose significant limitations on planner performance in compositional applications, in particular, in stream processing systems. In this paper we extend the classical planning formalism by introducing new language constructs that support the structure of stream processing domains. Exposing this structure to the planner can result in dramatic performance improvements: our experiments show exponential planning time reduction in comparison to most recent metric planners.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-191.pdf,Subjects: 1.11 Planning; 9.2 Computational Complexity
197,2005,Planning and Scheduling,,"Tran C. Son, Phan H. Tu, Michael Gelfond, Ricardo A. Morales","The paper presents a pair of new conformant planners, CpApc and CpAph, based on recent developments in theory of action and change. As an input the planners take a domain description D in action language AL which allows state constraints (non-stratified axioms), together with a set of CNF formulae describing the initial state, and a set of literals representing the goal. We propose two approximations of the transition diagram T defined by D. Both approximations are deterministic transition functions and can be computed efficiently. Moreover they are sound (and sometimes complete) with respect to  T. In its search for a plan, an approximation based planner analyses paths of an approximation instead of that of T. CpApc and CpAph are forward, best first search planners based on this idea. We compare them with two state-of-the-art conformant planners, KACMBP and Conformant-FF (CFF), over benchmarks in the literature, and over two new domains. One has large number of state constraints and another has a high degree of incompleteness. Our planners perform reasonably well in benchmark domains and outperform KACMBP and CFF in the first domain while still working well with the second one. Our experimental result shows that having an integral part of a conformant planner to deal with state constraints directly can significantly improve its performance, extending a similar claim for classical planners in (Thiebaux, Hoffmann, &amp; Nebel 2003).",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-192.pdf,Subjects: 1.11 Planning; 11. Knowledge Representation
198,2005,Planning and Scheduling,,"Sungwook Yoon, Alan Fern, Robert Givan","We study an approach to learning heuristics for planning domains from example solutions. There has been little work on learning heuristics for the types of domains used in deterministic and stochastic planning competitions. Perhaps one reason for this is the challenge of providing a compact heuristic language that facilitates learning. Here we introduce a new representation for heuristics based on lists of set expressions described using taxonomic syntax. Next, we review the idea of a measure of progress by Parmar, which is any heuristic that is guaranteed to be improvable at every state. We take finding a measure of progress as our learning goal, and describe a simple learning algorithm for this purpose. We evaluate our approach across a range of deterministic and stochastic planning-competition domains. The results show that often greedily following the learned heuristic is highly effective. We also show our heuristic can be combined with learned rule-based policies, producing still stronger results",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-193.pdf,Subjects: 1.11 Planning; 12. Machine Learning and Discovery
199,2005,Planning and Scheduling,,Neil Yorke-Smith,"Quantitative temporal constraints are an essential requirement for many planning domains. The HTN planning paradigm has proven to be better suited than other approaches to many applications. To date, however, efficiently integrating temporal reasoning with HTN planning has been little explored. This paper describes a means to exploit the structure of a HTN plan in performing temporal propagation on an associated Simple Temporal Network. By exploiting the natural restriction on permitted temporal constraints, the time complexity of propagation can be sharply reduced, while completeness of the inference is maintained. Empirical results indicate an order of magnitude improvement on real-world plans.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-194.pdf,Subjects: 3.6 Temporal Reasoning
200,2005,Planning and Scheduling,Sensor Selection for Active Information Fusion,"Yongmian Zhang, Qiang Ji","Active information fusion is to selectively choose the sensors so that the information gain can compensate the cost spent in information gathering. However, determining the most informative and cost-effective sensors requires an evaluation of all possible sensor combinations, which is computationally intractable, particularly, when information-theoretic criterion is used. This paper presents a methodology to actively select a sensor subset with the best tradeoff between information gain and sensor cost by exploiting the synergy among sensors. Our approach includes two aspects: a method for efficient mutual information computation and a graph-theoretic approach to reduce search space. The approach can reduce the time complexity significantly in searching for a near optimal sensor subset.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-195.pdf,Subjects: 1.11 Planning; 1.12 Scheduling
201,2005,Planning and Scheduling,Simultaneous Heuristic Search for Conjunctive Subgoals,"Lin Zhu, Robert Givan","We study the problem of building effective heuristics for achieving conjunctive goals from heuristics for individual goals. We consider a straightforward method for building conjunctive heuristics that smoothly trades off between previous common methods. In addition to first explicitly formulating the problem of designing conjunctive heuristics, our major contribution is the discovery that this straightforward method substantially outperforms previously used methods across a wide range of domains. Based on a single positive real parameter k, our heuristic measure sums the individual heuristic values for the subgoal conjuncts, each raised to the k'th power. Varying k allows loose approximation and combination of the previous min, max, and sum approaches, while mitigating some of the weaknesses in those approaches.Our empirical work shows that for many benchmark planning domains there exist fixed parameter values that perform well---we give evidence that these values can be found automatically by training. Our method, applied to top-level conjunctive goals, shows dramatic improvements over the heuristic used in the FF planner across a wide range of planning competition benchmarks. Also, our heuristic, without computing landmarks, consistently improves upon the success ratio of a recently published landmark-based planner FF-L.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-000.pdf,Subjects: 1.11 Planning; 15.7 Search
202,2005,Robotics,Reactive Planning in a Motivated Behavioral Architecture,"Eric Beuadry, Yannick Brosseau, Carle Cote, clement Raievsky, Dominic Letourneau, Froduald Kabanza, Francois Michaud","To operate in natural environmental settings, autonomous mobile robots need more than just the ability to navigate in the world, react to perceived situations or follow pre-determined strategies: they must be able to plan and to adapt those plans according to the robot’s capabilities and the situations encountered. Navigation, simultaneous localization and mapping, perception, motivations, planning, etc., are capabilities that contribute to the decision-making processes of an autonomous robot. How can they be integrated while preserving their underlying principles, and not make the planner or other capabilities a central element on which everything else relies on? In this paper, we address this question with an architectural methodology that uses a planner along with other independent motivational sources to influence the selection of behavior-producing modules. Influences of the planner over other motivational sources are demonstrated in the context of the AAAI Challenge.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-197.pdf,Subjects: 2. Architectures; 1.11 Planning
203,2005,Robotics,A Distributed Approach to Passive Localization for Sensor Networks,"Rahul Biswas, Sebastian Thrun","Sensors that know their location, from microphones to vibration sensors, can support a wider arena of applications than their location unaware counterparts. We offer a method for sensors to determine their own location relative to one another by using only exogenous sounds and the differences in the arrivals of these sounds at different sensors. We present a distributed and computationally efficient solution that offers accuracy on par with more active and computationally intense methods.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-198.pdf,Subjects: 3.2 Geometric Or Spatial Reasoning; 7. Distributed AI
204,2005,Robotics,Recovery Planning for Ambiguous Cases in Perceptual Anchoring,"Mathias Broxvall, Silvia Coradeschi, Lars Karlsson, Alessandro Saffiotti","An autonomous robot using symbolic reasoning, sensing and acting in a real environment needs the ability to create and maintain the connection between symbols representing objects in the world and the corresponding perceptual representations given by its sensors. This connection has been named perceptual anchoring. In complex environments, anchoring is not always easy to establish: the situation may often be ambiguous as to which percept actually corresponds to a given symbol. In this paper, we extend perceptual anchoring to deal robustly with ambiguous situations by providing general methods for detecting them and recovering from them. We consider different kinds of ambiguous situations and present planning-based methods to recover from them. We illustrate our approach by showing experiments involving a mobile robot equipped with a color camera and an electronic nose.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-199.pdf,Subjects: 17. Robotics; 1.11 Planning
205,2005,Robotics,A Multifrontal QR Factorization Approach to Distributed Inference Applied to Multi-Robot Localization and Mapping,"Frank Dellaert, Alexander Kipp, Peter Krauthausen","QR factorization is most often used as a ""black box"" algorithm, but is in fact an elegant computation on a factor graph. By computing a rooted clique tree on this graph, the computation can be parallelized across subtrees, which forms the basis of so-called multifrontal QR methods. By judiciously choosing the order in which variables are eliminated in the clique tree computation, we show that one straightforwardly obtains a method for performing inference in distributed sensor networks. One obvious application is distributed localization and mapping with a team of robots. We phrase the problem as inference on a large-scale Gaussian Markov Random Field induced by the measurement factor graph, and show how multifrontal QR on this graph solves for the global map and all the robot poses in a distributed fashion. The method is illustrated using both small and large-scale simulations, and validated in practice through actual robot experiments.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-200.pdf,Subjects: 17. Robotics; 19.1 Perception
206,2005,Robotics,Learning CPG Sensory Feedback with Policy Gradient for Biped Locomotion for a Full-Body Humanoid,"Gen Endo, Jun Morimoto, Takamitsu Matsubara, Jun Nakanishi, Gordon Cheng","This paper describes a learning framework for a central pattern generator based biped locomotion controller using a policy gradient method. Our goals in this study are to achieve biped walking with a 3D hardware humanoid, and to develop an efficient learning algorithm with CPG by reducing the dimensionality of the state space used for learning. We demonstrate that an appropriate feedback controller can be acquired within a thousand trials by numerical simulations and the obtained controller in numerical simulation achieves stable walking with a physical robot in the real world. Numerical simulations and hardware experiments evaluated walking velocity and stability. Furthermore, we present the possibility of an additional online learning using a hardware robot to improve the controller within 200 iterations.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-201.pdf,Subjects: 17. Robotics; 15.3 Control
207,2005,Robotics,Tactic-Based Motion Modelling and Multi-Sensor Tracking,Yang Gu,"Tracking in essence consists of using sensory information combined with a motion model to estimate the position of a moving object. Tracking efficiency completely depends on the accuracy of the motion model and of the sensory information. For a vision sensor like a camera, the estimation is translated into a command to guide the camera where to look. In this paper, we contribute a method to achieve efficient tracking through using a tactic-based motion model, combined vision and infrared sensory information. We use a supervised learning technique to map the state being tracked to the commands that lead the camera to consistently track the object. We present the probabilistic algorithms in detail and present empirical results both in simulation experiment and from their effective execution in a Segway RMP robot.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-202.pdf,Subjects: 17. Robotics; 16. Real-Time Systems
208,2005,Robotics,A Relational Representation for Procedural Task Knowledge,"Stephen Hart, Roderic Grupen, David Jensen",This paper proposes a methodology for learning joint probability estimates regarding the effect of sensorimotor features on the predicated quality of desired behavior. These relationships can then be used to choose actions that will most likely produce success. relational dependency networks are used to learn statistical models of procedural task knowledge. An example task expert for picking up objects is learned through actual experience with a humanoid robot. We believe that this approach is widely applicable and has great potential to allow a robot to autonomously determine which features in the world are salient and should be used to recommend policy for action.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-203.pdf,Subjects: 17. Robotics; 11. Knowledge Representation
209,2005,Robotics,Controlling Tiny Multi-Scale Robots for Nerve Repair,"Tad Hogg, David W. Sretavan","We designed and evaluated multiagent control for microscopic robots (""nanorobots"") aiding the surgical repair of damaged nerve cells. This repair operates on both nerves as a whole, at scales of hundreds of microns, and individual nerve cell axons, at scales of about a micron. We match the robots to these sizes using a combination of microelectomechanical (MEMS) machines for the larger operations and nanorobots for operations on individual cells. Multiagent control allows accurate and rapid repair with such robots, with only modest computational and communication requirements for the nanorobots, a significant benefit due to their physical limitations. Our simulations, using physical parameters dictated by nerve biology and plausible nanorobotic capabilities, show how specific control choices lead to trade-offs in clinical outcome. Beyond the specific example of nerve repair treated here, multi-scale robots could aid a variety of medical and biological tasks involving both the large scale of organs or tissues and the microscopic scale of individual cells.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-204.pdf,Subjects: 17. Robotics; 7.1 Multi-Agent Systems
210,2005,Robotics,Heterogeneous Multirobot Coordination with Spatial and Temporal Constraints,"Mary Koes, Illah Nourbakhsh, Katia Sycara","Existing approaches to multirobot coordination separate scheduling and task allocation, but finding the optimal schedule with joint tasks and spatial constraints requires robots to simultaneously solve the scheduling, task allocation, and path planning problems. We present a formal description of the multirobot joint task allocation problem with heterogeneous capabilities and spatial constraints and an instantiation of the problem for the search and rescue domain. We introduce a novel declarative framework for modeling the problem as a mixed integer linear programming (MILP) problem and present a centralized anytime algorithm with error bounds. We demonstrate that our algorithm can outperform standard MILP solving techniques, greedy heuristics, and a market based approach which separates scheduling and task allocation.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-205.pdf,Subjects: 17. Robotics; 3. Automated Reasoning
211,2005,Robotics,Consciousness: Drinking from the Firehose of Experience,Benjamin Kuipers,"The problem of consciousness has captured the imagination of philosophers, neuroscientists, and the general public, but has received little attention within AI. However, concepts from robotics and computer vision hold great promise to account for the major aspects of the phenomenon of consciousness, including philosophically problematical aspects such as the vividness of qualia, the first-person character of conscious experience, and the property of intentionality. This paper presents and evaluates such an account against eleven features of consciousness ""that any philosophical-scientific theory should hope to explain"", according to the philosopher and prominent AI critic John Searle.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-206.pdf,Subjects: 9.4 Philosophical Foundations; 17. Robotics
212,2005,Robotics,Semantic Place Classification of Indoor Environments with Mobile Robots using Boosting,"Axel Rottmann, Oscar Martinez Mozos, Cyrill Stachniss, Wolfram Burgard","Indoor environments can typically be divided into places with different functionalities like kitchens, offices, or seminar rooms. We believe that such semantic information enables a mobile robot to more efficiently accomplish a variety of tasks such as human-robot interaction, path-planning, or localization. This paper presents a supervised learning approach to label different locations using boosting. We train a classifier using features extracted from vision and laser range data. Furthermore, we apply a Hidden Markov Model to increase the robustness of the final classification. Our technique has been implemented and tested on real robots as well as in simulation. The experiments demonstrate that our approach can be utilized to robustly classify places into semantic categories. We also present an example of localization using semantic labeling.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-207.pdf,Subjects: 17. Robotics
213,2005,Robotics,Learning to Prevent Failure States for a Dynamically Balacning Robot,"Jeremy L Searock, Brett Browning","To achieve robust autonomy, robots must avoid getting stuck in states from which they cannot recover without external aid. While this is the role of the robot’s control algorithms, these are often imperfect. We examine how to detect failures by observing the robot’s internal sensors over time. For such cases, triggering a response when detecting the onset of a failure can increase the operational range of the robot. Concretely, we explore the use of supervised learning techniques to create a classifier that can detect a potential failure and trigger a response for a dynamically balancing robot. We present a fully implemented system, where the results clearly demonstrate an improved safety margin for the robot.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-208.pdf,Subjects: 17. Robotics
214,2005,Robotics,Autonomous Color Learning on a Mobile Robot,"Mohan Sridharan, Peter Stone","Color segmentation is a challenging subtask in computer vision. Most popular approaches are computationally expensive, involve an extensive off-line training phase and/or rely on a stationary camera. This paper presents an approach for color learning on-board a legged robot with limited computational and memory resources. A key defining feature of the approach is that it works without any labeled training data. Rather, it trains autonomously from a color-coded model of its environment. The process is fully implemented, completely autonomous, and provides high degree of segmentation accuracy.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-209.pdf,Subjects: 19. Vision; 17. Robotics
215,2005,Robotics,Mobile Robot Mapping and Localization in Non-Static Environments,"Cyrill Stachniss, Wolfram Burgard","Whenever mobile robots act in the real world, they need to be able to deal with non-static objects. In the context of mapping, a common technique to deal with dynamic objects is to filter out the spurious measurements corresponding to such objects. In this paper, we present a novel approach to estimate typical configurations of dynamic areas in the environment of a mobile robot. Our approach clusters local grid maps to identify the possible configurations. We furthermore describe how these clusters can be utilized within a Rao-Blackwellized particle filter to localize a mobile robot in a non-static environment. In practical experiments carried out with a mobile robot in a typical office environment, we demonstrate the advantages of our approach compared to alternative techniques for mapping and localization in dynamic environments.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-210.pdf,Subjects: 17. Robotics
216,2005,Robotics,Improving Simultaneous Mapping and Localization in 3D Using Global Constraints,"Rudolph A. Triebel, Wolfram Burgard","Recently, the problem of learning volumetric maps from three-dimensional range data has become quite popular in the context of mobile robotics. One of the key challenges in this context is to reduce the overall amount of data. The smaller the number of data points, however, the fewer information is available to register the scans and to compute a consistent map. In this paper we present a novel approach that estimates global constraints from the data and utilizes these constraints to improve the registration process. In our current system we simultaneously minimize the distance between scans and the distance of edges from planes extracted from the edges to obtain highly accurate three-dimensional models of the environment. Several experiments carried out in simulation as well as with three-dimensional data obtained with a mobile robot in an outdoor environment we show that our approach yields seriously more accurate models compared to a standard approach that does not utilize the global constraints.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-211.pdf,Subjects: 17. Robotics
217,2005,Robotics,Bitbots: Simple Robots Solving Complex Tasks,"Anna Yershova, Benjamin Tovar, Robert Ghrist, Steven M. LaValle","Sensing uncertainty is a central issue in robotics. Sensor limitations often prevent accurate state estimation, and robots find themselves confronted with a complicated information (belief) space. In this paper we define and characterize the information spaces of very simple robots, called Bitbots, which have severe sensor limitations. While complete estimation of the robot’s state is impossible, careful consideration and management of the uncertainty is presented as a search in the information space. We show that these simple robots can solve several challenging online problems, even though they can neither obtain a complete map of their environment nor exactly localize themselves. However, when placed in an unknown environment, Bitbots can build a topological representation of it and then perform pursuit-evasion (i.e., locate all moving targets inside this environment). This paper introduces Bitbots, and provides both theoretical analysis of their information spaces and simulation results.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-212.pdf,Subjects: 1.11 Planning; 17. Robotics
218,2005,Search,An Algorithm Better than AO*?,"Blai Bonet, Hector Geffner","Recently there has been a renewed interest in AO* as planning problems involving uncertainty and feedback can be naturally formulated as AND/OR graphs. In this work, we carry out what is probably the first detailed empirical evaluation of AO* in relation to other AND/OR search algorithms. We compare AO* with two other methods: the well-known Value Iteration (VI) algorithm, and a new algorithm, Learning in Depth-First Search (LDFS). We consider instances from four domains, use three different heuristic functions, and focus on the optimization of cost in the worst case (Max AND/OR graphs). Roughly we find that while AO* does better than VI in the presence of informed heuristics, VI does better than recent extensions of AO* in the presence of cycles in the AND/OR graph. At the same time, LDFS and its variant Bounded LDFS, which can be regarded as extensions of IDA*, are almost never slower than either AO* or VI, and in many cases, are orders-of-magnitude faster.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-213.pdf,Subjects: 15. Problem Solving; 15.7 Search
219,2005,Search,Speeding Up Learning in Real-time Search via Automatic State Abstraction,"Vadim Bulitko, Nathan Sturtevant, Maryia Kazakevich","Situated agents which use learning real-time search are well poised to address challenges of real-time path-finding in robotic and computer game applications. They interleave a local lookahead search with movement execution, explore an initially unknown map, and converge to better paths over repeated experiences. In this paper, we first investigate how three known extensions of the most popular learning real-time search algorithm (LRTA*) influence its performance in a path-finding domain. Then, we combine automatic state abstraction with learning real-time search. Our scheme of dynamically building a state abstraction allows us to generalize updates to the heuristic function, thereby speeding up learning. The novel algorithm converges up to 80 times faster than LRTA* with only one fifth of the response time of A*.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-214.pdf,Subjects: 15.7 Search; 16. Real-Time Systems
220,2005,Search,The Max K-Armed Bandit: A New Model of Exploration Applied to Search Heuristic Selection,"Vincent A Cicirello, Stephen F Smith","The multiarmed bandit is often used as an analogy for the tradeoff between exploration and exploitation in search problems. The classic problem involves allocating trials to the arms of a multiarmed slot machine to maximize the expected sum of rewards. We pose a new variation of the multiarmed bandit---the Max K-Armed Bandit---in which trials must be allocated among the arms to maximize the expected best single sample reward of the series of trials. Motivation for the Max K-Armed Bandit is the allocation of restarts among a set of multistart stochastic search algorithms. We present an analysis of this Max K-Armed Bandit showing under certain assumptions that the optimal strategy allocates trials to the observed best arm at a rate increasing double exponentially relative to the other arms. This motivates an exploration strategy that follows a Boltzmann distribution with an exponentially decaying temperature parameter. We compare this exploration policy to policies that allocate trials to the observed best arm at rates faster (and slower) than double exponentially. The results confirm, for two scheduling domains, that the double exponential increase in the rate of allocations to the observed best heuristic outperforms the other approaches.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-215.pdf,Subjects: 15.7 Search; 12. Machine Learning and Discovery
221,2005,Search,Cost-Algebraic Heuristic Search,"Stefan Edelkamp, Shahid Jabbar, Alberto Lluch Lafuente","Heuristic search is used to efficiently solve the single-node shortest path problem in weighted graphs. In practice, however, one is not only interested in finding a short path, but an optimal path, according to a certain cost notion. We propose an algebraic formalism that captures many cost notions, like typical Quality of Service attributes. We thus generalize A*, the popular heuristic search algorithm, for solving optimal-path problem. The paper provides an answer to a fundamental question for AI search, namely to which general notion of cost, heuristic search algorithms can be applied. We proof correctness of the algorithms and provide experimental results that validate the feasibility of the approach.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-216.pdf,Subjects: 9.3 Mathematical Foundations; 15.7 Search
222,2005,Search,Backbones and Backdoors in Satisfiability,"Philip Kilby, John Slaney, Sylvie Thiebaux, Toby Walsh","We study the backbone and the backdoors of propositional satisfiability problems. We make a number of theoretical, algorithmic and experimental contributions. From a theoretical perspective, we prove that backbones are hard even to approximate. From an algorithmic perspective, we present a number of different procedures for computing backdoors. From an empirical perspective, we study the correlation between being in the backbone and in a backdoor. Experiments show that there tends to be very little overlap between backbones and backdoors. We also study problem hardness for the Davis Putnam procedure. Problem hardness appears to be correlated with the size of strong backdoors, and weakly correlated with the size of the backbone, but does not appear to be correlated to the size of weak backdoors nor their number. Finally, to isolate the effect of backdoors, we look at problems with no backbone.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-217.pdf,Subjects: 15.7 Search; 15.2 Constraint Satisfaction
223,2005,Search,Search Versus Knowledge for Solving Life and Death Problems in Go,"Akihiro Kishimoto, Martin Mueller","In games research, Go is considered the classical board game that is most resistant to current AI techniques. Large-scale knowledge engineering has been considered indispensable for building state of the art programs, even for subproblems such as Life and Death, or tsume-Go. This paper describes the technologies behind TsumeGo Explorer, a high-performance tsume-Go search engine for enclosed problems. In empirical testing, this engine outperforms GoTools, which has been the undisputedly best tsume-Go program for 15 years.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-218.pdf,Subjects: 1.8 Game Playing; 15.7 Search
224,2005,Search,Large-Scale Parallel Breadth-First Search,"Richard E. Korf, Peter Schultze","Recently, best-first search algorithms have been introduced that store their nodes on disk, to avoid their inherent memory limitation. We introduce several improvements to the best of these, including parallel processing, to reduce their storage and time requirements. We also present a linear-time algorithm for bijectively mapping permutations to integers in lexicographic order. We use breadth-first searches of sliding-tile puzzles as testbeds. On the 3x5 Fourteen Puzzle, we reduce both the storage and time needed by a factor of 3.5 on two processors. We also performed the first complete breadth-first search of the 4x4 Fifteen Puzzle, with over ten trillion states.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-219.pdf,Subjects: 15.7 Search; 15. Problem Solving
225,2005,Search,Domain-Dependent Parameter Selection of Search-based Algorithms Compatible with User Performance Criteria,"Biplav Srivastava, Anupam Mediratta","Search-based algorithms, like planners, schedulers and satisfiability solvers, are notorious for having numerous parameters with a wide choice of values that can affect their performance drastically. As a result, the users of these algorithms, who may not be search experts, spend a significant time in tuning the values of the parameters to get acceptable performance on their particular problem domains. In this paper, we present a learning-based approach for automatic tuning of search-based algorithms to help such users. The benefit of our methodology is that it handles diverse parameter types, performs effectively for a broad range of systematic as well as non-systematic search based solvers (the selected parameters could make the algorithms solve up to 100% problems while the bad parameters would lead to none being solved), incorporates user-specified performance criteria and is easy to implement. Moreover, the selected parameter will satisfy the performance criteria in the first try or the ranked candidates can be used along with the performance criteria to minimize the number of times the parameter settings need to be adjusted until a problem is solved.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-220.pdf,Subjects: 8. Enabling Technologies; 15.7 Search
226,2005,Search,Partial Pathfinding Using Map Abstraction and Refinement,"Nathan Sturtevant, Michael Buro","Classical search algorithms such as A* or IDA* are useful for computing optimal solutions in a single pass, which can then be executed. But in many domains agents either do not have the time to compute complete plans before acting, or should not spend the time to do so, due to the dynamic nature of the environment. Extensions to A* such as LRTA* address this problem by gradually learning an exact heuristic function, but the learning process is quite slow. In this paper we introduce Partial-Refinement A* (PRA*), which can fully interleave planning and acting through path abstraction and refinement. We demonstrate the effectiveness of PRA* in the domain of real-time strategy (RTS) games. In maps taken from popular RTS games, we show that PRA* is not only able to cleanly interleave planning and execution, but it is also able to do so with only minimal losses of optimality.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-221.pdf,Subjects: 15.7 Search; 1.8 Game Playing
227,2005,Search,External-Memory Pattern Databases using Structured Duplicate Detection,"Rong Zhou, Eric A. Hansen","A pattern database is a lookup table that stores an exact evaluation function for a relaxed search problem, which provides an admissible heuristic for the original search problem. In general, the larger the pattern database, the more accurate the heuristic function. We consider how to build large pattern databases that are stored in external memory, such as disk, and how to use an external-memory pattern database efficiently in heuristic search. To limit the number of slow disk I/O operations needed to construct and query an external-memory pattern database, we adapt an approach to external-memory graph search called structured duplicate detection that localizes memory references by leveraging an abstraction of the state space. We present results that show this approach increases the scalability of heuristic search by allowing larger and more accurate pattern database heuristics.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-000.pdf,Subjects: 15.7 Search
228,2005,"Semantic Web, Information Retrieval, and Extraction",Selection and Ranking of Propositional Formulas for Large-Scale Service Directories,"Ion Constantinescu, Walter Binder, Boi Faltings","In this paper we consider scenarios, such as web service composition, where a planner needs to discover its operators by querying a potentially very large and dynamically changing directory. Our contribution is a directory system that represents service advertisements and requests as propositional formulas and provides a flexible query language allowing complex selection and ranking expressions. The internal structure of the directory enables efficient selection and ranking in the presence of a large number of services thanks to its organization as a balanced tree with an extra ""intersection predicate"". In order to optimally exploit the index structure of the directory, a transformation scheme is applied to the original query. Experimental results on randomly generated service composition problems illustrate the benefits of our approach.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-000.pdf,Subjects: 1.10 Information Retrieval; 1.11 Planning
229,2005,"Semantic Web, Information Retrieval, and Extraction",WebCrow: A WEB-based system for CROssWord solving,"Marco Ernandes, Giovanni Angelini, Marco Gori","Language games represent one of the most fascinating challenges of research in artificial intelligence. In this paper we give an overview of WebCrow, a system that tackles crosswords using the Web as a knowledge base. This appears to be a novel approach with respect to the available literature. It is also the first solver for non- English crosswords and it has been designed to be potentially multilingual. Although WebCrow has been implemented only in a preliminary version, it already displays very interesting results reaching the performance of a human beginner: crosswords that are ""easy"" for expert humans are solved, within competition time limits, with 80 percent of correct words and over 90 percent of correct letters.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-224.pdf,Subjects: 1.10 Information Retrieval; 15.2 Constraint Satisfaction
230,2005,"Semantic Web, Information Retrieval, and Extraction",A Learning-Based Term-Weighting Approach for Information Retrieval,"Guang Can Liu, Yong Yu, Xing Zhu","One of the core components in information retrieval(IR) is the document-term-weighting scheme. In this paper,we will propose a novel learning-based term-weighting approach to improve the retrieval performance of vector space model in homogeneous collections. We first introduce a simple learning system to weighting the index terms of documents. Then, we deduce a formal computational approach according to some theories of matrix computation and statistical inference. Our experiments on 8 collections will show that our approach outperforms classic TF.IDF weighting, about 20%~45%.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-225.pdf,Subjects: 1.10 Information Retrieval; 12. Machine Learning and Discovery
231,2005,"Semantic Web, Information Retrieval, and Extraction",Query Translation Disambiguation As Graph Partitioning,"Yi Liu, Rong Jin","Resolving ambiguity in the process of query translation is crucial to cross-language information retrieval when only a bilingual dictionary is available. In this paper we propose a novel approach for query translation disambiguation, named ""spectral query translation model"". The proposed approach views the problem of query translation disambiguation as a graph partitioning problem. For a given query, a weighted graph is first created for all possible translations of query words based on the co-occurrence statistics of the translation words. The best translation of the query is then determined by the most strongly connected component within the graph. The proposed approach distinguishes from previous approaches in that the translations of all query words are estimated simultaneously. Furthermore, translation probabilities are introduced in the proposed approach to capture the uncertainty in translating queries. Empirical studies with TREC datasets have shown that the spectral query translation model achieves a relative 20% - 50% improvement in cross-language information retrieval, compared to other approaches that also exploit word co-occurrence statistics for query translation disambiguation.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-226.pdf,Subjects: 1.10 Information Retrieval; 12. Machine Learning and Discovery
232,2005,"Semantic Web, Information Retrieval, and Extraction",Searching for Common Sense: Populating Cyc from the Web,"Cynthia Matuszek, Michael Witbrock, Robert C. Kahlert, John Cabral, Dave Schneider, Purvesh Shah, Doug Lenat","The Cyc project is predicated on the idea that effective machine learning depends on having a core of knowledge that provides a context for novel learned information - what is known informally as ""common sense."" Over the last twenty years, a sufficient core of common sense knowledge has been entered into Cyc to allow it to begin effectively and flexibly supporting its most important task: increasing its own store of world knowledge. In this paper, we present initial work on a method of using a combination of Cyc and the World Wide Web, accessed via Google, to assist in entering knowledge into Cyc. The long-term goal is automating the process of building a consistent, formalized representation of the world in the Cyc knowledge base via machine learning. We present initial results of this work and describe how we expect the knowledge acquisition process to become more accurate, faster, and more automated in the future.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-227.pdf,Subjects: 10. Knowledge Acquisition; 5. Common Sense Reasoning
233,2005,"Semantic Web, Information Retrieval, and Extraction",Automatic Text Summarization of Newswire: Lessons Learned from the Document Understanding Conference,Ani Nenkova,"Since 2001, the Document Understanding Conferences have been the forum for researchers in automatic text summarization to compare methods and results on common test sets. Over the years, several types of summarization tasks have been addressed---single document summarization, multi-document summarization, summarization focused by question, and headline generation. This paper is an overview of the achieved results in the different types of summarization tasks. We compare both the broader classes of baselines, systems and humans, as well as individual pairs of summarizers (both human and automatic). An analysis of variance model is fitted, with summarizer and input set as independent variables, and the coverage score as the dependent variable, and simulation-based multiple comparisons were performed. The results document the progress in the field as a whole, rather then focusing on a single system, and thus can serve as a future reference on the work done up to date, as well as a starting point in the formulation of future tasks. Results also indicate that most progress in the field has been achieved in generic multi-document summarization and that the most challenging task is that of producing a focused summary in answer to a question/topic.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-228.pdf,Subjects: 13. Natural Language Processing
234,2005,"Semantic Web, Information Retrieval, and Extraction",A Graph Theoretical Foundation for Integrating RDF Ontologies,"Octavian Udrea, Yu Deng, Edna Ruckhaus, V.S. Subrahmanian","RDF ontologies are rapidly increasing in number. We study the problem of integrating two RDF ontologies under a given set H of Horn clauses that specify semantic relationships between terms in the ontology, as well as under a given set of negative constraints. We formally define the notion of a witness to the integrability of two RDF ontologies under such constraints. A witness represents a way of integrating the ontologies together. We define a ""minimal"" witnesses and provide the polynomial CROW (Computing RDF Ontology Witness) algorithm to find a witness. We report on the performance of CROW both on DAML, SchemaWeb and OntoBroker ontologies as well as on synthetically generated data. The experiments show that CROW works very well on real-life ontologies and scales to massive ontologies.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-229.pdf,Subjects: 11.2 Ontologies
235,2005,Student Abstracts,Machine Learning and Its Application at Nooksack Falls Hydroelectric Station,"Scott Alexander, Dr. Jianna Zhang","The objective of this project is to control water delivery and distribution at Nooksack Falls Hydroelectric Station (NFHS) in order to maximize efficiency of the system, thereby increasing energy generation. Two machine learning algorithms will be applied. (1) Q-learning - a reinforcement learning approach to obtain a set of roughly optimal configurations. (2) Recurrent Neural Network (RNN) - rough configurations gathered by the Q-learning agent will be used to train the RNN. The RNN will refine these configurations as well as enabling lifelong learning. The significance of this project is to demonstrate the practical utility of the machine learning techniques described above when applied to real-world processes such as NFHS.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-001.pdf,Subjects: 12.1 Reinforcement Learning; 14. Neural Networks
236,2005,Student Abstracts,Helicopter Routing for Maintaining Remote Sites in Alaska using a Genetic Algorithm,"Nicholas Armstrong-Crews, Kenrick Mock","The Department of Fish and Game keeps observational sites in remote locations for such purposes as counting fish, measuring weather, and various research projects. In Alaska, fishing and natural tourism are vital to the economy of the state, making these measurements all the more important. However, due to large geographic spread with little transportation infrastructure (none, between many villages), helicopters must be used to visit these sites. It is extremely expensive, primarily in fuel costs, to fly helicopters all over the state, so optimal or near-optimal routing of these helicopters is paramount. Currently, the ""by-eye"" technique is used, in which a route is chosen that simply looks like it would have the lowest total distance. The well-known underlying problem at hand is the Vehicle Routing Problem (or VRP) in which a fleet of vehicles with a given capacity must make deliveries to a set of sites (Toth and Vigo 2001); this variant, however, only includes a subset of the problem specification. The primary changes from the basic VRP problem are the existence of multiple depots and the use of a single vehicle to visit all sites. A real-valued fuel constraint replaces the bin-packing constraints, essentially relaxing the bin-packing aspect of the problem. The particular variant described above is not addressed specifically in previous research; therefore, in this project, a genetic algorithm (GA) was created with a simple genome and a novel crossover technique in an attempt to produce better solutions for this simpler variant. Good results were achieved for ten and twenty-node graphs (reasonable and better than the ""by-eye"" technique). Further testing and fine-tuning is required before testing the algorithm against a standard algorithm for the more general problem, to see if this solution in fact outperforms standard algorithms for this simpler variant.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-002.pdf,Subjects: 1.9 Genetic Algorithms; 15. Problem Solving
237,2005,Student Abstracts,Autonomous Subgoal Discovery and Hierarchical Abstraction For Reinforcement Learning Using Monte Carlo Method,"Mehran Asadi, Manfred Huber","This paper presents a new method for the autonomous construction of hierarchical action and state representations in reinforcement learning, aimed at accelerating learning and extending the scope of such systems. In this approach, the agent uses information acquired while learning one task to discover subgoals by analyzing the learned policy using Monte Carlo sampling. By creating useful new subgoals and by off-line learning corresponding subtask policies as abstract actions, the agent is able to transfer knowledge to subsequent tasks and to accelerate learning. At the same time, the subgoal actions are used to construct a more abstract state representation using action-dependent approximate state space partitioning. This representation forms a new level in a state space hierarchy and serves as the initial representation for new learning tasks. In order to ensure that tasks are learnable, value functions are built simultaneously at different levels and inconsistencies are used to identify actions to be used to refine relevant portions of the abstract state space. Together these techniques permit the agent to form more abstract action and state representations over time. Experiments in deterministic and stochastic domains show that this method can significantly outperform learning on a flat state space representation.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-003.pdf,Subjects: 12. Machine Learning and Discovery; 12.1 Reinforcement Learning
238,2005,Student Abstracts,Mixed-Initiative Approach to Collaboration in the Mathematical Domain,"Nadya Belov, Joshua Shaffer","Using smart-phones for ad-hoc mathematical collaboration poses multiple user interface challenges. In this paper, software agents are used to lessen the cognitive load through automatic line labeling. Researchers in the human-computer interaction community have attempted to alleviate the problem of general usability through user interface engineering conventions. However, these engineering approaches can be improved upon through the application of mixed-initiative principles.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-004.pdf,Subjects: 6. Computer-Human Interaction; 1.3 Computer-Aided Education
239,2005,Student Abstracts,On Predicting User Intent,Nadya Belov,"Recent advances in computing capability and approaches have underlined the need for user support in task execution. This is especially evident in dynamic, real-time systems where decision making is critical and errors are costly. Environments such as air traffic control centers leave little time for human operators to make critical decisions. The main outcome of working in such an environment is cognitive overload, which leads to a significant error rate in decision making. Many in the human-computer interaction community have concentrated on looking for a solution to relieving cognitive overload through the application of user interface engineering conventions. These methods are expressed as rules which, when followed, are said to result in user interfaces that have high usability. However, regardless of the user interface, the operator must still make decisions and perform all of the tasks himself. This paper presents an outline for creating an intelligent agent to assist the user. The role of the agent is to attempt to predict the user’s intent. The agent can then act on its perceptions with the goal of accelerating the task’s completion and easing the cognitive load of the user by manipulating the user interface.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-005.pdf,Subjects: 7.2 Software Agents; 12. Machine Learning and Discovery
240,2005,Student Abstracts,DR-Prolog:A System for Reasoning with Rules and Ontologies on the Semantic Web,"Antonis Bikakis, Grigoris Antoniou","Defeasible reasoning is a rule-based approach for efficient reasoning with incomplete and inconsis-tent information. Such reasoning is, among others, useful for ontology integration, where conflicting information arises naturally; and for the modeling of business rules and policies, where rules with ex-ceptions are often used. This paper describes these scenarios in more detail, and reports on the imple-mentation of a system for defeasible reasoning on the Web. The system (a) is syntactically compati-ble with RuleML; (b) features strict and defeasible rules, priorities and two kinds of negation; (c) is based on a translation to logic programming with declarative semantics; (d) is flexible and adaptable to different intuitions within defeasible reasoning; and (e) can reason with rules, RDF, RDF Schema and (parts of) OWL ontologies.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-006.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 11. Knowledge Representation
241,2005,Student Abstracts,Genre Classification of Web Documents,"Elizabeth S Boese, Adele Howe","Retrieving relevant documents over the Web is an overwhelming task when search engines return thousands of Web documents. Sifting through these documents is time-consuming and sometimes leads to an unsuccessful search. One problem is that most search engines rely on matching a query to documents based solely on topical keywords. However, many users of search engines have a particular genre in mind for the desired documents. The genre of a document concerns aspects of the document such as the style or readability, presentation layout, and meta-content such as words in the title or the existence of graphs or photos. By including genre in Web searches, we hypothesize that Web document retrieval could greatly improve accuracy by better matching documents to the user’s information needs. Before implementing a search engine capable of discriminating on both genre and topic, a feasibility analysis of genre classification is needed. Our previous research achieved 91% classification accuracy across ten genres, whereas similar research range between 60 and 85% accuracy. However, the ten genres used in our research were mostly distinct and only exemplar Web documents (consisting of only one genre) were chosen. This paper discusses our current work which involves an in-depth analysis of maintaining high accuracy rates among genres that are very similar.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-007.pdf,Subjects: 1.10 Information Retrieval; 12. Machine Learning and Discovery
242,2005,Student Abstracts,Rule Refinement by Domain Experts in Complex Knowledge Bases,"Cristina Boicu, Gheorghe Tecuci, Mihai Boicu","We research how domain experts can develop knowledge-based systems that incorporate their expertise. Our approach is to develop a learning agent that an expert can teach by explaining it how to solve specific problems, and by critiquing agent’s attempts to solve new problems. In this paper we present an integrated set of methods that support the domain expert in refining the rules from the agent’s large knowledge base. We developed methods to focus the expert on those steps of agent’s reasoning process that require expert’s analysis. To alleviate the expert’s tendency to omit implicit details in human communication we developed two complementary rule analysis methods that guide the expert to provide more explanations of the rule’s examples. We developed methods that analyze the expert’s critique of an example and selects the best rule refinement strategy. We developed a lazy rule refinement method that allows the modification of a learned rule, or the learning of a closely related rule, without requiring the expert to perform an analysis of the rule’s representative examples at the time of the modification. Instead, this analysis is postponed until the agent applies the rule in problem solving.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-008.pdf,Subjects: 10. Knowledge Acquisition; 12. Machine Learning and Discovery
243,2005,Student Abstracts,Use of Expert Knowledge for Decision Tree Pruning,"Jingfeng Cai, John Durkin","There are many methods to prune decision trees, but the idea of cost-sensitive pruning and use of expert knowledge for decision tree pruning have received much less investigation even though additional flexibility and increased performance can be obtained from this method. In this paper, we introduce a cost-sensitive decision tree pruning algorithm called CC4.5 based on the C4.5 algorithm and illustrate how we use expert knowledge to help us set cost matrices. CC4.5 uses the same method as C4.5 to construct the original decision tree, but the pruning methods in CC4.5 are different from that in C4.5. CC4.5 includes three cost-sensitive pruning methods to deal with misclassification cost in the decision tree. Unlike other pruning algorithms, CC4.5 uses intelligent inexact classification and expert knowledge to consider both error and cost when pruning. Moreover, experiments show that CC4.5 results in improved decision trees with respect to the cost.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-009.pdf,Subjects: 15.6 Decision Trees; 1.7 Expert Systems
244,2005,Student Abstracts,Learning Support Vector Machines from Distributed Data Sources,"Cornelia Caragea, Doina Caragea, Vasant Honavar",In this paper we address the problem of learning Support Vector Machine (SVM) classifiers from distributed data sources. We identify sufficient statistics for learning SVMs and present an algorithm that learns SVMs from distributed data by iteratively computing the set of sufficient statistics. We prove that our algorithm is exact with respect to its centralized counterpart and efficient in terms of time complexity.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-010.pdf,Subjects: 12. Machine Learning and Discovery; 10. Knowledge Acquisition
245,2005,Student Abstracts,Boosting Semantic Web Data Access Using Swoogle,LI Ding and Tim Finin,We have developed swoogle to facilitate semantic web data access in the web context,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-011.pdf,Subjects: 1.10 Information Retrieval; 11.2 Ontologies
246,2005,Student Abstracts,Towards Exploiting Duality in Approximate Linear Programming for MDPs,"Dmitri Dolgov, Edmund Durfee","A weakness of classical Markov decision processes is that they scale very poorly due to the flat state-space representation. Factored MDPs attempt to address this by exploiting problem structure. However, in general, solutions to factored MDPs do not retain the structure and compactness of the problem representation, forcing approximate solutions, with approximate linear programming (ALP) emerging as a very promising MDP-approximation technique. However, the ALP work has focused on approximating the primal LP, and no effort has been invested in approximating the dual LP, which serves as the basis for solving a wide range of constrained MDPs. Our analysis of the dual LP shows that a straightforward application of linear approximations is not as well-suited for the dual, because some of the required computations cannot be carried out efficiently. Nonetheless, we demonstrate that this can be resolved by a method that approximates both the primal and the dual optimization coordinates, resulting in an ALP that is well-suited for constrained problems. It effectively approximates both the optimization coordinates and the feasible regions of the LPs, and thus also serves as a new method for a widely-discussed problem of dealing with exponentially many constraints, which plagues both the primal and the dual ALP formulations.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-012.pdf,Subjects: 3.4 Probabilistic Reasoning; 15.4 Reactive Control
247,2005,Student Abstracts,Manufacturing Processes Recognition of Machined Mechanical Parts using SVMs,"Cheuk Yiu Ip, William C. Regli",This research studied using curvature and support vector machines (SVMs) to identify manufacturing processes of mechanical parts. Prior developments in computer vision and graphics has been able to recognize shapes of 2D and 3D models. This work contributes a technique for recognizing manufacturing processes from CAD models. Prismatic machined and cast-then-machined are two typical processes for making mechanical parts; being able to recognize them respectively assists in manufacturing cost estimation. This work integrates surface curvature estimation (from computer graphics) and machine learning to perform manufacturing recognition of artifacts. Surface curvature is used as the discriminating feature; SVMs learn the separation in between the two manufacturing processes.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-013.pdf,Subjects: 1.6 Engineering And Science
248,2005,Student Abstracts,An Automated Distributed Meeting Scheduler for FCVW Plug-in,"Hsiang-Hwa Koo, Elhadi Shakshuki","People have faced conflicts for shifting scheduled meetings to other time slots in order to fit incoming meetings or to find a time slot to book a meeting. The goal of this research is to develop a personal distributed meeting scheduler in FCVW (Federated Collaborative Virtual Workspace) that assists users to deal with these situations. FCVW is an extension of CVW [6] developed by MITRE. In our approach to meeting scheduling, is to provide each user with meeting scheduler agent. Each agent is able to manage, negotiate and schedule tasks, meetings, events, appointments for its user. This paper describes the objective of our research to develop an automated distributed meeting scheduler.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-014.pdf,Subjects: 1.12 Scheduling; 7. Distributed AI
249,2005,Student Abstracts,Description Logic-Ground Knowledge Integration and Management,Joseph B Kopena,"This abstract describes ongoing work in developing large-scale knowledge repositories. The project addresses three primary aspects of such systems: integration of knowledge sources; access and retrieval of stored knowledge; scalable, effective repositories. Previous results have shown the effectiveness of description logic-based representations in integrating knowledge sources and the role of non-standard inferences in supporting repository reasoning tasks. Current efforts include developing general-purpose mechanisms for adapting reasoning algorithms for optimized inference under known domain structure and effective use of database technology as a large-scale knowledge base backend.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-015.pdf,Subjects: 11.1 Description Logics; 1.6 Engineering And Science
250,2005,Student Abstracts,Continuous Speech Recognition Using Modified Stack Decoding Algorithm,David C. Lee,This paper attempts to recognize a speech sequence with a series of words. We represent words with HMM models and use a modified version of stack decoding method as the primary algorithm to recognize words. This type of method allows us to recognize a streaming sequence of speech signal as we receive it. We introduced a heuristic function that works with stack decoding algorithm. We also observed how model parameters affect the performance of the algorithm.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-016.pdf,Subjects: 18. Speech Understanding
251,2005,Student Abstracts,Qualitative Dimensions in Question Answering: Extending the Definitional QA Task,"Lucian Lita, Andrew Hazen Schlaikjer, WeiChang Hong, Eric Nyberg","Current question answering tasks handle definitional questions by seeking answers which are factual in nature. While factual answers are a very important component in defining entities, a wealth of qualitative data is often ignored. In this incipient work, we define qualitative dimensions (credibility, sentiment, contradictions etc.) for evaluating answers to definitional questions and we explore potential benefits to users. These qualitative dimensions are leveraged to uncover indirect and implicit answers and can help satisfy the user’s information need.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-017.pdf,Subjects: 13. Natural Language Processing
252,2005,Student Abstracts,A Learning Support Method in Qualitative Simulation-based Economic Education,"Tokuro Matsuo, Takayuki Ito, Toramatsu Shintani","In this paper, we propose a support method of our e-learning support system based on qualitative simulation. In comparison existing education system using qualitative simulation, our system provide a simple input form in the simulation. When models and initial values are changed, users can know what influence its changing brings a result. Our system can be used without mentor, because users can input initial values easily in our system. Our system can be also a promising application as a self-learning system for a tele-education.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-018.pdf,Subjects: 3.5 Qualitative Reasoning
253,2005,Student Abstracts,Evolving AI Opponents in a First-Person-Shooter Video Game,"Christopher A. Overholtzer, Simon D. Levy","We show successful application of a genetic algorithm (GA) to evolving challenging opponents (agents) in an existing, open-source first-person-shooter (FPS) video game. Each of an agent’s possible decisions (jump over obstacle, shoot at human) is represented by a single boolean value, and a set of such values is combined into a single data structure representing the ""DNA"" for that agent. At the end of each ""generation"" (game), surviving agents are chosen probabilistically based on their fitness (performance); their DNA is saved to disk, and they are thereby ""reborn"" to play against a human in the next generation. Qualitatively, these agents end up being a lot more fun for a human to play against, than agents whose difficulty comes from hard-coded increments or increased numbers. Quantitatively, we were able to observe counter-intuitive patterns in the density of certain ""genes"" in the population, confirming the validity of the evolutionary approach. Our success also highlights the value of open-source platforms for the AI community.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-019.pdf,Subjects: 1.9 Genetic Algorithms; 1.8 Game Playing
254,2005,Student Abstracts,A Framework for Bayesian Network Mapping,"Rong Pan, Yun Peng","This research is motivated by the need to support inference across multiple intelligence systems involving uncertainty. Our objective is to develop a theoretical framework and related inference methods to map semantically similar variables between separate Bayesian networks in a principled way. The work is to be conducted in two steps. In the first step, we investigate the problem of formalizing the mapping between variables in two separate BNs with different semantics and distributions as pairwise linkages. In the second step, we aim to justify the mapping between networks as a set of selected variable linkages, and then conduct in-ference along it.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-020.pdf,Subjects: 3.4 Probabilistic Reasoning; 7. Distributed AI
255,2005,Student Abstracts,Minimizing Environmental Swings with a Recurrent Neural Network Control System,"Sam Skrivan, Dr. Jianna Zhang, Dr. Debra Jusak","Maintaining environmental stability in a dynamic system is a difficult challenge. In your living room, when you set your thermostat to 68 degrees the actual temperature cycles above and below 68 degrees. We use a Recurrent Neural Network (RNN) in an Aquarium Control System that reduces such environmental swings.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-021.pdf,Subjects: 14. Neural Networks; 15.3 Control
256,2005,Student Abstracts,Autonomous Learning of Tool Affordances by a Robot,Alexander Stoytchev,"This paper introduces a novel approach to representing and learning tool affordances by a robot. The tool representation described here uses a behavior-based approach to ground the tool affordances in the behavioral repertoire of the robot. The representation is learned during a behavioral babbling stage in which the robot randomly chooses different exploratory behaviors, applies them to the tool, and observes their effects on environmental objects. The paper shows how the autonomously learned affordance representation can be used to solve tool-using tasks by dynamically sequencing the exploratory behaviors based on their expected outcomes. The quality of the learned representation was tested on extension-of-reach tool-using tasks.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/SA05-022.pdf,Subjects: 17. Robotics
257,2005,Doctoral Consortium,Leveraging Language into Learning,Jacob Beal,"I hypothesize that learning a vocabulary to communicate between components of a system is equivalent to general learning. Moreover, I assert that some problems of general learning, such as eliminating bad hypotheses, deepening shallow representations, and generation of near-misses, will become simpler when refactored into communication learning problems.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-001.pdf,Subjects: 2. Architectures; 7. Distributed AI
258,2005,Doctoral Consortium,Dissertation in Progress: An Empirical Analysis of the Costs and Benefits of Naturalness in Spoken Dialog Systems,Ellen Campana,"In this paper I describe work for my Ph.D. dissertation which is currently in progress. The overarching goal of the work is to develop a methodology for empirically evaluating the effects of different interface design decisions in spoken dialogue systems. The methodology I will use is the dual-task method, borrowed from cognitive psychology, which is advantageous because it provides fine-grained information about the cognitive load of the user while he/she is engaged in interacting with the system. For my dissertation I will focus specifically on the use of definite referring expressions and the question of whether “natural” or “fully-specified” definite referring expressions are easier for users to generate and/or understand. The answers are important because both strategies are used in systems on the market today. More importantly, I hope my work will provide a tool for software developers, and encourage them to carefully weigh the empirically observed costs and benefits of various design decisions.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-002.pdf,Subjects: 6. Computer-Human Interaction; 13. Natural Language Processing
259,2005,Doctoral Consortium,Learning Source Descriptions for Web Services,Mark J Carman,"New Web Services are being made available on the internet all the time, and while some of them provide completely new functionality, most are slight variations on already existing services. I am interested in the problem of enabling systems to take advantage of new services without the need for reprogramming. In this extended abstract, I outline an approach to automatically generating Local-As-View models for the new Web Service using Inductive Logic Programming techniques.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-003.pdf,Subjects: 12. Machine Learning and Discovery
260,2005,Doctoral Consortium,Computational Aspects of Mechanism Design,Vincent Conitzer,"In a preference aggregation setting, a group of agents must jointly make a decision, based on the individual agents’ privately known preferences. To do so, the agents need some protocol (or mechanism) that will elicit this information from them, and make the decision. Examples of such mechanisms include voting protocols, auctions, and exchanges. In most real-world settings, preference aggregation is confronted with the following three computational issues. First, there is the complexity of executing the mechanism. Second, when standard mechanisms do not apply to or are suboptimal for the setting at hand, there is the complexity of designing the mechanism. Third, the agents face the complexity of (strategically) participating in the mechanism. My thesis statement is that by studying these computational aspects of the mechanism design process, we can significantly improve the generated mechanisms in a hierarchy of ways, leading to increased economic welfare.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-004.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
261,2005,Doctoral Consortium,On Boosting Semantic Web Data Access,Li Ding,Swoogle is a metadata and search engine for the semantic web. We enrich its features to make it supporting web scale semantic web data access.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-005.pdf,Subjects: 1.10 Information Retrieval; 11.2 Ontologies
262,2005,Doctoral Consortium,Dynamic Regime Identification and Prediction Based on Observed Behavior in Electronic Marketplaces,Wolfgang Ketter,"We present a method for an autonomous agent to identify dominant market conditions, such as oversupply or scarcity. The characteristics of economic regimes are learned from historic data and used, together with real-time observable information, to identify the current market regime and to forecast market changes. The approach is validated with data from the Trading Agent Competition for Supply Chain Management.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-006.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
263,2005,Doctoral Consortium,Adaptive Modeling and Planning for Reactive Agents,Mykel J. Kochenderfer,"This research is concerned with problems where an agent is situated in a stochastic world without prior knowledge of the world’s dynamics. The agent must act in such a way so as to maximize its expected discounted reward over time. The state and action spaces are extremely large or infinite, and control decisions are made in continuous time. The objective of this research is to create a system capable of generating competent behavior in real time.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-007.pdf,Subjects: 12.1 Reinforcement Learning; 15.4 Reactive Control
264,2005,Doctoral Consortium,Self-Emergence of Structures in Gene Expression Programming,Xin Li,"This thesis work aims at improving the problem solving ability of the Gene Expression Programming (GEP) algorithm to fulfill complex data mining tasks by preserving and utilizing the self-emergence of structures during its evolutionary process. The main contributions include the investigation of the constant creation techniques for promoting good functional structures emergent in the evolution, analysis of the limitation with the current implementation scheme of GEP, and introduction of a novel utilization of the emergent structures to achieve a flexible search process for solutions at a higher level.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-008.pdf,Subjects: 1.9 Genetic Algorithms; 12. Machine Learning and Discovery
265,2005,Doctoral Consortium,Concurrent Hierarchical Reinforcement Learning,Bhaskara Marthi,"We describe concurrent ALisp, a language that extends hierarchical reinforcement learning techniques to multi-effector domains.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-009.pdf,Subjects: 12. Machine Learning and Discovery; 7.1 Multi-Agent Systems
266,2005,Doctoral Consortium,Discourse Factors in Multi-document Summarization,Ani Nenkova,"The over-abundance of information today, especially on-line, has established the need for natural language technologies that can help the user find relevant information; multi-document summarization (MDS) and question answering (QA) are two examples. The requirement in MDS and open-ended QA to produce multi-sentential answers imposes the extra demand that the output of such systems be a coherent discourse. The problem of generating appropriate referring expressions to entities in these texts is non-trivial, because different sentences are taken from their original context and put together to form a text. The new context of the summary often requires changes in surface realization of the references, demanding the inclusion of additional information or removal of redundant information. Such changes can be implemented by gathering a collection of possible references to an entity from the input documents and then rewriting the references in the sentences selected for inclusion in the summary. A question arises how to determine which attributes or descriptions of the referent would be appropriate for the context of the summary.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-010.pdf,Subjects: 13. Natural Language Processing; 13.1 Discourse
267,2005,Doctoral Consortium,Structure Learning for Statistical Relational Models,Jennifer Neville,"Many data sets are relational in nature (e.g., citation graphs, the World Wide Web, genomic structures). These data offer unique opportunities to improve model accuracy, and thereby decision-making, if machine learning techniques can effectively exploit the relational information. To date research on statistical relational models has focused primarily on knowledge representation and inference--there has been little attention paid to the challenges and opportunities that are unique to learning in relational domains. This work will consider in depth the issue of structure learning and focus on developing accurate and efficient structure learning techniques for statistical relational models.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-011.pdf,Subjects: 12. Machine Learning and Discovery
268,2005,Doctoral Consortium,Towards Competence in Autonomous Agents,Ozgur Simsek,"My thesis aims to contribute towards building autonomous agents that are able to develop competency over their environment -- agents that are able to achieve mastery over their domain and are able to solve new problems as they arise using the knowledge and skills they acquired in the past. I propose a number of methods for building competence in autonomous agents using the reinforcement learning framework, a computational approach to learning from interaction. These methods allow an agent to autonomously develop a set of skills (closed-loop policies over lower-level actions) that allows the agent to interact effectively with its environment and flexibly deal with new tasks.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-012.pdf,Subjects: 12. Machine Learning and Discovery; 12.1 Reinforcement Learning
269,2005,Doctoral Consortium,Rover Science Autonomy: Probabilistic Planning for Science-Aware Exploration,Trey Smith,"Future Mars rovers will have the ability to autonomously navigate for distances of kilometers. In one sol a traverse may take a rover into unexplored areas beyond its local horizon. The rover can explore these areas more effectively if it is able to detect and react to science opportunities on its own, what we call science autonomy. We are studying science autonomy in two ways: first, by implementing a simple science autonomy system on a rover in the field, and second, by developing probabilistic planning technology that can enable more principled autonomous decision-making in future systems.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-013.pdf,Subjects: 3.4 Probabilistic Reasoning; 17. Robotics
270,2005,Doctoral Consortium,Natural Language Generation for Text-to-Text Applications Using an Information-Slim Representation,Radu Soricut,"I propose a representation formalism and algorithms to be used in a new language generation mechanism for text-to-text applications. The generation process is driven by both text-specific information encoded via probability distributions over words and phrases derived from the input text, and general language knowledge captured by n-gram and syntactic laguage models.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-014.pdf,Subjects: 13. Natural Language Processing
271,2005,Doctoral Consortium,Planning for Geospatial Data Integration,Snehal Thakkar,"In this extended abstract, I present my research on developing a geospatial data integration framework that can be utilized to rapidly generate applications, such as the Building Finder. In particular, I describe the work that I have done on modelling data sources and complex operations, query reformulation, and optimization. In addition, I discuss of the work that remains to be done.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-015.pdf,Subjects: 1.11 Planning; 1.6 Engineering And Science
272,2005,Doctoral Consortium,Improving Reinforcement Learning Function Approximators via Neuroevolution,Shimon Whiteson,"Reinforcement learning problems are commonly tackled with temporal difference methods, which use dynamic programming and statistical sampling to estimate the long-term value of taking each action in each state. In most problems of real-world interest, learning this value function requires a function approximator, which represents the mapping from state-action pairs to values via a concise, parameterized function and uses supervised learning methods to set its parameters. Function approximators make it possible to use temporal difference methods on large problems but, in practice, the feasibility of doing so depends on the ability of the human designer to select an appropriate representation for the value function. My thesis presents a new approach to function approximation that automates some of these difficult design choices by coupling temporal difference methods with policy search methods such as evolutionary computation. It also presents a particular implementation which combines NEAT, a neuroevolutionary policy search method, and Q-learning, a popular temporal difference method, to yield a new method called NEAT+Q that automatically learns effective representations for neural network function approximators. Empirical results in a server job scheduling task demonstrate that NEAT+Q can outperform both NEAT and Q-learning with manually designed neural networks.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/DC05-016.pdf,Subjects: 12.1 Reinforcement Learning; 1.9 Genetic Algorithms
273,2005,Doctoral Consortium,Supervised Ranking for Pronoun Resolution: Some Recent Improvements,Vincent Ng,"A recently-proposed machine learning approach to reference resolution --- the twin-candidate approach --- has been shown to be more promising than the traditional single-candidate approach. This paper presents a pronoun interpretation system that extends the twin-candidate framework by (1) equipping it with the ability to identify non-referential pronouns, (2) training different models for handling different types of pronouns, and (3) incorporating linguistic knowledge sources that are generally not employed in traditional pronoun resolvers. The resulting system, when evaluated on a standard coreference corpus, outperforms not only the original twin-candidate approach but also a state-of-the-art pronoun resolver.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/AAAI05-171.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
274,2005,Intelligent Systems Demonstrations,QUONTO: QUerying ONTOlogies,"Andrea Acciarri, Diego Calvanese, Giuseppe De Giacomo, Domenico Lembo,Maurizio Lenzerini, Mattia Palmieri, Riccardo Rosati","In this work, we present QUONTO, a query answeringsystem based on DL-Lite. Our system provides three basicfunctionalities: (1) specification of the intensional levelof the ontology (TBox), (2) specification of the extensionallevel of the ontology (ABox), and (3) query answering.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-001.pdf,
275,2005,Intelligent Systems Demonstrations,Building Applications Using End to End Composition ofWeb Services,"Vikas Agarwal, Girish Chafle, Koustuv Dasgupta, Neeran Karnik, Arun Kumar, Ashish Kundu, Anupam Mediratta, Sumit Mittal, and Biplav Srivastava","Two different approaches have been taken to standardize and compose web services. The business world has adopted a distributed systems approach in which web service instances are described using WSDL, composed into flows with a language like BPEL,and invoked with the SOAP protocol. Academia has propounded the AI approach of formally representing web service capabilities in ontologies, and reasoning about their functional composition using goaloriented inferencing techniques from planning. These approaches by themselves are piecemeal, and insufficient. Our system takes an end to end view that synergistically combines the AI approach and the distributed programming approach currently adopted by academia and industry respectively. It drives the composition process right from specification of the business process, through creation of desired functionality using planning techniques, through generation of a deployable workflow by selection and binding of appropriate service instances, to finally deploying and running the composite service. This integrated solution achieves the best of both worlds and provides scalability to the composition process.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-002.pdf,
276,2005,Intelligent Systems Demonstrations,The AI Technologies of the Philadelphia Area Urban Wireless Network Testbed,Gustave Anderson and Andrew Burnheimer and Vincent Cicirello and David Dorsey and Chris Dugan and Iris Howley and Moshe Kam and Joseph Kopena and Rob Lass and Kris Malfettone and Andy Mroczkowski and Gaurav Naik and Max Peysakhov and Brian Pyles and William Regli and Evan Sultanik and James Thiel and Kyle Usbeck and Dan Venutolo and Marc Winners,"Drexel University’s College of Engineering has been working with local law enforcement and transportation officials to develop a Philadelphia Area Urban Wireless Network Testbed (PA-UWNT). The PAUWNT is a mobile ad hoc network (MANET) consisting of PDAs (HP iPAQs), Tablet PCs, and laptops. The PAUWNT integrates: (1) the industrial-strength mobile agent platform of Lockheed’s Advanced Technology Laboratories known as the Extendable Mobile Agent Architecture (EMAA) (2) an 802.11b wireless network with ad hoc routing; and (3) lightweight computing platforms such as PDAs and Tablets. MANETs, such as the PA-UWNT, can allow for a ‘bring your own network” solution to communications and management of rescue workers at the location of a natural disaster, where traditional networking infrastructure is not likely to exist or at best is likely to be inoperable. One of the goals of the PA-UWNT is to enable researchers at Drexel University to study research problems of importance to the enabling of police, fire, security, and other emergency personnel to communicate and collaborate effectively over MANETs.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-003.pdf,
277,2005,Intelligent Systems Demonstrations,Proving Theorems of Type Theory Automatically with TPS,Peter B. Andrews,"Automated reasoning can be expected to play a significant role in many applications of artificial intelligence, and techniques for proving theorems automatically can serve as inference mechanisms in general purpose automated reasoning tools. We demonstrate and discuss how the TPS automated Theorem Proving System proves theorems of type theory, which is also known as higher-order logic and includes first-order logic. Notations used by TPS, which are very close to traditional notations of logic and mathematics, are explained. In a practical sense, type theory is a richer and more expressive formal language than first-order logic. A great variety of statements can be expressed very naturally in type theory, though most of the theorems which TPS has proved automatically thus far have a mathematical flavor. Examples include: X5305: Cantor’s Theorem that every set has more subsets than members. THM15B: If some iterate of a function f has a unique fixed point, then f has a fixed point. THM136: The transitive closure of a relation is transitive. THM145B: In a complete lattice, every monotone function has a fixed point.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-004.pdf,Subjects: 3. Automated Reasoning; 15.9 Theorem Proving
278,2005,Intelligent Systems Demonstrations,A Learning and Reasoning System for Intelligence Analysis,"Mihai Boicu, Gheorghe Tecuci, Cindy Ayers, Dorin Marcu, Cristina Boicu, Marcel Barbulescu, Bogdan Stanescu, William Wagner, Vu Le, Denitsa Apostolova, Adrian Ciubotariu","This paper presents a personal cognitive assistant, called Disciple-LTA, that can acquire expertise in intelligence analysis directly from intelligence analysts, can train new analysts, and can help analysts find solutions to complex problems through mixed-initiative reasoning, making possible the synergistic integration of a human’s experience and creativity with an automated agent’s knowledge and speed, and facilitating the collaboration with complementary experts and their agents.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-005.pdf,
279,2005,Intelligent Systems Demonstrations,MADbot: A Motivated And Goal Directed Robot,"Alex Coddington, Maria Fox, Jonathan Gough, Derek Long, Ivan Serina","In most work in plan generation and execution the assumption has been made that the goals being addressed by the planning system (and executive) are imposed externally and that once a plan has been constructed to achieve these goals the activity of the planner can cease. Similarly, once the plan has been successfully executed and a state satisfying the externally imposed goals has been reached, it has been assumed that the planning and execution behaviours will suspend until a new goal set and consequent plan has been imposed. These assumptions do not hold for fully autonomous systems, which are capable of directing their own behaviour and prioritising their own goals. The problem we are most concerned with is determining how goals arise during the autonomous behaviour of a system.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-006.pdf,Subjects: 1.11 Planning; 17. Robotics
280,2005,Intelligent Systems Demonstrations,Swoogle: Searching for knowledge on the Semantic Web,"Tim Finin, Li Ding, Rong Pan, Anupam Joshi, Pranam Kolari, Akshay Java and Yun Peng","The Semantic Web’s distributed nature raises significant data access problems — how can an agent discover, index, search and navigate knowledge on the Semantic Web? Swoogle was developed to facilitate webscale semantic web data access by providing these services to both human and software agents. It focuses on two levels of knowledge granularity: URI based semantic web vocabulary and semantic web documents (SWDs), i.e., RDF and OWL documents encoded in XML, NTriples or N3.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-007.pdf,
281,2005,Intelligent Systems Demonstrations,Optimal Rhode Island Hold'em Poker,"Andrew Gilpin, Tuomas Sandholm","Rhode Island Hold'em is a poker card game that has been proposed as a testbed for AI research. This game, with a tree size larger than 3.1 billion nodes, features many characteristics present in full-scale poker (e.g., Texas Hold'em). Our research advances in equilibrium computation have enabled us to solve for the optimal (equilibrium) strategies for this game. Some features of the equilibrium include poker techniques such as bluffing, slow-playing, check-raising, and semi-bluffing. In this demonstration, participants will compete with our optimal opponent and will experience these strategies firsthand.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-008.pdf,Subjects: 1.8 Game Playing; 7.1 Multi-Agent Systems
282,2005,Intelligent Systems Demonstrations,Evolution of an Empathetic Digital Entity: Phase One,Margaret Manella Kozak,"This demonstration highlights the first of seven segments designed to develop a digital entity that will possess the potential for human empathy. The experiences in the first phase of the digital entity Zoe (Zero-One Entity) parallel a subset of learning and development activities encountered by human beings during their first nine months of existence. A website has been created to provide a window to observe Zoe’s experiences and action selection process in order to make her basic learning observable, cumulative, and evolutionary. The human observer is invited to influence her action selection by setting the intensity of Zoe’s digital personality traits such as assertiveness, reasoning ability, and disposition. Actions generate body-based and emotive-based feelings which are stored in memory structures. Significantly, these structures serve as a foundation for later stages of learning, understanding and reasoning.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-009.pdf,
283,2005,Intelligent Systems Demonstrations,Language Independent Extractive Summarization,Rada Mihalcea,"TextRank is a system for unsupervised extractive summarization that relies on an innovative application of iterative graph-based ranking algorithms to graphs encoding the cohesive structure of texts. An important characteristic of the system is that it does not rely on any language-specific knowledge resources or any manually constructed training data, and thus it is highly portable to new languages or domains.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-010.pdf,Subjects: 13. Natural Language Processing; 6. Computer-Human Interaction
284,2005,Intelligent Systems Demonstrations,TIELT: A Testbed for Gaming Environments,Matthew Molineaux and David W. Aha,"Many AI researchers want to test the utility of their systemsin complex task environments defined by (e.g., real-timestrategy) gaming simulators and/or simulators of computergeneratedforces. Also, many developers of commercial andmilitary gaming simulators seek behaviors that can besupported by these systems. However, these integrationsrequire great effort. We will demonstrate the late Alphaversion of TIELT, a testbed designed to fill these needs.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-011.pdf,
285,2005,Intelligent Systems Demonstrations,SenseRelate::TargetWord-A Generalized Framework for Word Sense Disambiguation,"Siddharth Patwardhan, Satanjeev Banerjee, and Ted Pedersen",Many words in natural language have different meanings when used in different contexts. SenseRelate::TargetWord is a Perl package that disambiguates a target word in context by finding the sense that is most related to its neighbors according to a WordNet::Similarity measure of relatedness.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-012.pdf,
286,2005,Intelligent Systems Demonstrations,Identifying Similar Words and Contexts in Natural Language Using SenseClusters,"Ted Pedersen, Anagha Kulkarni","SenseClusters is a freely available intelligent system that clusters together similar contexts in natural language text. Thereafter it assigns identifying labels to these clusters based on their content. It is a purely unsupervised approach that is language independent, and uses no knowledge other than what is available in raw un-annotated corpora. In addition to clustering similar contexts, it can be used to identify synonyms and sets of related words. It has been applied to a diverse range of problems, including proper name disambiguation, word sense discrimination, email organization, and document clustering. SenseClusters is a complete system that supports feature selection from large corpora, several different context representation schemes, various clustering algorithms, the creation of descriptive and discriminating labels for the discovered clusters, and evaluation relative to gold standard data.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-013.pdf,Subjects: 13. Natural Language Processing
287,2005,Intelligent Systems Demonstrations,Song Search and Retrieval by Tapping,"Geoff Peters, Caroline Anthony, Michael Schwartz","We present an interactive, web based system for musical song search and retrieval, using rhythmic tapping as the primary means of query input. Our approach involves encoding the input rhythm as a contour string, and using approximate string matching to determine the most likely match with songs in the database.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-014.pdf,Subjects: 1.1 Art And Music; 1.10 Information Retrieval
288,2005,Intelligent Systems Demonstrations,The Proteome Analyst Suite of Automated Function Prediction Tools,"Brett Poulin, Duane Szafron, Paul Lu, Russell Greiner, David Wishart, Roman Eisner, Alona Fyshe, Brandon Pearcy, Luca Pireddu","Proteome Analyst (PA) is a publicly available, high-throughput, web-based system for automatically predicting the function and properties of proteins. Biologists can use PA to predict, for example, the Gene Ontology (GO) molecular function and subcellular localization of a protein based on sequence information. Using sequence analysis tools and machine learning, PA gives high accuracy and broad coverage for both molecular function and subcellular localization predictions.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-015.pdf,Subjects: 12. Machine Learning and Discovery
289,2005,Intelligent Systems Demonstrations,DiamondHelp: A Collaborative Task Guidance Framework for Complex Devices,"Charles Rich, Candy Sidner, Neal Lesh, Andrew Garland, Shane Booth, Markus Chimani","DiamondHelp is a reusable Java framework for building collaborative task guidance systems for complex devices, such as digitally enabled home appliances. DiamondHelp combines a generic conversational interface, adapted from online chat programs, with an application-specific direct manipulation interface. DiamondHelp provides ‘a things to say” mechanism for use without spoken language understanding; it also supports extensions to take advantage of speech technology. DiamondHelp’s software architecture factors all application-specific content into two modular plug-ins, one of which includes Collagen and a task model.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-016.pdf,
290,2005,Intelligent Systems Demonstrations,Remote Supervisory Control of a Humanoid Robot,"Michael T. Rosenstein, Andrew H. Fagg, Robert Platt, John D. Sweeney, Roderic A. Grupen","For this demonstration, participants have the opportunity to control a humanoid robot located hundreds of miles away. The general task is to reach, grasp, and transport various objects in the vicinity of the robot. Although remote ""pick-and-place"" operations of this sort form the basis of numerous practical applications, they are frequently error-prone and fatiguing for human operators. Participants can experience the relative difficulty of remote manipulation both with and without the use of an assistive interface. This interface simplifies the task by injecting artificial intelligence in key places without seizing higher-level control from the operator. In particular, we demonstrate the benefits of two key components of the system: a video display of predicted operator intentions, and a haptic-based controller for automated grasping.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-017.pdf,Subjects: 17. Robotics; 6.3 User Interfaces
291,2005,Intelligent Systems Demonstrations,MGLAIR Agents in Virtual and other Graphical Environments,"Stuart C. Shapiro, Josephine Anstey, David E. Pape, Trupti Devdas Nayak, Michael Kandefer, Orkan Telhan","We are demonstrating several intelligent agents built according to the MGLAIR (Modal Grounded Layered Architecture with Integrated Reasoning) agent architecture. The top layer of MGLAIR is implemented in SNePS and its acting subsystem, SNeRE (the SNePS Rational Engine). The major demonstration will be act 3 of The Trial The Trail, an interactive drama running on an immersive Virtual Reality system, in which a human participant interacts with several MGLAIR actor-agents. We will also demonstrate several other MGLAIR agents that operate in non-VR graphical environments. All these agents illustrate our approach to building agents with integrated first-person, on-line reasoning and acting.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-018.pdf,Subjects: 1.1 Art And Music; 6.4 Virtual Reality
292,2005,Intelligent Systems Demonstrations,Solo: A Cognitive Orthosis,"Richard C Simpson, Edmund LoPresti, Debra Schreckenghost, Ned Kirsch, Steve Hayashi","Solo is a cognitive assistive device which provides support in remembering when to perform tasks, executing the steps in a task, and recovering from unexpected events. The system includes an interface for clients to receive reminders, an interface for caregivers to enter information about the client’s scheduled tasks, and a Cognition Manager which provides reminders and task guidance at appropriate times.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-019.pdf,Subjects: 1. Applications; 1.11 Planning
293,2005,Intelligent Systems Demonstrations,SAGA-ML: An Active Learning System for Semi-automated Gameplay Analysis,"Finnegan Southey, Robert C. Holte","As software systems grow, software testing has become increasingly onerous. Consequently, statistical software testing and machine learning techniques have become increasingly attractive. Following these approaches, we present SAGA-ML (Semi-Automated Gameplay Analysis by Machine Learning), an active learning system for blackbox software testing, and SoccerViz, an analysis vizualization tool for Electronic Arts’ FIFA Soccer game. SAGA-ML was developed in the context of commercial video games, complex virtual worlds with state spaces too large for exhaustive testing. Beyond program correctness, developers must evaluate the gameplay of a game (e.g. its difficulty). SAGA-ML, which is not game-specific, samples the blackbox software system to learn a model of the system’s behaviour. This model is used to i) select new points for sampling, and ii) summarize the game’s behaviour for the developer. The demonstration shows how models learned by SAGA-ML (generated offline) can be visualized and explored by the developer via the game-specific SoccerViz tool.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-020.pdf,Subjects: 12. Machine Learning and Discovery; 1. Applications
294,2005,Intelligent Systems Demonstrations,Using the GEMS System for Cancer Diagnosis and Biomarker Discovery from Microarray Gene Expression Data,"Alexander Statnikov, Ioannis Tsamardinos, Constantin F. Aliferis","We will demonstrate the GEMS system for automated development and evaluation of high-quality cancer diagnostic models and biomarker discovery from microarray gene expression data. The development of GEMS was informed by the results of an extensive algorithmic evaluation using 11 microarray datasets. The system was further evaluated in two cross-dataset applications and using 5 microarray datasets. The performance of models produced by GEMS is comparable or better than the results obtained by human analysts, and these models generalize well to independent samples in cross-dataset applications. The system is freely available for download from http://www.gems-system.org for noncommercial use.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-021.pdf,
295,2005,Intelligent Systems Demonstrations,The TaskTracer System,"Simone Stumpf, Xinlong Bao, Anton Dragunov, Thomas G. Dietterich, Jon Herlocker, Kevin Johnsrude, Lida Li, JianQiang Shen","Knowledge workers spend the majority of their working hours processing and manipulating information. These users face continual costs as they switch between tasks to retrieve and create information. The TaskTracer project at Oregon State University investigates the possibilities of a desktop software system that will record in detail how knowledge workers complete tasks, and intelligently leverage that information to increase efficiency and productivity. Our approach assigns each observed user interface action to a task for which it is likely being performed. In this demonstration we show how we have applied machine learning in this environment.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/ISD05-022.pdf,Subjects: 6. Computer-Human Interaction
296,2005,Mobile Robot Competition and Exhibition,Low-cost Outdoor Robot Platform for the Penn State Abington Mini Grand Challenge,Robert Avanzato,"A low-cost, autonomous, outdoor mobile robot platform has been designed to facilitate student participation in the Penn State Abington ""Mini Grand Challenge"" contest. The robot platform consists of a modified PowerWheels electric car robot base, servo-controlled steering and drive, vision system, GPS interface, sonar, and text-to-speech engine with a speaker for interaction with the contest spectators. The expected applications and outcomes of the robot platform and Mini Grand Challenge include curriculum enhancement, increased interest in undergraduate research, recruitment and retention, and K-12 outreach",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-001.pdf,Subjects: 17. Robotics; 	 	19. Vision
297,2005,Mobile Robot Competition and Exhibition,Pyro: An Integrated Environment for Robotics Education,"Douglas Blank, Deepak Kumar, Lisa Meeden, Holly Yanco","Pyro, which stands for Python Robotics, is a Python-based robotics programming environment that enables students to explore topics in robotics. Programming robot behaviors in Pyro is akin to programming in a high-level general purpose programming language; Pyro provides abstractions for low-level robot-specific features much like the abstractions provided in high-level programming languages. Consequently, robot control programs written for a small robot (such as K-Team’s hockey puck sized, infrared-based Khepera robot) can be used, without any modifications, to control a much larger robot (such as ActivMedia’s human-scale, laser-based PeopleBot). This represents an advance over previous robot programming methodologies in which robot programs were written for specific motor controllers, sensors, communications protocols and other low-level features. Programming robot behaviors is carried out using the programming language Python, which enables several additional pedagogical benefits. We have developed an extensive set of robot programming modules, modeling techniques, and learning materials that can be used in graduate and undergraduate curricula in a variety of ways.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-002.pdf,Subjects: 17. Robotics
298,2005,Mobile Robot Competition and Exhibition,"Ready or Not, Here I Come ...","Magdalena Bugajska, William Adams, Scott Thomas, J. Gregory Trafton, Alan C. Schultz","We believe that integrating a computational cognitive model with a robotic system gives us a more principled way of creating behaviors such hiding and seeking and basic skills such as perspective taking. For this demonstration, we implemented a cognitive model of hiding and seeking, which incorporates a cognitive model of perspective taking and allows for more complex and dynamic behaviors than our previous model.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-003.pdf,Subjects: 17. Robotics; 	 	4. Cognitive Modeling
299,2005,Mobile Robot Competition and Exhibition,Robots in an Intelligent Systems Course,"Debra Burhans, Andre Nelson, Victoria Steck",This year we incorporated a robotics project into an intelligent systems course. Qualitative and quantitative information gathered from students indicates an extremely positive reaction from students. It was observed that students tended to work more in a scientific and experimental manner than is typically seen with course projects. The project along with some future ideas are presented.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-004.pdf,Subjects: 1.3 Computer-Aided Education; 	 	17. Robotics
300,2005,Mobile Robot Competition and Exhibition,Scavenging with a Laptop Robot,"Alan Davidson, Mac Mason, Susanna Ricco, Ben Tribelhorn, Zachary Dodds",This synopsis presents Harvey Mudd College’s entry into the 2005 AAAI scavenger hunt competition. We are submiting a laptop-controlled robot which uses commodity parts and limited sensors to localize itself and perform arrow following and object recognition.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-005.pdf,Subjects: 17. Robotics
301,2005,Mobile Robot Competition and Exhibition,Social Tag: Finding the Person with the Pink Hat,"Carl DiSalvo, Didac Font, Laura Hiatt, Nik Melchior, Marek Michalowski, Reid Simmons","At the AAAI 2005 Robot Exhibition, the robot GRACE (Graduate Robot Attending a ConferencE) will be playing a game that involves human-robot social interaction, navigation, and interface design. The task is for Grace to locate and rendezvous with one of our team members, who will be wearing a pink hat. The game can be seen as a social version of ""tag"" or ""Marco Polo,"" where the the robot finds the target not through the modalities of sight or sound, but rather through social interactions with strangers in the environment. The task has four phases, which are repeated until the pink hat is located visually: Identification of approachable humans, approach toward a human with whom the robot would like to interact, asking for directions to the person with the pink hat, and following those directions.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-006.pdf,Subjects: 17. Robotics; 	 	6. Computer-Human Interaction
302,2005,Mobile Robot Competition and Exhibition,Upending the Uncanny Valley,"David Hanson, Andrew Olney, Steve Prilliman, Eric Mathews, Marge Zielke, Derek Hammons, Raul Fernandez, Harry Stephanou","Although robotics researchers commonly contend that robots should not look too humanlike, many artforms have successfully depicted people and have come to be accepted as great and important works, with examples such as Rodin’s Thinker, Mary Cassat’s infants, and Disney’s Abe Lincoln simulacrum. Extending this tradition to intelligent robotics, the authors have depicted late sci-fi writer Philip K Dick with an autonomous, intelligent android. In doing so, the authors aspire to bring robotic systems up to the level of great art, while using the technology as a mirror for examining human nature in social AI development and cognitive science experiments.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-007.pdf,Subjects: 17. Robotics
303,2005,Mobile Robot Competition and Exhibition,Catoms: Moving Robots Without Moving Parts,"Brian Kirby, Jason Campbell, Burak Aksak, Padmanabhan Pillai, James Hoburg, Todd Mowry, Seth Copen Goldstein","We demonstrate modular robot prototypes developed as part of the Claytronics Project. Among the novel features of these robots (""catoms"") is their ability to reconfigure (move) relative to one another without moving parts. The absence of moving parts is central to one key aim of our work, namely, plausible manufacturability at smaller and smaller physical scales using high-volume, low-unit-cost techniques such as batch photolithography, multi-material submicron 3D lithographic processing, and self assembly. Claytronics envisions multi-million-module robot ensembles able to form into three dimensional scenes, eventually with sufficient fidelity so as to convince a human observer the scenes are real. This work presents substantial challenges in mechanical and electronic design, control, programming, reliability, power delivery, and motion planning (among other areas), and holds the promise of radically altering the relationship between computation, humans, and the physical world.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-008.pdf,Subjects: 17. Robotics; 	 	6.4 Virtual Reality
304,2005,Mobile Robot Competition and Exhibition,NavBot: The Navigational Search-and-Rescue Robot,"Matthew Marge, Ayman Sawas, Juan Carlos Liberato, Murtaza M. Karim, Manish Muttreja, Nader Alrawahi, Brian Fink","The Stony Brook Robot Design Team has focused on two main areas of research in the creation of NavBot, our new robot created for the American Association of Artificial Intelligence’s (AAAI) Scavenger Hunt Event: navigation and computer vision. The purpose is to create an intelligent machine that is able to navigate the conference floor for specific objects at the AAAI Conference in Pittsburgh, Pennsylvania.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-009.pdf,Subjects: 17. Robotics; 	 	19. Vision
305,2005,Mobile Robot Competition and Exhibition,A Brochette of Socially Interactive Robots,"Francois Michaud, D. Letourneau, P. Lepage, Y. Morin, F. Gagnon, P. Giguere, E. Beaudry, Y. Brosseau, C. Cote, A. Duquette, J.F. Laplante, M.A. LEgault, P. Moisan, A. Ponchon, C. Raievsky, ...","The design of interactive mobile robots is a multidisciplinary endeavor that profits from putting robots with people and studying their effects and impacts. To do so, two main issues must be addressed: giving robots capabilities in order to interact in meaningful and efficient ways with people, and the ability to move in human settings. This paper briefly describes four robotic platforms that are going to be demonstrated at the AAAI 2005 Robot Competition.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-010.pdf,Subjects: 17. Robotics; 	 	1.6 Engineering And Science
306,2005,Mobile Robot Competition and Exhibition,Indoor Aerial Robot Competition: Challenges in Search and Rescue Applications,"Paul Oh, William Green, Keith Sevcik","Tasks like bomb-detection, search-and-rescue, and reconnaissance in near-Earth environments are time, cost and labor intensive. Aerial robots could assist in such missions and offset the demand in resources and personnel. However, flying in environments rich with obstacles presents many more challenges which have yet to be identified. For example, telephone wire is one obstacle that is known to be hard to detect in mid-flight. This paper describes how a blimp can be used in an aerial robot competition to identify other key challenges when flying in these cluttered environments.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-011.pdf,Subjects: 17. Robotics; 	 	15.3 Control
307,2005,Mobile Robot Competition and Exhibition,Toward Affective Cognitive Robots for Human-Robot Interaction,"Matthias Scheutz, James Kramer, Chris Middendorff, Paul Schermerhorn, Michael Heilman, Dave Anderson, Peter Bui",We present a brief overview of an architecture for a complex affective robot for human-robot interaction.,https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-012.pdf,Subjects: 17. Robotics; 	 	6. Computer-Human Interaction
308,2005,Mobile Robot Competition and Exhibition,Using a Sketch Pad Interface for Interacting with a Robot Team,"Marjorie Skubic, Derek Anderson, Samuel Blisard, Dennis Perzanowski, William Adams, J. Gregory Trafton, Alan C. Schultz","We believe that high level tasks, such as strategic planning, are the role of human users, and that the interface should be the tool by which humans can easily, intelligently, and even intuitively communicate their goals to a robot or a team of robots. We will be exhibiting one such interface to control a team of mobile robots. By drawing on the sketch pad of a tablet PC, users can draw environment landmarks and label them, as well as indicate goal points and paths for robot navigation for a single robot or a group of robots. The information that the human presents to the robots via the interface need not be absolute. From the robot’s point of view, the task is based on its real-time sensing and the relative position of paths and landmarks. We are looking into the relationship between the accuracy of the user’s knowledge, the conveyance of that information via the interface, the amount of adaptability required by the system to compensate for inaccuracies, and the workload placed on the user.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-013.pdf,Subjects: 6.3 User Interfaces; 	 	7.1 Multi-Agent Systems
309,2005,Mobile Robot Competition and Exhibition,Tekkotsu: A Framework for AIBO Cognitive Robotics,"David S. Touretzky, Ethan J. Tira-Thompson","Tekkotsu (the name means ""framework"" in Japanese; see www.Tekkotsu.org) is an application development framework for the Sony AIBO robot dog. Over the last two years we have been developing a new layer of Tekkotsu to support an approach to robot programming that we call ""cognitive robotics"". The idea is to provide a set of higher level primitives for perception and action, inspired by ideas from cognitive science, so that programmers can construct intelligent behaviors at a much more abstract level. Three components of our approach are described here: visual routines, dual-coding representations, and perceivable affordances.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-014.pdf,Subjects: 17. Robotics; 	 	4. Cognitive Modeling
310,2005,Mobile Robot Competition and Exhibition,Improving Human-Robot Interaction for Remote Robot Operation,"Holly A. Yanco, Michael Baker, Robert Casey, Andrew Chanler, Munjal Desai, Dan Hestand, Brenden Keyes, and Philip Thoren","We have been investigating ways to improve human-robot interaction (HRI) and situation awareness (SA) in urban search and rescue (USAR). In this task, a human directs the navigation of a remotely located robot using an interface that provides controls and status information. In this paper, we discuss the many facets of our work aimed at improving HRI for remote robot operation.",https://aaai.org/Library/AAAI/2005/../../../Papers/AAAI/2005/RBC05-015.pdf,Subjects: 17. Robotics; 	 	6. Computer-Human Interaction
