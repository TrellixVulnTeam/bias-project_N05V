,conference_year,category,title,author,abstract,download_url,keywords
0,2004,Contents,AAAI Organization,AAAI,"List of officers, committee members, staff, and volunteers associated with the AAAI-04 conference and AAAI.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-172.pdf,
1,2004,Contents,Program Committees,"George Ferguson, Deborah L. McGuinness, Randall Hill, and Neil Jacobstein",Program committee members for AAAI-04 and IAAI-04.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-173.pdf,
2,2004,Contents,AAAI-04 Outstanding Paper Award,AAAI,List of papers receiving the outstanding paper award at AAAI-04.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-174.pdf,
3,2004,Contents,Sponsoring Organizations,Carol Hamilton,List of sponsors of AAAI-04.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-175.pdf,
4,2004,Contents,Preface,"George Ferguson, Deborah L. McGuinness, Randall Hill, and Neil Jacobstein.",Preface to the AAAI-04 and IAAI-04 Proceedings.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-176.pdf,
5,2004,Contents,Invited Talks and Panels,"Daniel J. Clancy, Edward Feigenbaum, Russ B. Altman, Paul Cohen, Ian Lane Davis, Tim Finin, Peter Norvig, Alex (Sandy) Pentland, Martha E. Pollack, Astro Teller, Sebastian Thrun","Abstracts of the talks and panels presented at the AAAI-04 conference in San Jose, California.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-177.pdf,
6,2004,Agents and Multi-Agent Systems,Performance Bounded Reinforcement Learning in Strategic Interactions,Bikramjit Banerjee and Jing Peng,"Despiteincreasing deployment of agent technologies in several business and industry domains, user confidence in fully automated agent driven applications is noticeably lacking. The main reasons for such lack of trust in complete automation are scalability and non-existence of reasonable guarantees in the performance of self-adapting software. In this paper we address the latter issue in the context of learning agents in a Multiagent System (MAS). Performance guarantees for most existing on-line Multiagent Learning (MAL) algorithms are realizable only in the limit, thereby seriously limiting its practical utility. Our goal is to provide certain meaningful guarantees about the performance of a learner in a MAS, while it is learning. In particular, we present a novel MAL algorithm that (1) converges to a best response against stationary opponents, (2) converges to a Nash equilibrium in self-play and (3) achieves a constant bounded expected regret at any time (no-average-regret asymptotically) in arbitrary sized general-sum games with non-negative payoffs, and against any number of opponents.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-001.pdf,
7,2004,Agents and Multi-Agent Systems,Searching for Stable Mechanisms: Automated Design for Imperfect Players,Andrew J. Blumberg and Abhi Shelat,"RecentlyConitzer and Sandholm introduced the concept of ""automated mechanism design"", whereby mechanism design problems are solved using constraint-satisfaction methods. Traditionally, mechanism design has focused on producing games which yield the desired outcomes when played by ideal rational players. However actual players are never perfectly rational --- human irrationality has been exhaustively studied and computational agents have both resource bounds and potentially implementation flaws. In this paper, we discuss extensions of the techniques of automated mechanism design to produce games which are robust in the face of player imperfections. We model limited rationality by examining agents which converge on their strategy by using a simple variant of ""fictitious play"" (simulation of repeated play). This model associates to each game a system of differential equations describing the trajectory of the agent’s strategies. We describe additional constraints which guarantee that automated mechanism design search problems yield stable mechanisms. In particular, we present negative results for structural stability and positive results for asymptotic stability by considering strict Bayesian-Nash equilibria and by employing Lyapunov techniques.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-002.pdf,
8,2004,Agents and Multi-Agent Systems,Affective Recruitment of Distributed Heterogeneous Agents,Aaron Gage and Robin R. Murphy,"Members of multi-robot teams may need to collaborate to accomplish a task due to differences in capabilities. This paper describes an extension of the ALLIANCE architecture that enables agent recruitment within a decentralized UAV-UGV robot team without task preemption but (1) uses a formal model of emotions and (2) handles heterogeneity. Affective computing allows recruitment to be robust under loss of communication between agents and minimizes the number of messages passed. Data from 66 simulations show that the affective strategy succeeds with a random message loss rate up to 25% and requires 19.1% fewer messages to be sent compared to greedy and random, and that of these, affective scales best with team size. Comparisons of broadcast to unicast messaging are also made in simulation.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-003.pdf,
9,2004,Agents and Multi-Agent Systems,Visibility-Based Pursuit-Evasion with Limited Field of View,"Brian P. Gerkey, Sebastian Thrun, and Geoff Gordon","We study a formof the pursuit-evasion problem, in which one or more searchers must move through a given environment so as to guarantee detection of any and all evaders, which can move arbitrarily fast. Our goal is to develop techniques for coordinating teams of robots to execute this task in application domains such as clearing a building, for reasons of security or safety. To this end, we introduce a new class of searcher, the phi-searcher, which can be readily instantiated as a physical mobile robot. We present a detailed analysis of the pursuit-evasion problem using φ-searchers. We show that computing the minimum number of phi-searchers required to search a given environment is NP-hard, and present the first complete search algorithm for a single phi-searcher. We show how this algorithm can be extended to handle multiple searchers, and give examples of computed trajectories.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-004.pdf,
10,2004,Agents and Multi-Agent Systems,Task Allocation via Self-Organizing Swarm Coalitions in Distributed Mobile Sensor Network,"Kian Hsiang Low, Wee Kheng Leow, and Marcelo H. Ang, Jr.","This paper presents a task allocation scheme via self organizing swarm coalitions for distributed mobile sensor network coverage. Our approach uses the concepts of ant behavior to self-regulate the regional distributions of sensors in proportion to that of the moving targets to be tracked in a non-stationary environment. As a result, the adverse effects of task interference between robots are minimized and sensor network coverage is improved. Quantitative comparisons with other tracking strategies such as static sensor placement, potential fields, and auction-based negotiation show that our approach can provide better coverage and greater flexibility to respond to environmental changes.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-005.pdf,
11,2004,Agents and Multi-Agent Systems,GROWRANGE: Anytime VCG-Based Mechanisms,David C. Parkes and Grant Schoenebeck,"We introduce anytime mechanisms for distributed optimization with self-interested agents. Anytime mechanisms retain good incentive properties even when interrupted before the optimal solution is computed, and provide better quality solutions when given additional time. Anytime mechanisms can solve easy instances of a hard problem quickly and optimally, while providing approximate solutions on very hard instances. In a particular instantiation, GROWRANGE, we successively expand the range of outcomes considered, computing the optimal solution for each range. Truth-revelation remains a dominant strategy equilibrium with a stage-based interruption, and is a best-response with high probability when the interruption is time-based.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-006.pdf,
12,2004,Agents and Multi-Agent Systems,Useful Roles of Emotions in Artificial Agents: A Case Study from Artificial Life,Matthias Scheutz,"In this paper, we discuss the role of emotions in AI and possible ways to determine their utility for the design of artificial agents. We propose a research methodology for determining the utility of emotional control and apply it to the study of autonomous agents that compete for resources in an artificial life environment. The results show that the emotional control can improve performance in some circumstances.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-007.pdf,
13,2004,Automated Reasoning,Low-Knowledge Algorithm Control,Tom Carchrae and J. Christopher Beck,"This paper addresses the question of allocating computational resources among a set of algorithms in order to achieve the best performance on a scheduling problem instance. Our primary motivation in addressing this problem is to reduce the expertise needed to apply constraint technology. Therefore, we investigate algorithm control techniques that make decision based only on observations of the improvement in solution quality achieved by each algorithm. We call our approach ""low-knowledge"" since it does not rely on complex prediction models. We show that such an approach results in a system that achieves significantly better performance than all of the pure algorithms without requiring additional human expertise. Furthermore the low knowledge approach achieves performance equivalent to a perfect high-knowledge classification approach.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-008.pdf,
14,2004,Automated Reasoning,Implementing a Generalized Version of Resolution,"Heidi E. Dixon, Matthew L. Ginsberg, David K. Hofer, Eugene M. Luks, and Andrew J. Parkes","We have recently proposed augmenting clauses in a Boolean database with groups of permutations, the augmented clauses then standing for the set of all clauses constructed by acting on the original clause with a permutation in the group. This approach has many attractive theoretical properties, including representational generality and reductions from exponential to polynomial proof length in a variety of settings. In this paper, we discuss the issues that arise in implementing a group-based generalization of resolution, and give preliminary results describing this procedure’s effectiveness.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-009.pdf,
15,2004,Automated Reasoning,SAT-Based Answer Set Programming,"Enrico Giunchiglia, Yuliya Lierler, and Marco Maratea","The relation between answer set programming (ASP) and propositional satisfiability (SAT) is at the center of many research papers, partly because of the tremendous performance boost of SAT solvers during last years. Various translations from ASP to SAT are known but the resulting SAT formula either includes many new variables or may have an unpractical size. There are also well known results showing a one-to-one correspondence between the answer sets of a logic program and the models of its completion. Unfortunately, these results only work for specific classes of problems. In this paper we present a SAT-based decision procedure for answer set programming that (i) deals with any (non disjunctive) logic program, (ii) works on a SAT formula without additional variables, and (iii) is guaranteed to work in polynomial space. Further, our procedure can be extended to compute all the answer sets still working in polynomial space. The experimental results of a prototypical implementation show that the approach can pay off sometimes by orders of magnitude.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-010.pdf,
16,2004,Automated Reasoning,A Polynomial-Time Algorithm for Simple Temporal Problems with Piecewise Constant Domain Preference Functions,T. K. Satish Kumar,"In this paper, we provide a polynomial-time algorithm for solving an important class of metric temporal problems that involve simple temporal constraints between various events (variables) and piecewise constant preference functions over variable domains. We are given a graph G = (X, E) where X = {X0, X1...Xn} is a set of events (X0 is the ""beginning of the world"" node and is set to 0 by convention) and e = (Xi, Xj) in E, annotated with the bounds [LB(e), UB(e)], is a simple temporal constraint between Xi and Xj indicating that Xj must be scheduled between LB(e) and UB(e) seconds after Xi is scheduled (LB(e) <= UB(e)). A family of stepwise constant preference functions F = {f_Xi(t): R -> R} specifies the preference attached with scheduling Xi at time t. The goal is to find a schedule for all the events such that all the temporal constraints are satisfied and the sum of the preferences is maximized. Our polynomial-time algorithm for solving such problems (which we refer to as extended simple temporal problems (ESTPs)) has important consequences in dealing with limited forms of disjunctions and preferences in metric temporal reasoning that would otherwise require an exponential search space.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-011.pdf,
17,2004,Automated Reasoning,Using Performance Profile Trees to Improve Deliberation Control,Kate Larson and Tuomas Sandholm,"Performance profile trees have recently been proposed as a theoretical basis for fully normative deliberation control. In this paper we conduct the first experimental study of their feasibility and accuracy in making stopping decisions for anytime algorithms on optimization problems. Using data and algorithms from two different real-world domains, we compare performance profile trees to other well-established deliberation-control techniques. We show that performance profile trees are feasible in practice and lead to significantly better deliberation control decisions. We then conduct experiments using performance profile trees where deliberation-control decisions are made using conditioning on multiple features of the solution to illustrate that such an approach is feasible in practice.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-012.pdf,
18,2004,Automated Reasoning,On Odd and Even Cycles in Normal Logic Programs,Fangzhen Lin and Xishun Zhao,"An odd cycle of a logic program is a simple cycle that has an odd number of negative edges in the dependency graph of the program. Similarly, an even cycle is one that has an even number of negative edges. For a normal logic program that has no odd cycles, while it is known that such a program always has a stable model, and such a stable model can be computed in polynomial time, we show in this paper that checking whether an atom is in a stable model is NP-complete, and checking whether an atom is in all stable models is co-NP complete, both are the same as in the general case for normal logic programs. Furthermore, we show that if a normal logic program has exactly one odd cycle, then checking whether it has a stable model is NP-complete, again the same as in the general case. For normal logic programs with a fixed number of even cycles, we show that there is a polynomial time algorithm for computing all stable models. Furthermore, this polynomial time algorithm can be improved significantly if the number of odd cycles is also fixed.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-013.pdf,
19,2004,Automated Reasoning,Logic Programs with Abstract Constraint Atoms,Victor W. Marek and Miroslaw Truszczynski,"We propose and study extensions of logic programming with constraints represented as generalized atoms of the form C(X), where X is a finite set of atoms and C is an abstract constraint (formally, a collection of sets of atoms). Atoms C(X) are satisfied by an interpretation (set of atoms) M, if M ∩ X ∈ C. We focus here on monotone constraints, that is, those collections C that are closed under the superset. They include, in particular, weight (or pseudo-boolean) constraints studied both by the logic programming and SAT communities. We show that key concepts of the theory of normal logic programs such as the one-step provability operator, the semantics of supported and stable models, as well as several of their properties including complexity results, can be lifted to such case.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-014.pdf,
20,2004,Automated Reasoning,Adding Time and Intervals to Procedural and Hierarchical Control Specifications,"Tran Cao Son, Chitta Baral, and Le-Chi Tuan",In this paper we introduce the language Golog+HTN TI for specifying control using procedural and HTN-based constructs together with deadlines and time restrictions. Our language starts with features from GOLOG and HTN and extends them so that we can deal with actions with duration by being able to specify time intervals between the start (or end) of an action (or a program) and the start (or end) of another action (or program). We then discuss an off-line interpreter based on the answer set planning paradigm such that the answer sets of the logic program have a one to one correspondence with the traces of the Golog+HTN TI specification.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-015.pdf,
21,2004,Automated Reasoning,Model Checking Temporal Logics of Knowledge in Distributed Systems,Kaile Su,"Model checking is a promising approach to automatic verification, which has concentrated on specification expressed in temporal logic. Comparatively little attention has been given to temporal logics of knowledge, although such logics have been proven to be very useful in the specifications of protocols for distributed systems. In this paper, we address ourselves to the model checking problem for a temporal logic of knowledge (Halpern and Vardi’s logic of CKLn). Based on the semantics of interpreted systems with local propositions, we develop an approach to symbolic CKLn model checking via OBDDs. In our approach to model checking specifications involving agents’ knowledge, the knowledge modalities are eliminated via quantifiers over agents’ non-observable variables.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-016.pdf,
22,2004,Automated Reasoning,Identifying Linear Causal Effects,Jin Tian,"This paper concerns the assessment of linear cause-effect relationships from a combination of observational data and qualitative causal structures. The paper shows how techniques developed for identifying causal effects in causal Bayesian networks can be used to identify linear causal effects, and thus provides a new approach for assessing linear causal effects in structural equation models. Using this approach the paper develops a systematic procedure for recognizing identifiable direct causal effects.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-017.pdf,
23,2004,Complexity,The Complexity of Global Constraints,"Christian Bessiere, Emmanuel Hebrard, Brahim Hnich, and Toby Walsh","We study the computational complexity of reasoning with global constraints. We show that reasoning with such constraints is intractable in general. We then demonstrate how the same tools of computational complexity can be used in the design and analysis of specific global constraints. In particular, we illustrate how computational complexity can be used to determine when a lesser level of local consistency should be enforced, when decomposing constraints will lose pruning, and when combining constraints is tractable. We also show how the same tools can be used to study symmetry breaking, meta-constraints like the cardinality constraint, and learning nogoods.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-018.pdf,
24,2004,Complexity,Complexity of Contextual Reasoning,Floris Roelofsen and Luciano Serafini,"This paper delineates the computational complexity of propositional multi-context systems. We establish NP-membershipby translating multi-context systems into bounded modal Kn,and obtain more refined complexity results by achieving theso-called bounded model property: the number of local models needed to satisfy a set of formulas φ in a multi-contextsystem MS is bounded by the number of contexts addressedby φ plus the number of bridge rules in MS.Exploiting this property of multi-context systems, we are ableto encode contextual satisfiability into purely propositionalsatisfiability, providing for the implementation of contextualreasoners based on already existing specialized SAT solvers.Finally, we apply our results to improve complexity boundsfor McCarthy’s propositional logic of context — we showthat satisfiability in this framework can be settled in nondeterministic polynomial time O(|ψ|2).",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-019.pdf,
25,2004,Complexity,The Backdoor Key: A Path to Understanding Problem Hardness,"Yongshao Ruan, Henry Kautz, and Eric Horvitz","We introduce our work on the backdoor key, a concept that shows promise for characterizing problem hardness in backtracking search algorithms. The general notion of backdoors was recently introduced to explain the source of heavy-tailed behaviors in backtracking algorithms. We describe empirical studies that show that the key faction,i.e., the ratio of the key size to the corresponding backdoor size, is a good predictor of problem hardness of ensembles and individual instances within an ensemble for structure domains with large key fraction.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-020.pdf,
26,2004,Constraint Satisfaction and Satisfiability,Hiding Satisfying Assignments: Two Are Better than One,"Dimitris Achlioptas, Haixia Jia, and Cristopher Moore","The evaluation of incomplete satisfiability solvers depends critically on the availability of hard satisfiable instances. A plausible source of such instances are k-CNF formulas whose clauses are chosen uniformly at random among all clauses satisfying some randomly chosen truth assignment A. Unfortunately, instances generated in this manner are relatively easy and can be solved efficiently by practical heuristics. Roughly speaking, as the number of clauses is increased, A acts as a stronger and stronger attractor. Motivated by recent results on the geometry of the space of solutions for random k-SAT and NAE-k-SAT instances, we propose a very simple twist on this model that greatly increases the hardness of the resulting formulas. Namely, in addition to forbidding the clauses violated by the hidden assignment A, we also forbid the clauses violated by its complement, so that both A and the complement of A are satisfying. It appears that under this ""symmetrization"" the effects of the two attractors largely cancel out, making it much harder for an algorithm to ""feel"" (and find) either one. We give theoretical and experimental evidence supporting this assertion.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-021.pdf,
27,2004,Constraint Satisfaction and Satisfiability,Modeling Choices in Quasigroup Completion: SAT Versus CSP,"Carlos Ansótegui, Alvaro del Val, Iván Dotuacute;, Cèsar Fernández, and Felip Manyà","We perform a systematic comparison of SAT and CSP models for a challenging combinatorial problem, quasigroup completion (QCP). Our empirical results clearly indicate the superiority of the 3D SAT encoding, with various solvers, over other SAT and CSP models. We propose a partial explanation of the observed performance. Analytically, we focus on the relative conciseness of the 3D model and the pruning power of unit propagation. Empirically, the focus is on the role of the unit-propagation heuristic of the best performing solver, Satz, which proves crucial to its success, and results in a significant improvement in scalability when imported into the CSP solvers. Our results strongly suggest that SAT encodings of permutation problems may well prove quite competitive in other domains, in particular when compared with the currently preferred channeling CSP models.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-022.pdf,
28,2004,Constraint Satisfaction and Satisfiability,Leap Before You Look: An Effective Strategy in an Oversubscribed Scheduling Problem,"Laura Barbulescu, L. Darrell Whitley, and Adele E. Howe","Oversubscribed scheduling problems require removing or partially satisfying tasks when enough resources are not available. For a particular oversubscribed problem, Air Force Satellite Control Network scheduling, we find that the best approaches make long leaps in the search space. We find this is in part due to large plateaus in the search space. Algorithms moving only one task at a time are impractical. Both a genetic algorithm and Squeaky Wheel Optimization (SWO) make long leaps in the search space and produce good solutions almost 100 times faster than local search. Greedy initialization is shown to be critical to good performance, but is not as important as directed leaps. When using fewer than 2000 evaluations, SWO shows superior performance; with 8000 evaluations, a genetic algorithm using a population seeded with greedy solutions further improves on the SWO results.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-023.pdf,
29,2004,Constraint Satisfaction and Satisfiability,Domain Transmutation in Constraint Satisfaction Problems,James Bowen and Chavalit Likitvivatanavong,"We study local interchangeability of values in constraint networks based on a new approach where a single value in the domain of a variable can be treated as a combination of “subvalues.” We present an algorithm for breaking up values and combining identical fragments. Experimental results show that the transformed problems take less time to solve for all solutions and yield more compactly-representable, but equivalent, solution sets. We obtain new theoretical results on context dependent interchangeability and full interchangeability, and suggest some other applications.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-024.pdf,
30,2004,Constraint Satisfaction and Satisfiability,Collapsibility and Consistency in Quantified Constraint Satisfaction,Hubie Chen,"The concept of consistency has pervaded studies of the constraint satisfaction problem. We introduce two concepts, which are inspired by consistency, for the more general framework of the quantified constraint satisfaction problem (QCSP). We use these concepts to derive, in a uniform fashion, proofs of polynomial-time tractability and corresponding algorithms for certain cases of the QCSP where the types of allowed relations are restricted. We not only unify existing tractability results and algorithms, but also identify new classes of tractable QCSPs.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-025.pdf,
31,2004,Constraint Satisfaction and Satisfiability,Complete Local Search for Propositional Satisfiability,Hai Fang and Wheeler Ruml,"Algorithms based on following local gradient information are surprisingly effective for certain classes of constraint satisfaction problems. Unfortunately, previous local search algorithms are notoriously incomplete: They are not guaranteed to find a feasible solution if one exists and they cannot be used to determine unsatisfiability. We present an algorithmic framework for complete local search and discuss in detail an instantiation for the propositional satisfiability problem (SAT). The fundamental idea is to use constraint learning in combination with a novel objective function that converges during search to a surface without local minima. Although the algorithm has worst-case exponential space complexity, we present empirical results on challenging SAT competition benchmarks that suggest that our implementation can perform as well as state-of-the-art solvers based on more mature techniques. Our framework suggests a range of possible algorithms lying between tree-based search and local search.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-026.pdf,
32,2004,Constraint Satisfaction and Satisfiability,QUICKXPLAIN: Preferred Explanations and Relaxations for Over-Constrained Problems,Ulrich Junker,"Over-constrained problems can have an exponential number of conflicts, which explain the failure, and an exponential number of relaxations, which restore the consistency. A user of an interactive application, however, desires explanations and relaxations containing the most important constraints. To address this need, we define preferred explanations and relaxations based on user preferences between constraints and we compute them by a generic method which works for arbitrary CP, SAT, or DL solvers. We significantly accelerate the basic method by a divide-and-conquer strategy and thus provide the technological basis for the explanation facility of a principal industrial constraint programming tool, which is, for example, used in numerous configuration applications.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-027.pdf,
33,2004,Constraint Satisfaction and Satisfiability,MAX-2-SAT: How Good Is Tabu Search in the Worst-Case?,Monaldo Mastrolilli and Luca Maria Gambardella,"Tabu search algorithms are amongst the most successful local search based methods for the maximum satisfiability problem. The practical superiority of tabu search over the local search alone has been already shown experimentally several times. A natural question addressed here is to understand if this superiority holds also from the worst-case point of view. Moreover, it is well known that the main critical parameter of tabu techniques is the tabu list length. Focussing on MAX-2-SAT problem, the main contribution of this paper is a worst-case analysis of tabu search as a function of the tabu list length. We give a first theoretical evidence of the advantage of a tabu search strategy over the basic local search alone that critically depends on the tabu list length.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-028.pdf,
34,2004,Constraint Satisfaction and Satisfiability,The Practice of Approximated Consistency for Knapsack Constraints,Meinolf Sellmann,"Knapsack constraints are a key modeling structure in discrete optimization and form the core of many real-life problem formulations. Only recently, a cost-based filtering algorithm for Knapsack constraints was published that is based on some previously developed approximation algorithms for the Knapsack problem. In this paper, we provide an empirical evaluation of approximated consistency for Knapsack constraints by applying it to the Market Split Problem and the Automatic Recording Problem.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-029.pdf,
35,2004,Constraint Satisfaction and Satisfiability,Study of Lower Bound Functions for MAX-2-SAT,Haiou Shen and Hantao Zhang,"Recently, several lower bound functions are proposed for solving the MAX-2-SAT problem optimally in a branch-and-bound algorithm. These lower bounds improve significantly the performance of these algorithms. Based on the study of these lower bound functions, we propose a new, linear-time lower bound function. We show that the new lower bound function is admissible and it is consistently and substantially better than other known lower bound functions. The result of this study is a high-performance implementation of an exact algorithm for MAX-2-SAT which outperforms any implementation of the same class.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-030.pdf,
36,2004,Constraint Satisfaction and Satisfiability,Additive versus Multiplicative Clause Weighting for SAT,"John Thornton, Duc Nghia Pham, Stuart Bain, and Valnir Ferreira Jr.","This paper examines the relative performance of additive and multiplicative clause weighting schemes for propositional satisfiability testing. Starting with one of the most recently developed multiplicative algorithms (SAPS), an experimental study was constructed to isolate the effects of multiplicative in comparison to additive weighting, while controlling other key features of the two approaches, namely the use of random versus flat moves, deterministic versus probabilistic weight smoothing and multiple versus single inclusion of literals in the local search neighborhood. As a result of this investigation we developed a pure additive weighting scheme (PAWS) which can outperform multiplicative weighting on a range of difficult problems, while requiring considerably less effort in terms of parameter tuning. We conclude that additive weighting shows better scaling properties because it makes less distinction between costs and so considers a larger domain of possible moves.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-031.pdf,
37,2004,Constraint Satisfaction and Satisfiability,Tractable Tree Convex Constraint Networks,Yuanlin Zhang and Eugene C. Freuder,"A binary constraint network is tree convex if we can construct a tree for the domain of the variables so that for any constraint, no matter what value one variable takes, all the values allowed for the other variable form a subtree of the constructed tree. It is known that a tree convex network is globally consistent if it is path consistent. However, if a tree convex network is not path consistent, enforcing path consistency on it may not make it globally consistent. In this paper, we identify a sub-class of tree convex networks which are locally chain convex and union closed. This class of problems can be made globally consistent by path consistency and thus is tractable. More interestingly, we also find that some scene labeling problems can be modeled by tree convex constraints in a natural and meaningful way.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-032.pdf,
38,2004,Game Theory and Economic Models,Eliciting Bid Taker Non-price Preferences in (Combinatorial) Auctions,"Craig Boutilier, Tuomas Sandholm, and Rob Shields","Recent algorithms provide powerful solutions to the problem of determining cost-minimizing (or revenue-maximizing) allocations of items in combinatorial auctions. However, in many settings, criteria other than cost (e.g., the number of winners, the delivery date of items, etc.) are also relevant in judging the quality of an allocation. Furthermore, the bid taker is usually uncertain about her preferences regarding tradeoffs between cost and nonprice features. We describe new methods that allow the bid taker to determine (approximately) optimal allocations despite this. These methods rely on the notion of minimax regret to guide the elicitation of preferences from the bid taker and to measure the quality of an allocation in the presence of utility function uncertainty. Computational experiments demonstrate the practicality of minimax computation and the efficacy of our elicitation techniques.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-033.pdf,
39,2004,Game Theory and Economic Models,Combinatorial Auctions with Structured Item Graphs,"Vincent Conitzer, Jonathan Derryberry, and Tuomas Sandholm","Coalition formation is a key problem in automated negotiation among self-interested agents. In order for coalition formation to be successful, a key question that must be answered is how the gains from cooperation are to be distributed. Various solution concepts have been proposed, but the computational questions around these solution concepts have received little attention. We study a concise representation of characteristic functions which allows for the agents to be concerned with a number of independent issues that each coalition of agents can address. For example, there may be a set of tasks that the capacity-unconstrained agents could undertake, where accomplishing a task generates a certain amount of value (possibly depending on how well the task is accomplished). Given this representation, we show how to quickly compute the Shapley value—a seminal value division scheme that distributes the gains from cooperation fairly in a certain sense. We then show that in (distributed) marginal-contribution based value division schemes, which are known to be vulnerable to manipulation of the order in which the agents are added to the coalition, this manipulation is NP-complete. Thus, computational complexity serves as a barrier to manipulating the joining order. Finally, we show that given a value division, determining whether some subcoalition has an incentive to break away (in which case we say the division is not in the core) is NP-complete. So, computational complexity serves to increase the stability of the coalition.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-034.pdf,
40,2004,Game Theory and Economic Models,"Computing Shapley Values, Manipulating Value Division Schemes, and Checking Core Membership inMulti-Issue Domains",Vincent Conitzer and Tuomas Sandholm,"Coalition formation is a key problem in automated negotiation among self-interested agents. In order for coalition formation to be successful, a key question that must be answered is how the gains from cooperation are to be distributed. Various solution concepts have been proposed, but the computational questions around these solution concepts have received little attention. We study a concise representation of characteristic functions which allows for the agents to be concerned with a number of independent issues that each coalition of agents can address. For example, there may be a set of tasks that the capacity-unconstrained agents could undertake, where accomplishing a task generates a certain amount of value (possibly depending on how well the task is accomplished). Given this representation, we show how to quickly compute the Shapley value—a seminal value division scheme that distributes the gains from cooperation fairly in a certain sense. We then show that in (distributed) marginal-contribution based value division schemes, which are known to be vulnerable to manipulation of the order in which the agents are added to the coalition, this manipulation is NP-complete. Thus, computational complexity serves as a barrier to manipulating the joining order. Finally, we show that given a value division, determining whether some subcoalition has an incentive to break away (in which case we say the division is not in the core) is NP-complete. So, computational complexity serves to increase the stability of the coalition.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-035.pdf,
41,2004,Game Theory and Economic Models,Learning Social Preferences in Games,"Ya’akov Gal, Avi Pfeffer, Francesca Marzo, and Barbara J. Grosz","This paper presents a machine-learning approach to modeling human behavior in one-shot games. It provides a framework for representing and reasoning about the social factors that affect people’s play. The model predicts how a human player is likely to react to different actions of another player, and these predictions are used to determine the best possible strategy for that player. Data collection and evaluation of the model were performed on a negotiation game in which humans played against each other and against computer models playing various strategies. A computer player trained on human data outplayed Nash equilibrium and Nash bargaining computer players as well as humans. It also generalized to play people and game situations it had not seen before.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-036.pdf,
42,2004,Game Theory and Economic Models,Methods for Boosting Revenue in Combinatorial Auctions,Anton Likhodedov and Tuomas Sandholm,"We study the recognized open problem of designing revenue-maximizing combinatorial auctions. It is unsolved even for two bidders and two items for sale. Rather than pursuing the pure economic approach of attempting to characterize the optimal auction, we explore techniques for automatically modifying existing mechanisms in a way that increase expected revenue. We introduce a general family of auctions, based on bidder weighting and allocation boosting, which we call virtual valuations combinatorial auctions (VVCA). All auctions in the family are based on the Vickrey-Clarke-Groves (VCG) mechanism, executed on virtual valuations that are linear transformations of the bidders’ real valuations. The restriction to linear transformations is motivated by incentive compatibility. The auction family is parameterized by the coefficients in the linear transformations. The problem of designing a high revenue mechanism is therefore reduced to search in the parameter space of VVCA. We analyze the complexity of the search for the optimal such mechanism and conclude that the search problem is computationally hard. Despite that, optimal parameters for VVCA can be found at least in settings with few items and bidders (the experiments show that VVCA yield a substantial increase in revenue over the traditionally used VCG). In larger auctions locally optimal parameters, which still yield an improvement over VCG, can be found.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-037.pdf,
43,2004,Game Theory and Economic Models,Using Contracts to Influence the Outcome of a Game,Robert McGrew and Yoav Shoham,"We consider how much influence a center can exert on a game if its only power is to propose contracts to the agents before the original game, and enforce the contracts after the game if all agents sign it. Modelling the situation as an extensiveform game, we note that the outcomes that are enforceable are precisely those in which the payoff to each agent is higher than its payoff in at least one of the Nash equilibria of the original game. We then show that these outcomes can still be achieved without any effort actually expended by the center: We propose a mechanism in which the center does not monitor the game, and the contracts are written so that in equilibrium all agents sign and obey the contract, with no need for center intervention.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-038.pdf,
44,2004,Knowledge Representation and Reasoning,Scaling Up Reasoning about Actions Using Relational Database Technology,Giuseppe De Giacomo and Toni Mancini,"Reiter’s variant of the Situation Calculus is tightly related to relational databases, when complete information on the initial situation is available. In particular, the information on the initial situation can be seen as a relational database, and actions, as specified by the preconditions and successor state axioms, can be seen as operations that change the state of the database. In this paper, we show how to exploit such a correspondence to build systems for reasoning about actions based on standard relational database technology. Indeed, by exploiting standard relational DBMS services, a system may be able to perform both Projection, exploiting DBMS querying services, and Progression, exploiting DBMS update services, in very large action theories. A key result towards such a realization, is that under very natural conditions Reiter’s basic action theories turn out to be made of “safe formulas” (where basically negation is used as a form of difference between predicates only) and that regression and progression preserve such a safeness. This is a fundamental property to efficiently exploit relational database technology for reasoning. We then show that, even when action theories are not “safe”, they can be made so while trying to retain efficiency as much as possible. Finally, we briefly discuss how such results can be extended to certain forms of incomplete information.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-039.pdf,
45,2004,Knowledge Representation and Reasoning,Conservative Belief Revision,"James P. Delgrande, Abhaya C. Nayak, and Maurice Pagnucco","A standard assumption underlying traditional accounts of belief change is the principle of minimal change, that an agent’s belief state should be modified minimally to incorporate new information. In this paper we introduce a novel account of belief change in which the agent’s belief state is modified minimally to incorporate exactly the new information. Thus a revision by p V q will result in a new belief state in which p v q is believed, but a stronger proposition (such as p & q) is not, regardless of the initial form of the belief state. This form of belief change is termed conservative belief change and corresponds to a Gricean interpretation of the input formula. We investigate belief revision in this framework, and provide a representation result between a set of postulates characterising this form of belief change and a construction in terms of systems of spheres. This approach is extended to that of belief revision with respect to a specified context. Last, we show how this approach resolves a longstanding problem in belief revision.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-040.pdf,
46,2004,Knowledge Representation and Reasoning,Mereological Semantics for Bio-Ontologies,"Udo Hahn, Stefan Schulz, and Kornél Markó","Biomedical ontologies are typically structured in a biaxial way, reflecting both a taxonomic and a mereological order. Common examples such as the Gene Ontology and the Unified Medical Language System (UMLS) excel in terms of coverage but lack an adequate semantics of the mereological relations they incorporate. This shortcoming is particularly evident as far as the (non-)mandatory existence of parts for their wholes is concerned, on the one hand, and the propagation of properties across part-whole hierarchies, on the other hand. We provide a formal specification of the semantic foundations of mereology in the biomedical domain that is closely linked to the paradigm of description logics. In essence, we here propose to emulate mereological reasoning by taxonomic reasoning. In an attempt to capture much of the shared intuition underlying merelogical reasoning in the biomedical domain, we distinguish for each mereologically relevant concept four different classes of parts and wholes which allow for the expression of five different propagation patterns.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-041.pdf,
47,2004,Knowledge Representation and Reasoning,CASEE: A Hierarchical Event Representation for the Analysis of Videos,"Asaad Hakeem, Yaser Sheikh, and Mubarak Shah","A representational gap exists between low-level measurements (segmentation, object classification, tracking) and high-level understanding of video sequences. In this paper, we propose a novel representation of events in videos to bridge this gap, based on the CASE representation of natural languages. The proposed representation has three significant contributions over existing frameworks. First, we recognize the importance of causal and temporal relationships between sub-events and extend CASE to allow the representation of temporal structure and causality between sub-events. Second, in order to capture both multi-agent and multi-threaded events, we introduce a hierarchical CASE representation of events in terms of sub-events and case-lists. Last, for purposes of implementation we present the concept of a temporal event-tree, and pose the problem of event detection as subtree pattern matching. By extending CASE, a natural language representation, for the representation of events, the proposed work allows a plausible means of interface between users and the computer. We show two important applications of the proposed event representation for the automated annotation of standard meeting video sequences, and for event detection in extended videos of railroad crossings.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-042.pdf,
48,2004,Knowledge Representation and Reasoning,Making Argumentation More Believable,Anthony Hunter,"There are a number of frameworks for modelling argumentation in logic. They incorporate a formal representation of individual arguments and techniques for comparing conflicting arguments. A problem with these proposals is that they do not consider the believability of the arguments from the perspective of the intended audience. In this paper, we start by reviewing a logic-based framework for argumentation based on argument trees which provide a way of exhaustively collating arguments and counter-arguments. We then extend this framework to a model-theoretic evaluation of the believability of arguments. This extension assumes that the beliefs of a typical member of the audience for argumentation can be represented by a set of classical formulae (a beliefbase). We compare a beliefbase with each argument to evaluate the empathy (or similarly the antipathy) that an agent has for the argument. We show how we can use empathy and antipathy to define a pre-ordering relation over argument trees that captures how one argument tree is “more believable” than another. We also use these to define criteria for deciding whether an argument at the root of an argument tree is defeated or undefeated given the other arguments in the tree.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-043.pdf,
49,2004,Knowledge Representation and Reasoning,Towards Higher Impact Argumentation,Anthony Hunter,"There are a number of frameworks for modelling argumentation in logic. They incorporate a formal representation of individual arguments and techniques for comparing conflicting arguments. An example is the framework by Besnard and Hunter that is based on classical logic and in which an argument (obtained from a knowledgebase) is a pair where the first item is a minimal consistent set of formulae that proves the second item (which is a formula). In the framework, the only counter-arguments (defeaters) that need to be taken into account are canonical arguments (a form of minimal undercut). Argument trees then provide a way of exhaustively collating arguments and counter-arguments. A problem with this set up is that some argument trees may be “too big” to have sufficient impact. In this paper, we address the need to increase the impact of argumentation by using pruned argument trees. We formalize this in terms of how arguments resonate with the intended audience of the arguments. For example, if a politician wants to make a case for raising taxes, the arguments used would depend on what is important to the audience: Arguments based on increased taxes are needed to pay for improved healthcare would resonate better with an audience of pensioners, whereas arguments based on increased taxes are needed to pay for improved transport infrastructure would resonate better with an audience of business executives. By analysing the resonance of arguments, we can prune argument trees to raise their impact.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-044.pdf,
50,2004,Knowledge Representation and Reasoning,Loop Formulas for Circumscription,Joohyung Lee and Fangzhen Lin,"Clark’s completion is a simple nonmonotonic formalism and a special case of many nonmonotonic logics. Recently there has been work on extending completion with ``loop formulas'' so that general cases of nonmonotonic logics such as logic programs (under the answer set semantics) and McCain-Turner causal logic can be characterized by propositional logic in the form of ""completion + loop formulas."" In this paper, we show that the idea is applicable to McCarthy’s circumscription in the propositional case. We also show how to embed propositional circumscription in logic programs and in causal logic, inspired by the uniform characterization of completion + loop formulas.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-045.pdf,
51,2004,Knowledge Representation and Reasoning,An Instance-Based State Representation for Network Repair,"Michael L. Littman, Nishkam Ravi, Eitan Fenson, and Rich Howard","We describe a formal framework for diagnosis and repair problems that shares elements of the well known partially observable MDP and cost-sensitive classification models. Our cost-sensitive fault remediation model is amenable to implementation as a reinforcement-learning system, and we describe an instance-based state representation that is compatible with learning and planning in this framework. We demonstrate a system that uses these ideas to learn to efficiently restore network connectivity after a failure.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-046.pdf,
52,2004,Knowledge Representation and Reasoning,"Logical Foundations of Negotiation: Outcome, Concession, and Adaptation","Thomas Meyer, Norman Foo, Rex Kwok, and Dongmo Zhang","This paper provides a logical framework for negotiation between agents that are assumed to be rational, cooperative and truthful. We present a characterisation of the permissible outcomes of a process of negotiation in terms of a set of rationality postulates, as well as a method for constructing exactly the rational outcomes. The framework is extended by describing two modes of negotiation from which an outcome can be reached. In the concessionary mode, agents are required to weaken their demands in order to accommodate the demands of others. In the adaptationist mode, agents are required to adapt to the demands of others in some appropriate fashion. Both concession and adaptation are characterised in terms of rationality postulates. We also provide methods for constructing exactly the rational concessions, as well as the rational adaptations. The central result of the paper is the observation that the outcomes obtained from the concessionary and adaptationist modes both correspond to the rational outcomes. We conclude by pointing out the links between negotiation and AGM belief change, and providing a glimpse of how this may be used to define a notion of preference-based negotiation.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-047.pdf,
53,2004,Knowledge Representation and Reasoning,Repeated Observation Models,Avi Pfeffer,"Repetition is an important phenomenon in a variety of domains, such as music, computer programs and architectural drawings. A generative model for these domains should account for the possibility of repetition. We present repeated observation models (ROMs), a framework for modeling sequences that explicitly allows for repetition. In a ROM, an element is either generated by copying a previous element, or by using a base model. We show how to build ROMs using n-grams and hidden Markov models as the base model. We also describe an extension of ROMs in which entire subsequences are repeated together. Results from a music modeling domain show that ROMs can lead to dramatic improvement in predictive ability.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-048.pdf,
54,2004,Knowledge Representation and Reasoning,Encoding Probabilistic Causal Model in Probabilistic Action Language,Nam Tran and Chitta Baral,Pearl’s probabilistic causal model has been used in many domains to reason about causality. Pearl’s treatment of actions is very different from the way actions are represented explicitly in action languages. In this paper we show how to encode Pearl’s probabilistic causal model in the action language PAL thus relating this two distinct approaches to reasoning about actions.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-049.pdf,
55,2004,Knowledge Representation and Reasoning,Evaluating Ontology Cleaning,"Christopher Welty, Ruchi Mahindru, and Jennifer Chu-Carroll","Ontology as a discipline of Computer Science has made many claims about its usefulness, however to date there has been very little evaluation of those claims. We present the results of an experiment using a hybrid search system with a significant knowledge-based component to measure, using precision and recall, the impact of improving the quality of an ontology on overall performance. We demonstrate that improving the ontology using OntoClean (Guarino and Welty, 2002), does positively impact performance, and that having knowledge of the search domain is more effective than domain-knowledge-free search techniques such as link analysis.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-050.pdf,
56,2004,Knowledge Representation and Reasoning,Negotiation as Mutual Belief Revision,"Dongmo Zhang, Norman Foo, Thomas Meyer, and Rex Kwok",This paper presents a logical framework for negotiation based on belief revision theory. We consider that a negotiation process is a course or multiple courses of mutual belief revision. A set of AGM-style postulates are proposed to capture the rationality of competitive and cooperative behaviors of negotiation. We first show that the AGM revision and its iterated extension is a special case of negotiation function. Then we show that a negotiation function can be constructed by two related iterated belief revision functions under a certain coordination mechanism. This provides a qualitative method for constructing negotiation space and rational concessions. It also shows a glimpse of how to express game-theoretical concepts in logical framework.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-051.pdf,
57,2004,Learning,Hierarchical Hidden Markov Models with General State Hierarchy,"Hung H. Bui, Dinh Q. Phung, and Svetha Venkatesh","The hierarchical hidden Markov model (HHMM) is an extension of the hidden Markov model to include a hierarchy of the hidden states. This form of hierarchical modeling has been found useful in applications such as handwritten character recognition, behavior recognition, video indexing, and text retrieval. Nevertheless, the state hierarchy in the original HHMM is restricted to a tree structure. This prohibits two different states from having the same child, and thus does not allow for sharing of common substructures in the model. In this paper, we present a general HHMM in which the state hierarchy can be a lattice allowing arbitrary sharing of substructures. Furthermore, we provide a method for numerical scaling to avoid underflow, an important issue in dealing with long observation sequences. We demonstrate the working of our method in a simulated environment where a hierarchical behavioral model is automatically learned and later used for recognition.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-052.pdf,
58,2004,Learning,An Ensemble Technique for Stable Learners with Performance Bounds,Ian Davidson,"Ensemble techniques such as bagging and DECORATE exploit the ""instability"" of learners, such as decision trees, to create a diverse set of models. However, creating a diverse set of models for stable learners such as naïve Bayes is difficult as they are relatively insensitive to training data changes. Furthermore, many popular ensemble techniques do not have a rigorous underlying theory and often provide no insight into how many models to build. We formally define stable learner as having a second order derivative of the posterior density function and propose an ensemble technique specifically for stable learners. Our ensemble technique, bootstrap model averaging, creates a number of bootstrap samples from the training data, builds a model from each and then sums the joint instance and class probability over all models built. We show that for stable learners our ensemble technique for infinite bootstrap samples approximates posterior model averaging (aka the optimal Bayes classifier (OBC)). For finite bootstrap samples we estimate the increase over the OBC error using Chebychev bounds. We empirically illustrate our approach’s usefulness for several stable learners and verify our bound’s correctness.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-053.pdf,
59,2004,Learning,On the Optimality of Probability Estimation by Random Decision Trees,Wei Fan,"Random decision tree is an ensemble of decision trees. The feature at any node of a tree in the ensemble is chosen randomly from remaining features. A chosen discrete feature on a decision path cannot be chosen again. Continuous feature can be chosen multiple times, however, with a different splitting value each time. During classification, each tree outputs raw posterior probability. The probabilities from each tree in the ensemble are averaged as the final posterior probability estimate. Although remarkably simple and somehow counter-intuitive, random decision tree has been shown to be highly accurate under 0-1 loss and cost-sensitive loss functions. Preliminary explanation of its high accuracy is due to the “error-tolerance” property of probabilistic decision making. Our study has shown that the actual reason for random tree’s superior performance is due to its optimal approximation to each example’s true probability to be a member of a given class.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-054.pdf,
60,2004,Learning,Fibring Neural Networks,Artur S. d’Avila Garcez and Dov M. Gabbay,"Neural-symbolic systems are hybrid systems that integrate symbolic logic and neural networks. The goal of neural-symbolic integration is to benefit from the combination of features of the symbolic and connectionist paradigms of artificial intelligence. This paper introduces a new neural network architecture based on the idea of fibring logical systems. Fibring allows one to combine different logical systems in a principled way. Fibred neural networks may be composed not only of interconnected neurons but also of other networks, forming a recursive architecture. A fibring function then defines how this recursive architecture must behave by defining how the networks in the ensemble relate to each other, typically by allowing the activation of neurons in one network (A) to influence the change of weights in another network (B). Intuitively, this can be seen as training network B at the same time that one runs network A. We show that, in addition to being universal approximators like standard feedforward networks, fibred neural networks can approximate any polynomial function to any desired degree of accuracy, thus being more expressive than standard feedforward networks. Keywords: Neural-Symbolic Integration, Fibring Systems, Recursion.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-055.pdf,
61,2004,Learning,Learning and Inferring Transportation Routines,"Lin Liao, Dieter Fox, and Henry Kautz",This paper introduces a hierarchical Markov model that can learn and infer a user’s daily movements through the community. The model uses multiple levels of abstraction in order to bridge the gap between raw GPS sensor measurements and high level information such as a user’s mode of transportation or her goal. We apply Rao-Blackwellised particle filters for efficient inference both at the low level and at the higher levels of the hierarchy. Significant locations such as goals or locations where the user frequently changes mode of transportation are learned from GPS data logs without requiring any manual labeling. We show how to detect abnormal behaviors (e.g. taking a wrong bus) by concurrently tracking his activities with a trained and a prior model. Experiments show that our model is able to accurately predict the goals of a person and to recognize situations in which the user performs unknown activities.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-056.pdf,
62,2004,Learning,Learning and Applying Competitive Strategies,Esther Lock and Susan L. Epstein,"Learning reusable sequences can support the development of expertise in many domains, either by improving decisionmaking quality or decreasing execution speed. This paper introduces and evaluates a method to learn action sequences for generalized states from prior problem experience. From experienced sequences, the method induces the context that underlies a sequence of actions. Empirical results indicate that the sequences and contexts learned for a class of problems are actually those deemed important by experts for that particular class, and can be used to select appropriate action sequences when solving problems there.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-057.pdf,
63,2004,Learning,Bayesian Network Classifiers Versus k-NN Classifier Using Sequential Feature Selection,Franz Pernkopf,The aim of this paper is to compare Bayesian network classifiers to the k-NN classifier based on a subset of features. This subset is established by means of sequential feature selection methods. Experimental results show that Bayesian network classifiers more often achieve a better classification rate on different data sets than selective k-NN classifiers. The k-NN classifier performs well in the case where the number of samples for learning the parameters of the Bayesian network is small. Bayesian network classifiers outperform selective k-NN methods in terms of memory requirements and computational demands. This paper demonstrates the strength of Bayesian networks for classification.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-058.pdf,
64,2004,Learning,Online Parallel Boosting,"Jesse A. Reichler, Harlan D. Harris, and Michael A. Savchenko","This paper presents a new boosting (arcing) algorithm called POCA, Parallel Online Continuous Arcing. Unlike traditional boosting algorithms (such as Arc-x4 and Adaboost), that construct ensembles by adding and training weak learners sequentially on a round-by-round basis, training in POCA is performed over an entire ensemble continuously and in parallel. Since members of the ensemble are not frozen after an initial learning period (as in traditional boosting) POCA is able to adapt rapidly to nonstationary environments, and because POCA does not require the explicit scoring of a fixed exemplar set, it can perform online learning of non-repeating data. We present results from experiments conducted using neural network experts that show POCA is typically faster and more adaptive than existing boosting algorithms. Results presented for the UCI letter dataset are, to our knowledge, the best published scores to date.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-059.pdf,
65,2004,Learning,Bayesian Inference on Principal Component Analysis Using Reversible Jump Markov Chain Monte Carlo,"Zhihua Zhang, Kap Luk Chan, James T. Kwok, and Dit-Yan Yeung","Based on the probabilistic reformulation of principal component analysis (PCA), we consider the problem of determining the number of principal components as a model selection problem. We present a hierarchical model for probabilistic PCA and construct a Bayesian inference method for this model using reversible jump Markov chain Monte Carlo (MCMC). By regarding each principal component as a point in a one-dimensional space and employing only birthdeath moves in our reversible jump methodology, our proposed method is simple and capable of automatically determining the number of principal components and estimating the parameters simultaneously under the same disciplined framework. Simulation experiments are performed to demonstrate the effectiveness of our MCMC method.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-060.pdf,
66,2004,Learning,Error Detection and Impact-Sensitive Instance Ranking in Noisy Datasets,"Xingquan Zhu, Xindong Wu, and Ying Yang","Given a noisy dataset, how to locate erroneous instances and attributes and rank suspicious instances based on their impacts on the system performance is an interesting and important research issue. We provide in this paper an Error Detection and Impact-sensitive instance Ranking (EDIR) mechanism to address this problem. Given a noisy dataset D, we first train a benchmark classifier T from D. The instances, that cannot be effectively classified by T are treated as suspicious and forwarded to a subset S. For each attribute Ai, we switch Ai and the class label C to train a classifier APi for Ai. Given an instance Ik in S, we use APi and the benchmark classifier T to locate the erroneous value of each attribute Ai. To quantitatively rank instances in S, we define an impact measure based on the Information-gain Ratio (IR). We calculate IRi between attribute Ai and C, and use IRi as the impact-sensitive weight of Ai. The sum of impact-sensitive weights from all located erroneous attributes of Ik indicates its total impact value. The experimental results demonstrate the effectiveness of our strategies.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-061.pdf,
67,2004,Learning,Natural Language Processing and Information Extraction Comparing Cognitive and Computational Models of Narrative Structure,David B. Christian and R. Michael Young,"A growing number of applications seek to incorporate automatically generated narrative structure into interactive virtual environments. In this paper, we evaluate a representation for narrative structure generated by an automatic planning system by 1) mapping the plans that control plot into conceptual graphs used by QUEST, an existing framework for question-answering analysis that includes structures for modeling a reader’s narrative comprehension and 2) using methods originally employed by QUEST’s developers to determine if the plan structures can serve as effective models of the understanding that human users form after viewing corresponding stories played out within a virtual world. Results from our analysis are encouraging, though additional work is required to expand the plan language to cover a broader class of narrative structure.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-062.pdf,
68,2004,Learning,Methods for Domain-Independent Information Extraction from the Web: An Experimental Comparison,"Oren Etzioni, Michael Cafarella, Doug Downey, Ana-Maria Popescu, Tal Shaked, Stephen Soderland, Daniel S. Weld, and Alexander Yates","Our KNOWITALL system aims to automate the tedious process of extracting large collections of facts (e.g., names of scientists or politicians) from the Web in an autonomous, domain-independent, and scalable manner. In its first major run, KNOWITALL extracted over 50,000 facts with high precision, but suggested a challenge: How can we improve KNOWITALL’s recall and extraction rate without sacrificing precision? This paper presents three distinct ways to address this challenge and evaluates their performance. Rule Learning learns domain-specific extraction rules. Subclass Extraction automatically identifies sub-classes in order to boost recall. List Extraction locates lists of class instances, learns a “wrapper” for each list, and extracts elements of each list. Since each method bootstraps from KNOWITALL’s domain-independent methods, no hand-labeled training examples are required. Experiments show the relative coverage of each method and demonstrate their synergy. In concert, our methods gave KNOWITALL a 4-fold to 19-fold increase in recall, while maintaining high precision, and discovered 10,300 cities missing from the Tipster Gazetteer.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-063.pdf,
69,2004,Learning,Interpreting Loosely Encoded Questions,James Fan and Bruce Porter,"Knowledge-based question-answering systems have become quite competent and robust at answering a wide range of questions in different domains, however in order to ask questions correctly, one needs to have intimate knowledge of the structure of the knowledge base, and typical users lack this knowledge. We address this problem by developing a system that uses the content of the knowledge base to automatically align a user’s encoding of a query to the structure of the knowledge base. Our preliminary evaluation shows the system detects and corrects most misalignments, and users are able to pose most questions quickly.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-064.pdf,
70,2004,Learning,Learning Indexing Patterns from One Language for the Benefit of Others,"Udo Hahn, Kornél Markó, and Stefan Schulz","Using language technology for text analysis and light-weight ontologies as a content-mediating level, we acquire indexing patterns from vast amounts of indexing data for English-language medical documents. This is achieved by statistically relating interlingual representations of these documents (based on text token bigrams) to their associated index terms. From these ""English"" indexing patterns, we then induce the associated index terms for German and Portuguese documents when their interlingual representations match those of English documents. Thus, we learn from past English indexing experience and transfer it in an unsupervised way to non-English texts, without ever having seen concrete indexing data for languages other than English.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-065.pdf,
71,2004,Learning,Interactive Information Extraction with Constrained Conditional Random Fields,"Trausti Kristjansson, Aron Culotta, Paul Viola, and Andrew McCallum","Information Extraction methods can be used to automatically “fill-in” database forms from unstructured data such as Web documents or email. State-of-the-art methods have achieved low error rates but invariably make a number of errors. The goal of an interactive information extraction system is to assist the user in filling in database fields while giving the user confidence in the integrity of the data. The user is presented with an interactive interface that allows both the rapid verification of automatic field assignments and the correction of errors. In cases where there are multiple errors, our system takes into account user corrections, and immediately propagates these constraints such that other fields are often corrected automatically. Linear-chain conditional random fields (CRFs) have been shown to perform well for information extraction and other language modelling tasks due to their ability to capture arbitrary, overlapping features of the input in a Markov model. We apply this framework with two extensions: a constrained Viterbi decoding which finds the optimal field assignments consistent with the fields explicitly specified or corrected by the user; and a mechanism for estimating the confidence of each extracted field, so that low-confidence extractions can be highlighted. Both of these mechanisms are incorporated in a novel user interface for form filling that is intuitive and speeds the entry of data—providing a 23% reduction in error due to automated corrections.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-066.pdf,
72,2004,Learning,Identification and Tracing of Ambiguous Names: Discriminative and Generative Approaches,"Xin Li, Paul Morie, and Dan Roth","A given entity — representing a person, a location or an organization — may be mentioned in text in multiple, ambiguous ways. Understanding natural language requires identifying whether different mentions of a name, within and across documents, represent the same entity. We present two machine learning approaches to this problem, which we call the ""Robust Reading"" problem. Our first approach is a discriminative approach, trained in a supervised way. Our second approach is a generative model, at the heart of which is a view on how documents are generated and how names (of different entity types) are ""sprinkled"" into them. In its most general form, our model assumes: (1) a joint distribution over entities (e.g., a document that mentions President Kennedy is more likely to mention Oswald or White House than Roger Clemens), (2) an author model, that assumes that at least one mention of an entity in a document is easily identifiable, and then generates other mentions via (3) an appearance model, governing how mentions are transformed from the representative mention. We show that both approaches perform very accurately, in the range of $90%-95% F1 measure for different entity types, much better than previous approaches to (some aspects of) this problem. Our extensive experiments exhibit the contribution of relational and structural features and, somewhat surprisingly, that the assumptions made within our generative model are strong enough to yield a very powerful approach, that performs better than a supervised approach with limited supervised information.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-067.pdf,
73,2004,Learning,Text Classification by Labeling Words,"Bing Liu, Xiaoli Li, Wee Sun Lee, and Philip S. Yu","Traditionally, text classifiers are built from labeled training examples. Labeling is usually done manually by human experts (or the users), which is a labor intensive and time consuming process. In the past few years, researchers investigated various forms of semi-supervised learning to reduce the burden of manual labeling. In this paper, we propose a different approach. Instead of labeling a set of documents, the proposed method labels a set of representative words for each class. It then uses these words to extract a set of documents for each class from a set of unlabeled documents to form the initial training set. The EM algorithm is then applied to build the classifier. The key issue of the approach is how to obtain a set of representative words for each class. One way is to ask the user to provide them, which is difficult because the user usually can only give a few words (which are insufficient for accurate learning). We propose a method to solve the problem. It combines clustering and feature selection. The technique can effectively rank the words in the unlabeled set according to their importance. The user then selects/labels some words from the ranked list for each class. This process requires less effort than providing words with no help or manual labeling of documents. Our results show that the new method is highly effective and promising.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-068.pdf,
74,2004,Learning,On the Relationship between Lexical Semantics and Syntax for the Inference of Context-Free Grammars,"Tim Oates, Tom Armstrong, Justin Harris, and Mark Nejman","Context-free grammars cannot be identified in the limit from positive examples, yet natural language grammars are more powerful than context-free grammars and humans learn them with remarkable ease from positive examples. Identifiability results for formal languages ignore a potentially powerful source of information available to learners of natural languages, namely, meanings. This paper explores the learnability of syntax (i.e. context-free grammars) given positive examples and knowledge of lexical semantics, and the learnability of lexical semantics given knowledge of syntax. The long-term goal is to develop an approach to learning both syntax and semantics that bootstraps itself, using limited knowledge about syntax to infer additional knowledge about semantics, and limited knowledge about semantics to infer additional knowledge about syntax.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-069.pdf,
75,2004,Learning,Distributed Representation of Syntactic Structure by Tensor Product Representation and Non-Linear Compression,Heidi H. T. Yeung and Peter W. M. Tsang,"Representing lexicons and sentences with the subsymbolic approach (using techniques such as Self Organizing Map (SOM) or Artificial Neural Network (ANN)) is a relatively new but important research area in natural language processing. The performance of this approach however, is highly dependent on whether representations are well formed so that members within each cluster are corresponding to sentences or phrases of similar meaning. Despite the moderate success and the rapid advancement of contemporary computing power, it is still difficult to establish an efficient learning method so that natural language can be represented in a way close to the benchmark exhibited by human beings. One of the major problems is due to the general lack of effective method(s) to encapsulate semantic information into quantitative expressions or structures. In this paper, we propose to alleviate this problem with a novel technique based on Tensor Product Representation and Non-linear Compression. The method is capable of encoding sentences into distributed representations that are closely associated with the semantic contents, being more comprehensible and analyzable from the perspective of human intelligence.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-070.pdf,
76,2004,Perception,Rapid Object Recognition from Discriminative Regions of Interest,"Gerald Fritz, Christin Seifert, Lucas Paletta, and Horst Bischof","Object recognition and detection represent a relevant component in cognitive computer vision systems, such as in robot vision, intelligent video surveillance systems, or multi-modal interfaces. Object identification from local information has recently been investigated with respect to its potential for robust recognition, e.g., in case of partial object occlusions, scale variation, noise, and background clutter in detection tasks. This work contributes to this research by a thorough analysis of the discriminative power of local appearance patterns and by proposing to exploit local information content to model object representation and recognition. We identify discriminative regions in the object views from a posterior entropy measure, and then derive object models from selected discriminative local patterns. For recognition, we determine rapid attentive search for locations of high information content from learned decision trees. The recognition system is evaluated by various degrees of partial occlusion and Gaussian image noise, resulting in highly robust recognition even in the presence of severe occlusion effects.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-071.pdf,
77,2004,Perception,Automatically Transforming Symbolic Shape Descriptions for Use in Sketch Recognition,Tracy Hammond and Randall Davis,"Sketch recognition systems are currently being developed for many domains, but can be time consuming to build if they are to handle the intricacies of each domain. This paper presents the first translator that takes symbolic shape descriptions (written in the LADDER sketch language) and automatically transforms them into shape recognizers, editing recognizers, and shape exhibitors for use in conjunction with a domain independent sketch recognition system. This transformation allows us to build a single domain independent recognition system that can be customized for multiple domains. We have tested our framework by writing several domain descriptions and automatically created a domain specific sketch recognition system for each domain.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-072.pdf,
78,2004,Perception,Large-Scale Map-Making,Kurt Konolige,"Current mapping algorithms using Consistent Pose Estimation (CPE) algorithms can successfully map areas of 104 square meters, using thousands of poses. However, the computation to construct the map grows as O(n log n), so larger maps get increasingly difficult to build. We present an abstraction method for postponing the growth in computation. This method solves a much smaller problem in the space of the connection graph of the map.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-073.pdf,
79,2004,Perception,A Multi-Resolution Pyramid for Outdoor Robot Terrain Perception,Michael Montemerlo and Sebastian Thrun,"This paper addresses the problem of outdoor terrain modeling for the purposes of mobile robot navigation. We propose an approach in which a robot acquires a set of terrain models at differing resolutions. Our approach addresses one of the major shortcomings of Bayesian reasoning when applied to terrain modeling, namely artifacts that arise from the limited spatial resolution of robot perception. Limited spatial resolution causes small obstacles to be detectable only at close range. Hence, a Bayes filter estimating the state of terrain segments must consider the ranges at which that terrain is observed. We develop a multi-resolution approach that maintains multiple navigation maps, and derive rational arguments for the number of layers and their resolutions. We show that our approach yields significantly better results in a practical robot system, capable of acquiring detailed 3-D maps in large-scale outdoor environments.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-074.pdf,
80,2004,Perception,Self-Organizing Visual Maps,Robert Sim and Gregory Dudek,"This paper deals with automatically learning the spatial distribution of a set of images. That is, given a sequence of images acquired from well-separated locations, how can they be arranged to best explain their genesis? The solution to this problem can be viewed as an instance of robot mapping although it can also be used in other contexts. We examine the problem where only limited prior odometric information is available, employing a feature-based method derived from a probabilistic pose estimation framework. Initially, a set of visual features is selected from the images and correspondences are found across the ensemble. The images are then localized by first assembling the small subset of images for which odometric confidence is high, and sequentially inserting the remaining images, localizing each against the previous estimates, and taking advantage of any priors that are available. We present experimental results validating the approach, and demonstrating metrically and topologically accurate results over two large image ensembles. Finally, we discuss the results, their relationship to the autonomous exploration of an unknown environment, and their utility for robot localization and navigation.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-075.pdf,
81,2004,Perception,Reconstruction of 3D Models from Intensity Images and Partial Depth,Luz A. Torres-Méndez and Gregory Dudek,"This paperaddresses the probabilistic inference of geometric structures from images. Specifically, of synthesizing range data to enhance the reconstruction of a 3D model of an indoor environment by using video images and (very) partial depth information. In our method, we interpolate the available range data using statistical inferences learned from the concurrently available video images and from those (sparse) regions where both range and intensity information is available. The spatial relationships between the variations in intensity and range can be efficiently captured by the neighborhood system of a Markov Random Field (MRF). In contrast to classical approaches to depth recovery (i.e. stereo, shape from shading), we can afford to make only weak prior assumptions regarding specific surface geometries or surface reflectance functions since we compute the relationship between existing range data and the images we start with. Experimental results show the feasibility of our method.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-076.pdf,
82,2004,Perception,Perceptually Based Learning of Shape Descriptions for Sketch Recognition,Olya Veselova and Randall Davis,"We areinterested in enabling a generic sketch recognition system that would allow more natural interaction with design tools in various domains, such as mechanical engineering, military planning, logic design, etc. We would like to teach the system the symbols for a particular domain by simply drawing an example of each one — as easy as it is to teach a person. Studies in cognitive science suggest that, when shown a symbol, people attend preferentially to certain geometric features. Relying on such biases, we built a system capable of learning descriptions of hand-drawn symbols from a single example. The generalization power is derived from a qualitative vocabulary reflecting human perceptual categories and a focus on perceptually relevant global properties of the symbol. Our user study shows that the system agrees with the subjects’ majority classification about as often as any individual subject did.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-077.pdf,
83,2004,Perception,On the Integration of Grounding Language and Learning Objects,Chen Yu and Dana H. Ballard,"This paper presents a multimodal learning system that can ground spoken names of objects in their physical referents and learn to recognize those objects simultaneously from naturally co-occurring multisensory input. There are two technical problems involved: (1) the correspondence problem in symbol grounding — how to associate words (symbols) with their perceptually grounded meanings from multiple cooccurrences between words and objects in the physical environment. (2) object learning — how to recognize and categorize visual objects. We argue that those two problems can be fundamentally simplified by considering them in a general system and incorporating the spatio-temporal and crossmodal constraints of multimodal data. The system collects egocentric data including image sequences as well as speech while users perform natural tasks. It is able to automatically infer the meanings of object names from vision, and categorize objects based on teaching signals potentially encoded in speech. The experimental results reported in this paper reveal the effectiveness of using multimodal data and integrating heterogeneous techniques in machine learning, natural language processing and computer vision.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-078.pdf,
84,2004,Planning and Scheduling,"Generating Safe Assumption-Based Plans for Partially Observable, Nondeterministic Domains",Alexandre Albore and Piergiorgio Bertoli,"Reactive planning using assumptions is a well-known approach to tackle complex planning problems for nondeterministic, partially observable domains. However, assumptions may be wrong; this may cause an assumption-based plan to fail. In general, it is not possible to decide at runtime whether an assumption has failed and is putting at danger the success of the plan; thus, plan execution has to be controlled taking into account every possible success-endangering assumption failure. The possibility of tracing such failures strongly depends on the actions performed by the plan. In this paper, focusing on a simple assumption language, we provide two main contributions. First, we formally characterize safe assumption-based plans, i.e. plans that not only succeed whenever the assumption holds, but also guarantee that any success-endangering assumption failure is traced by a suitable monitor. In this way, replanning may be triggered only when actually needed. Second, we extend the planner in a reactive platform in order to produce safe assumption-based plans. We experimentally show that safe assumption-based (re)planning is a good alternative to its unsafe counterpart, minimizing the need for replanning while retaining the efficiency in plan generation.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-079.pdf,
85,2004,Planning and Scheduling,Regrets Only! Online Stochastic Optimization under Time Constraints,Russell Bent and Pascal Van Hentenryck,"This paper considers online stochastic optimization problems where time constraints severely limit the number of offline optimizations which can be performed at decision time and/or in between decisions. It proposes a novel approach which combines the salient features of the earlier approaches: the evaluation of every decision on all samples (expectation) and the ability to avoid distributing the samples among decisions (consensus). The key idea underlying the novel algorithm is to approximate the regret of a decision $d$. The regret algorithm is evaluated on two fundamentally different applications: online packet scheduling in networks and online multiple vehicle routing with time windows. On both applications, it produces significant benefits over prior approaches.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-080.pdf,
86,2004,Planning and Scheduling,Assessing the Complexity of Plan Recognition,Christopher W. Geib,This paper presents a discussion of the theoretical complexity of plan recognition on the basis of an analysis of the number of explanations that any complete plan recognition algorithm must consider given various properties of the plan library. On the basis of these results it points out properties of plan libraries that make them computationally expensive.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-081.pdf,
87,2004,Planning and Scheduling,Forward-Chaining Planning in Nondeterministic Domains,Ugur Kuter and Dana Nau,"In this paper, we present a general technique for taking forward-chaining planners for deterministic domains (e.g., HSP, TLPlan, TALplanner, and SHOP2) and adapting them to work in nondeterministic domains. Our results suggest that our technique preserves many of the desirable properties of these planners, such as the ability to use heuristic techniques to achieve highly efficient planning. In our experimental studies on two problem domains, the well-known MBP algorithm took exponential time, confirming prior results by others. A nondeterminized version of SHOP2 took only polynomial time. The polynomial-time figures are confirmed by a complexity analysis, and a similar complexity analysis shows that a nondeterminized version of TLPlan would perform similarly.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-082.pdf,
88,2004,Planning and Scheduling,Transport Logistics Planning with Service-Level Constraints,"Hoong Chuin Lau, Kien Ming Ng, and Xiaotao Wu","In this paper, we study a logistics problem arising in military transport planning. A military organization operates a large fleet of vehicles in a depot to serve the requests of various operational units. Each request has a fixed start and end time, and is served by a prescribed number of vehicles. We address the following two problems: (1) how many vehicles are at least needed to meet a given service level of requests; and (2) suppose we allow each request to shift its start time by a constant duration, can all the requests be met? A Niche genetic algorithm, together with a hybridized variant, are applied to the problem.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-083.pdf,
89,2004,Planning and Scheduling,Distance Estimates for Planning in the Discrete Belief Space,Jussi Rintanen,"We present a general framework for studying heuristics for planning in the belief space. Earlier work has focused on giving implementations of heuristics that work well on benchmarks, without studying them at a more analytical level. Existing heuristics have evaluated belief states in terms of their cardinality or have used distance heuristics directly based on the distances in the underlying state space. Neither of these types of heuristics is very widely applicable: often goal belief state is not approached through a sequence of belief states with a decreasing cardinality, and distances in the state space ignore the main implications of partial observability. To remedy these problems we present a family of admissible, increasingly accurate distance heuristics for planning in the belief space, parameterized by an integer n. We show that the family of heuristics is theoretically robust: it includes the simplest heuristic based on the state space as a special case and as a limit the exact distances in the belief space.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-084.pdf,
90,2004,Planning and Scheduling,Continuous Time in a SAT-Based Planner,Ji-Ae Shin and Ernest Davis,"The TM-LPSAT planner can construct plans in domains containing atomic actions and durative actions; events and processes; discrete, real-valued, and interval-valued fluents; and continuous linear change to quantities. It works in three stages. In the first stage, a representation of the domain and problem in an extended version of PDDL+ is compiled into a system of propositional combinations of propositional variables and linear constraints over numeric variables. In the second stage, the LPSAT constraint engine is used to find a solution to the system of constraints. In the third stage, a correct parallel plan is extracted from this solution. We discuss the structure of the planner and show how a real-time temporal model is compiled into LPSAT constraints. Keywords: Propositional planning, LPSAT, continuoustime, numerical quantities, processes.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-085.pdf,
91,2004,Planning and Scheduling,Analogical Path Planning,Saul Simhon and Gregory Dudek,"We present a probabilistic method for path planning that considers trajectories constrained by both the environment and an ensemble of restrictions or preferences on preferred motions for a moving robot. Our system learns constraints and preference biases on a robot’s motion from examples, and then synthesizes behaviors that satisfy these constraints. This behavior can encompass motions that satisfy diverse requirements such as a sweep pattern for floor coverage, or, in particular in our experiments, satisfy restrictions on the robot’s physical capabilities such as restrictions on its turning radius. Given an approximate path that may not satisfy the required conditions, our system computes a refined path that satisfies the constraints and also avoids obstacles. Our approach is based on a Bayesian framework for combining a prior probability distribution on the trajectory with environmental constraints. The prior distribution is generated by decoding a Hidden Markov Model, which is itself is trained over a particular set of preferred motions. Environmental constraints are modeled using a potential field over the configuration space. This paper poses the requisite theoretical framework and demonstrates its effectiveness with several examples.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-086.pdf,
92,2004,Planning and Scheduling,An Effective Algorithm for Project Scheduling with Arbitrary Temporal Constraints,Tristan B. Smith and John M. Pyle,"The resource-constrained project scheduling problem with time windows (RCPSP/max) is an important generalization of a number of well studied scheduling problems. In this paper, we present a new heuristic algorithm that combines the benefits of squeaky wheel optimization with an effective conflict resolution mechanism, called bulldozing, to address RCPSP/max problems. On a range of benchmark problems, the algorithm is competitive with state-of-the-art systematic and non-systematic methods and scales well.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-087.pdf,
93,2004,Planning and Scheduling,"Shortest Path Discovery Problems: A Framework, Algorithms and Experimental Results",Csaba Szepesvári,"In this paper we introduce and study Shortest Path Discovery (SPD) problems, a generalization of shortest path problems: In SPD one is given a directed edgeweighted graph and the task is to find a the shortest path for fixed source and target nodes such that initially the edge-weights are unknown, but they can be queried. Querying the cost of an edge is expensive and hence the goal is to minimize the total number of edge cost queries executed. In this article we characterize some common properties of sound SPD algorithms, propose a particular algorithm that is shown to be sound and effective. Experimental results on real-world OCR task demonstrate the usefulness of the approach whereas the proposed algorithm is shown to yield a substantial speed-up of the recognition process.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-088.pdf,
94,2004,Planning and Scheduling,Regression with Respect to Sensing Actions and Partial States,"Le-Chi Tuan, Chitta Baral, Xin Zhang, and Tran Cao Son","In this paper, we present a state-based regression function for planning domains where an agent does not have complete information and may have sensing actions. We consider binary domains 1, and employ the 0-approximation to define the regression function. In binary domains, the use of 0-approximation means using 3-valued states. Although planning using this approach is incomplete with respect to the full semantics, we adopt it to have a lower complexity. We prove the soundness and completeness of our regression formulation with respect to the definition of progression and develop a conditional planner that utilizes our regression function.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-089.pdf,
95,2004,Planning and Scheduling,Effective Approaches for Partial Satisfaction (Over-Subscription) Planning,"Menkes van den Briel, Romeo Sanchez, Minh B. Do, and Subbarao Kambhampati","In many real world planning scenarios, agents often do not have enough resources to achieve all of their goals. Consequently, they are forced to find plans that satisfy only a subset of the goals. Solving such partial satisfaction planning (PSP) problems poses several challenges, including an increased emphasis on modeling and handling plan quality (in terms of action costs and goal utilities). Despite the ubiquity of such PSP problems, very little attention has been paid to them in the planning community. In this paper, we start by describing a spectrum of PSP problems and focus on one of the more general PSP problems, termed PSP NET BENEFIT. We develop three techniques, (i) one based on integer programming, called OptiPlan, (ii) the second based on regression planning with reachability heuristics, called AltAlt ps , and (iii) the third based on anytime heuristic search for a forward state-space heuristic planner, called Sapa ps . Our empirical studies with these planners show that the heuristic planners generate plans that are comparable to the quality of plans generated by OptiPlan, while incurring only a small fraction of the cost.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-090.pdf,
96,2004,Planning and Scheduling,Branching and Pruning: An Optimal Temporal POCL Planner Based on Constraint Programming,Vincent Vidal and Héctor Geffner,"A key feature of modern optimal planners such as Graphplan and Blackbox is their ability to prune large parts of the search space. Previous Partial Order Causal Link (POCL) planners provide an alternative branching scheme but lacking comparable pruning mechanisms do not perform as well. In this paper, a domain-independent formulation of temporal planning based on Constraint Programming is introduced that successfully combines a POCL branching scheme with powerful and sound pruning rules. The key novelty in the formulation is the ability to reason about supports, precedences, and causal links involving actions that are not in the plan. Experiments over a wide range of benchmarks show that the resulting optimal temporal planner is much faster than current ones and is competitive with the best parallel planners in the special case in which actions have all the same duration.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-091.pdf,
97,2004,Planning and Scheduling,High-Level Goal Recognition in a Wireless LAN,"Jie Yin, Xiaoyong Chai, and Qiang Yang","Plan recognition has traditionally been developed forlogically encoded application domains with a focus onlogical reasoning. In this paper, we present an integrated plan-recognition model that combines low-levelsensory readings with high-level goal inference. A twolevel architecture is proposed to infer a user’s goals ina complex indoor environment using an RF-based wireless network. The novelty of our work derives from ourability to infer a user’s goals from sequences of signal trajectory, and the ability for us to make a tradeoff between model accuracy and inference efficiency.The model relies on a dynamic Bayesian network to infer a user’s actions from raw signals, and an N-grammodel to infer the users’ goals from actions. We presenta method for constructing the model from the past dataand demonstrate the effectiveness of our proposed solution through empirical studies using some real data thatwe have collected.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-092.pdf,
98,2004,Qualitative Modeling,Spatial Aggregation for Qualitative Assessment of Scientific Computations,Chris Bailey-Kellogg and Naren Ramakrishnan,"Qualitative assessment of scientific computations is an emerging application area that applies a data-driven approach to characterize, at a high level, phenomena including conditioning of matrices, sensitivity to various types of error propagation, and algorithmic convergence behavior. This paper develops a spatial aggregation approach that formalizes such analysis in terms of model selection utilizing spatial structures extracted from matrix perturbation datasets. We focus in particular on the characterization of matrix eigenstructure, both analyzing sensitivity of computations with spectral portraits and determining eigenvalue multiplicity with Jordan portraits. Our approach employs spatial reasoning to overcome noise and sparsity by detecting mutually reinforcing interpretations, and to guide subsequent data sampling. It enables quantitative evaluation of properties of a scientific computation in terms of confidence in a model, explainable in terms of the sampled data and domain knowledge about the underlying mathematical structure. Not only is our methodology more rigorous than the common approach of visual inspection, but it also is often substantially more efficient, due to well-defined stopping criteria. Results show that the mechanism efficiently samples perturbation space and successfully uncovers high-level properties of matrices.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-093.pdf,
99,2004,Qualitative Modeling,A Qualitative-Quantitative Methods-Based e-Learning Support System in Economic Education,"Tokuro Matsuo, Takayuki Ito, and Toramatsu Shintani","This paper describes a new qualitative-quantitative simulator to help buyers learn how to make decisions when they purchase goods. In this paper, we propose an e-learning support system (LSDM) for assisting user decision making by applying artificial intelligence technology. When buyers purchase expensive items, they must carefully select these items from many alternatives. The learning support system provides useful information that assists consumers in purchasing goods. We employ qualitative simulations because the output simulation results are useful. Our system consists of a qualitative processing system and a quantitative calculation system. When users use the system, they first input information on the goods they want to purchase. The information input by users is used in the qualitative simulation. Next, they supply the details of their budgets, the rate of loans, and several other factors, on a form. The system then integrates the results of simulation and the user’s input data and proposes plans to aid in their decision process. The system has several advantages: it can be used by simple input, the process of simulation is easy to understand, users can learn how to make decisions by trial and error, and the users can base their decision making on synthetic results.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-094.pdf,
100,2004,Robotics,Skill Acquisition and Use for a Dynamically-Balancing Soccer Robot,"Brett Browning, Ling Xu, and Manuela Veloso","Dynamically-balancing robots have recently been made available by Segway LLC, in the form of the Segway RMP (Robot Mobility Platform). We have addressed the challenge of using these RMP robots to play soccer, building up upon our extensive previous work in this multi-robot research domain. In this paper, we make three contributions. First, we present a new domain, called Segway Soccer, for investigating the coordination of dynamically formed, mixed human-robot teams within the realm of a team task that requires real-time decision making and response. Segway Soccer is a game of soccer between two teams consisting of both Segway riding humans and Segway RMPs. We believe Segway Soccer is the first game involving both humans and robots in cooperative roles and with similar capabilities. In conjunction with this new domain, we present our work towards developing a soccer playing robot using the RMP platform with vision as its primary sensor. Our third contribution is that of skill acquisition from a human teacher, where the learned skill is then used seamlessly during robot execution as part of its control hierarchy. Skill acquisition and use addresses the challenge of rapidly developing the low-level actions that are environment dependent and are not transferable across robots.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-095.pdf,
101,2004,Robotics,Common Sense Data Acquisition for Indoor Mobile Robots,Rakesh Gupta and Mykel J. Kochenderfer,Common sense knowledge can be efficiently collected from non-experts over the web in a similar fashion to the Open Mind family of distributed knowledge capture projects. We describe the collection of common sense data through the Open Mind Indoor Common Sense (OMICS) website. We restrict the domain to indoor home and office environments to obtain dense knowledge. The knowledge was collected through sentence templates that were generated dynamically based on previous user input. Entries were converted into relations and saved into a database. We discuss the results of this online collaborative effort and describe two applications of the collected data to indoor mobile robots. We discuss active desire selection based on current beliefs and commands and a room-labeling application based on probability estimates from the common sense knowledge base.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-096.pdf,
102,2004,Robotics,Machine Learning for Fast Quadrupedal Locomotion,Nate Kohl and Peter Stone,"For a robot, the ability to get from one place to another is one of the most basic skills. However, locomotion on legged robots is a challenging multidimensional control problem. This paper presents a machine learning approach to legged locomotion, with all training done on the physical robots. The main contributions are a specification of our fully automated learning environment and a detailed empirical comparison of four different machine learning algorithms for learning quadrupedal locomotion. The resulting learned walk is considerably faster than all previously reported hand-coded walks for the same robot platform.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-097.pdf,
103,2004,Robotics,Interleaving Temporal Planning and Execution in Robotics Domains,Solange Lemai and Félix Ingrand,"Many autonomous systems such as mobile robots, UAVs or spacecraft, have limited resource capacities and move in dynamic environments. Performing on-board mission planning and execution in such a context requires deliberative capabilities to generate plans achieving mission goals while respecting deadlines and resource constraints, as well as run-time plan adaption mechanisms during execution. In this paper we propose a framework to integrate deliberative planning, plan repair and execution control in a dynamic environment with stringent temporal constraints. It is based on lifted partial order temporal planning techniques which produce flexible plans and allow, under certain conditions discussed in the paper, plan repair interleaved with plan execution. This framework has been implemented using the IxTeT planner and used to control a robotic platform.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-098.pdf,
104,2004,Robotics,Reinforcement Learning for CPG-Driven Biped Robot,"Takeshi Mori, Yutaka Nakamura, Masa-aki Sato, and Shin Ishii","Animal’s rhythmic movements such as locomotion are considered to be controlled by neural circuits called central pattern generators (CPGs). This article presents a reinforcement learning (RL) method for a CPG controller, which is inspired by the control mechanism of animals. Because the CPG controller is an instance of recurrent neural networks, a naive application of RL involves difficulties. In addition, since state and action spaces of controlled systems are very large in real problems such as robot control, the learning of the value function is also difficult. In this study, we propose a learning scheme for a CPG controller called a CPGactor-critic model, whose learning algorithm is based on a policy gradient method. We apply our RL method to autonomous acquisition of biped locomotion by a biped robot simulator. Computer simulations show our method is able to train a CPG controller such that the learning process is stable.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-099.pdf,
105,2004,Robotics,Advice Generation from Observed Execution: Abstract Markov Decision Process Learning,Patrick Riley and Manuela Veloso,"An advising agent, a coach, provides advice to other agents about how to act. In this paper we contribute an advice generation method using observations of agents acting in an environment. Given an abstract state definition and partially specified abstract actions, the algorithm extracts a Markov Chain, infers a Markov Decision Process, and then solves the MDP (given an arbitrary reward signal) to generate advice. We evaluate our work in a simulated robot soccer environment and experimental results show improved agent performance when using the advice generated from the MDP for both a sub-task and the full soccer game.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-100.pdf,
106,2004,Search,Compressing Pattern Databases,"Ariel Felner, Ram Meshulam, Robert C. Holte, and Richard E. Korf","A pattern database is a heuristic function stored as a lookup table which stores the lengths of optimal solutions for instances of subproblems. All previous pattern databases had a distinct entry in the table for each subproblem instance. In this paper we investigate compressing pattern databases by merging several adjacent entries into one, thereby allowing the use of pattern databases that exceed available memory in their uncompressed form. We show that since adjacent entries are highly correlated, much of the information is preserved. Experiments on the sliding tile puzzles and the 4-peg Towers of Hanoi puzzle show that, for a given amount of memory, search time is reduced by up to 3 orders of magnitude by using compressed pattern databases.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-101.pdf,
107,2004,Search,A General Solution to the Graph History Interaction Problem,Akihiro Kishimoto and Martin Müller,"Since the state space of most games is a directed graph, many game-playing systems detect repeated positions with a transposition table. This approach can reduce search effort by a large margin. However, it suffers from the so-called Graph History Interaction (GHI) problem, which causes errors in games containing repeated positions. This paper presents a practical solution to the GHI problem that combines and extends previous techniques. Because our scheme is general, it is applicable to different game tree search algorithms and to different domains. As demonstrated with the two algorithms α β and df-pn in the two games checkers and Go, our scheme incurs only a very small overhead, while guaranteeing the correctness of solutions.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-102.pdf,
108,2004,Search,Best-First Frontier Search with Delayed Duplicate Detection,Richard E. Korf,"Best-first search is limited by the memory needed to store the Open and Closed lists, primarily to detect duplicate nodes. Magnetic disks provide vastly more storage, but random access of a disk is extremely slow. Instead of checking generated nodes immediately against existing nodes in a hash table, delayed duplicate detection (DDD) appends them to a file, then periodically removes the duplicate nodes using only sequential disk accesses. Frontier search saves storage in a best-first search by storing only the Open list and not the Closed list. The main contributions of this paper are to provide a scalable implementation of DDD, to combine it with frontier search, and to extend it to more general best-first searches such as A*. We illustrate these ideas by performing complete breadth-first searches of sliding-tile puzzles up to the 3x5 Fourteen Puzzle. For the 4-peg Towers of Hanoi problem, we perform complete searches with up to 20 disks, searching a space of over a trillion nodes, and discover a surprising anomaly concerning the problem-space diameter of the 15 and 20-disk problems. We also verify the presumed optimal solution lengths for up to 24 disks. In addition, we implement A* with DDD on the Fifteen Puzzle. Finally, we present a scalable implementation of DDD based on hashing rather than sorting.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-103.pdf,
109,2004,Search,Temperature Discovery Search,"Martin Müller, Markus Enzenberger, and Jonathan Schaeffer","Temperature Discovery Search (TDS) is a new minimax-based game tree search method designed to compute or approximate the temperature of a combinatorial game. TDS is based on the concept of an enriched environment, where a combinatorial game G is embedded in an environment consisting of a large set of simple games of decreasing temperature. Optimal play starts in the environment, but eventually must switch to G. TDS finds the temperature of G by determining when this switch must happen. Both exact and heuristic versions of TDS are described and evaluated experimentally. In experiments with sum games in Amazons, TDS outperforms an alphabeta searcher.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-104.pdf,
110,2004,Search,Simple Search Methods for Finding a Nash Equilibrium,"Ryan Porter, Eugene Nudelman, and Yoav Shoham","We present two simple search methods for computing a sample Nash equilibrium in a normal-form game: one for 2player games and one for n-player games. We test these algorithms on many classes of games, and show that they perform well against the state of the art — the Lemke-Howson algorithm for 2-player games, and Simplicial Subdivision and Govindan-Wilson for n-player games.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-105.pdf,
111,2004,Search,Towards Efficient Sampling: Exploiting Random Walk Strategies,"Wei Wei, Jordan Erenrich, and Bart Selman","From a computational perspective, there is a close connection between various probabilistic reasoning tasks and the problem of counting or sampling satisfying assignments of a propositional theory. We consider the question of whether state-of-the-art satisfiability procedures, based on random walk strategies, can be used to sample uniformly or nearuniformly from the space of satisfying assignments. We first show that random walk SAT procedures often do reach the full set of solutions of complex logical theories. Moreover, by interleaving random walk steps with Metropolis transitions, we also show how the sampling becomes near-uniform.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-106.pdf,
112,2004,Search,Space-Efficient Memory-Based Heuristics,Rong Zhou and Eric A. Hansen,"A memory-based heuristic is a heuristic function that is stored in a lookup table. Very accurate heuristics have been created by building very large lookup tables, sometimes called pattern databases. Most previous work assumes that a memorybased heuristic is computed for the entire state space, and the cost of computing it is amortized over many problem instances. But in some cases, it may be useful to compute a memory-based heuristic for a single problem instance. If the start and goal states of the problem instance are used to restrict the region of the state space for which the heuristic is needed, the time and space used to compute the heuristic may be substantially reduced. In this paper, we review recent work that uses this idea to compute space-efficient heuristics for the multiple sequence alignment problem. We then describe a novel development of this idea that is simpler and more general. Our approach leads to improved performance in solving the multiple sequence alignment problem, and is general enough to apply to other domains.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-107.pdf,
113,2004,Search,Structured Duplicate Detection in External-Memory Graph Search,Rong Zhou and Eric A. Hansen,"Weconsider how to use external memory, such as disk storage, to improve the scalability of heuristic search in statespace graphs. To limit the number of slow disk I/O operations, we develop a new approach to duplicate detection in graph search that localizes memory references by partitioning the search graph based on an abstraction of the state space, and expanding the frontier nodes of the graph in an order that respects this partition. We demonstrate the effectiveness of this approach both analytically and empirically.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-108.pdf,
114,2004,Uncertainty,Stochastic Local Search for POMDP Controllers,Darius Braziunas and Craig Boutilier,"The search for finite-state controllers for partially observable Markov decision processes (POMDPs) is often based on approaches like gradient ascent, attractive because of their relatively low computational cost. In this paper, we illustrate a basic problem with gradient-based methods applied to POMDPs, where the sequential nature of the decision problem is at issue, and propose a new stochastic local search method as an alternative. The heuristics used in our procedure mimic the sequential reasoning inherent in optimal dynamic programming (DP) approaches. We show that our algorithm consistently finds higher quality controllers than gradient ascent, and is competitive with (and, for some problems, superior to) other state-of-the-art controller and DP-based algorithms on large-scale POMDPs.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-109.pdf,
115,2004,Uncertainty,A Computational Study of the Kemeny Rule for Preference Aggregation,Andrew Davenport and Jayant Kalagnanam,"We consider from a computational perspective the problem of how to aggregate the ranking preferences of a number of alternatives by a number of different voters into a single consensus ranking, following the majority voting rule. Social welfare functions for aggregating preferences in this way have been widely studied since the time of Condorcet (1785). One drawback of majority voting procedures when three or more alternatives are being ranked is the presence of cycles in the majority preference relation. The Kemeny order is a social welfare function which has been designed to tackle the presence of such cycles. However computing a Kemeny order is known to be NP-hard. We develop a greedy heuristic and an exact branch and bound procedure for computing Kemeny orders. We present results of a computational study on these procedures.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-110.pdf,
116,2004,Uncertainty,PROBCONS: Probabilistic Consistency-Based Multiple Alignment of Amino Acid Sequences,"Chuong B. Do, Michael Brudno, and Serafim Batzoglou","Obtaining an accurate multiple alignment of protein sequences is a difficult computational problem for which many heuristic techniques sacrifice optimality to achieve reasonable running times. The most commonly used heuristic is progressive alignment, which merges sequences into a multiple alignment by pairwise comparisons along the nodes of a guide tree. To improve accuracy, consistency-based methods take advantage of conservation across many sequences to provide a stronger signal for pairwise comparisons. In this paper, we introduce the concept of probabilistic consistency for multiple sequence alignments. We also present PROBCONS, an HMM-based protein multiple sequence aligner, based on an approximation of the probabilistic consistency objective function. On the BAliBASE benchmark alignment database, PROBCONS demonstrates a statistically significant improvement in accuracy compared to several leading alignment programs while maintaining practical running times.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-111.pdf,
117,2004,Uncertainty,Dynamic Programming for Partially Observable Stochastic Games,"Eric A. Hansen, Daniel S. Bernstein, and Shlomo Zilberstein","We develop an exact dynamic programming algorithm for partially observable stochastic games (POSGs). The algorithm is a synthesis of dynamic programming for partially observable Markov decision processes (POMDPs) and iterated elimination of dominated strategies in normal form games. We prove that when applied to finite-horizon POSGs, the algorithm iteratively eliminates very weakly dominated strategies without first forming a normal form representation of the game. For the special case in which agents share the same payoffs, the algorithm can be used to find an optimal solution. We present preliminary empirical results and discuss ways to further exploit POMDP theory in solving POSGs.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-112.pdf,
118,2004,Uncertainty,Solving Concurrent Markov Decision Processes,Mausam and Daniel S. Weld,"Typically, Markov decision problems (MDPs) assume a single action is executed per decision epoch, but in the real world one may frequently execute certain actions in parallel. This paper explores concurrent MDPs, MDPs which allow multiple non-conflicting actions to be executed simultaneously, and presents two new algorithms. Our first approach exploits two provably sound pruning rules, and thus guarantees solution optimality. Our second technique is a fast, sampling-based algorithm, which produces close-to-optimal solutions extremely quickly. Experiments show that our approaches outperform the existing algorithms producing up to two orders of magnitude speedup.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-113.pdf,
119,2004,Uncertainty,Low-cost Addition of Preferences to DTPs and TCSPs,Bart Peintner and Martha E. Pollack,"We present an efficient approach to adding soft constraints, in the form of preferences, to Disjunctive Temporal Problems (DTPs) and their subclass Temporal Constraint Satisfaction Problems (TCSPs). Specifically, we describe an algorithm for checking the consistency of and finding optimal solutions to such problems. The algorithm borrows concepts from previous algorithms for solving TCSPs and Simple Temporal Problems with Preferences (STPPs), in both cases using techniques for projecting and solving component sub-problems. We show that adding preferences to DTPs and TCSPs requires only slightly more time than corresponding algorithms for TCSPs and DTPs without preferences. Thus, for problems where DTPs and TCSPs make sense, adding preferences provides a substantial gain in expressiveness for a marginal cost.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-114.pdf,
120,2004,Uncertainty,mCP Nets: Representing and Reasoning with Preferences of Multiple Agents,"F. Rossi, K. B. Venable, and T. Walsh","We introduce mCP nets, an extension of the CP net formalism to model and handle the qualitative and conditional preferences of multiple agents. We give a number of different semantics for reasoning with mCP nets. The semantics are all based on the idea of individual agents voting. We describe how to test optimality and preference ordering within a mCP net, and we give complexity results for such tasks. We also discuss whether the voting schemes fairly combine together the preferences of the individual agents.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-115.pdf,
121,2004,Uncertainty,Extending CP-Nets with Stronger Conditional Preference Statements,Nic Wilson,"A logic of conditional preferences is defined, with a language which allows the compact representation of certain kinds of conditional preference statements, a semantics and a proof theory. CP-nets can be expressed in this language, and the semantics and proof theory generalise those of CP-nets. Despite being substantially more expressive, the formalism maintains important properties of CP-nets; there are simple sufficient conditions for consistency, and, under these conditions, optimal outcomes can be efficiently generated. It is also then easy to find a total order on outcomes which extends the conditional preference order, and an approach to constrained optimisation can be used which generalises a natural approach for CP-nets. Some results regarding the expressive power of CP-nets are also given.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-116.pdf,
122,2004,Uncertainty,Solving Generalized Semi-Markov Decision Processes Using Continuous Phase-Type Distributions,Håkan L. S. Younes and Reid G. Simmons,"We consider a general model of stochastic discrete event systems with asynchronous events, and propose to develop efficient algorithms for verification and control of such systems.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-117.pdf,
123,2004,User Modeling,Exploring More Realistic Evaluation Measures for Collaborative Filtering,Giuseppe Carenini and Rita Sharma,"Collaborative filtering is a popular technique for recommending items to people. Several methods for collaborative filtering have been proposed in the literature and the quality of their predictions compared in empirical studies. In this paper, we argue that the measures of quality used in these studies are based on rather simple assumptions. We propose and apply additional measures for comparing the effectiveness of collaborative filtering methods which are grounded in decision-theory.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-118.pdf,
124,2004,User Modeling,Mining Opinion Features in Customer Reviews,Minqing Hu and Bing Liu,"It is a common practice that merchants selling products on the Web ask their customers to review the products and associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds. This makes it difficult for a potential customer to read them in order to make a decision on whether to buy the product. In this project, we aim to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we are only interested in the specific features of the product that customers have opinions on and also whether the opinions are positive or negative. We do not summarize the reviews by selecting or rewriting a subset of the original sentences from the reviews to capture their main points as in the classic text summarization. In this paper, we only focus on mining opinion/product features that the reviewers have commented on. A number of techniques are presented to mine such features. Our experimental results show that these techniques are highly effective.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-119.pdf,
125,2004,User Modeling,Just How Mad Are You? Finding Strong and Weak Opinion Clauses,"Theresa Wilson, Janyce Wiebe, and Rebecca Hwa","There has been a recent swell of interest in the automatic identification and extraction of opinions and emotions in text. In this paper, we present the first experimental results classifying the strength of opinions and other types of subjectivity and classifying the subjectivity of deeply nested clauses. We use a wide range of features, including new syntactic features developed for opinion recognition. In 10-fold cross-validation experiments using support vector regression, we achieve improvements in mean-squared error over baseline ranging from 57% to 64%.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-120.pdf,
126,2004,Student Abstracts,A Correspondence Metric for Imitation,R. Amit and Maja Mataric,"Learning by imitation is a powerful form of learning. Different forms of imitation, like mimicry, copying, response facilitation, etc. have been studied extensively. Recent research in robotics has begun to explore imitation as a means to allow complex robots, like humanoid robots, acquire new skills. One of the key issues in imitation learning is the correspondence problem. This problem concerns the answer to the question: what action sequence of the imitator is similar to that of the demonstrator and how similar it is? The notion of “similarity” has remained subjective thus far. Robotics research in imitation has mostly focussed on action learning and classification, and not on the correspondence problem. Our aim is to develop a generalized metric that provides a scalar measure of dissimilarity/distance between any given pair of action sequences. This, we expect would be a uniform means to evaluate imitation in agents. The metric can also be used as a part of the action selection mechanism in an imitator agent.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-121.pdf,
127,2004,Student Abstracts,Fuzzy Induction in Dynamic User Profiling for Information Filtering,Rafal A. Angryk and Costin Barbu,"In this paper we investigate the role of the user profile in information filtering and we introduce a novel algorithm for learning the user profile based on user’s initial profile and on a queries’ interpretation using fuzzy generalization. Thousands of documents are usually retrieved by search engines for a given query during an information search on WWW. One way to prune irrelevant documents is to take advantage of the user’s implicit interests to filter the documents returned by the search engine, or to reformulate the query based on these interests.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-122.pdf,
128,2004,Student Abstracts,Semantically Guiding a First-Order Theorem Prover with a Soft Model,Arnold Binas and John Slaney,"Various versions of our first-order logic theorem prover SCOTT have been developed over the past decade to employ the concept of semantic guidance for improving the underlying system OTTER by McCune. We introduce our latest attempt to speed up OTTER’s proof search, Softie. While the various SCOTTs consulted an ordinary constraint solver to gain information about the problem to be solved, Softie is implemented from scratch and uses a solver capable of handling soft constraints.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-123.pdf,
129,2004,Student Abstracts,Metrics for Finite Markov Decision Processes,"Norm Ferns, Prakash Panangaden, and Doina Precup","The notion of equivalence for stochastic processes is problematic because it requires that the transition probabilities agree exactly. This is not a robust concept, especially considering that usually, the numbers used in probabilistic models come from experimentation or are approximate estimates; what is needed is a quantitative notion of equivalence. In our work we provide such a notion via semimetrics distance functions on the state space that assign distance quantifying “how equivalent” states are. These semimetrics could potentially be used as a new theoretical tool to analyze current state compression algorithms for MDPs, or in practice to guide state aggregation directly. The ultimate goal of this research is to efficiently compress and analyze continuous state space MDPs. Here we focus on finite MDPs, but note that most of our results should hold, with slight modifications, in the context of continuous state spaces.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-124.pdf,
130,2004,Student Abstracts,Robust Solutions for Constraint Satisfaction and Optimization,Emmanuel Hebrard,"Supersolutions are solutions in which, if a small number of variables lose their values, we are guaranteed to be able to repair the solution with only a few changes. In this paper, we stress the need to extend the super solution framework along several dimensions to make it more useful practically. We demonstrate the usefulness of those extensions on an example from jobshop scheduling, an optimization problem solved through constraint satisfaction. In such a case there is indeed a trade-off between optimality and robustness, however robustness may be increased without sacrificing optimality.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-125.pdf,
131,2004,Student Abstracts,Generation of Emotional Behavior for Non-Player Characters — Development of EmoBot for Quake II,"Tye Hooley, Burt Hunking, Mike Henry, and Atsushi Inoue","EmoBot fabricates emotional behavior with fuzzy logic in the extended logic programming language: FRIL — Fuzzy Relational Inference Language (Baldwin, et. al. 1995). The deployment of fuzzy logic is primarily justified by the fuzziness of personality, and its great success in control applications analogous to EmoBot tasks.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-126.pdf,
132,2004,Student Abstracts,Knowledge State Reconsideration: Hindsight Belief Revision,Frances L. Johnson and Stuart C. Shapiro,"As a knowledge representation and reasoning (KRR) system gathers and reasons about information, it has to update its belief space to maintain consistency. Some belief change operations it can perform include expansion (addition with no consistency checking), contraction (aka removal or retraction), revision (consistent prioritized addition), and consolidation (elimination of any and all inconsistencies). Whether belief change operations are performed on theories or bases, with ideal agents or those that are resource-bounded, there is no doubt that the order of operations typically affects the makeup of the resulting belief base. If a KRR system gains new information that, in hindsight, might have altered the outcome of an earlier belief change decision, the earlier decision should be re-examined. We call this operation reconsideration, and the result is an optimal belief base regardless of the order of previous belief change operations.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-127.pdf,
133,2004,Student Abstracts,Utilizing Internal State in Multi-Robot Coordination Tasks,Chris Jones and Maja J. Mataric,"In this paper, we present a principled framework suitable for describing and reasoning about the intertwined entities involved in any task-achieving multi-robot system -- the task environment, task definition, and the capabilities of the robots themselves. Using this framework, we present a systematic procedure by which to synthesize controllers for robots in a multi-robot system such that a given sequential task is correctly executed.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-128.pdf,
134,2004,Student Abstracts,Generating “Random” 3-SAT Instances with Specific Solution Space Structure,"Pushkin R. Pari, Jane Lin, Lin Yuan, and Gang Qu","Generating good benchmarks is important for the evaluation and improvement of any algorithm for NP-hard problems such as the Boolean satisfiability (SAT) problem. Carefully designed benchmarks are also helpful in the study of the nature of NP-completeness . Probably the most well-known and successful story is the discovery of the phase transition phenomenon (Cheeseman, Kanefsky, and Taylor 1991). More recently, (Achlioptas et al. 2000) pointed out the importance of generating satisfiable problem instances. In this abstract, we consider how to create 3-SAT formulas that look like random but with specific solution structures. In particular, we show that random 3-SAT formulas do not have their solutions distributed randomly in the solution space and we further develop generators to build random 3-SAT formulas with randomly distributed solutions or fixed number of solutions.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-129.pdf,
135,2004,Student Abstracts,Occam’s Razor and a Non-Syntactic Measure of Decision Tree Complexity,Goutam Paul,"Occam’s razor, attributed to the fourteenth century English philosopher William of Occam, states: “plurality should not be assumed without necessity.” The machine learning interpretation of Occam’s razor is that if two models have the same performance on the training set, choose the simpler. Decision tree learning widely uses Occam’s razor. Popular decision tree generating algorithms are based on information gain criterion which inherently prefers shorter trees (Mitchel 1997). Furthermore, decision tree pruning is common regardless of the splitting criterion. Experiments suggest that shorter trees indeed have better generalization accuracy (GA), typically estimated by a validation set prediction accuracy. However, some case studies show evidence apparently against Occam’s razor. Recently, Webb (1996) has built C4.5X, a version of C4.5 decision tree classifier (Quinlan 1993) with a postprocessor, which adds more nodes and branches to the tree generated by basic C4.5. He showed that though C4.5 and C4.5X have identical training set accuracies, the generalization accuracy over some datasets is better for C4.5X. But Webb’s argument is based on the traditional syntactic complexity measure (number of nodes) of decision trees. In this paper, we explore a non-syntactic measure of decision tree complexity using the notion of Kolmogorov Complexity (Kolmogorov 1965) and show that in this measure the complexity of C4.5X tree is less than that of C4.5 tree on average. Hence, according to our measure of complexity, C4.5X does not violate Occam’s razor.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-130.pdf,
136,2004,Student Abstracts,Discriminating Among Word Meanings by Identifying Similar Contexts,Amruta Purandare and Ted Pedersen,"Word sense discrimination is an unsupervised clustering problem, which seeks to discover which instances of a word/s are used in the same meaning. This is done strictly based on information found in raw corpora, without using any sense tagged text or other existing knowledge sources. Our particular focus is to systematically compare the efficacy of a range of lexical features, context representations, and clustering algorithms when applied to this problem.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-131.pdf,
137,2004,Student Abstracts,A Bayes Net Approach to Argumentation,Sabyasachi Saha and Sandip Sen,Argumentation-based negotiation approaches have been proposed to present realistic negotiation contexts. This paper presents a novel Bayesian network based argumentation and decision making framework that allows agents to utilize models of other agents. Our goal is to use Bayesian networks to capture the opponent model through an incremental learning process and use the model to generate more effective arguments to convince the opponent to accept favorable contracts.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-132.pdf,
138,2004,Student Abstracts,Identifying an Object that is Perceptually Indistinguishable from One Previously Perceived,John F. Santore and Stuart C. Shapiro,"People often encounter objects that are perceptually indistinguishable from objects that they have seen before. When this happens, how do they decide whether the object they are looking at is something never before seen, or if it is the same one they encountered before? To identify these objects people surely use background knowledge and contextual cues. We propose a computational theory of identifying perceptually indistinguishable objects (PIOs) based on a set of experiments which were designed to identify the knowledge and perceptual cues that people use to identify PIOs. By identifying a PIO, we mean deciding which individual object is encountered, not deciding what category of objects it belongs to. In particular, identifying a PIO means deciding if the object just encountered is a new, never before seen object, or if it has been previously encountered, which previously perceived object it is. Our agent’s beliefs and reasoning are based on an intensional representation. Intensional representations model the sense of an object rather than the object referent, itself. The terms of our representation language, SNePS, denote mental entities. Some such entities are propositions; others are abstract ideas; others are the agent’s “concepts” or “ideas” of objects in the world. This is important for the task of identifying PIOs, because before the identification task is complete, the agent may have two mental entities, e1 and e2, that it might or might not conclude correspond to the same object in the world.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-133.pdf,
139,2004,Student Abstracts,Evaluating Consistency Algorithms for Temporal Metric Constraints,"Yang Shi, Anagh Lal, and Berthe Y. Choueiry",We study propagation mechanisms in networks of metric temporal constraints. We compare the performance of some known algorithms for solving the Simple Temporal Problem (STP) and the Temporal Constraint Satisfaction Problem (TCSP).,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-134.pdf,
140,2004,Student Abstracts,Mixed-Initiative Workflow Composition,Marc Spraragen,"Complex applications in many areas, including scientific computations and business-related systems, are represented as computational workflows composed out of multiple components. There are several approaches that help a user compose these workflows. Some composition systems implement a user-system interactive approach. These systems are useful for expressing user preferences during composition; however, they can be tedious to use if a large number of tasks are needed in the workflow, as composition is done one step at a time, manually. Another approach to workflow composition is full automation, which aims to eliminate unnecessary user interaction during composition. This approach is efficient, but is not ideal if user preferences need to be expressed during composition. Our approach combines the strengths of manual and automatic approaches into mixed-initiative workflow composition. This combined approach uses automated planning techniques, while also incorporating user preferences during composition. Our approach is implemented in a new system, AutoCAT, by combining an interactive workflow editor (Composition Analysis Tool or CAT) and a planner, Prodigy.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-135.pdf,
141,2004,Student Abstracts,Mobile Agent-Based Search for Service Discovery on Dynamic Peer-to-Peer Networks,Evan A. Sultanik,No fixed memory deterministic algorithm can locate a service in a network in a fixed amount of time. We propose a fixed-memory randomized method for approximating the location of a service in a dynamic network with a probabilistic certainty in a fixed amount of time.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-136.pdf,
142,2004,Student Abstracts,Finding Redundant Constraints for FSM Minimization,"Lin Yuan, Pushkin R. Pari, and Gang Qu","Finite state machine (FSM) is a computation model that consists of a finite set of states, a start state, an input alphabet, and a transition function that defines the next state and/or outputs based on the current state and input symbols. Finding an equivalent FSMwith minimal number of states is generally referred as state minimization or state reduction (SR) problem. State minimization is an effective approach in logic synthesis to optimize sequential circuit design in terms of area and power(Kam, 1997). The SR problem of FSM is NP-complete and can be treated as a special case of the Constraint Satisfaction Problem(CSP) where the transition function defines all the constraints that need to be satisfied. Interestingly, we observe that not all the constraints are required to obtain a given SR solution. Identifying the redundancy in the FSM will be useful in the following occasions. First, it helps to understand the nature of the NP-complete SR problem and to build FSM benchmarks to test the effectiveness of SR solvers. Second, the redundancy can be utilized to hide information and thus provide security protection to the FSM. Simulation results on real life FSMs reveal the existence of extremely rich redundancy.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-137.pdf,
143,2004,SIGART/AAAI Doctoral Consortium,Semi-Supervised Clustering with Limited Background Knowledge,Sugato Basu,"In many machine learning domains, there is a large supply of unlabeled data but limited labeled data, which can be expensive to generate. Consequently, semi-supervised learning, learning from a combination of both labeled and unlabeled data, has become a topic of significant recent interest. Our research focus is on semi-supervised clustering, which uses a small amount of supervised data in the form of class labels or pairwise constraints on some examples to aid unsupervised clustering. Semi-supervised clustering can be either constraint-based, i.e., changes are made to the clustering objective to satisfy user-specified labels/constraints, or metricbased, i.e., the clustering distortion measure is trained to satisfy the given labels/constraints. Our main goal in this thesis is to study constraint-based semi-supervised clustering algorithms, integrate them with metric-based approaches, characterize some of their properties and empirically validate our algorithms on different domains, e.g., text processing and bioinformatics.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-138.pdf,
144,2004,SIGART/AAAI Doctoral Consortium,Learnable Similarity Functions and their Applications to Clustering and Record Linkage,Mikhail Bilenko,"Many problems in machine learning and data mining depend on distance estimates between observations, e.g., instance-based classification, clustering, information retrieval, and record linkage in databases. However, the appropriate notion of similarity can vary depending on the particular domain, dataset, or task at hand. Consequently, a large number of functions that compute similarity between objects have been developed for different data types, varying greatly in their expressiveness, mathematical properties, and assumptions. Additionally, there exists a substantial body of research on feature space transformations that attempt to provide a more salient representation of data than the original feature space, e.g. Principal Component Analysis and Locally Linear Embedding. All of these techniques make certain assumptions about the optimal representation of data and its influence on computing similarity which may or may not be applicable for specific datasets and tasks. Therefore, it is desirable to learn accurate similarity functions from training data to capture the correct notion of distance for a particular task at hand in a given domain. Recently, several approaches have been suggested for training such functions using pairwise relations between instances, e.g. pairwise equivalence, common cluster membership, and relative comparisons. These approaches have shown improvements over traditional similarity functions for different data types such as vectors in Euclidean space, strings, and database records composed of multiple text fields. While these initial results are encouraging, there still remains a large number of similarity functions that are currently unable to adapt to a particular domain. In our research, we attempt to bridge this gap by developing both new learnable similarity functions and methods for their application to particular problems in machine learning and data mining.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-139.pdf,
145,2004,SIGART/AAAI Doctoral Consortium,Flexible Decision-Making in Sequential Auctions,Gangshu Cai,"I develop a multi-dimensional sequential auction design space based on Wurman, et al.’s classification, which includes three dimensions: bidding rules, clearing policy, and information revelation policy. The flexible decision-making system is designed to automatically generate strategies for different models with a specification of the parameters. In next section, I present an approach to generate strategies for sequential auctions with discrete strategy spaces. In the following section, I provide two conjectures and discuss an algorithm to compute strategies for sequential auctions with continuous strategy spaces.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-140.pdf,
146,2004,SIGART/AAAI Doctoral Consortium,A Framework for Optimal Sequential Planning in Multiagent Settings,Prashant J. Doshi,"In this thesis, we present a new framework called Interactive POMDPS (I-POMDPs) for optimal planning by an agent interacting with other autonomous agents in a sequential environment and maximizing its reward that depends on joint actions of all agents.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-141.pdf,
147,2004,SIGART/AAAI Doctoral Consortium,User-Sensitive Text Summarization,Noemie Elhadad,"In mythesis, I investigate strategies to take user characteristics into account in the summarization process. Acquiring a user model is by itself a wide subject of research. I do not focus on ways to acquire a user model, and I assume that there is an existing user model in my framework. Rather, my focus is on the challenges entailed in incorporating knowledge about the user into summarization strategies and providing the user with a text relevant to his needs.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-142.pdf,
148,2004,SIGART/AAAI Doctoral Consortium,Connecting Cognitive and Physical Worlds with Dynamic Cost Function Definition,Jamie Lennon,Our goal is to mesh the symbolic reasoning capabilities of a cognitive model with the constrained optimization possibilities inherent in optimal controls. We plan to develop and test such a system for several different dynamical models in environments of differing uncertainty and differing efficiency requirements.,https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-143.pdf,
149,2004,SIGART/AAAI Doctoral Consortium,Interesting Instance Discovery in Multi-Relational Data,Shou-de Lin,"Thegeneral area of machine discovery focuses on methods to use computers to perform or assist discovery tasks. Herbert Simon described it as ""gradual problemsolving processes of searching large problem spaces for incompletely defined goal objects."" Today machine discovery research falls into two major categories, scientific discovery and knowledge discovery and data mining (KDD). In this paper we propose a new research direction that lies somewhere in-between these two trends: we call it interesting instance discovery (IID) which aims at discovering interesting instances in large, multi-relational datasets.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-144.pdf,
150,2004,SIGART/AAAI Doctoral Consortium,Adaptive Algorithms for Routing and Traffic Engineering in Stochastic Networks,Sudip Misra and B. John Oommen,"In this paper we report some of the research endeavors we are embarking on as part of the Doctoral research of the first author. We have already completed an investigation of some of the existing algorithms in the areas of Network Routing and Traffic Engineering, and we propose superior algorithms that would adapt to the changes in the environment in which they operate. In this attempt, we intend to use the theory of Learning Automata (LA) (Narendra and Thathachar, 1989; Obaidat et al. 2002) to address the problems we are investigating.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-145.pdf,
151,2004,SIGART/AAAI Doctoral Consortium,Inducing Constraint-Based Grammars using a Domain Ontology,Smaranda Muresan,"This thesis presents a framework for domain specific text to-knowledge acquisition, with focus on medical domain. The main challenge of this domain is the abundance of linguistic phenomena that require both syntactic and semantic information in order to “understand” the meaning of the text, and thus to acquire knowledge. Examples include prepositional phrases, coordinations, noun-noun compounds and nominalizations, phenomena which are not well covered by existing syntactic or semantic parsers.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-146.pdf,
152,2004,SIGART/AAAI Doctoral Consortium,Capturing User Intent for Information Retrieval,Hien Nguyen,"We study the problem of employing a cognitive user model for information retrieval in which knowledge about a user is captured and used for improving retrieval performance and user satisfaction. In this proposed research, we improve retrieval performance and user satisfaction for information retrieval by building a user model to capture user intent dynamically through analyzing behavioral information from retrieved relevant documents, and by combining captured user intent with the elements of an information retrieval system. We use decision theoretic principles and bayesian networks for building this model. The novelties of our approach lie with the fine-grained representation of the model, the ability to learn user knowledge incrementally and dynamically, the integration of user intent and system elements for improving retrieval performance and the unified evaluation framework to assess the accuracy of user intent captured and effectiveness of our model.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-147.pdf,
153,2004,SIGART/AAAI Doctoral Consortium,A Metric for the Evaluation of Imitation,Amit Ramesh,"Learning by imitation and learning from demonstration have recently received considerable attention in robotics. However, very little research has been in the direction of providing a quantitative measure of the quality of imitation. We are interested in developing a generalized comprehensive metric that provides a scalar measure of dissimilarity/distance between any pair of action sequences. By developing such a metric, we intend to provide a standardized means to quantitatively evaluate imitation.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-148.pdf,
154,2004,SIGART/AAAI Doctoral Consortium,Planning and Verification for Stochastic Processes with Asynchronous Events,Håkan L. S. Younes,"We consider a general model of stochastic discrete event systems with asynchronous events, and propose to develop efficient algorithms for verification and control of such systems.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-149.pdf,
155,2004,Intelligent Systems Demonstrations,Intelligent Systems Demonstration: The Secure Wireless Agent Testbed (SWAT),"Gustave Anderson, Andrew Burnheimer, Vincent Cicirello, David Dorsey, Saturnino Garcia, Moshe Kam, Joseph Kopena, Kris Malfettone, Andy Mroczkowski, Gaurav Naik, Max Peysakhov, William Regli, Joshua Shaffer, Evan Sultanik, Kenneth Tsang, Leonardo Urbano, Kyle Usbeck, and Jacob Warren","We will demonstrate the Secure Wireless Agent Testbed (SWAT), a unique facility developed at Drexel University to study integration, networking and information assurance for next-generation wireless mobile agent systems. SWAT is an implemented system that fully integrates: (1) mobile agents, (2) wireless ad hoc multi-hop networks, and (3) security. The demonstration will show the functionality of a number of decentralized agent-based applications, including applications for authentication, collaboration, messaging, and remote sensor monitoring. The demonstration will take place on a live mobile ad hoc network consisting of approximately a dozen nodes (PDAs, tablet PCs, and laptops) and hundreds of mobile software agents.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-150.pdf,
156,2004,Intelligent Systems Demonstrations,"Multi-Agent System Development: Design, Runtime, and Analysis","K. S. Barber, J. Ahn, K. Fullam, T. Graser, N. Gujral, D. C. Han, D. N. Lam, R. McKay, J. Park, and M. Vanzin","Dynamic and unexpected events are defining characteristics of numerous application domains. These environments often require decision-makers to solve many problems with insufficient time and resources. To effectively assess options, decision-makers require situation analysis and decision-support tools that model the dynamism of these environments to make rapid, robust decisions. Autonomous agents and multi-agent systems satisfy these requirements for decision-making in dynamic environments. Developing a multi-agent system (MAS) is a challenging task, considering sophisticated agent interactions and uncertain environmental dynamics and domain requirements. This demonstration addresses the comprehensive development process for multi-agent systems; illustrating tools for the initial design of the agent system, the capabilities encoded in the individual agents, and analysis tools that enhance developer comprehension of system behavior.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-151.pdf,
157,2004,Intelligent Systems Demonstrations,Visual Odometry Using Commodity Optical Flow,"Jason Campbell, Rahul Sukthankar, and Illah Nourbakhsh","A wide variety of techniques for visual navigation using robot-mounted cameras have been described over the past several decades, yet adoption of optical flow navigation techniques has been slow. This demo illustrates what visual navigation has to offer: robust hazard detection (including precipices and obstacles), high-accuracy open-loop odometry, and stable closed-loop motion control implemented via an optical flow based visual odometry system. This work is based on (1) open source vision code, (2) common computing hardware, and (3) inexpensive, consumer-quality cameras, and as such should be accessible to many robot builders.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-152.pdf,
158,2004,Intelligent Systems Demonstrations,Engineering Open Multi-Agent Systems as Electronic Institutions,"M. Esteva, D. de la Cruz, B. Rosell, J. Ll. Arcos, J. A. Rodríguez-Aguilar, and G. Cuní","In this demo we focus on the engineering of open multi-agent systems as electronic institutions. Electronic institutions are a formalism to define the rules which structure agent interactions, establishing what agents are permitted and forbidden to do. We present a set of tools that support the specification, analysis and execution of institutions, as well as the implementation of agents. Our methodology allows for a successive refinement approach to multi-agent systems engineering.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-153.pdf,
159,2004,Intelligent Systems Demonstrations,iBundler: An Agent-Based Decision Support Service for Combinatorial Negotiations,"A. Giovannucci, J. A. Rodríguez-Aguilar, Jésus Cerquides, A. Reyes, and F. X. Noria","Negotiation events in industrial procurement involving multiple, highly customisable goods pose serious challenges to buying agents when trying to determine the best set of providing agents’ offers. Typically, a buying agent’s decision involves a large variety of constraints that may involve attributes of a very same item as well as attributes of multiple items. In this paper we describe iBundler, an agent-aware negotiation service to solve the winner determination problem considering buyers’ and providers’ constraints and preferences.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-154.pdf,
160,2004,Intelligent Systems Demonstrations,Domain-Independent Reason-Enhanced Controller for Task-ORiented Systems — DIRECTOR,"Darsana P. Josyula, Michael L. Anderson, and Don Perlis","We are developing a perturbation tolerant, domain independent interfacing agent by modeling the beliefs, desires, intentions, expectations and achievements of the agent. The current version of the agent has been successfully integrated with and tested on six different TOSs.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-155.pdf,
161,2004,Intelligent Systems Demonstrations,Agent-Based Modeling with Social Networks for Terrorist Recruitment,Teresa H. Ko and Nina M. Berry,"The Seldon model combines concepts from agent-based modeling and social network analysis to create a computation model of social dynamics for terrorist recruitment. The underlying recruitment model is based on a unique hybrid agent-based architecture that contains simple agents (individuals such as expatriates) and abstract agents (conceptual entities such as society and mosques). Interactions between agents are determined by multiple social networks which form and dissipate according to the actions of the individual. We have implemented a Java-based toolkit to evaluate the dynamics of social behavior and the specific dynamics associated with terrorist recruitment described by expert social scientists, creating an architecture for simple adaptation to other group phenomenon.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-156.pdf,
162,2004,Intelligent Systems Demonstrations,Mobile Emergency Triage Support System,"Wojtek Michalowski, Roman Slowinski, and Szymon Wilk","We are designing and developing a mobile clinical decision support system, known as MET (Mobile Emergency Triage), for supporting emergency triage of different types of acute pain presentations. MET needs to interact with an existing hospital information system, run on handheld computing devices and be suitable for operation in weak connectivity conditions (with unstable connections between mobile clients and a server). The MET system captures necessary hospital data, allows for patients’ data entry and provides triage support. By operating on handheld computers, it fits to the regular clinical workflow without introducing any hindrances and disruptions. It supports triage anytime and anywhere, directly at the point of care, and can be used as an electronic patient chart that facilitates structured data collection.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-157.pdf,
163,2004,Intelligent Systems Demonstrations,CMRadar: A Personal Assistant Agent for Calendar Management,"Pragnesh Jay Modi, Manuela Veloso, Stephen F. Smith, and Jean Oh","One of the more compelling visions for agents research is the development of “personal assistant agents” that are tasked with making people and organizations more efficient by autonomously handling routine tasks on behalf of their users. Most recently, several researchers including ourselves have embarked on a large research project, called The Radar Project, whose overall goal is to develop a personalized agent that is able to assist its user in a wide range of everyday tasks. Within this larger project, we are concerned with the more focused task of managing a user’s calendar. While isolated aspects of calendar management have been investigated before, in this paper, we present CMRadar, a complete agent with capabilities ranging across the full spectrum of calendar management, from natural language processing of incoming scheduling-related emails, to making autonomous scheduling decisions, to negotiating with other users, to user interfacing and visualization. Although many research issues remain, we believe CMRadar is the first end-to-end agent for automated calendar management.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-158.pdf,
164,2004,Intelligent Systems Demonstrations,Centibots: Very Large Scale Distributed Robotic Teams,"Charlie Ortiz, Kurt Konolige, Regis Vincent, Benoit Morisset, Andrew Agno, Michael Eriksen, Dieter Fox, Benson Limketkai, Jonathan Ko, Benjamin Steward, and Dirk Schulz","In this paper, we describe the development of Centibots, a framework for very large teams of robots that are able to perceive, explore, plan and collaborate in unknown environments. Teams consist of approximately 100 robots which can be deployed in unexplored areas and which can efficiently distribute tasks among themselves; the system also makes use of a mixed initiative mode of interaction in which a user can easily influence missions as necessary. In contrast to simulation-based systems which abstract away aspects of the environment for examining component technologies, our design reflects an integrated, end-to-end system.Fex",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-159.pdf,
165,2004,Intelligent Systems Demonstrations,WordNet::Similarity — Measuring the Relatedness of Concepts,"Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi","WordNet::Similarity is a freely available software package that makes it possible to measure the semantic similarity or relatedness between a pair of concepts (or word senses). It provides six measures of similarity, and three measures of relatedness, all of which are based on the lexical database WordNet. These measures are implemented as Perl modules which take as input two concepts, and return a numeric value that represents the degree to which they are similar or related.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-160.pdf,
166,2004,Intelligent Systems Demonstrations,PRECISE on ATIS: Semantic Tractability and Experimental Results,"Ana-Maria Popescu, Alex Armanasu, Oren Etzioni, David Ko, and Alexander Yates","The need for Natural Language Interfaces to databases (NLIs) has become increasingly acute as more and more people access information through their web browsers, PDAs, and cell phones. Yet NLIs are only usable if they map natural language questions to SQL queries correctly — people are unwilling to trade reliable and predictable user interfaces for intelligent but unreliable ones. We describe a reliable NLI, PRECISE, that incorporates a modern statistical paser and a semantic module. PRECISE provably handles a large class of natural language questions correctly. On the benchmark ATIS data set, PRECISE achieves 93.8% accuracy.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-161.pdf,
167,2004,Intelligent Systems Demonstrations,"SEM-Ether: Semantic Web Based Pervasive Computing Framework — Integrating Web, Devices and People","Sushil Puradkar, Sachin Singh, Chintan Patel, Kartik Vishwanath, Rahul Gupta, and Yugyung Lee","Pervasive computing aims to build an aggregated environment around a user by knitting diverse computing and communicating devices and software services into a single homogeneous unit. Our work is to develop a Pervasive computing framework which harnesses the power of Semantic Web and Web Services, facilitating the development of effective and intelligent Pervasive environments. This paper presents a high level view of the framework and how different Pervasive services can be built on this framework",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-162.pdf,
168,2004,Intelligent Systems Demonstrations,SenseClusters — Finding Clusters that Represent Word Senses,Amruta Purandare and Ted Pedersen,"SenseClusters is a freely available word sense discrimination system that takes a purely unsupervised clustering approach. It uses no knowledge other than what is available in a raw unstructured corpus, and clusters instances of a given target word based only on their mutual contextual similarities. It is a complete system that provides support for feature selection from large corpora, several different context representation schemes, various clustering algorithms, and evaluation of the discovered clusters.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-163.pdf,
169,2004,Intelligent Systems Demonstrations,CAMEO: Modeling Human Activity in Formal Meeting Situations,"Paul E. Rybski, Fernando de la Torre, Raju Patil, Carlos Vallespi, Manuela Veloso, and Brett Browning","We present CAMEO, the Camera Assisted Meeting Event Observer, which is a physical awareness system designed for use by an agent-based electronic assistant. CAMEO is used to observe formal meeting environments and infer the activities of people attending them.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-164.pdf,
170,2004,Intelligent Systems Demonstrations,A Robotic Model of Human Reference Resolution,"Matthias Scheutz, Virgil Andronache, and Kathleen Eberhard","Evidence from psychology suggests that humans process definite descriptions that refer to objects present in a visual scene incrementally upon hearing them, rather than constructing explicit parse trees after the whole sentence was said, which are then used to determine the referents. In this paper, we describe a real-time distributed robotic architectures for human reference resolution that demonstrates various interactions of auditory, visual, and semantic processing components hypothesized to underlie human processes.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-165.pdf,
171,2004,Intelligent Systems Demonstrations,SCoT: A Spoken Conversational Tutor,"Karl Schultz, Brady Clark, Heather Pon-Barry, Elizabeth Owen Bratt, and Stanley Peters","We describe SCoT, a Spoken Conversational Tutor, which has been implemented in order to investigate the advantages of natural language in tutoring, especially spoken language. SCoT uses a generic architecture for conversational intelligence which has capabilities such as turn management and coordination of multi-modal input and output. SCoT also includes a set of domain independent tutorial recipes, a domain specific production-rule knowledge base, and many natural language components including a bi-directional grammar, a speech recognizer, and a text-to-speech synthesizer. SCoT leads a reflective tutorial discussion based on the details of a problem solving session with a real-time Navy shipboard damage control simulator. The tutor attempts to identify and remediate gaps in the student’s understanding of damage control doctrine by decomposing its tutorial goals into dialogue acts, which are then acted on by the dialogue manager to facilitate the conversation.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-166.pdf,
172,2004,Intelligent Systems Demonstrations,Intelligent Agents for Coalition Search and Rescue Task Support,"Austin Tate, Jeff Dalton, Clauirton de Siebra, Stuart Aitken, Jeffrey M. Bradshaw, and Andrzej Uszok","The Coalition Search and Rescue Task Support demonstration shows cooperative agents supporting a highly dynamic mission in which AI task planning, inter-agent collaboration, workflow enactment, policy-managed communications, semantic web queries, semantic web services matchmaking and knowledge-based notifications are employed.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-167.pdf,
173,2004,Intelligent Systems Demonstrations,The Autonomous Sciencecraft Experiment Onboard the EO-1 Spacecraft,"Daniel Tran, Steve Chien, Rob Sherwood, Rebecca Castano, Benjamin Cichy, Ashley Davies, and Gregg Rabideau","The Autonomous Sciencecraft Experiment (ASE), currently flying onboard the Earth Observing-1 (EO-1) spacecraft, integrates several autonomy software technologies enabling autonomous science analysis and mission planning. The experiment demonstrates the potential for future space missions to use onboard decision-making to respond autonomously to capture short-lived science phenomena. The AAAI software demonstration will consist of two sections: a real-time display of an ASE-commanded ground contact from the EO-1 spacecraft, and a simulation of the full ASE autonomous science-response scenario.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-168.pdf,
174,2004,Intelligent Systems Demonstrations,"Online Semantic Extraction by Backpropagation Neural Network with VariousSyntactic Structure Representations",Heidi H. T. Yeung,"The sub-symbolic approach on Natural Language Processing (NLP) is one of the mainstreams in Artificial Intelligence. Indeed, we have plenty of algorithms for variations of NLP such as syntactic structure representation or lexicon classification theoretically. The goal of these researches is obviously for developing a hybrid architecture which can process natural language as what human does. Thus, we propose an online intelligent system to extract the semantics (utterance interpretation) by applying a 3-layer back propagation neural network to classify the encoded syntactic structures into corresponding semantic frame types (e.g. AGENT_ACTION_PATIENT). The results are generated dynamically according to training sets and user inputs in webpage-form. It can diminish the manipulating time while using extra tools and share the statistical results with colleagues in clear and standard forms.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-169.pdf,
175,2004,Intelligent Systems Demonstrations,Responsive Information Architect: A Context-Sensitive Multimedia Conversation Framework for Information Seeking,"Michelle Zhou, Keith Houck, Rosario Uceda-Sosa, Shimei Pan, Min Chen, Vikram Aggarwal, and James Shaw","We are building a context-sensitive framework, called Responsive Information Architect (RIA), which engages users in automatically generated multimedia conversations. Unlike existing information browsing paradigm that forces users to explore information following pre-defined paths (e.g., GUI menus), RIA allows users to express their information requests flexibly using a mixture of input modalities, including speech, text, and gesture. Using a rich context, such as conversation history and data semantics, RIA is capable of understanding user inputs, including these complex data queries.",https://aaai.org/Library/AAAI/2004/../../../Papers/AAAI/2004/AAAI04-170.pdf,
