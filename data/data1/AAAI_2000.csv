,conference_year,category,title,author,abstract,download_url,keywords
0,2000,Contents,AAAI Organization,AAAI,List of the officers and staff of AAAI in 2000.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-217.pdf,
1,2000,Contents,Outstanding Paper Award,AAAI,List of the AAAI and IAAI 2000 program committees.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-218.pdf,
2,2000,Contents,Outstanding Paper Award,AAAI,Outstanding papers from the AAAI-2000 conference.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-219.pdf,
3,2000,Contents,Sponsoring Organizations,AAAI,List of sponsors of the AAAI-2000 conference.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-220.pdf,
4,2000,Contents,Preface,Henry Kautz and Bruce Porter,Preface to the AAAI-2000 proceedings.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-216.pdf,
5,2000,Contents,Invited Talks,AAAI,Abstracts of the AAAI-2000 invited talks.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-221.pdf,
6,2000,Agents,Inter-Layer Learning Towards Emergent Cooperative Behavior,,"As applications for artificially intelligent agents increase in complexity, we can no longer rely on clever heuristics and hand-tuned behaviors to develop their programming. Even the interaction between various components cannot be reduced to simple rules, as the complexities of realistic dynamic environments become unwieldy to characterize manually. To cope with these challenges, we propose an architecture for inter-layer learning consisting of three tiers: basic skills, individual strategy, and team strategy, each of which can be constructed using machine learning techniques, incorporating the skills developed in the previous layer. Using RoboCup soccer as a testbed, we demonstrate the potential of this architecture for the development of effective, cooperative, multi-agent systems. First, individual basic skills are developed and refined in isolation through neural networks and reinforcement learning techniques, and then, the interaction between these skills at higher layers is also learned. Finally, reinforcement learning is applied to emergent cooperative behaviour between the teammates. The inter-layer learning architecture provides an explicit learning model for deciding individual and cooperative tactics in a dynamic environment and proved to be promising in real-time competition.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-001.pdf,
7,2000,Agents,Coordination Failure and Congestion in Information Networks,"A. M. Bell, NASA Ames Research Center; W. A. Sethares and J. A. Bucklew, University of Wisconsin-Madison","Coordination failure, or agents’ uncertainty about the action of other agents, may be an important source of congestion in large decentralized systems. The market entry game studied by experimental economists and the El Farol problem proposed by W. Brian Arthur provide a simple paradigm for congestion and coordination problems that may arise with over utilization of the Internet. This paper reviews the market entry game and the El Farol problem and surveys previous approaches, which typically involve complex deterministic learning algorithms that exhibit chaotic-like trajectories. This paper recasts the problem in a stochastic framework and derives a simple adaptive strategy that has intriguing optimization properties; a large collection of decentralized decision makers, each acting in their own best interests and with limited knowledge, converge to a solution that (optimally) solves a complex congestion and social coordination problem. A variation in which agents are allowed access to full information is not nearly as successful. The algorithm, which can be viewed as a kind of habit formation, is analyzed using a weak convergence approach, and simulations illustrate the major results.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-002.pdf,
8,2000,Agents,Non-Deterministic Social Laws,"Michael H. Coen, MIT Artificial Intelligence Lab","The paper generalizes the notion of a social law, the foundation of the theory of artificial social systems developed for coordinating Multi-Agent Systems. In an artificial social system, its constituent agents are given a common social law to obey and are free to act within the confines it legislates, which are carefully designed to avoid inter-agent conflict and deadlock. In this paper, we argue that social laws can be overly restrictive in that they indiscriminately apply to all distributions of agent behavior, even when the probability of conflicting conditions arising is acceptably small. We define the notion of a non-deterministic social law applicable to a family of probability distributions that describe the expected behaviors of a system’s agents. We demonstrate that taking these distributions into account can lead to the formulation of more efficient social laws and the algorithms that adhere to them. We illustrate our approach with a traffic domain problem and demonstrate its utility through an extensive series of simulations.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-003.pdf,
9,2000,Agents,Solving Combinatorial Auctions Using Stochastic Local Search,"Holger H. Hoos, University of British Columbia; Craig Boutilier, University of Toronto","Combinatorial auctions (CAs) have emerged as an important model in economics and show promise as a tool for resource allocation in AI. Unfortunately, winner determination for CAs is NP-hard and recent algorithms have difficulty with problems involving goods and bids beyond the hundreds. In this paper we apply a new stochastic local search algorithm, Casanova, to this problem. We demonstrate that it finds high quality (even optimal) solutions much faster than recently proposed methods (in many cases several orders of magnitude), particularly for large problems. In addition, we propose a logical language for naturally expressing combinatorial bids in which a single logical bid corresponds to a large (often exponential) number of explicit bids. We show that Casanova performs much better than systematic methods on such problems as well.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-004.pdf,
10,2000,Agents,A Mechanism for Group Decision Making in Collaborative Activity,"Luke Hunsberger, Harvard University; Massimo Zancanaro, ITC-irst","The SharedPlans formalization of collaboration stipulates that collaborating agents must commit to certain decision-making processes, but it does not specify those processes. This paper presents a mechanism for group decision making that may be applied to the decisions that agents involved in a SharedPlan need to make: adopting the initial commitment, selecting a recipe, assigning agents to subtasks, and identifying various action parameters. The paper thus more fully specifies the dynamic expansion of a partial SharedPlan to a more complete plan. The decision-making mechanism is represented by a fixed, fully-specified SharedPlan. A set of speech acts and conditions under which those speech acts invoke the decision-making SharedPlans are also defined. The definition of the force of declarative speech acts is based on Searle’s notion of constitutive rules.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-005.pdf,
11,2000,Agents,Cobot in LambdaMOO: A Social Statistics Agent,"Charles Lee Isbell, Jr., Michael Kearns, Dave Kormann, Satinder Singh, and Peter Stone, AT&T Shannon Labs","We describe our development of Cobot, a software agent who lives in LambdaMOO, a popular virtual world frequented by hundreds of users. We present a detailed discussion of the functionality that has made him one of the objects most frequently interacted with in LambdaMOO, human or artificial.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-006.pdf,
12,2000,Agents,Semantics of Agent Communication Languages for Group Interaction,"Sanjeev Kumar, Marcus J. Huber, David R. McGee, and Philip R. Cohen, Oregon Graduate Institute; Hector J. Levesque, University of Toronto","Group communication is the core of societal interactions. Therefore, artificial agents should be able to communicate with groups as well as individuals. However, most contem-porary agent communication languages, notably FIPA and KQML, have either no provision or no well-defined seman-tics for group communication. We give a semantics for group communication that we believe can profitably enrich the agent communication languages. In our semantics, indi-vidual communication is a special case of group communication wherein each communicating group consists of a single agent. One of the novel features of this semantics is that it allows senders to send messages even without knowing all the potential recipients of those messages -- a typical scenario in broadcast communication.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-007.pdf,
13,2000,Agents,Deliberation in Equilibrium: Bargaining in Computationally Complex Problems,"Kate Larson and Tuomas Sandholm, Washington University","We develop a normative theory of interaction - negotiation in particular - among self-interested computationally limited agents where computational actions are game-theoretically treated as part of an agent’s strategy. We focus on a 2-agent setting where each agent has an intractable individual problem, and there is a potential gain from pooling the problems, giving rise to an intractable joint problem. At any time, an agent can compute to improve its solution to its problem, its opponent’s problem, or the joint problem. At a deadline the agents then decide whether to implement the joint solution, and if so, how to divide its value (or cost). We present a fully normative model for controlling anytime algorithms where each agent has statistical performance profiles which are optimally conditioned on the problem instance as well as on the path of results of the algorithm run so far. Using this model, we analyze the perfect Bayesian equilibria of the games which differ based on whether the performance profiles are deterministic or stochastic, whether the deadline is known or not, and whether the proposer is known in advance. Finally, we present algorithms for finding the equilibria.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-008.pdf,
14,2000,Agents,An Algorithm for Multi-Unit Combinatorial Auctions,"Kevin Leyton-Brown, Yoav Shoham, and Moshe Tennenholtz, Stanford University","We present a novel algorithm to compute the winners in a combinatorial auction (CA), that is, an auction in which bidders bid for bundles of goods. Recently published algorithms are limited to single-unit CAs, already a hard computational problem. In contrast, here we address the more general problem in which there are multiple units of each good, and each bid specifies the number of units desired from each good. We prove that our branch-and-bound algorithm, which incorporates a specialized dynamic programming procedure, is correct. We then provide very encouraging initial experimental results with an implemented version of the algorithm.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-009.pdf,
15,2000,Agents,Maintainability: A Weaker Stabilizability Like Notion for High Level Control,"Mutsumi Nakamura, University of Texas at Arlington; Chitta Baral, Arizona State University; Marcus Bjäreland, Linköping University","The goal of most agents is not just to reach a goal state, but rather also (or alternatively) to put restrictions on its trajectory, in terms of states it must avoid and goals that it must maintain. This is analogous to the notions of `safety' and `stability' in the discrete event systems and temporal logic community. In this paper we argue that the notion of `stability' is too strong for formulating `maintenance' goals of an agent -- in particular, reactive and software agents, and give examples of such agents. We present a weaker notion of `maintainability' and show that our agents which do not satisfy the stability criteria, do satisfy the weaker criteria. We give algorithms to test maintainability, and also to generate control for maintainability. We then develop the notion of `supportability' that generalizes both `maintainability' and `stabilizability, develop an automata theory that distinguishes between exogenous and control actions, and develop a temporal logic based on it.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-010.pdf,
16,2000,Agents,Agent Capabilities: Extending BDI Theory,"Lin Padgham, RMIT University; Patrick Lambrix, Linköpings Universitet","This paper presents a formalisation of capabilities within the framework of beliefs, goals and intentions (BDI) and indicates how capabilities can affect agent reasoning about its intentions. We define a style of agent commitment which we refer to as a self-aware agent which allows an agent to modify its goals and intentions as its capabilities change. We also indicate which aspects of the specification of a BDI interpreter are affected by the introduction of capabilities and give some indications of additional reasoning which could be incorporated into an agent system on the basis of both the theoretical analysis and the existing implementation. The introduction of capabilities in the BDI framework has a number of advantages such as a better mapping of theory to intuition, the elimination of a mismatch between theory and actual systems, and an indication of issues and areas for further development of implemented reasoning in agent systems.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-011.pdf,
17,2000,Agents,Iterative Combinatorial Auctions: Theory and Practice,"David C. Parkes and Lyle H. Ungar, University of Pennsylvania","Combinatorial auctions, which allow agents to bid directly for bundles of resources, are necessary for optimal auction-based solutions to resource allocation problems with agents that have non-additive values for resources, such as distributed scheduling and task assignment problems. We introduce iBundle, the first iterative combinatorial auction that is optimal for a reasonable agent bidding strategy, in this case myopic best-response bidding. Its optimality is proved with a novel connection to primal-dual optimization theory. We demonstrate orders of magnitude performance improvements over the only other known optimal combinatorial auction, the Generalized Vickrey Auction.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-012.pdf,
18,2000,Agents,Preventing Strategic Manipulation in Iterative Auctions: Proxy Agents and Price-Adjustment,"David C. Parkes and Lyle H. Ungar, University of Pennsylvania","Iterative auctions have many computational advantages over sealed-bid auctions, but can present new possibilities for strategic manipulation. We propose a two-stage technique to make iterative auctions that compute optimal allocations with myopic best-response bidding strategies more robust to manipulation. First, introduce proxy bidding agents to constrain bidding strategies to (possibly untruthful) myopic best-response. Second, after the auction terminates adjust the prices towards those given in the Vickrey auction, a sealed-bid auction in which truth-revelation is optimal. We present an application of this methodology to iBundle, an iterative combinatorial auction which gives optimal allocations for myopic best-response agents.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-013.pdf,
19,2000,Agents,Improved Algorithms for Optimal Winner Determination in Combinatorial Auctions and Generalizations,"Tuomas Sandholm and Subhash Suri, Washington University","Combinatorial auctions can be used to reach efficient resource and task allocations in multiagent systems where the items are complementary. Determining the winners is NP-complete and inapproximable, but it was recently shown that optimal search algorithms do very well on average. This paper presents a more sophisticated search algorithm for optimal (and anytime) winner determination, including structural improvements that reduce search tree size, faster data structures, and optimizations at search nodes based on driving toward, identifying and solving tractable special cases. We also uncover a more general tractable special case, and design algorithms for solving it as well as for solving known tractable special cases substantially faster. We generalize combinatorial auctions to multiple units of each item, to reserve prices on singletons as well as combinations, and to combinatorial exchanges---all allowing for substitutability. Finally, we present algorithms for determining the winners in these generalizations.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-014.pdf,
20,2000,Agents,Some Tractable Combinatorial Auctions,"Moshe Tennenholtz, Technion, Israel Institute of Technology","Auctions are the most widely used strategic game-theoretic mechanism in the Internet. Auctions have been mostly studied from a game-theoretic and economic perspective, although recent work in AI and OR has been concerned with computational aspects of auctions as well. When faced from a computational perspective, combinatorial auctions are perhaps the most challenging type of auctions. Combinatorial auctions are auctions where agents may submit bids for bundles of goods. Given that finding an optimal allocation of the goods in a combinatorial auction is intractable, researchers have been concerned with exposing tractable instances of combinatorial auctions. In this work we introduce polynomial solutions for a variety of non-trivial combinatorial auctions, such as combinatorial network auctions, various sub-additive combinatorial auctions, and some restricted forms of multi-unit combinatorial auctions.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-015.pdf,
21,2000,Agents,Collective Intelligence and Braess’ Paradox,"Kagan Tumer and David Wolpert, NASA Ames Research Center","We consider the use of multi-agent systems to control network routing. Conventional approaches to this task are based on Ideal Shortest Path routing Algorithm (ISPA), under which at each moment each agent in the network sends all of its traffic down the path that will incur the lowest cost to that traffic. We demonstrate in computer experiments that due to the side-effects of one agent’s actions on another agent’s traffic, use of ISPA’s can result in large global cost. Indeed, in a simulation of Braess’ paradox we see that adding new capacity to a network with ISPA agents can decrease overall throughput. The theory of COllective INtelligence (COIN) design concerns precisely the issue of avoiding such side-effects. We use that theory to derive an idealized routing algorithm and show that a practical machine-learning-based version of this algorithm, in which costs are only imprecisely estimated substantially outperforms the ISPA, despite having access to less information than does the ISPA. In particular, this practical COIN algorithm avoids Braess’ paradox.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-016.pdf,
22,2000,Agents,Robust Combinatorial Auction Protocol against False-Name Bids,"Makoto Yokoo, Yuko Sakurai, and Shigeo Matsubara, NTT Communication Science Laboratories","This paper presents a new combinatorial auction protocol (LDS protocol) that is robust against false-name bids. Internet auctions have become an integral part of Electronic Commerce (EC) and a promising field for applying agent and Artificial Intelligence technologies. Although the Internet provides an excellent infrastructure for combinatorial auctions, we must consider the possibility of a new type of cheating, i.e., an agent tries to profit from submitting several bids under fictitious names (false-name bids). If there exists no false-name bid, the generalized Vickrey auction (G.V.A.) satisfies individual rationality, Pareto efficiency, and incentive compatibility. On the other hand, when false-name bids are possible, it is theoretically impossible for a combinatorial auction protocol to simultaneously satisfy these three properties.The LDS protocol, which is a modification of the G.V.A., utilizes reservation prices of auctioned goods for making decisions on whether to sell goods in a bundle or separately. The LDS protocol satisfies individual rationality and incentive compatibility, although it is not guaranteed to achieve a Pareto efficient social surplus. Simulation results show that the LDS protocol can achieve a better social surplus than that for a protocol that always sells goods in a bundle.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-017.pdf,
23,2000,Cognitive Modeling,Self-Organization of Innate Face Preferences: Could Genetics Be Expressed through Learning?,"James A. Bednar and Risto Miikkulainen, The University of Texas at Austin","Self-organizing models develop realistic cortical structures when given approximations of the visual environment as input, and are an effective way to model the development of face recognition abilities. However, environment-driven self-organization alone cannot account for the fact that newborn human infants will preferentially attend to face-like stimuli even immediately after birth. Recently it has been proposed that internally generated input patterns, such as those found in the developing retina and in PGO waves during REM sleep, may have the same effect on self-organization as does the external environment. Internal pattern generators constitute an efficient way to specify, develop, and maintain functionally appropriate perceptual organization. They may help express complex structures from minimal genetic information, and retain this genetic structure within a highly plastic system. Simulations with the RF-LISSOM model show that such preorganization can account for newborn face preferences, providing a computational framework for examining how genetic influences interact with experience to construct a complex system.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-018.pdf,
24,2000,Cognitive Modeling,A Self-Organizing Neural Network for Contour Integration through Synchronized Firing,"Yoonsuck Choe and Risto Miikkulainen, The University of Texas at Austin","Contour integration is believed to occur based on lateral interaction between neurons with similar orientation tuning. The exact neural mechanisms underlying such interactions, and their developmental origins, are not well understood. This paper suggests through computational simulations that synchronized firing of neurons mediated by patchy lateral connections, formed through input-driven self-organization, can serve as such a mechanism. Furthermore, we argue that different degree of such patchy connections established during development may explain why different areas of the visual field show different degrees of contour integration in psychophysical experiments.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-019.pdf,
25,2000,Cognitive Modeling,Anchoring Symbols to Sensor Data: Preliminary Report,"Silvia Coradeschi and Alessandro Saffiotti, Örebro University","Anchoring is the process of creating and maintaining the correspondence between symbols and percepts that refer to the same physical objects. Although this process must necessarily be present in any symbolic reasoning system embedded in a physical environment (e.g., an autonomous robot), no systematic study of anchoring as a clearly separated problem has been reported in the intelligent system community. In this paper, we propose a domain-independent definition of the anchoring problem, and identify its three basic functionalities: find, reacquire, and track. We illustrate our definition on two working systems in two different domains: an unmanned airborne vehicle for aerial surveillance; and a mobile robot for office navigation",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-020.pdf,
26,2000,Cognitive Modeling,Modeling Classification and Inference Learning,"Bradley C. Love and Arthur B. Markman, The University of Texas at Austin; Takashi Yamauchi, University of Pittsburgh","Human categorization research is dominated by work in classification learning. The field may be in danger of equating the classification learning paradigm with the more general phenomenon of category learning. This paper compares classification and inference learning and finds that different patterns of behavior emerge depending on which learning mode is engaged. Inference learning tends to focus subjects on the internal structure of each category, while classification learning highlights information that discriminates between the categories. The data suggest that different learning modes lead to the formation of different internal representations. SUSTAIN successfully models inference and classification learning by developing different internal representations for different learning modes. Other models do not fair as well.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-021.pdf,
27,2000,Cognitive Modeling,Reading a Robot’s Mind: A Model of Utterance Understanding Based on the Theory of Mind Mechanism,"Tetsuo Ono and Michita Imai, ATR Media Integration and Communications Research Laboratories","The purpose of this paper is to construct a methodology for smooth communications between humans and robots. Here, focus is on a mindreading mechanism, which is indispensable in human-human communications. We propose a model of utterance understanding based on this mechanism. Concretely speaking, we apply the model of a mindreading system [Baron-Cohen 96] to a model of human-robot communications. Moreover, we implement a robot interface system that applies our proposed model. Psychological experiments were carried out to explore the validity of the following hypothesis: by reading a robot’s mind, a human can estimate the robot’s intention with ease, and, moreover, the person can even understand the robot’s unclear utterances made by synthesized speech sounds. The results of the experiments statistically supported our hypothesis.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-022.pdf,
28,2000,Cognitive Modeling,Visual Event Classification via Force Dynamics,"Jeffrey Mark Siskind, NEC Research Institute, Inc.","This paper presents an implemented system that classifies simple spatial motion events, such as pick-up and put-down, from video input. Unlike previous systems which classify events based on their motion profile, this system uses changes in the state of force-dynamic relations, such as support, contact, and attachment, to distinguish between event types. This paper presents an overview of the entire system along with the details of the algorithm that recovers force-dynamic interpretations using prioritized circumscription and a stability test based on a reduction to linear programming. This paper also presents an example illustrating the end-to-end performance of the system classifying an event from video input.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-023.pdf,
29,2000,Constraint Satisfaction,Counting Models Using Connected Components,"Roberto J. Bayardo Jr., IBM Almaden Research Center; J. D. Pehoushek, M.U.S.T. Centre","Recent work by Birnbaum and Lozinskii [1999] demonstrated that a clever yet simple extension of the well-known Davis-Putnam procedure for solving instances of propositional satisfiability yields an efficient scheme for counting the number of satisfying assignments (models). We present a new extension, based on recursively identifying disconnected constraint-graph components, that substantially improves counting performance. Experiments are performed on random 3-SAT instances as well as instances from the SATLIB and Beijing benchmark suites. In addition, we show that from a structure-based perspective of worst-case complexity, counting models appears to be no harder than determining satisfiability.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-024.pdf,
30,2000,Constraint Satisfaction,DATALOG with Constraints -- An Answer-Set Programming System,"Deborah East and Miroslaw Truszczynski, University of Kentucky","Answer-set programming (ASP) has emerged recently as a viable programming paradigm well attuned to search problems in AI, constraint satisfaction and combinatorics. Propositional logic is, arguably, the simplest ASP system with an intuitive semantics supporting direct modeling of problem constraints. However, for some applications, especially those requiring that transitive closure be computed, it requires additional variables and results in large theories. Consequently, it is not a pratical computational tool for such problems. On the other hand, ASP systems based on nonmonotonic logics, such as stable logic programming, can handle transitive closure computation efficiently and, in general, often offer very concise theories as problem representations. Their semantics are, however, more complex. Searching for the middle ground, in this paper we introduce a new nonmonotonic logic, DATALOG with constraints or DC. Informally, DC theories consist of propositional clauses (constraints) and of Horn rules (DATALOG). The semantics of DC is a simple and natural extension of the semantics of the propositional logic. However, thanks to the presence of Horn rules in the system, modeling of transitive closure becomes straightforward. We describe the syntax and semantics of DC, and study its properties. We discuss an implementation of DC and present results of experimental study of the effectiveness of DC, comparing it with the CSAT satisfiability checker and SMODELS implementation of stable logic programming. Our results show that DC is competitive with the other two approaches, in the case of many search problems, yielding much more efficient solutions.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-025.pdf,
31,2000,Constraint Satisfaction,Local Search with Constraint Propagation and Conflict-Based Heuristics,"Narendra Jussien, École des Mines de Nantes; Olivier Lhomme, ILOG","In this paper, we introduce a new solving algorithm for Constraint Satisfaction Problems (CSP). It performs an overall local search together with a domain filtering technique to prune the search space. Conflicts detected during filtering are used to guide the search. First experiments with a tabu version of the algorithm have shown good results on hard instances of open shop scheduling problems. It competes well with the best highly specialized algorithms.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-026.pdf,
32,2000,Constraint Satisfaction,A Game-Theoretic Approach to Constraint Satisfaction,"Phokion G. Kolaitis, University of California, Santa Cruz; Moshe Y. Vardi, Rice University","In this paper, we shed light on the connections between different approaches to constraint satisfaction by showing that the main consistency concepts used to derive tractability results for constraint satisfaction are intimately related to certain combinatorial pebble games that were originally introduced in the context of Datalog. The crucial insight that relates pebble games to constraint satisfaction is that the key concept of strong k-consistency is equivalent to a property of winning strategies for a player called the Duplicator in the, so-called, existential k-pebble game. Furthermore, we show that strong k-consistency can be established if and only if the Duplicator wins the existential k pebble game. Moreover, whenever strong k-consistency can be established, one method for doing this is to first compute the largest winning strategy for the Duplicator in the existential k-pebble game and then modify the original problem by augmenting it with the constraints expressed by the largest winning strategy. We use this basic result to derive deeper connections between pebble games, consistency properties, and tractability of constraint satisfaction. Finally, using k-pebble games, we introduce the concept of $k$-locality and show that it constitutes a new tractable case of constraint satisfaction that properly extends the well known case in which establishing strong k-consistency implies global consistency.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-027.pdf,
33,2000,Constraint Satisfaction,Using Auxiliary Variables and Implied Constraints to Model Non-Binary Problems,"Barbara Smith, University of Leeds; Kostas Stergiou, University of Strathclyde; Toby Walsh, University of York","We perform an extensive theoretical and empirical analysis of the use of auxiliary variables and implied constraints in modelling a class of non-binary constraint satisfaction problems called problems of distance. This class of problems includes 1-d, 2-d and circular Golomb rulers. We identify a large number of different models, both binary and non-binary, and compare theoretically the level of consistency achieved by generalized arc consistency on them. Our experiments show that the introduction of auxiliary variables and implied constraints can significantly reduce the size of the search space. For instance, our final models reduce the time to find an optimal 10-mark Golomb ruler 50-fold.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-028.pdf,
34,2000,Game Playing,The Game of Hex: An Automatic Theorem Proving Approach to Game Programming,"Vadim V. Anshelevich, Vanshel Consulting","The game of Hex is a two-player game with simple rules, a deep underlying mathematical beauty, and a strategic complexity comparable to that of Chess and Go. The massive game-tree search techniques developed mostly for Chess, and successfully used for Checkers, Othello, and a number of other games, become less useful for games with large branching factors like Go and Hex. We offer a new approach, which results in superior playing strength. This approach emphasizes deep analysis of relatively few game positions. In order to reach this goal, we develop an automatic theorem proving technique for topological analysis of Hex positions. We also discuss in detail an idea of modeling Hex positions with electrical resistor circuits. We explain how this approach is implemented in Hexy - the strongest known Hex-playing computer program, able to compete with best human players.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-029.pdf,
35,2000,Game Playing,Combining Knowledge and Search to Solve Single-Suit Bridge,"Ian Frank, Electrotechnical Laboratory; David Basin, Universität Freiburg; Alan Bundy, University of Edinburgh","In problem solving, it is often important not only to find a solution but also to be able to explain it. We use the game of Bridge to illustrate how tactics, which formalise domain-specific expertise, can be used for both these tasks. Our Bridge tactics constrain search to the point where optimal strategies can be identified, and also provide the key to explaining these strategies in human-understandable terms. We demonstrate this by solving, in the technical sense, a canonical set of single-suit Bridge problems from a definitive expert text: in addition to always finding optimal solutions (and revealing a 3% error rate in the expert answers), each solution is automatically explained in language comparable to that of the expert text.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-030.pdf,
36,2000,Game Playing,On Pruning Techniques for Multi-Player Games,"Nathan R. Sturtevant and Richard E. Korf. University of California, Los Angeles","Maxn is the extension of the minimax backup rule to multi-player games. We have shown that only a limited version of alpha-beta pruning, shallow pruning, can be applied to a maxn search tree. We extend this work by calculating the exact bounds needed to use this pruning technique. In addition, we show that branch-and-bound pruning, using a monotonic heuristic, has the same limitations as alpha-beta pruning in a maxn tree. We present a hybrid of these algorithms, alpha-beta branch-and-bound pruning, which combines a monotonic heuristic and backed-up values to prune even more effectively. We also briefly discuss the reduction of a n-player game to a CEparanoid 2-player game. In Sergeant Major, a 3-player card game, we averaged node expansions over 200 height 15 trees. Shallow pruning and branch-and-bound each reduced node expansions by a factor of about 100. Alpha-beta branch-and-bound reduced the expansions by an additional factor of 19. The 2-player reduction was a factor of 3 better than alpha-beta branch-and-bound. Using heuristic bounds in the 2-player reduction reduced node expansions another factor of 12.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-031.pdf,
37,2000,Human-Computer Interaction,Human-Guided Simple Search,"David Anderson, Emily Anderson, Neal Lesh, Joe Marks, Brian Mirtich, and David Ratajczak, MERL -- Mitsubishi Electric Research Laboratory; Kathy Ryall, MERL -- Mitsubishi Electric Research Laboratory and University of Virginia","Sampling has become an important strategy for inference in belief networks. It can also be applied to the problem of selecting actions in influence diagrams. In this paper, we present methods with probabilistic guarantees of selecting a near-optimal action. We establish bounds on the number of samples required for the traditional method of estimating the utilities of the actions, then go on to extend the traditional method based on ideas from sequential analysis, generating a method requiring fewer samples. Finally, we exploit the intuition that equally good value estimates for each action are not required, to develop a heuristic method that achieves major reductions in required sample size. The heuristic method is validated empirically. Scheduling, routing, and layout tasks are examples of hard operations-research problems that have broad application in industry. Typical algorithms for these problems combine some form of gradient descent to find local minima with some strategy for escaping nonoptimal local minima. Our idea is to divide these two subtasks cleanly between human and computer: in our paradigm of human-guided simple search the computer is responsible only for finding local minima using a simple hill-climbing search; using visualization and interaction techniques, the human user identifies promising regions of the search space for the computer to explore, and intervenes to help it escape nonoptimal local minima. We have applied our approach to the problem of capacitated vehicle routing with time windows, a commercially important problem with a rich research history. Despite its simplicity, our prototype system is competitive with the majority of previously reported systems on benchmark academic problems, and has the added advantage of keeping a human tightly in the loop to handle the complexities of real-world applications.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-032.pdf,
38,2000,Human-Computer Interaction,Predicting Future User Actions by Observing Unmodified Applications,"Peter Gorniak and David Poole, University of British Columbia","Intelligent user interfaces often rely on modified applications and detailed application models. Such modifications and models are expensive to build and maintain. We propose to automatically model the use of unmodified applications to solve this problem. We observe a user’s interactions with the application’s interface and from these observations deduce a state space which the user navigates and the stochastic policy he or she follows. ONISI, the algorithm presented here, builds this state space implicitly and on-line, and uses it to predict future user actions. Trials with real users show that this algorithm predicts the next user action significantly better than other algorithms.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-033.pdf,
39,2000,Human-Computer Interaction,Acquiring Problem-Solving Knowledge from End Users: Putting Interdependency Models to the Test,"Jihie Kim and Yolanda Gil, University of Southern California","Developing tools that allow non-programmers to enter knowledge has been an ongoing challenge for AI. In recent years researchers have investigated a variety of promising approaches to knowledge acquisition (KA), but they have often been driven by the needs of knowledge engineers rather than by end users. This paper reports on a series of experiments that we conducted in order to understand how far a particular KA tool that we are developing is from meeting the needs of end users, and to collect valuable feedback to motivate our future research. This KA tool, called EMeD, exploits Interdependency Models that relate individual components of the knowledge base in order to guide users in specifying problem-solving knowledge. We describe how our experiments helped us address several questions and hypotheses regarding the acquisition of problem-solving knowledge from end users and the benefits of Interdependency Models, and discuss what we learned in terms of improving not only our KA tools but also about KA research and experimental methodology.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-034.pdf,
40,2000,Human-Computer Interaction,Predicting UNIX Command Lines: Adjusting to User Patterns,"Benjamin Korvemaker and Russell Greiner, University of Alberta","As every user has his own idiosyncrasies and preferences, an interface that is honed for one user may be problematic for another. To accommodate a diverse range of users, many computer applications therefore include an interface that can be customized --- e.g., by adjusting parameters, or defining macros. This allows each user to have his ``own'' version of the interface, honed to his specific preferences. However, most such interfaces require the user to perform this customization by hand -- a tedious process that requires the user to be aware of his personal preferences. We are therefore exploring adaptive interfaces, that can autonomously determine the user’s preference, and adjust the interface appropriately. This paper describes such an adaptive system --- here a UNIX-shell that can predict the user’s next command, and then use this prediction to simplify the user’s future interactions. These predictions are determined by combining the distributions learned by a set of relatively simple experts, each using its own type of information. In a series of experiments, on real-world data, we demonstrate that this system can correctly predict the user’s next command almost 50% of the time, and can do so robustly -- across a range of different users.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-035.pdf,
41,2000,Human-Computer Interaction,Generation of Ideologically-Biased Historical Documentaries,"Michael Mateas, Carnegie Mellon University; Paul Vanouse, University of Buffalo; Steffi Domike, Chatham College","Terminal Time is a machine that constructs ideologically-biased documentary histories in response to audience feedback. The audience answers multiple-choice questions via an applause meter. The answers to these questions influence which historical events are chosen from a knowledge base, how these events will be slanted to embody the bias implied in the audience’s answers, and how the events will be connected together to form a historical narrative. Terminal Time’s architecture consists of a knowledge base and inference engine for querying the knowledge base, ideological goal trees and rhetorical devices which represent the current bias, a natural language generator to turn the constructed history into narrative prose, and an indexed multimedia database used to sequence video against the narration.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-036.pdf,
42,2000,Human-Computer Interaction,Self-Supervised Learning for Visual Tracking and Recognition of Human Hand,"Ying Wu and Thomas S. Huang, University of Illinois at Urbana-Champaign","Due to the large variation and richness of visual inputs, statistical learning gets more and more concerned in the practice of visual processing such as visual tracking and recognition. Statistical models can be trained from a large set of training data. However, in many cases, since it is not trivial to obtain a large labeled and representative training data set, it would be difficult to obtain a satisfactory generalization. Another difficulty is how to automatically select good features for representation. By combining both labeled and unlabeled training data, this paper proposes a new learning paradigm, self-supervised learning, to investigate the issues of learning bootstrapping and model transduction. Inductive learning and transductive learning are the two main cases of self-supervised learning, in which the proposed algorithm, Discriminant-EM (D-EM), is a specific learning technique. Vision-based gesture interface is employed as a testbed in our research.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-037.pdf,
43,2000,Human-Computer Interaction,Interactive Training for Synthetic Characters,"Song-Yee Yoon, Robert C. Burke, Bruce M. Blumberg, and Gerald E. Schneider, Massachusetts Institute of Technology","Compelling synthetic characters must behave in ways that reflect their past experience and thus allow for individual personalization. We therefore need a method that allows characters to learn. But simply adding traditional machine learning algorithms without considering the characters’ own motivations and desires will break the illusion of life. Intentional characters require interactive learning. In this paper, we present the results of Sydney K9.0, a project based on the Synthetic Characters creature kernel framework. Inspired by pet training, we have implemented a character that can be trained using the ``clicker training'' technique. Clicker training utilizes the natural desires of an animal and employs operant conditioning procedures for shaping their behavior. The necessary plasticity of system interconnections shaped by associations and rewards that is required by clicker training was integrated into the creature kernel framework. The implemented system includes a module named DogEar that is designed for collecting real world acoustic data, such as human voice commands, integrated into the creature kernel’s perception system. This provides a seamless interface between the simulated and real worlds. Detailed implementation and interaction results are presented.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-038.pdf,
44,2000,Boolean Satisfiability,Generating Satisfiable Problem Instances,"Dimitris Achlioptas, Microsoft Research; Carla Gomes, Cornell University; Henry Kautz, AT&T Research; Bart Selman, Cornell University","A major difficulty in evaluating incomplete local-search style algorithms for constraint satisfaction problems is the need for a source of hard problem instances that are guaranteed to be satisfiable. A standard approach to evaluate incomplete search methods has been to use a general problem generator and a complete search method to filter out the unsatisfiable instances. Unfortunately, this approach cannot be used to create problem instances that are beyond the reach of complete search methods. So far, it has proven surprisingly difficult to develop a direct generator for satisfiable instances only. In this paper, we propose the first such generator that outputs uniformly distributed satisfiable problem instances. We also show how one can finely control the hardness of the satisfiable instances by establishing a connection between problem hardness and a new kind of phase transition phenomenon in the space of problem instances. Finally, we use our problem distribution to provide the first conclusive evidence for the existence of an easy-hard-easy pattern in search complexity for local search procedures, analogous to the previously reported pattern for complete search methods.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-039.pdf,
45,2000,Boolean Satisfiability,Solving the Round Robin Problem Using Propositional Logic,"Ramón Béjar and Felip Many&eagrave, Universitat de Lleida","A major difficulty in evaluating incomplete local-search style algorithms for constraint satisfaction problems is the need for a source of hard problem instances that are guaranteed to be satisfiable. A standard approach to evaluate incomplete search methods has been to use a general problem generator and a complete search method to filter out the unsatisfiable instances. Unfortunately, this approach cannot be used to create problem instances that are beyond the reach of complete search methods. So far, it has proven surprisingly difficult to develop a direct generator for satisfiable instances only. In this paper, we propose the first such generator that outputs uniformly distributed satisfiable problem instances. We also show how one can finely control the hardness of the satisfiable instances by establishing a connection between problem hardness and a new kind of phase transition phenomenon in the space of problem instances. Finally, we use our problem distribution to provide the first conclusive evidence for the existence of an easy-hard-easy pattern in search complexity for local search procedures, analogous to the previously reported pattern for complete search methods.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-040.pdf,
46,2000,Boolean Satisfiability,A Demand-Driven Algorithm for Generating Minimal Models,"Rachel Ben-Eliyahu - Zohary, Ben-Gurion University of the Negev","The task of generating minimal models of a knowledge base is a significant computational problem in artificial intelligence. This task is at the computational heart of diagnosis systems like truth maintenance systems, and of nonmonotonic systems like autoepistemic logic, default logic, and disjunctive logic programs. Unfortunately, it is NP-hard. In this paper we present a hierarchy of classes of knowledge bases, Psi1, Psi2, ..., with the following properties: first, Psi1 is the class of all Horn knowledge bases; second, if a knowledge base Pi is in Psik, then Pi has at most k minimal models, and all of them may be found in time O(lnk), where l is the length of the knowledge base and n the number of atoms in Pi; third, for an arbitrary knowledge base Pi, we can find the minimum k such that Pi belongs to Psik in time polynomial in the size of Pi ; and, last, where K is the class of all knowledge bases, it is the case that union i=1 infty Psii = K , that is, every knowledge base belongs to some class in the hierarchy. The algorithm is demand-driven, that is, it is capable of generating one model at a time.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-041.pdf,
47,2000,Boolean Satisfiability,Redundancy in Random SAT Formulas,"Yacine Boufkhad and Olivier Roussel, Université d'Artois","The random k-SAT model is extensively used to compare satisfiability algorithms or to find the best settings for the parameters of some algorithm. Conclusions are derived from the performances measured on a large number of random instances. The size of these instances is, in general, small to get these experiments done in reasonable time. This assumes that the small size formulas have the same properties than the larger ones. We show that small size formulas have at least a characteristic that makes them relatively easier than the larger ones (beyond the increase in the size of the formulas). This characteristic is the redundancy. We show, experimentally, that the irredundant formulas are harder for both complete and incomplete methods. Besides, the randomly generated formulas tend to be naturally irredundant as their size become larger. Thus, irredundant small formulas are more suitable for testing algorithms because they better reflect the hardness of the larger ones.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-042.pdf,
48,2000,Boolean Satisfiability,On 2-SAT and Renamable Horn,"Alvaro del Val, Universidad Autónoma de Madrid","We introduce new linear time algorithms for satisfiability of binary propositional theories (2-SAT), and for recognition and satisfiability of renamable Horn theories. The algorithms are based on unit resolution, and are thus likely easier to integrate within general SAT solvers than other graph-based algorithms.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-043.pdf,
49,2000,Boolean Satisfiability,A Distributed Algorithm to Evaluate Quantified Boolean Formulae,"Rainer Feldmann, Burkhard Monien, and Stefan Schamberger, University of Paderborn","In this paper, we present PQsolve, a distributed theorem-prover for Quantified Boolean Formulae. First, we introduce our sequential algorithm Qsolve, which uses new heuristics and improves the use of known heuristics to prune the search tree. As a result, Qsolve is more efficient than the QSAT-solvers previously known. We have parallelized Qsolve.The resulting distributed QSAT-solver PQsolve uses parallel search techniques, which we have developed for distributed game tree search.PQsolve runs efficiently on distributed systems, i.e. parallel systems without any shared memory.We briefly present experiments that show a speedup of about114 on 128 processors.To the best of our knowledge we are the first to introduce an efficient parallel QSAT-solver.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-044.pdf,
50,2000,Boolean Satisfiability,Integrating Equivalency Reasoning into Davis-Putnam Procedure,"Chu Min Li, Univ. de Picardie Jules Verne","Equivalency clauses (Xors or modulo 2 arithmetics) represent a common structure in the SAT-encoding of many hard real-world problems and constitute a major obstacle to Davis-Putnam (DP) procedure. We report on the performance of an equivalency reasoning enhanced DP procedure on SAT instances containing equivalency clauses derived from problems in parity learning, cryptographic key search and model checking. Our results show that integrating equivalency reasoning renders easy many problems which were beyond DP’s reach. We also compare equivalency reasoning with general CSP look-back techniques on equivalency clauses.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-045.pdf,
51,2000,Boolean Satisfiability,Local Search Characteristics of Incomplete SAT Procedures,"Dale Schuurmans and Finnegan Southey, University of Waterloo","Effective local search methods for finding satisfying assignments of CNF formulae exhibit several systematic characteristics in their local search. We identify a series of measurable characteristics of local search behavior that are predictive of problem solving efficiency. These measures are shown to be useful for diagnosing inefficiencies in given search procedures, tuning parameters, and predicting the value of innovations to existing strategies. We then introduce a new local search method, SDF (``smoothed descent and flood''), that builds upon the intuitions gained by our study. SDF works by greedily descending in an informative objective (that considers how strongly clauses are satisfied, in addition to counting the number of unsatisfied clauses) and, once trapped in a local minima, ``floods'' this minima by re-weighting unsatisfied clauses to create a new descent direction. The resulting procedure exhibits effective local search characteristics under our measures. We then show that our method is competitive with the state of the art techniques, and typically reduces the number of search steps by a significant factor.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-046.pdf,
52,2000,Boolean Satisfiability,MarketSAT: An Extremely Decentralized (but Really Slow) Algorithm for Propositional Satisfiability,"William E. Walsh and Michael P. Wellman, University of Michigan","We describe MarketSAT, a highly decentralized, market-based algorithm for propositional satisfiability. The approach is based on a formulation of satisfiability as production on a supply chain, where producers of particular variable assignments must acquire licenses to fail to satisfy particular clauses. MarketSAT employs a market protocol for general supply chain problems, which we show to be expressively equivalent to 3SAT. Experiments suggest that MarketSAT reliably converges to market allocations corresponding to satisfiable truth assignments. We experimentally compare the computational performance with GSAT, a centralized local search algorithm.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-047.pdf,
53,2000,Boolean Satisfiability,An Efficient Global-Search Strategy in Discrete Lagrangian Methods for Solving Hard Satisfiability Problems,"Zhe Wu and Benjamin W. Wah, University of Illinois at Urbana-Champaign","In this paper, we present an efficient global search strategy in a search based on the theory of discrete Lagrange multipliers to solve difficult SAT problems. Although a basic discrete Lagrangian method (DLM) can solve most of the satisfiable DIMACS SAT benchmarks efficiently, a few of the large benchmarks have eluded solutions by any local-search methods today. These difficult benchmarks generally have many traps or deep valleys that attract local-search trajectories. In contrast to the implicit trap-escaping strategies, we use an explict global search strategy that can force a search leave traps more efficiently by adding penalty related to Hamming distance between the current search point and past points in the search trajectory. This new global search strategy significantly improves over other results.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-048.pdf,
54,2000,Case-Based Reasoning,Assessing Relevance with Extensionally Defined Principles and Cases,"Bruce M. McLaren and Kevin D. Ashley, University of Pittsburgh","Expert decision-makers often explain decisions by citing general principles. In some domains, however, it is nearly impossible to define principles intensionally so that they may be applied deductively. After investigating hundreds of professional ethics case opinions, we hypothesized that the decision-makers’ explanations extensionally defined principles over time, in effect, operationalizing them. To model this phenomenon computationally, we constructed SIROCCO, a system for retrieving principles and past cases. This paper presents empirical evidence that operationalization information can be leveraged to predict more accurately the principles and past cases that are relevant in the analysis of new cases.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-049.pdf,
55,2000,Case-Based Reasoning,Dynamic Case Creation and Expansion for Analogical Reasoning,"Thomas Mostek, Kenneth D. Forbus, and Cara Meverden, Northwestern University","Most CBR systems rely on a fixed library of cases, where each case consists of a set of facts specified in advance. This paper describes techniques for dynamically extracting cases for analogical reasoning from general-purpose knowledge bases, and dynamically expanding them during the course of analogical reasoning. These techniques have several advantages: (1) Knowledge authoring is simplified, since facts can be added without regard to which case(s) they will be used in. (2) Reasoning is more efficient, since task constraints can be used during case extraction to focus on facts likely to be relevant. (3) Larger problems can be tackled, since cases can be dynamically expanded with more details during the matching process itself, rather than starting with completely detailed cases. We describe algorithms for case extraction and case expansion, including how a version of the Structure-Mapping Engine (SME) has been modified to incorporate this new matching technique. The utility of this technique is illustrated by results obtained with two large knowledge bases, created by other groups, and used to answer questions in the DARPA High-Performance Knowledge Base Crisis Management Challenge Problem.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-050.pdf,
56,2000,Case-Based Reasoning,Memory-Based Forecasting for Weather Image Patterns,"Kazuhiro Otsuka and Tsutomu Horikoshi, NTT Cyber Solutions Laboratories; Satoshi Suzuki, NTT East Corporation; Haruhiko Kojima, NTT Cyber Solutions Laboratories","A novel method and a framework called Memory-Based Forecasting are proposed to forecast complex and time-varying natural patterns with the goal of supporting experts’ decision making. This paper targets the local precipitation phenomena captured as echo patterns in weather radar images, and aims to realize a tool that supports weather forecasters. In our framework, past image patterns similar to the present pattern are retrieved from a large set held in an image database, and the forecast image is produced by using the patterns that follow the retrieved patterns; it is analogous to human forecasters who imagine the future patterns based on their past experience. Appearance-based image features and temporal texture features are introduced to characterize the non-rigid complex echo patterns found in such radar images. The similarity between two image sequences is defined as the normalized distance between paths of feature points in eigenspaces of the image features to retrieve similar past sequences. Forecast images are then constructed from a future point in the feature spaces, which is estimated by a nonlinear prediction scheme. Statistical experiments using weather radar images verify the effectiveness of our method and framework especially for drastically changing patterns.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-051.pdf,
57,2000,Computational Complexity of Reasoning,The Complexity of Restricted Consequence Finding and Abduction,"Alvaro del Val, Universidad Autónoma de Madrid","We analyse the complexity of propositional kernel resolution (del Val, 1999), a general method for obtaining logical consequences in restricted target languages. Different choices of target are relevant to important AI tasks, e.g. prime implicates, satisfiability, abduction and non-monotonic reasoning, and polynomial-size knowledge compilation. Based on a generalized concept of induced width, we identify new tractable classes for various targets, and show how to estimate in advance the complexity of every problem, under various atom orderings. This can be used to choose an ordering for kernel resolution. Two applications are discussed: estimating the number of prime implicates of any theory; and identifying tractable abduction problems.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-052.pdf,
58,2000,Computational Complexity of Reasoning,Tractable Classes for Directional Resolution,"Alvaro del Val, Universidad Autónoma de Madrid","The original, resolution-based Davis-Putnam satisfiability algorithm (Davis and Putnam 1960) was recently revived by (Dechter and Rish, 1994) under the name ``directional resolution'' (DR). We provide new positive complexity results for DR. First, we identify a class of theories (ACT, Acyclic Component Theories), which includes many real-world theories, for which DR takes polynomial time. Second, we present an improved analysis of the complexity of directional resolution through refined notions of induced width, which yields new tractable classes for DR, and much better predictions of its space and time requirements under various atom orderings. These estimates can be used for heuristically choosing among various orderings before running DR.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-053.pdf,
59,2000,Computational Complexity of Reasoning,Compilability of Abduction,"Paolo Liberatore and Marco Schaerf, Universit&eagrave di Roma ""La Sapienza""","Abduction is one of the most important forms of reasoning and it has been successfully applied to several practical problems such as diagnosis. In this paper we investigate whether the computational complexity of abduction can be reduced by an appropriate use of preprocessing or compilation. This is motivated by the fact that part of the data of the problem (namely, the set of all possible assumptions and the theory relating assumptions and manifestations) are often known before the rest of the problem. We present a detailed analysis of the computational complexity of abduction when compilation is allowed.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-054.pdf,
60,2000,Decision Theory,"Decision-Theoretic, High-Level Agent Programming in the Situation Calculus","Craig Boutilier, Ray Reiter, and Mikhail Soutchanski, University of Toronto; Sebastian Thrun, Carnegie Mellon University","This paper proposes a framework for robot programming, which allows the seamless integration of explicit agent programming with decision-theoretic planning. Specifically, the DTGolog model allows one to partially specify a control program in a high-level, logical language, but it also provides an interpreter that---given a logical axiomatization of a domain---will determine the optimal completion of that program (viewed as an MDP). We demonstrate the utility of this model by describing results obtained in an office delivery robotics domain.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-055.pdf,
61,2000,Decision Theory,Making Rational Decisions Using Adaptive Utility Elicitation,"Urszula Chajewska, Daphne Koller, and Ronald Parr, Stanford University","Rational decision making requires full knowledge of the utility function of the person affected by the decisions. However, in many cases, the task of acquiring such knowledge is not feasible due to the size of the outcome space and the complexity of the utility elicitation process. Given that the amount of utility information we can acquire is limited, we need to make decisions with partial utility information and should carefully select which utility elicitation questions we ask. In this paper, we propose a new approach for making decisions based on limited utility information, and for targetting our utility elicitation process so as to lead to a good decision using a small number of questions. Our approach is based on the idea that we have a prior probability distribution over the person’s utility function, perhaps learned from a population of similar people. The relevance of a utility elicitation question for the current decision problem can then be measured using its value of information. We propose an algorithm that interleaves the analysis of the decision problem and utility elicitation to allow these two tasks to inform each other. At every step, it asks the utility elicitation question giving us the highest value of information, and then computes the best strategy based on the information acquired so far. The process continues until the expected utility loss resulting from our (possibly suboptimal) recommendation falls below a pre-specified threshold. We show how the various steps of this algorithm can be implemented efficiently.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-056.pdf,
62,2000,Decision Theory,Back to the Future for Consistency-Based Trajectory Tracking,"James Kurien, NASA Ames Research Center; P. Pandurang Nayak, PurpleYogi.com and RIACS","Given a model of a physical process and a sequence of commands and observations received over time, the task of an autonomous controller is to determine the likely states of the process and the actions required to move the process to a desired configuration. We introduce a representation and algorithms for incrementally generating approximate belief states for a restricted but relevant class of partially observable Markov decision processes with very large state spaces. The algorithm presented incrementally generates, rather than revises, an approximate belief state at any point by abstracting and summarizing segments of the likely trajectories of the process. This enables applications to efficiently maintain a partial belief state when it remains consistent with observations and revisit past assumptions about the system’s evolution when the belief state is ruled out. The system presented has been implemented and results fromapplying it to real world examples from the domain of spacecraft control are presented.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-057.pdf,
63,2000,Decision Theory,Sampling Methods for Action Selection in Influence Diagrams,"Luis E. Ortiz, Brown University and Leslie Pack Kaelbling, Massachusetts Institute of Technology","Sampling has become an important strategy for inference in belief networks. It can also be applied to the problem of selecting actions in influence diagrams. In this paper, we present methods with probabilistic guarantees of selecting a near-optimal action. We establish bounds on the number of samples required for the traditional method of estimating the utilities of the actions, then go on to extend the traditional method based on ideas from sequential analysis, generating a method requiring fewer samples. Finally, we exploit the intuition that equally good value estimates for each action are not required, to develop a heuristic method that achieves major reductions in required sample size. The heuristic method is validated empirically.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-058.pdf,
64,2000,Logic,Answering Queries Using Views over Description Logics Knowledge Bases,"Diego Calvanese, Giuseppe De Giacomo, and Maurizio Lenzerini, Universit&eagrave di Roma ""La Sapienza""","Answering queries using views amounts to computing the answer to a query having information only on the extension of a set of precomputed queries (views). This problem is relevant in several fields, such as information integration, query optimization, and data warehousing, and has been studied recently in different settings. None of the previous work allows for the possibility to take into account intensional knowledge about the domain. In this paper we address answering queries using views in a setting where domain knowledge is represented using a very expressive description logic equipped with n-ary relations, and queries are nonrecursive datalog queries whose predicates are the concepts and relations that appear in the description logic knowledge base. We study the problem under different assumptions, namely, closed and open domain, and sound, complete, and exact information on view extensions. We show that under the closed domain assumption, in which the set of all objects in the knowledge base coincides with the set of objects stored in the views, answering queries using views is already intractable. We show also that under the open domain assumption the problem is decidable in double exponential time.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-059.pdf,
65,2000,Logic,A Consistency-Based Model for Belief Change: Preliminary Report,"James P. Delgrande, Simon Fraser University; Torsten Schaub, Universität Potsdam","We develop a general, consistency-based framework for belief change. Informally, in revising K by A, we begin with A and incorporate as much of K as consistently possible. Formally, a knowledge base K and sentence A are expressed, via renaming propositions in K, in separate languages. Using a maximization process, we assume the languages are the same insofar as consistently possible. Lastly, we express the resultant knowledge base in a single language. There may be more than one way in which A can be so extended by K: in choice revision, one such extension represents the revised state; alternately revision consists of the intersection of all such extensions. The most general formulation of our approach is flexible enough to express various other approaches to revision and update, the merging of knowledge bases, and the incorporation of static and dynamic integrity constraints. Our framework differs from work based on ordinal conditional functions, notably with respect to iterated revision. We argue that the approach is well-suited for implementation: choice revision gives better complexity results than general revision; the approach can be expressed in terms of a finite knowledge base; and the scope of a revision can be restricted to just those propositions mentioned in the sentence for revision A.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-060.pdf,
66,2000,Logic,A Conjunctive Query Language for Description Logic Aboxes,"Ian Horrocks and Sergio Tessaris, University of Manchester","A serious shortcoming of many Description Logic based knowledge representation systems is the inadequacy of their query languages. In this paper we present a novel technique that can be used to provide an expressive query language for such systems. One of the main advantages of this approach is that, being based on a reduction to knowledge base satisfiability, it can easily be adapted to most existing (and future) Description Logic implementations. We believe that providing Description Logic systems with an expressive query language for interrogating the knowledge base will significantly increase their utility.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-061.pdf,
67,2000,Nonmonotonic Reasoning,A Flexible Framework for Defeasible Logics,"G. Antoniou, D. Billington, G. Governatori, and M. J. Maher, Griffith University","Logics for knowledge representation suffer from over-specialization: while each logic may provide an ideal representation formalism for some problems, it is less than optimal for others. A solution to this problem is to choose from several logics and, when necessary, combine the representations. In general, such an approach results in a very difficult problem of combination. However, if we can choose the logics from a uniform framework then the problem of combining them is greatly simplified. In this paper, we develop such a framework for defeasible logics. It supports all defeasible logics that satisfy a strong negation principle. We use logic meta-programs as the basis for the framework.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-062.pdf,
68,2000,Nonmonotonic Reasoning,Towards a Logic-Based Theory of Argumentation,"Philippe Besnard, Université Paul Sabatier; Anthony Hunter, University College London","There are a number of frameworks for modelling argumentation in logic. They incorporate formal representation of individual arguments and techniques for comparing conflicting arguments. In these frameworks, if there are a number of arguments for and against a particular conclusion, an aggregation function determines whether the conclusion is taken to hold. We propose a generalization of these frameworks. In particular, this new framework makes it possible to define aggregation functions that are sensitive to the number of arguments for or against (in most other frameworks, aggregation functions just consider the existence of arguments for and against). In this paper, we explore this framework (based on classical logic) in which an argument is a pair where the first item in the pair is a minimal consistent set of formulae that proves the second item (which is a formula).",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-063.pdf,
69,2000,Nonmonotonic Reasoning,Solving Advanced Reasoning Tasks Using Quantified Boolean Formulas,"Uwe Egly, Thomas Eiter, Hans Tompits, and Stefan Woltran, Technische Universität Wien","We consider compiling reasoning tasks into the evaluation problem of Quantified Boolean Formulas (QBFs) which are useful as an approach to develop prototype reasoning systems for experimental purposes. Such a method has been recently proposed by other researchers, who provided algorithms for evaluating QBFs. However, these algorithms require input formulas in prenex clausal normal form. In this paper, we complement these investigations by describing a framework, QUIP, which handles arbitrary QBFs. QUIPs reasoning engine is boole, an evaluator for QBFs based on binary decision diagrams (BDDs). We present translations of several well-known reasoning tasks from the area of nonmonotonic reasoning (NMR) into QBFs, and compare their implementation in QUIP with established NMR-provers. The results show reasonable performance, and document that the QBF approach is an attrative tool for rapid prototyping of experimental KR systems.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-064.pdf,
70,2000,Nonmonotonic Reasoning,Total Knowledge,"Ian Pratt-Hartmann, University of Manchester","In this paper, we analyse a concept of total knowledge based on the idea that an agent’s total knowledge is the strongest proposition the agent knows. We propose semantics for propositional and first-order languages with a modal operator TK representing total knowledge, and establish a result showing that total knowledge is epistemically categorical, in the sense that it determines the agent’s knowledge over a broad range of contents. We show that (subject to some restrictions) total knowledge is always total knowledge of an objective content, and that, for such objective contents, our TK-operator corresponds in a straightforward way to Levesque’s operator O.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-065.pdf,
71,2000,Nonmonotonic Reasoning,Computing Circumscriptive Databases by Integer Programming: Revisited,"Ken Satoh and Hidenori Okamoto, Hokkaido University","In this paper, we consider a method of omputing minimal models in circumscription using integer programming in propositional logic and first-order logic with domain closure axioms and unique name axioms. This kind of treatment is very important since this enable to apply various technique developed in operations research to nonmonotonic reasoning.Nerode et al. are the first to propose a method of computing circumscription using integer programming. They claimed their method was correct for circumscription with fixed predicate, but we show that their method does not correctly reflect their claim. We show a correct method of computing all the minimal models not only with fixed predicates but also with varied predicates and we extend our method to compute prioritized circumscription as well.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-066.pdf,
72,2000,Ontology,Using Prior Knowledge: Problems and Solutions,"Vinay K. Chaudhri, Mark E. Stickel, Jerome F. Thomere, and Richard J. Waldinger, SRI International","Encoding knowledge is time consuming and expensive. A possible solution to reduce the cost of developing a new knowledge base (KB) is to reuse existing knowledge. Previous work addressing this problem has focused on standards for representing, exchanging, and accessing knowledge, and on creating large repositories of knowledge. Results on the level of reuse achievable have been reported. In this paper, we focus on the process of reuse and report a case study on constructing a KB by reusing existing knowledge. The reuse process involved the following steps: translation, comprehension, slicing, reformulation, and merging. We discuss technical problems encountered at each of these steps and explain how we solved them.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-067.pdf,
73,2000,Ontology,Dynamic Ontologies on the Web,"Jeff Heflin and James Hendler, University of Maryland","We discuss the problems associated with managing ontologies in distributed environments such as the Web. The Web poses unique problems for the use of ontologies because of the rapid evolution and autonomy of web sites. We present SHOE, a web-based knowledge representation language that supports multiple versions of ontologies. We describe SHOE in the terms of a logic that separates data from ontologies and allows ontologies to provide different perspectives on the data. We then discuss the features of SHOE that address ontology versioning, the effects of ontology revision on SHOE web pages, and methods for implementing ontology integration using SHOE’s extension and version mechanisms.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-068.pdf,
74,2000,Ontology,PROMPT: Algorithm and Tool for Automated Ontology Merging and Alignment,"Natalya Fridman Noy and Mark Musen, Stanford University","Researchers in the ontology-design field have developed the content for ontologies in many domain areas. Recently, ontologies have become increasingly common on the World-Wide Web where they provide semantics for annotations in Web pages. This distributed nature of ontology development has led to a large number of ontologies covering overlapping domains. In order for these ontologies to be reused, they first need to be merged or aligned to one another. The processes of ontology alignment and merging are usually handled manually and often constitute a large and tedious portion of the sharing process. We have developed and implemented PROMPT, an algorithm that provides a semi-automatic approach to ontology merging and alignment. PROMPT performs some tasks automatically and guides the user in performing other tasks for which his intervention is required. PROMPT also determines possible inconsistencies in the state of the ontology, which result from the user’s actions, and suggests ways to remedy these inconsistencies. PROMPT is based on an extremely general knowledge model and therefore can be applied across various platforms. Our formative evaluation showed that a human expert followed 90% of the suggestions that PROMPT generated and that 74% of the total knowledge-base operations invoked by the user were suggested by PROMPT.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-069.pdf,
75,2000,Reasoning about Actions and Time,(De)Composition of Situation Calculus Theories,"Eyal Amir, Stanford University","In this paper, we show that designing large situation calculus theories can be made simple by using object-oriented techniques and tools together with established solutions to the frame problem. Situation calculus (McCarthy-Hayes 1969) is one of the leading logical models for action and change, but large situation calculus theories are not easy to design and maintain, nor are they flexible for extension or reuse. However, we wish to use it to represent large, complex domains. To solve this problem, we apply our proposed methodology to situation calculus theories and analyze the composition of theories in its light. The object-oriented tools that we use do not change the semantics for situation calculus, so all the original situation calculus results apply in our setting and vice versa. We get two additional results from this approach. First, we offer a new treatment to loosely interacting agents that uses situation calculus without abandoning the -result- formalism. This treatment allows a theory-builder to construct a theory without considering its potential inclusion in a multiple-agents setup. Second, theories that we build in this way admit specialized reasoning algorithms.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-070.pdf,
76,2000,Reasoning about Actions and Time,Disjunctive Temporal Reasoning in Partially Ordered Models of Time,"Mathias Broxvall and Peter Jonsson, Linköpings Universitet","Certain problems concerning for example cooperating agents and distributed systems require reasoning about time which is measured on incomparable or unsynchronized time scales. In such situations, it is sometimes appropriate to use a temporal model that only provides a partial order on time points. We study the computational complexity of partially ordered temporal reasoning in expressive formalisms consisting of point algebras extended with disjunctions. We show that the resulting algebra for partially ordered time contains four maximal tractable subclasses while the algebra for total-ordered time contains two.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-071.pdf,
77,2000,Reasoning about Actions and Time,An Interval Algebra for Indeterminate Time,"Wes Cowley, University of South Florida; Dimitris Plexousakis, University of Crete and ICS-FORTH","Temporal indeterminacy is an inherent problem which arises when capturing and manipulating temporal data in many application areas. As such, representation and manipulation of timestamps with indeterminacy is a requirement for these applications. We present an extension of Allen’s thirteen interval relationships to indeterminate temporal intervals based on a novel representation for indeterminate timestamps. The timestamps can be derived from and translated to interval constraints. We provide a set of simple and useful operators for manipulating both convex and non-convex indeterminate intervals represented by these timestamps.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-072.pdf,
78,2000,Reasoning about Actions and Time,cc-Golog: Towards More Realistic Logic-Based Robot Controllers,"Henrik Grosskreutz and Gerhard Lakemeyer, Aachen University of Technology","High-level robot controllers in realistic domains typically deal with processes which operate concurrently, change the world continuously, and where the execution of actions is event-driven as in ``charge the batteries as soon as the voltage level is low''. While non-logic-based robot control languages are well suited to express such scenarios, they fare poorly when it comes to projecting, in a conspicuous way, how the world evolves when actions are executed. On the other hand, a logic-based control language like \congolog, based on the situation calculus, is well-suited for the latter. However, it has problems expressing event-driven behavior. In this paper, we show how these problems can be overcome by first extending the situation calculus to support continuous change and event-driven behavior and then presenting \ccgolog, a variant of \congolog\ which is based on the extended situation calculus. One benefit of \ccgolog\ is that it narrows the gap in expressiveness compared to non-logic-based control languages while preserving a semantically well-founded projection mechanism.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-073.pdf,
79,2000,Reasoning about Actions and Time,What Sensing Tells Us: Towards a Formal Theory of Testing for Dynamical Systems,"Sheila A. McIlraith, Stanford University; Richard Scherl, New Jersey Institute of Technology","Just as actions can have indirect effects on the state of the world, so too can sensing actions have indirect effects on an agent’s state of knowledge. In this paper, we investigate what sensing actions tell us, i.e., what an agent comes to know indirectly from the outcome of a sensing action, given knowledge of its actions and state constraints that hold in the world. Building on this foundation, we define the notion of a test, a complex action designed to achieve a knowledge goal. We show how such tests can be computed, or alternately, how they can be specified as complex actions. To this end, we propose a formalization of the notion of testing within a dialect of the situation calculus that includes knowledge and knowledge-producing actions. Realizing this formalization requires addressing the ramification problem for knowledge-producing actions. We formalize simple tests as sensing actions. Complex tests are described in the logic programming language Golog. We examine what it means to perform a test, and how the outcome of a test affects an agent’s state of knowledge. Finally we discuss the issue of selecting tests to confirm, refute, or discriminate a space of hypotheses. The work presented in this paper is relevant to a number of application domains including diagnostic problem solving, natural language understanding, plan recognition, and active vision.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-074.pdf,
80,2000,Reasoning about Actions and Time,Execution of Temporal Plans with Uncertainty,"Paul Morris, Caelum Research Corporation / NASA Ames Research Center; Nicola Muscettola, NASA Ames Research Center","Simple Temporal Networks (STNs) have proved useful in applications that involve metric time. However, many applications involve events whose timing is uncertain in the sense that it is not controlled by the execution agent. In this paper we consider execution algorithms for temporal networks with events of uncertain duration. We present two such algorithms. The first retains maximum flexibility, but requires potentially costly updates during execution. The second surrenders some flexibility in order to obtain a fast execution comparable to that available for ordinary STNs.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-075.pdf,
81,2000,Reasoning about Actions and Time,"Modeling Actions with Ramifications in Nondeterministic, Concurrent, and Continuous Domains and a Case Study","Michael Thielscher, Dresden University of Technology","Combining into a consistent theory co-existing models for different phenomena in reasoning about actions can be a problem as challenging as addressing new aspects. We present a uniform theory for reasoning about actions with indirect effects in nondeterministic, concurrent, and continuous domains. We report on a case study to which our theory has been successfully applied.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-076.pdf,
82,2000,Spatial Reasoning,Describing Rigid Body Motions in a Qualitative Theory of Spatial Regions,"Brandon Bennett, Anthony G. Cohn, Paolo Torrini, and Shyamanta Hazarika, University of Leeds","We explore the expressive power of a recently developed qualitative region-based geometry and apply it to the problem of representing andreasoning about the motion of rigid bodies within a confining environment.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-077.pdf,
83,2000,Spatial Reasoning,GeoRep: A Flexible Tool for Spatial Representation of Line Drawings,"Ronald W. Ferguson and Kenneth D. Forbus, Northwestern University","A key problem in diagrammatic reasoning is understanding how people reason about qualitative relationships in diagrams. We claim that progress in diagrammatic reasoning is slowed by two problems: (1) researchers tend to start from scratch, creating new spatial reasoners for each new problem area, and (2) constraints from human visual processing are rarely considered. To address these problems, we created GeoRep, a spatial reasoning engine that generates qualitative spatial descriptions from line drawings. GeoRep has been successfully used in several research projects, including cognitive simulation studies of human vision. In this paper, we outline GeoRep’s architecture, explain the domain-independent and domain-specific aspects of its processing, and motivate the representations it produces. We then survey how GeoRep has been used in three different projects--a model of symmetry, a model of understanding juxtaposition diagrams of physical situations, and a system for reasoning about military courses of action.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-078.pdf,
84,2000,Spatial Reasoning,STA: Spatio-Temporal Aggregation with Applications to Analysis of Diffusion-Reaction Phenomena,"Iván Ordóñez, The Ohio State University; Feng Zhao, Xerox Palo Alto Research Center","Spatio-temporal data sets arise when time-varying physical fields are discretized for simulation or analysis. Examples of time-varying fields are isothermal regions in the sea, or pattern formations in natural systems, such as convection rolls or diffusion-reaction systems. The analysis of these data sets is essential to generate qualitative interpretations for human understanding. This paper presents Spatio-Temporal Aggregation (STA), a system for recognizing and tracking qualitative structures in spatio-temporal data sets. STA algorithms record and maintain temporal events and compile event se-quences into concise history descriptions. This is carried out at several levels of description, from the bottom up: first, low level events are identified and tracked, and then a subset of those events, relevant at the next description level, is identified. The process is iterated until a high level narrative of the system’s temporal evolution is obtained. STA has been demonstrated on a class of diffusion-reaction systems in two dimensions and has successfully generated high-level symbolic descriptions of systems similar to those produced by scientists through carefully hand-tuned computational experiments.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-079.pdf,
85,2000,Uncertainty,On the Recognition of Abstract Markov Policies,"Hung H. Bui, Svetha Venkatesh, and Geoff West, Curtin University of Technology","Abstraction plays an essential role in the way the agents plan their behaviours, especially to reduce the computational complexity of planning in large domains. However, the effects of abstraction in the inverse process -- plan recognition -- are unclear. In this paper, we present a method for recognising the agent’s behaviour in noisy and uncertain domains, and across multiple levels of abstraction. We use the concept of abstract Markov policies in abstract probabilistic planning as the model of the agent’s behaviours and employ probabilistic inference for Dynamic Bayesian Networks (DBN) to infer the correct policy from a sequence of observations. When the states are fully observable, we show that for a broad and often-used class of abstract policies, the complexity of policy recognition scales well with the number of abstraction levels in the policy hierarchy. For the partially observable case, we derive an efficient hybrid inference scheme on the corresponding DBN to overcome the exponential complexity.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-080.pdf,
86,2000,Uncertainty,Bayesian Fault Detection and Diagnosis in Dynamic Systems,"Uri Lerner, Ronald Parr, and Daphne Koller, Stanford University; Gautam Biswas, Vanderbilt University","We address two challenges in the task of tracking and diagnosing complex systems with mixtures of discrete and continuous variables: Accurate tracking and correct diagnosis of failures. This problem is a difficult one, particularly when the system dynamics are nondeterministic, not all aspects of the system are directly observed, and the sensors are subject to noise. In this paper, we propose a new approach to this task, based on the framework of hybrid dynamic Bayesian networks (DBN). We show that the DBN structure can be generated from a temporal causal graph. These models contain both continuous variables representing the state of the system and discrete variables representing discrete changes such as failures; these models can represent a variety of faults, including burst faults, measurement errors, and gradual drifts. We present a novel algorithm for tracking in hybrid DBNs, that deals with the challenges posed by this difficult problem. We demonstrate how the resulting algorithm can be used to detect faults in a complex hybrid system.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-081.pdf,
87,2000,Uncertainty,Semantics and Inference for Recursive Probability Models,"Avi Pfeffer, Harvard University; Daphne Koller, Stanford University","In recent years, there have been several proposals that extend the expressive power of Bayesian networks with that of relational models. These languages open the possibility for the specification of recursive probability models, where a variable might depend on a potentially infinite(but finitely describable) set of variables. These models are very natural in a variety of applications, e.g., in temporal, genetic, or language models. In this paper, we provide a structured representation language that allows us to specify such models, a clean model-theoretic semantics for this language, and a probabilistic inference algorithm that exploits the structure of the language for efficient query-answering.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-082.pdf,
88,2000,Uncertainty,Towards Feasible Approach to Plan Checking under Probabilistic Uncertainty: Interval Methods,"Raúl Trejo and Vladik Kreinovich, University of Texas at El Paso; Chitta Baral, Arizona State University","The main problem of {\it planning} is to find a sequence of actions that an agent must perform to achieve a given objective. An important part of planning is checking whether a given plan achieves the desired objective. Historically, in AI, the planning and plan checking problems were mainly formulated and solved in a {\it deterministic} environment, when the initial state is known precisely and when the results of each action in each state is known (and uniquely determined). In this deterministic case, planning is difficult, but plan checking is straightforward. In many real-life situations, we only know the probabilities of different fluents; in such situations, even plan checking becomes computationally difficult. {\em In this paper, we describe how methods of interval computations can be used to get a feasible approximation to plan checking under probabilistic uncertainty.} The resulting method is a natural generalization of 0-approximation proposed earlier to describe planning in the case of partial knowledge. It turns out that some of the resulting probabilistic techniques coincides with heuristically proposed ``fuzzy`` methods. Thus, we justify these fuzzy heuristics as a reasonable feasible approximation to the (NP-hard) probabilistic problem.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-083.pdf,
89,2000,Machine Learning and Data Mining,ADVISOR: A Machine Learning Architecture for Intelligent Tutor Construction,"Joseph E. Beck, Beverly Park Woolf, and Carole R. Beal, University of Massachusetts","We have constructed a two-agent machine learning architecture for intelligent tutoring systems (ITS). The purpose of this architecture is to centralize the reasoning of an ITS into a single component to allow customization of teaching goals and simplify performance improvements. The first agent is responsible for learning a model of how students perform using the tutor in a variety of contexts. The second agent is provided this model of student behavior and a goal specifying the desired educational objective. Reinforcement learning is used by this agent to derive a teaching policy that meets the specified educational goal. Component evaluation studies show each agent performs adequately in isolation. We have also conducted an evaluation with actual students of the complete architecture. Results show our architecture was successful in learning a teaching policy that met the educational objective provided. Although this set of machine learning agents has been integrated with a specific intelligent tutor, the general technique could be applied to a broad class of ITS.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-084.pdf,
90,2000,Machine Learning and Data Mining,Automatic Invention of Integer Sequences,"Simon Colton and Alan Bundy, University of Edinburgh; Toby Walsh, University of York","We report on the application of the HR program to the problem of automatically inventing integer sequences. Seventeen sequences invented by HR are interesting enough to have been accepted into the Encyclopedia of Integer Sequences, and all were supplied with interesting conjectures about their nature, also discovered by HR. By extending HR, we have enabled it to perform a two stage process of invention and investigation. This involves generating both the definition and terms of a new sequence, relating it to sequences already in the Encyclopedia and pruning the output to help identify the most surprising and interesting results.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-085.pdf,
91,2000,Machine Learning and Data Mining,A Unified Bias-Variance Decomposition for Zero-One and Squared Loss,"Pedro Domingos, University of Washington","The bias-variance decomposition is a very useful and widely-used tool for understanding machine-learning algorithms. It was originally developed for squared loss. In recent years, several authors have proposed decompositions for zero-one loss, but each has significant shortcomings. In particular, all of these decompositions have only an intuitive relationship to the original squared-loss one. In this paper, we define bias and variance for an arbitrary loss function, and show that the resulting decomposition specializes to the standard one for the squared-loss case, and to a close relative of Kong and Dietterich’s (1995) one for the zero-one case. The same decomposition also applies to variable misclassification costs. We show a number of interesting consequences of the unified definition. For example, Schapire et al.’s (1997) notion of margin can be expressed as a function of the zero-one bias and variance, making it possible to formally relate a classifier ensemble’s generalization error to the base learner’s bias and variance on training examples. Experiments with the unified definition lead to further insights.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-086.pdf,
92,2000,Machine Learning and Data Mining,Generalizing Boundary Points,"Tapio Elomaa, University of Helsinki; Juho Rousu, VTT Biotechnology","The complexity of numerical domain partitioning depends on the number of potential cut points. For a large family of attribute evaluation functions only boundary points need to be considered as candidates. We prove that an even more general property holds for many commonly-used functions. They do not obtain their optimal value within a segment of examples in which the relative class frequency distribution of examples is static. The borders of such segments are a subset of boundary points. Thus, even less cut points need to be examined for these functions.The results shed a new light on the splitting properties of common attribute evaluation functions and they have practical value as well. The functions that are examined also include non-convex ones. Hence, the property introduced is not just another consequence of the convexity of a function.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-087.pdf,
93,2000,Machine Learning and Data Mining,Boosted Wrapper Induction,"Dayne Freitag, Just Research; Nicholas Kushmerick, University College Dublin","Recent work in machine learning for information extraction has focused on two distinct sub-problems: the conventional problem of filling template slots from natural language text, and the problem of wrapper induction, learning simple extraction procedures (``wrappers'') for highly structured text such as Web pages produced by CGI scripts. For suitably regular domains, existing wrapper induction algorithms can efficiently learn wrappers that are simple and highly accurate, but the regularity bias of these algorithms makes them unsuitable for most conventional information extraction tasks. Boosting is a technique for improving the performance of a simple machine learning algorithm by repeatedly applying it to the training set with different example weightings. We describe an algorithm that learns simple, low-coverage wrapper-like extraction patterns, which we then apply to conventional information extraction problems using boosting. The result is BWI, a trainable information extraction system with a strong precision bias and F1 performance competitive with or better than a state-of-the-art techniques using hidden Markov models.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-088.pdf,
94,2000,Machine Learning and Data Mining,Information Extraction with HMM Structures Learned by Stochastic Optimization,"Dayne Freitag and Andrew McCallum, Just Research","Recent research has demonstrated the strong performance of hidden Markov models applied to information extraction--the task of populating database slots with corresponding phrases from text documents. A remaining problem, however, is the selection of state-transition structure for the model. This paper demonstrates that extraction accuracy strongly depends on the selection of structure, and presents an algorithm for automatically finding good structures by stochastic optimization. Our algorithm begins with a simple model and then performs hill-climbing in the space of possible structures by splitting states and gauging performance on a validation set. Experimental results show that this technique finds HMM models that almost always out-perform a fixed model, and have superior average performance across tasks.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-089.pdf,
95,2000,Machine Learning and Data Mining,Localizing Search in Reinforcement Learning,"Greg Grudic and Lyle Ungar, University of Pennsylvania","Reinforcement learning (RL) can be impractical for many high dimensional problems because of the computational cost of doing stochastic search in large state spaces. We propose a new RL method, Boundary Localized Reinforcement Learning (BLRL), which maps RL into a mode switching problem where an agent deterministically chooses an action based on its state, and limits stochastic search to small areas around mode boundaries, drastically reducing computational cost. BLRL starts with an initial set of parameterized boundaries that partition the state space into distinct control modes. Reinforcement reward is used to update the boundary parameters using the policy gradient formulation of Sutton et al. (2000). We demonstrate that stochastic search can be limited to regions near mode boundaries, thus greatly reducing search, while still guaranteeing convergence to a locally optimal deterministic mode switching policy. Further, we give conditions under which the policy gradient can be arbitrarily well approximated without the use of any stochastic search. These theoretical results are supported experimentally via simulation.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-090.pdf,
96,2000,Machine Learning and Data Mining,Recognizing End-User Transactions in Performance Management,"Joseph L. Hellerstein, T. S. Jayram, and Irina Rish, IBM Thomas J. Watson Research Center","Providing good quality of service (e.g., low response times) in distributed computer systems requires measuring end-user perceptions of performance. Unfortunately, in practice such measures are often expensive or impossible to obtain. Herein, we propose a machine learning approach to recognizing end-user transactions consisting of sequences of remote procedure calls (RPCs) received at a server. Two problems are addressed. The first is labeling previously segmented transaction instances with the correct transaction type. This is akin to work done in document classification. The second problem is segmenting RPC sequences into transaction instances. This is a more difficult problem, but it is similar to segmenting sounds into words as in speech understanding. Using Naive Bayes, we tackle the labeling problem with four combinations of feature vectors and probability distributions: RPC occurrences with the Bernoulli distribution, RPC counts with the multinomial distribution, RPC counts with the geometric distribution, and RPC counts with the shifted geometric distribution. Our approach to segmentation searches for sequences of RPCs that have a sufficiently high probability of being a known transaction type, as determined by one of our classifiers. For both problems, good accuracies are obtained, although the labeling problem achieves higher accuracies (85\%) than does segmentation (70\%).",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-091.pdf,
97,2000,Machine Learning and Data Mining,ATMOSPHERE -- Automatic Track Mining and Objective Satellite Pattern Hunting System Using Enhanced RBF and EGDLM,"Raymond S. T. Lee and James N. K. Liu, Hong Kong Polytechnic University","Severe weather prediction, such as tropical cyclone (TC) forecast is a typical data mining and forecasting problem that involves high level data manipulation and interpretation of meteorological information such as satellite pictures and other meteorological observation data. In this paper, we present a fully automatic and integrated system known as ""ATOMOSPHER"" - Automatic Track Mining and Object Satellite Pattern Hunting system using Enhanced RBF and EGDLM - to provide a neural network based TC identification and tracking system. The proposed system consists of two main modules: 1) Object Dvorak technique for TC satellite pattern identification based on an Elastic Graph Dynamic Link Model (EGDLM) and 2) TC tracking system based on an Enhanced Radial Basis Function (RBF) network model. For system evaluation, 120 TC cases appeared in the period from 1985 to 1998 (provided by National Oceanic and Atmospheric Administration (NOAA)) are adopted. Promising results of over 87% of TC pattern segmentation and 97% of correct classification rate are attained respectively. For TC tracking, an overall of over 86% correct prediction result is achieved.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-092.pdf,
98,2000,Machine Learning and Data Mining,Learning the Common Structure of Data,"Kristina Lerman and Steven Minton, University of Southern California",The proliferation of online information sources has accentuated the need for tools that automatically validate and recognize data. We present an efficient algorithm that learns structural information about data from positive examples alone. We describe two Web wrapper maintenance applications that employ this algorithm. The first application detects when a wrapper is not extracting correct data. The second application automatically identifies data on Web pages so that the wrapper may be re-induced when the source format changes.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-093.pdf,
99,2000,Machine Learning and Data Mining,Intuitive Representation of Decision Trees Using General Rules and Exceptions,"Bing Liu, Minqing Hu, and Wynne Hsu, National University of Singapore","Producing too many rules is a major problem with many data mining techniques. This paper argues that one of the key reasons for the large number of rules is that an inefficient knowledge representation scheme has been used. The current predominant representation of the discovered knowledge is the if-then rules. This representation often severely fragments the knowledge that exists in the data, thereby resulting in a large number of rules. The fragmentation also makes the discovered rules hard to understand and to use. In this paper, we propose a more efficient representation scheme, called general rules and exceptions. In this representation, a unit of knowledge consists of a single general rule and a set of exceptions. This scheme reduces the complexity of the discovered knowledge substantially. It is also intuitive and easy to understand. This paper focuses on using the representation to express the knowledge embedded in a decision tree. An algorithm that converts a decision tree to the new representation is presented. Experiment results show that the new representation dramatically simplifies the decision tree. Real-life applications also confirm that this representation is more intuitive to the human user.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-094.pdf,
100,2000,Machine Learning and Data Mining,Selective Sampling with Redundant Views,"Ion Muslea, Steven Minton, and Craig A. Knoblock, University of Southern California","Selective sampling, a form of active learning, reduces the cost of labeling training data by asking only for the labels of the most informative unlabeled examples. We introduce a novel approach to selective sampling which we call co-testing. Co-testing can be applied to problems with redundant views (i.e., problems with multiple disjoint sets of attributes that can be used for learning). We analyze the most general algorithm in the co-testing family, naive co-testing, which can be used with virtually any type of learner. Naive co-testing simply selects at random an example on which the existing views disagree. We applied our algorithm to a variety of domains, including three real-world problems: wrapper induction, Web page classification, and discourse trees parsing. The empirical results show that besides reducing the number of labeled examples, naive co-testing may also boost the classification accuracy.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-095.pdf,
101,2000,Machine Learning and Data Mining,A Mutually Beneficial Integration of Data Mining and Information Extraction,"Un Yong Nahm and Raymond J. Mooney, University of Texas at Austin","Text mining concerns applying data mining techniques to unstructured text. Information extraction (IE) is a form of shallow text understanding that locates specific pieces of data in natural language documents, transforming unstructured text into a structured database. This paper describes a system called DiscoTEX, that combines IE and data mining methodologies to perform text mining as well as improve the performance of the underlying extraction system. Rules mined from a database extracted from a corpus of texts are used to predict additional information to extract from future documents, thereby improving the recall of IE. Encouraging results are presented on applying these techniques to a corpus of computer job postings from an Internet newsgroup.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-096.pdf,
102,2000,Machine Learning and Data Mining,Multivariate Clustering by Dynamics,"Marco Ramoni, The Open University; Paola Sebastiani, Imperial College; Paul Cohen, University of Massachusetts",We present a Bayesian clustering algorithm for multivariate time series. A clustering is represented as a probabilistic model in which the unknown auto-correlation structure of a time series is approximated by a first order Markov Chain and the overall joint distribution of the variables is simplified by conditional independence assumptions. The algorithm searches for the most probable set of clusters given the data using a entropy-based heuristic search method. The algorithm is evaluated on a batch of multivariate time series of propositions produced by a mobile robot perceptual system.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-097.pdf,
103,2000,Machine Learning and Data Mining,Toward a Theory of Learning Coherent Concepts,"Dan Roth and Dmitry Zelenko, University of Illinois at Urbana-Champaign","We develop a theory for learning scenarios where multiple learners co-exist but there are mutual compatibility constraints on theiroutcomes. This is natural in cognitive learning situations, where multiple learning tasks co-exist but there are mutual compatibility constraints on their outcomes, so that a valid sentence, image or any other domain representation is produced.We suggest that work in this direction may help to resolve the contrast between the hardness of learning as predicted by the current theoretical models and the apparent ease at which cognitive systems seem to learn.A model of concept learning is studied in which the target concept is required to cohere with other concepts of interest. The coherency is expressed via a (Boolean) constraint that the concepts have to satisfy. Under this model, learning a concept is shown to be easier (in terms of sample complexity and mistake bounds) and the concepts learned are shown to be more robust to noise in their input (attribute noise). These properties are established for half spaces and the connection to large margin theory is discussed.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-098.pdf,
104,2000,Machine Learning and Data Mining,Empirical Evaluation of a Reinforcement Learning Spoken Dialogue System,"Satinder Singh, Michael Kearns, Diane J. Litman, and Marilyn A. Walker, AT&T Labs","We report on the design, construction, and empirical evaluation of a large-scale spoken dialogue system that optimizes its performancevia reinforcement learning on human user dialogue data.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-099.pdf,
105,2000,Machine Learning and Data Mining,Unsupervised Learning and Interactive Jazz/Blues Improvisation,"Belinda Thom, Carnegie Mellon University","We present a new and exciting domain for unsupervised learning: automatically customizing the computer to a specific melodic performer by listening to them improvise. We also describe our system BoB, which performs this task in the context of real-time solo trading. We develop a probabilistic mixture model of variable-sized multinomials and a procedure that uses this model to learn how to perceive/generate variable-sized histograms. This model is used to cluster bars of improvisation based on the nominal pitch-classes played therein, which adds a new dimension to the problem: the need to learn from sparse data. With simulated data, we show that useful results can be learned with sparse histograms. In BoB, we show that this approach enables powerful musical abstractions to emerge on multiple levels for bebop saxaphonist Charlie Parker.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-100.pdf,
106,2000,Machine Learning and Data Mining,Restricted Bayes Optimal Classifiers,"Simon Tong and Daphne Koller, Stanford University","We introduce the notion of restricted Bayes optimal classifiers. These classifiers attempt to combine the flexibility of the generative approach to classification with the high accuracy associated with discriminative learning. They first create a model of the joint distribution over class labels and features. Instead of choosing the decision boundary induced directly from the model, they restrict the allowable types of decision boundaries and learn the one that minimizes the probability of misclassification relative to the estimated joint distribution. In this paper, we investigate two particular instantiations of this approach. The first uses a non-parametric density estimator - Parzen Windows with Gaussian kernels - and hyperplane decision boundaries. We show that the resulting classifier is asymptotically equivalent to a maximal margin hyperplane classifier, a highly successful discriminative classifier. We therefore provide an alternative justification for maximal margin hyperplane classifiers. The second instantiation uses a mixture of Gaussians as the estimated density; in experiments on real-world data, we show that this approach allows data with missing values to be handled in a principled manner, leading to improved performance over regular discriminative approaches.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-101.pdf,
107,2000,Machine Learning and Data Mining,A Quantitative Study of Small Disjuncts,"Gary M. Weiss and Haym Hirsh, Rutgers University","Systems that learn from examples often express the learned concept in the form of a disjunctive description. Disjuncts that correctly classify few training examples are known as small disjuncts and are interesting to machine learning researchers because they have a much higher error rate than large disjuncts. Previous research has investigated this phenomenon by performing ad hoc analyses of a small number of datasets. In this paper we present a quantitative measure for evaluating the effect of small disjuncts on learning, and use it to analyze thirty benchmark datasets. We investigate the relationship between small disjuncts and pruning, training set size and noise to an extent that was not previously possible.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-102.pdf,
108,2000,Natural Language Processing and Information Retrieval,Translating with Scarce Resources,"Yaser Al-Onaizan, Ulrich Germann, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Daniel Marcu, and Kenji Yamada, University of Southern California","Current corpus-based machine translation techniques do not work very well when given scarce linguistic resources. To examine the gap between human and machine translators, we created an experiment in which human beings were asked to translate an unknown language into English on the sole basis of a very small bilingual text. Participants performed quite well, and debriefings revealed a number of valuable strategies. We discuss these strategies and apply some of them to a statistical translation system.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-103.pdf,
109,2000,Natural Language Processing and Information Retrieval,The Rules Behind Roles: Identifying Speaker Role in Radio Broadcasts,"Regina Barzilay, Columbia University; Michael Collins, Julia Hirschberg, and Steve Wittaker, AT&T Labs -- Research",Previous work has shown that providing information about story structure is critical for browsing audio broadcasts. We investigate the hypothesis that Speaker Role is an important cue to story structure. We implement an algorithm that classifies story segments into three Speaker Roles based on several content and duration features. The algorithm correctly classifies about 80\% of segments (compared with a baseline frequency of 36\%) when applied to ASR derived transcriptions of broadcast data.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-104.pdf,
110,2000,Natural Language Processing and Information Retrieval,Cognitive Status and Form of Reference in Multimodal Human-Computer Interaction,"Andrew Kehler, University of California, San Diego","We analyze a corpus of referring expressions collected from user interactions with a multimodal travel guide application. The analysis suggests that, in dramatic contrast to human-human interaction, the interpretation of referring expressions can be computed with very high accuracy using a model which pairs a highly impoverished notion of discourse state with a simple set of rules that are insensitive to the type of referring expression used. We attribute this unexpected result to the implicit manner in which the interface conveys the system’s beliefs about the operative discourse state, to which users appear to tailor their choice of referring expressions. This result offers new insight into the way that computer interfaces can shape a user’s language behavior, insights which can be exploited to bring otherwise difficult interpretation problems into the realm of tractability.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-105.pdf,
111,2000,Natural Language Processing and Information Retrieval,Class-Based Construction of a Verb Lexicon,"Karin Kipper, Hoa Trang Dang, and Martha Palmer, University of Pennsylvania","We present an approach to building a verb lexicon compatible with WordNet but with explicitly stated syntactic and semantic information, using Levin verb classes to systematically construct lexical entries. By using verb classes we capture generalizations about verb behavior and reduce the effort needed to construct the lexicon. The syntactic frames for the verb classes are represented by a Lexicalized Tree Adjoining Grammar augmented with semantic predicates, which allows a compositional interpretation.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-106.pdf,
112,2000,Natural Language Processing and Information Retrieval,Preserving Ambiguities in Generation via Automata Intersection,"Kevin Knight and Irene Langkilde, University of Southern California","When human beings produce summaries of documents, they do not simply extract sentences and concatenate them. Rather, they create new sentences that are grammatical, that cohere with one another, and that capture the most salient pieces of information in the original document. Given that large collections of text/abstract pairs are available online, it is now possible to envision algorithms that are trained to mimic this process. In this paper, we focus on sentence compression, a simpler version of this larger challenge. We aim to achieve two goals simultaneously: our compressions should be grammatical, and they should retain the most important pieces of information. These two goals can conflict. We devise both noisy-channel and decision-tree approaches to the problem, and we evaluate results against manual compressions and a simple baseline.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-107.pdf,
113,2000,Natural Language Processing and Information Retrieval,Statistics-Based Summarization -- Step One: Sentence Compression,"Kevin Knight and Daniel Marcu, University of Southern California","We discuss the problem of generating text that preserves certain ambiguities, a capability that is useful in applications such as machine translation. We show that it is relatively simple to extend a hybrid symbolic/statistical generator to do ambiguity preservation. The paper gives algorithms and examples, and it discusses practical linguistic difficulties that arise in ambiguity preservation.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-108.pdf,
114,2000,Natural Language Processing and Information Retrieval,Estimating Word Translation Probabilities from Unrelated Monolingual Corpora Using the EM Algorithm,"Philipp Koehn and Kevin Knight, University of Southern California","Selecting the right word translation among several options in the lexicon is a core problem for machine translation. We present a novel approach to this problem that can be trained using only unrelated monolingual corpora and a lexicon. By estimating word translation probabilities using the EM algorithm, we extend upon target language modeling. We construct a word translation model for 3830 German and 6147 English noun tokens, with very promising results.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-109.pdf,
115,2000,Natural Language Processing and Information Retrieval,The Automatic Interpretation of Nominalizations,"Maria Lapata, University of Edinburgh","This paper discusses the interpretation of compound nouns in domain independent wide-coverage text. We focus on the interpretation of nominalizations, i.e., compounds whose head noun is a nominalized verb and whose prenominal modifier is derived from either the underlying subject or direct object of this verb (Levi 1978). Examples of nominalizations are given in (1)-(3).(1) datum holder(2) neighbour behaviour(3) reader receptionAny attempt to automatically interpret nominalizations needs to take into account: (a) the selectional constraints imposed by the deverbal compound head, (b) the fact that these constraints can be easily overridden by contextual or pragmatic factors, and (c) the fact that the relation of the modifier and the head noun can be ambiguous out of context (see example (3)). The interpretation of nominalizations poses a challenge for probabilistic approaches since the argument relations between a head and its modifier are not readily available in the corpus.We present a probabilistic model which treats the interpretation task as a disambiguation problem. We show how the severe sparse data problems can be overcome by using partial parsing, smoothing techniques and domain independent taxonomic information (e.g., WordNet). We report on the results of four experiments which achieve a combined precision of 80% over a baseline of 59% on the British National Corpus, a 100 million word collection of samples of written and spoken language from a wide range of sources designed to represent a wide cross-section of current British English.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-110.pdf,
116,2000,Natural Language Processing and Information Retrieval,Predicting and Adapting to Poor Speech Recognition in a Spoken Dialogue System,"Diane J. Litman, AT&T Labs -- Research; Shimei Pan, Columbia University","Spoken dialogue system performance can vary widely for different users, as well as for the same user during different dialogues. This paper presents the design and evaluation of an adaptive spoken dialogue system. The system predicts whether a user is having speech recognition problems as a particular dialogue progresses, and automatically adapts its dialogue strategies based on its predictions. An empirical evaluation demonstrates the utility of the approach.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-111.pdf,
117,2000,Natural Language Processing and Information Retrieval,Social Choice Theory and Recommender Systems: Analysis of the Axiomatic Foundations of Collaborative Filtering,"David M. Pennock, NEC Research Institute; Eric Horvitz, Microsoft Research; C. Lee Giles, NEC Research Institute","The growth of Internet commerce has stimulated the use of collaborative filtering (CF) algorithms as recommender systems. Such systems leverage knowledge about the behavior of multiple users to recommend items of interest to individual users. CF methods have been harnessed to make recommendations about such items as web pages, movies, books, and toys. Researchers have proposed several variations of the technology. We take the perspective of CF as a methodology for combining preferences. The preferences predicted for the end user is some function of all of the known preferences for everyone in a database. Social Choice theorists, concerned with the properties of voting methods, have been investigating preference aggregation for decades. At the heart of this body of work is Arrow’s result demonstrating the impossibility of combining preferences in a way that satisfies several desirable and innocuous-looking properties. We show that researchers working on CF algorithms often make similar assumptions. We elucidate these assumptions and extend results from Social Choice theory to CF methods. We show that only very restrictive CF functions are consistent with desirable aggregation properties. Finally, we discuss practical implications of these results.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-112.pdf,
118,2000,Natural Language Processing and Information Retrieval,Learning Subjective Adjectives from Corpora,"Janyce M. Wiebe, New Mexico State University","Subjectivity tagging is distinguishing sentences used to present opinions and evaluations from sentences used to objectively present factual information. There are numerous applications for which subjectivity tagging is relevant, including information extraction and information retrieval. This paper identifies strong clues of subjectivity using the results of a method for clustering words according to distributional similarity (Lin 1998), seeded by a small amount of detailed manual annotation. These features are then further refined with the addition of lexical semantic features of adjectives, specifically polarity and gradability (Hatzivassiloglou and McKeown 1997), which can be automatically learned from corpora. In 10-fold cross validation experiments, features based on both similarity clusters and the lexical semantic features are shown to have higher precision than features based on each alone.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-113.pdf,
119,2000,Planning and Scheduling,Iterative Flattening: A Scalable Method for Solving Multi-Capacity Scheduling Problems,"Amedeo Cesta and Angelo Oddi, IP-CNR, National Research Council of Italy; Stephen F. Smith, Carnegie Mellon University","One challenge for research in constraint-based scheduling has been to produce scalable solution procedures under fairly general representational assumptions. Quite often, the computational burden of techniques for reasoning about more complex types of temporal and resource capacity constraints places fairly restrictive limits on the size of problems that can be effectively addressed. In this paper, we focus on developing a scalable heuristic procedure to an extended, multi-capacity resource version of the job shop scheduling problem (MCJSSP). Our starting point is a previously developed procedure for generating feasible solutions to more complex, multi-capacity scheduling problems with maximum time lags. Adapting the procedure to exploit the simpler temporal structure of MCJSSP, we are able to produce a quite efficient solution generator. However, the procedure only indirectly attends to MCJSSP’s objective criteria and produces sub-optimal solutions. To provide a scalable, optimizing procedure, we propose a simple, local-search procedure called {\em iterative flattening}, which utilizes the core solution generator to perform an extended iterative improvement search. Despite its simplicity, experimental analysis shows the iterative improvement search to be quite effective. On a set of reference problems ranging in size from 100 to 900 activities, the iterative flattening procedure efficiently and consistently produces solutions within 10\% of computed upper bounds. Overall, the concept of iterative flattening is quite general and provides an interesting new basis for designing more sophisticated local search procedures.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-114.pdf,
120,2000,Planning and Scheduling,Planning as Satisfiability in Nondeterministic Domains,"Paolo Ferraris and Enrico Giunchiglia, DIST -- Universit&eagrave di Genova","We focus on planning as satisfiability in simple nondeterministic domains. By ``simple'' we mean specified in a simple extension to the STRIPS formalism allowing for specifying actions with nondeterministic effects. This allows us to simplify and extend the theory presented in (XXXXXX KR'2000). The result is a planning system which, on simple nondeterministic domains, is competitive with other state-of-the-art planners.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-115.pdf,
121,2000,Planning and Scheduling,Open World Planning in the Situation Calculus,"Alberto Finzi and Fiora Pirri, Universit&eagrave degli Studi di Roma ""La Sapienza""; Ray Reiter, University of Toronto","We describe a forward reasoning planner for open worlds that uses domain specific information for pruning its search space. The planner is written in the situation calculus-based programming language GOLOG, and it uses a situation calculus axiomatization of the application domain. Given a sentence sigma to prove,the planner regresses it to an equivalent sentence sigma0 about the initial situation, then invokes a theorem prover to determine whether the initial database entails sigma0 and hence sigma. We describe two approaches to this theorem proving task, one based on compiling the initial database to prime implicate form, the other based on Relsat, a Davis/Putnam-based procedure. Finally, we report on our experiments with open world planning based on both these approaches to the theorem proving task.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-116.pdf,
122,2000,Planning and Scheduling,Discovering State Constraints in DISCOPLAN: Some New Results,"Alfonso Gerevini, Universit&eagrave di Brescia; Lenhart Schubert, University of Rochester","DISCOPLAN is an implemented set of efficient preplanning algorithms intended to enable faster domain-independent planning. It includes algorithms for discovering state constraints (invariants) that have been shown to be very useful, for example, for speeding up SAT-based planning. DISCOPLAN originally discovered only certain types of implicative constraints involving up to two fluent literals and any number of static literals, where one of the fluent literals contains all of the variables occurring in the other literals; only planning domains with strips-like operators were handled. We have now extended discoplan in several directions. We describe new techniques that handle operators with conditional effects, and enable discovery of several new types of constraints. Moreover, discovered constraints can be fed back into the discovery process to obtain additional constraints. Finally, we outline unimplemented (but provably correct) methods for discovering additional types of constraints, including XOR constraints, and constraints involving arbitrarily many fluent literals.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-117.pdf,
123,2000,Planning and Scheduling,A Logic for Planning under Partial Observability,"A. Herzig, J. Lang, D. Longin, and T. Polacsek, IRIT-UPS","We propose an epistemic dynamic logic EDL able to represent the interactions between action and knowledge that are fundamental to planning under partial observability. EDL enables us representing incomplete knowledge, nondeterministic actions, observations, sensing actions and conditional plans; it also enables a logical expression of several frequently made assumptions about the nature of the domain, such as determinism, full observability, unobservability, or pure sensing. Plan verification corresponds to checking the validity of a given EDL formula. The allowed plans are conditional, and a key point of our framework is that a plan is meaningful if and only if the branching conditions bear on the knowledge of the agent only, and not on the real world (to which that agent may not have access); this leads us to consider ``plans that reason'' which may contain branching conditions referring to implicit knowledge to be evaluated at execution time.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-118.pdf,
124,2000,Planning and Scheduling,Graph Construction and Analysis as a Paradigm for Plan Recognition,"Jun Hong, University of Ulster at Jordanstown","We present a novel approach to plan recognition in which graph construction and analysis is used as a paradigm. We use a graph structure called a Goal Graph for the plan recognition problem. The Goal Graph is first constructed to represent the observed actions, the state of the world, and the achieved goals at consecutive time steps. It also represents various connections between nodes in the Goal Graph. The Goal Graph can then be analysed at each time step to recognise those achieved goals that are consistent with the actions observed so far. The Goal Graph analysis can also reveal valid plans for the recognised goals or part of the recognised goals. We describe two algorithms, GoalGraphConstructor and GoalGraphAnalyser, based on this paradigm. These algorithms are sound, polynomial-time and polynomial-space. The algorithms have been tested in two domains with up to 245 goal schemata and 100000 possible goals. They perform well in these domains in terms of efficiency, accuracy and scalability.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-119.pdf,
125,2000,Planning and Scheduling,Solving a Supply Chain Optimization Problem Collaboratively,"Hoong Chuin Lau, Andrew Lim, and Qi Zhang Liu, National University of Singapore","We propose a novel algorithmic framework to solve an integrated planning and scheduling problem in supply chain management. This problem involves the integration of an inventory management problem and the vehicle routing problem with time windows, both of which are known to be NP-hard. Under this framework, algorithms that solve the underlying sub-problems collaborate rigorously yet in a computationally efficient manner to arrive at a good solution. We will then present two algorithms to solve the inventory management problem: a complete mathematical model integrating integer programming with constraint programming, and an incomplete algorithm based on tabu search. We present experimental results based on extended Solomon benchmark vehicle routing problems.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-120.pdf,
126,2000,Planning and Scheduling,From Causal Theories to Successor State Axioms and STRIPS-Like Systems,"Fangzhen Lin, The Hong Kong University of Science and Technology","We describe a system for specifying the effects of actions. Unlike those commonly used in AI planning, our system uses an action description language that allows one to specify the effects of actions using domain rules, which are state constraints that can entail new action effects from old ones. Declaratively, an action domain in our language corresponds to a nonmonotonic causal theory in the situation calculus. Procedurally, such an action domain is compiled into a set of propositional theories, one for each action in the domain, from which fully instantiated successor state-like axioms and STRIPS-like systems are then generated. We expect the system to be a useful tool for knowledge engineers writing action specifications for classical AI planning systems, GOLOG systems, and other systems where formal specifications of actions are needed.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-121.pdf,
127,2000,Planning and Scheduling,TCBB Scheme: Applications to Single Machine Job Sequencing Problems,"Sakib A. Mondal, Infosys Technologies Limited, India; Anup K. Sen, New Jersey Institute of Technology","Transpose-and-Cache Branch-and-Bound (TCBB) has shown promise in solving large single machine quadratic penalty problems. There exist other classes of single machine job sequencing problems which are of more practical importance and which are also of considerable interest in the area of AI search. In the weighted earliness tardiness problem (WET), the best known heuristic estimate is not consistent; this is contrary to the general belief about relaxation-based heuristic. In the quadratic penalty problem involving setup times (SQP) of jobs, the evaluation function is non-order-preserving In this paper, we present the TCBB scheme to solve these problems as well. Experiments indicate that (i) for the WET problem, the TCBB scheme is highly effective in solving large problem instances and (ii) for the SQP problem, it can solve larger instances than algorithm GREC in a given available memory.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-122.pdf,
128,2000,Planning and Scheduling,Extracting Effective and Admissible State Space Heuristics from the Planning Graph,"XuanLong Nguyen and Subbarao Kambhampati, Arizona State University","Graphplan and heuristic state space planners such as HSP-R and UNPOP are two of the most effective approaches for solving classical planning problems. These approaches have hither-to been seen as largely orthogonal. In this paper, we show that the planning graph structure that Graphplan builds in polynomial time, provides a rich substrate for deriving more effective heuristics for state space planners. Specifically, we show that the heuristics used by planners such as HSP-R and UNPOP do badly in several domains due to their failure to consider the interactions between subgoals, and that the mutex information in the planning graph captures exactly this interaction information. We develop several families of heuristics, some aimed at search speed and others at optimality of solutions. Our empirical studies show that our heuristics significantly out-perform the existing state space heuristics",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-123.pdf,
129,2000,Planning and Scheduling,An Iterative Algorithm for Synthesizing Invariants,"Jussi Rintanen, Albert-Ludwigs-Universität Freiburg","We present a general algorithm for synthesizing state invariants that speed up automated planners and have other applications in reasoning about change. Invariants are facts that hold in all states that are reachable from an initial state by the application of a number of operators. In comparison to earlier work on synthesizing invariants, we recognize the fact that establishing an invariant may require considering other invariants, and this in turn seems to require viewing synthesis of invariants as fixpoint computation. Also, our algorithm is not inherently restricted to invariants of particular syntactic forms.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-124.pdf,
130,2000,Planning and Scheduling,RealPlan: Decoupling Causal and Resource Reasoning in Planning,"Biplav Srivastava, Arizona State University","Recent work has demonstrated that treating resource reasoning separately from causal reasoning can lead to improved planning performance and rational resource management where increase in resources does not degrade planning performance. However, the resources were scheduled procedurally and limited to cases that could be solved backtrack-free. Terming the decoupled framework as RealPlan, in this work, I extend it with a general approach to convert the resource allocation problem as a declaratively specified dynamic constraint satisfaction problem (DCSP), compile it into CSP and solve it with a CSP solver. By doing so, the resource scheduling problem can be handled in its full complexity and can provide a computational characterization of the different scheduling classes. The CSP formulation also facilitates planner-scheduler interaction by helping the scheduler interpret the resource allocation policies proposed by the planner in terms of constraints on values of scheduling variables. Moreover, if the extraction of causal plan is also formulated as a CSP problem, the two CSPs can enable dependency directed backtracking between them. I have implemented declarative scheduling on top of Graphplan and GP-CSP planners (which poses the backward search of Graphplan as a CSP problem), and the resulting planners reiterate the benefits of decoupling planning and scheduling while providing elegant CSP models (RealPlan-MS, RealPlan-PP) for investigating planner-scheduler communication.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-125.pdf,
131,2000,Planning and Scheduling,Gridworlds as Testbeds for Planning with Incomplete Information,"Craig Tovey and Sven Koenig, Georgia Institute of Technology","Gridworlds are popular testbeds for planning with incomplete information but not much is known about their properties. We study a fundamental planning problem, localization, to investigate whether gridworld make good testbeds for planning with incomplete information. We find empirically that greedy planning methods that interleave planning and plan execution can localize robots very quickly on gridworlds with random obstacles. Thus random gridworlds may not provide adequately challenging testbeds. On the other hand, we show that finding localization plans that are within a log factor of optimal is NP-hard. Thus there are instances of gridworlds on which all greedy planning methods perform very poorly, and we show how to construct them. These theoretical results help empirical researchers to select appropriate planning methods as well as testbeds to demonstrate them.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-126.pdf,
132,2000,Robotics,Performance Comparison of Landmark Recognition Systems for Navigating Mobile Robots,"Tom Duckett, University of Örebro; Ulrich Nehmzow, University of Manchester","Self-localization is an essential competence for mobile robot navigation. Due to the fundamental unreliability of dead reckoning, a robot must depend on its perception of external environmental features or landmarks to localize itself. A key question is how to evaluate landmark recognition systems for mobile robots. This paper answers this question by means of quantitative performance measures. An empirical study is presented in which a number of algorithms are compared in four environments. The results of this analysis are then applied to the development of a novel landmark recognition system for a Nomad~200 robot. Subsequent experiments demonstrate that the new system obtains a similar level of performance to the best alternative method, but at a much lower computational cost.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-127.pdf,
133,2000,Robotics,Active Audition for Humanoid,"Kazuhiro Nakadai and Tino Lourens, Japan Science and Technology Corporation; Hiroshi G. Okuno, Japan Science and Technology Corporation and Science University of Tokyo; Hiroaki Kitano, Japan Science and Technology Corporation and Sony Computer Science Laboratories, Inc.","In this paper, we present an active audition system for humanoid robot {\it SIG}. The audition system of the highly intelligent humanoid requires localization of sound sources and identification of meanings of the sound in the auditory scene. The active audition reported in this paper focuses on improved sound source tracking by integrating audition, vision, and motor movements and their motion information. Given the multiple sound sources in the auditory scene, {\it SIG the humanoid} actively moves its head to improve localization by aligning microphones orthogonal to the sound source and by capturing the possible sound sources by vision. However, such an active head movement inevitably creates motor noise. The system must adaptively cancel motor noise using motor control signals. The experimental result demonstrates that the active audition by integration of audition, vision, and motor control enables sound source tracking in variety of conditions.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-128.pdf,
134,2000,Robotics,Property Mapping: A Simple Technique for Mobile Robot Programming,"Illah R. Nourbakhsh, Carnegie Mellon University","In this paper we turn to the mobile robot programming problem, which is a software engineering challenge that is not easily conquered using contemporary software engineering best practices. We propose robot observability as a measure of the diagnostic transparency of a situated robot program, then describe property mapping as a simple language-independent approach to implementing reliable robot programs by maximizing robot observability. Examples from working real-world robots are given in Lisp and Java.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-129.pdf,
135,2000,Robotics,A Method for Clustering the Experiences of a Mobile Robot that Accords with Human Judgments,"Tim Oates, Matthew D. Schmill, and Paul R. Cohen, University of Massachusetts","If robotic agents are to act autonomously they must have the ability to construct and reason about models of their physical environment. For example, planning to achieve goals requires knowledge of how the robot’s actions affect the state of the world over time. The traditional approach of hand-coding this knowledge is often quite difficult, especially for robotic agents with rich sensing abilities that exist in dynamic and uncertain environments. Ideally, robots would acquire knowledge of their environment and then use this knowledge to act. We present an unsupervised learning method that allows a robotic agent to identify and represent qualitatively different outcomes of actions. Experiments with a Pioneer-1 mobile robot demonstrate the utility of the approach with respect to capturing the structure and dynamics of a complex, real-world environment, and show that the models acquired by the robot correlate surprisingly well with human models of the environment.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-130.pdf,
136,2000,Robotics,Coordination for Multi-Robot Exploration and Mapping,"Reid Simmons and David Apfelbaum, Carnegie Mellon University; Wolfram Burgard, University of Freiburg; Dieter Fox, Carnegie Mellon University; Mark Moors, University of Bonn; Sebastian Thrun and Håkan Younes, Carnegie Mellon University","This paper addresses the problem of exploration and mapping of an unknown environment by multiple robots. The mapping algorithm is an on-line approach to likelihood maximization that uses hill climbing to find maps that are maximally consistent with sensor data and odometry. The exploration algorithm explicitly coordinates the robots, based on estimates of expected information gain at different locations. It tries to maximize overall utility by minimizing the potential for overlap in information gain amongst the various robots. For both the exploration and mapping algorithms, most of the computations are distributed. The techniques have been tested extensively in real-world trials and simulations. The results demonstrate the performance improvements and robustness that accrue from our multi-robot approach to exploration.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-131.pdf,
137,2000,Robotics,Monte Carlo Localization with Mixture Proposal Distribution,"Sebastian Thrun and Dieter Fox, Carnegie Mellon University; Wolfram Burgard, University of Freiburg","Recently, Monte Carlo localization (MCL) has been applied successfully to state estimation problems mobile robotics. This paper points out a limitation of MCL that is counter-intuitive, namely that better sensors can yield worse results. An analysis of this problem leads to the formulation of the ``dual'' MCL algorithm, which works well in cases were MCL fails. Combining both, MCL and its dual, leads to an extremely robust filter that consistently outperforms MCL and dual MCL.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-132.pdf,
138,2000,Robotics,Appearance-Based Obstacle Detection with Monocular Color Vision,"Iwan Ulrich and Illah Nourbakhsh, Carnegie Mellon University","This paper presents a new vision-based obstacle detection method for mobile robots. Each individual image pixel is classified as belonging either to an obstacle or the ground based on its color appearance. The method uses a single passive color camera, performs in real-time, and provides a binary obstacle image at high resolution. The system is easily trained by simply driving the robot through its environment. In the adaptive mode, the system keeps learning the appearance of the ground during operation. The system has been tested successfully in a variety of environments, indoors as well as outdoors.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-133.pdf,
139,2000,Robotics,Multi-Fidelity Robotic Behaviors: Acting with Variable State Information,"Elly Winner and Manuela Veloso, Carnegie Mellon University","Our work is driven by one of the core purposes of artificial intelligence: to develop real robotic agents that achieve complex high-level goals in real-time environments. Robotic behaviors select actions as a function of the state of the robot and of the world. Designing robust and appropriate robotic behaviors is a well-recognized and difficult problem due to the noise, uncertainty and cost of acquiring the necessary state information. We addressed this challenge within the concrete domain of robotic soccer with the fully autonomous Sony legged robots. In this paper, we present one of the outcomes of this research: the introduction of multi-fidelity behaviors to explicitly and efficiently adapt to different levels of state information accuracy. The paper motivates and introduces our general approach and then reports on our concrete work with the Sony robots. The multi-fidelity behaviors we developed allow the robots to successfully achieve their goals in a dynamic and adversarial environment. A robot acts according to a set of behaviors that aggressively balance the cost of acquiring state information with the value of that information to the robot’s ability to achieve its high-level goals. The paper includes empirical experiments which support our method of balancing the cost and benefit of the incrementally-accurate state information.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-134.pdf,
140,2000,Search,Dynamic Representations and Escaping Local Optima: Improving Genetic Algorithms and Local Search,"Laura Barbulescu, Jean-Paul Watson, and L. Darrell Whitley, Colorado State University","Local search algorithms often get trapped in local optima.Algorithms such as tabu search and simulated annealing 'escape' local optima by accepting non-improving moves. Another possibility is to dynamically change between representations; a local optimum under one representation may not be a local optimum under another. \emph{Shifting} is a mechanism which dynamically switches between Gray code representations in order to escape local optima. Gray codes are widely used in conjunction with genetic algorithms and bit-climbing algorithms for parameter optimization problems. We present new theoretical results that substantially improve our understanding of the shifting mechanism, on the number of Gray codes accessible via shifting, and on how neighborhood structure changes during shifting. We show that shifting can significantly improve the performance of a simple hill-climber; it can also help to improve one of the best genetic algorithms currently available.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-135.pdf,
141,2000,Search,Localizing A*,"Stefan Edelkamp, Institut für Informatik; Stefan Schrödl, DaimlerChrysler Research and Technology","Heuristic search in large problem spaces inherently calls for algorithms capable of running under restricted memory. This question has been investigated in a number of articles. However, in general the efficient usage of two-layered storage systems is not further discussed. Even if hard-disk capacity is sufficient for the problem instance at hand, the limitation of main memory}may still represent the bottleneck for their practical applications. Since breadth-first and best-first strategies do not exhibit any locality of expansion, standard virtual memory management can soon result in thrashing due to excessive page faults. In this paper a new extension scheme to the A* algorithm is proposed which minimizes page faults by reordering the sequence of expansions. We prove its admissibility and evaluate it in a real-world scenario of searching a large road map in a route planning system.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-136.pdf,
142,2000,Search,Speeding up the Convergence of Real-Time Search,"David Furcy and Sven Koenig, Georgia Institute of Technology","Learning Real-Time A* (LRTA*) is a real-time search method that makes decisions fast and still converges to a shortest path when solving the same planning task repeatedly. In this paper, we propose new methods to speed up its convergence. We show that LRTA* often converges significantly faster when it breaks ties towards successors with smallest f-values (a la A*) and even faster when it moves to successors with smallest f-values instead of only breaking ties in favor of them. FALCONS, our novel real-time search method, uses a sophisticated implementation of this successor-selection rule and thus selects successors very differently from LRTA*, which always minimizes the estimated cost to go. We first prove that FALCONS terminates and converges to a shortest path, and then present experiments in which FALCONS finds a shortest path up to sixty percent faster than LRTA* in terms of action executions and up to seventy percent faster in terms of trials. This paper opens up new avenues of research for the design of novel successor-selection rules that speed up the convergence of both real-time search methods and reinforcement-learning methods.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-137.pdf,
143,2000,Search,Change Detection in Heuristic Search,"Eyke Hüllermeier, IRIT -- Université Paul Sabatier","The order in which nodes are explored in a (depth-first) iterative deepening search strategy is principally determined by the condition under which a path of the search tree is cut off in each search phase. A corresponding criterion, which has a strong influence on the performance of the overall (heuristic) search procedure, is generally realized in form of an upper cost bound. In this paper, we develop an effective and computationally efficient termination criterion based on statistical methods of change detection. The criterion is local in the sense that it depends on properties of a path itself, rather than on the comparison with other paths. Loosely spoken, the idea is to take a systematic change in the (heuristic) evaluation of nodes along a search path as an indication of suboptimality. An expected utility criterion which also takes the consequence of the suboptimal search decision on the solution quality into account is proposed as a generalization of this idea.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-138.pdf,
144,2000,Search,Preference-Based Search for Scheduling,"Ulrich Junker, ILOG","Preference-based search (PBS) is a new search procedure for solving combinatorial optimization problems. Given a set of preferences between search decisions, PBS searches through a space of preferred solutions, which is tighter than the space of all solutions. The definition of preferred solutions is based on work in nonmonotonic reasoning (Brewka 1989; Geffner 1990; Grosof 1991) on priorities between defaults. The basic idea of PBS is quite simple: Always pick a locally best decision alpha. Either make this decision alpha or make other locally best decisions that allow to deduce not alpha and thus represent a counterargument for alpha. If there is no possible counterargument then PBS does not explore the subtree of not alpha. Further pruning of the search space is obtained by nonmonotonic inference rules that are inspired by Doyle’s TMS and that detect decisions belonging to all or none preferred solution. We show that PBS can optimally solve various important scheduling problems. First experimental results for job-shop scheduling problems such as MT20 are encouraging.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-139.pdf,
145,2000,Search,Divide-and-Conquer Frontier Search Applied to Optimal Sequence Alignment,"Richard E. Korf, University of California, Los Angeles; Weixiong Zhang, USC Information Sciences Institute","We present a new algorithm that reduces the space complexity of heuristic search. It is most effective for problem spaces that grow polynomially with problem size, but contain large numbers of short cycles. For example, the problem of finding an optimal global alignment of several DNA or amino-acid sequences can be solved by finding a lowest-cost corner-to-corner path in a d-dimensional grid. A previous algorithm, called divide-and-conquer bidirectional search, saves memory by storing only the Open lists and not the Closed lists. We show that this idea can be applied in a unidirectional search as well. This extends the technique to problems where bidirectional search is not applicable, and is more efficient in both time and space than the bidirectional version. If n is the length of the strings, and d is the number of strings, this algorithm can reduce the memory requirement from O(n^d) to O(n^(d-1)). While our current implementation of DCFS is somewhat slower than existing dynamic programming approaches for optimal alignment of multiple gene sequences, DCFS is a more general algorithm.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-140.pdf,
146,2000,Search,Asynchronous Search with Aggregations,"Marius Calin Silaghi, Djamila Sam-Haroud, and Boi Faltings, Swiss Federal Institute of Technology","Many problem-solving tasks can be formalized as constraint satisfaction problems (CSPs). In a multi-agent setting, information about constraints and variables may be distributed among different agents and kept confidential. Existing algorithms for distributed constraint satisfaction consider mainly the case where access to variables is restricted to certain agents, but constraints may have to be revealed. In this paper, we propose methods where constraints are private but variables can be manipulated by any agent. We describe a new search technique for distributed CSPs, called asynchronous aggregation search (AAS). It differs from existing methods in that it treats sets of partial solutions, exchanges information about aggregated valuations for combinations of variables and uses customized messages to allow distributed solution detection. Three new distributed backtracking algorithms based on AAS are then presented and analyzed. While the approach we propose provides a more general framework for dealing with privacy requirements on constraints, its overall performance is comparable or better than that of existing methods, as shown by the experiments.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-141.pdf,
147,2000,Search,A* with Partial Expansion for Large Branching Factor Problems,"Takayuki Yoshizumi, Teruhisa Miura, and Toru Ishida, Kyoto University","The multiple sequence alignment problem is one of the important problems in Genome Informatics. The notable feature of this problem is that its state-space forms a lattice. Researchers have applied search algorithms such as A* and memory-bounded search algorithms including SNC to this problem. Unfortunately, previous work could align only seven sequences at most. Korf proposed DCBDS, which exploits the features of a grid, and suggested that DCBDS probably solved this problem, effectively. We found, however, that DCBDS was not effective for aligning many sequences. In this paper, we propose a simple and effective search algorithm, A* with Partial Expansion, for state-spaces with large branching factors. The aim of this algorithm is to store only necessary nodes for finding an optimal solution. In node expansion, A* stores all child nodes, while our algorithm stores only promising child nodes. This mechanism enables us to reduce the memory requirements during a search. We apply our algorithm to the multiple sequence alignment problem. It can align seven sequences with only 4.7% of the stored nodes required by A*.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-142.pdf,
148,2000,Search,Depth-First Branch-and-Bound versus Local Search: A Case Study,"Weixiong Zhang, University of Southern California","Depth-first branch-and-bound (DFBnB) is a complete algorithm that is typically used to find optimal solutions of difficult combinatorial optimization problems. It can also be adapted to an approximation algorithm and run as an anytime algorithm. In this paper, we study DFBnB as an approximation and anytime algorithm. We compare DFBnB against the Kanellakis-Papadimitriou local search algorithm, the best known approximation algorithm, on the asymmetric Traveling Salesman Problem (ATSP), an important NP-hard problem. Our experimental results show that DFBnB significantly outperforms the local search on large ATSP and various ATSP structures, finding better solutions faster than the local search; and the quality of approximate solutions from a prematurely terminated DFBnB, called truncated DFBnB, is several times better than that from the local search.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-143.pdf,
149,2000,Student Abstracts,Identifying Words to Explain to a Reader: A Preliminary Study,"Greg Aist, Carnegie Mellon University","The core idea of this paper is familiar to teachers: While a child is reading, explain unfamiliar words. Project LISTEN’s Reading Tutor listens to children read aloud and helps them learn to read. We want the Reading Tutor to explain unfamiliar words. To elicit explanations from an expert, the computer should suggest -- or let the expert select -- words to annotate. To capture explanations, the expert will type in and then narrate an explanation. Text and narration will be saved for later use. To utilize explanations during assisted reading, we will display the explanations as extra sentences to be read aloud with the computer’s help. Explanations will be provided on student request or computer tutor initiative. We focus here on how to select words for annotation.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-144.pdf,
150,2000,Student Abstracts,Speculative Execution for Information Agents,"Greg Barish, Craig A. Knoblock, and Steven Minton, University of Southern California","Practical deployments of information agents can suffer from sub- optimal performance and scalability for a number of reasons. In the case of web-based information integration, for example, data sources are remote and their latency can have a substantial effect on overall execution performance. Scalability can also be poor, since concurrent queries can cause multiple, simultaneous remote data retrievals (often of the same information), quickly consuming available bandwidth. At the same time, web-based information agents are often I/O-bound and wasting millions of CPU cycles as execution proceeds. In this paper, we describe how speculative execution can be applied to improve performance and scalability in practical agent deployments. Our approach enables both control and data-predictive styles of speculation, as well as a flexible framework for generating spculative hints, and scalable infrastructure for incorporating speculation seamlessly into existing agent plans.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-145.pdf,
151,2000,Student Abstracts,Heterogeneous Neuron Models Based on Similarity,"Lluís A. Belanche Muñoz, Universitat Politècnica de Catalunya","This work deals with the development of general classes of neuron models, accepting heterogeneous inputs by aggregation of continuous (crisp or fuzzy) numbers, linguistic information, and discrete (either ordinal or nominal) quantities, with provision also for missing information. The internal stimulation of these neural models is based on an explicit similarity relation between the input and the weight tuples (which are also heterogeneous). The framework is very comprehensive and several particular models can be derived as instances thereof. These networks are capable to learn from non-trivial data sets with an effectiveness comparable, and often better, than that of classical networks.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-146.pdf,
152,2000,Student Abstracts,"Mixed-Initiative Reasoning for Integrated Domain Modeling, Learning and Problem Solving","Mihai Boicu and Gheorghe Tecuci, George Mason University","This paper introduces a powerful and flexible mixed-initiative plausible reasoner that allows the expert to train an agent in a variety of ways, and in as natural a manner as possible, similar to the way the expert would train a human apprentice. The plausible reasoner distinguishes between four types of increasingly complex problem solving situations, routine, innovative, inventive and creative, providing a basis for an integration of the domain modeling, learning and problem solving processes involved in developing the knowledge base of the agent.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-147.pdf,
153,2000,Student Abstracts,A Methodology for Modeling and Representing Expert Knowledge that Supports Teaching-Based Intelligent Agent Development,"Michael Bowman, Gheorghe Tecuci, and Mihai Boicu, George Mason University","This paper introduces a general domain modeling methodology for building knowledge-based agents that is tightly integrated with an apprenticeship multistrategy learning approach to knowledge acquisition and problem solving. This methodology allows domain experts to naturally express their expertise in a form that supports several aspects of knowledge base development, including ontology formation, rule learning, and natural language generation of solutions and justifications.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-148.pdf,
154,2000,Student Abstracts,Automated Learning of Pricing and Bundling Strategies in Information Economies,"Christopher H. Brooks and Edmund H. Durfee, University of Michigan","The emergence of the Internet and the potential of software agents for conducting electronic commerce presents a new set of challenges for producers of information goods. We discuss how a producer of information goods can learn a price schedule to charge and a set of goods to offer while contending with an unknown and changing consumer population and competition from other producers. We take a decision- theoretic approach, emphasizing the cost of learning and the need for a producer to quickly find an acceptable solution, due to the dynamics of the problem and the small number of potential interactions with a consumer population. We also discuss the use of taxonomic information as a guide when selecting which goods to offer.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-149.pdf,
155,2000,Student Abstracts,Incremental and Distributed Learning with Support Vector Machines,"Doina Caragea, Adrian Silvescu, and Vasant Honavar, Iowa State University","Due to the increase in the amount of data gathered every day in the real world problems (e.g., bioinformatics), there is a need for inductive learning algorithms that can incrementally process large amounts of data that is being accumulated over time in physically distributed, autonomous data repositories. In the incremental setting, the learner gradually refines a hypothesis (or a set of hypotheses) as new data become available. Because of the large volume of data involved, it may not be practical to store and access the entire dataset during learning. Thus, the learner does not have access to data that has been encountered at a previous time. Learning in the distributed setting can be defined in a similar fashion. An incremental or distributed learning algorithm is said to be exact if it gives the same results as those obtained by batch learning (i.e., when the entire dataset is accessible to the learning algorithm during learning). We explore exact distributed and incremental learning algorithms that are variants and extensions of the support vector machine (SVM) family of learning algorithms.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-150.pdf,
156,2000,Student Abstracts,System that Identifies Writers,"Sung-Hyuk Cha and Sargur N. Srihari, State University of New York at Buffalo","The writer identification problem is stated as follows. There are m writing exemplars of each of n people (n = very large). Given a writing exemplar, x, of an unknown writer, the task is to determine whether x was written by any of the n writers and if so, identify the writer. A writer identifier that uses inductive hypothesis must engage statistical proof; it is necessary to determine the statistical validity of individuality in handwriting based on measurement of features, quantification, and statistical analysis. There exist various parametric and non-parametric techniques to solve the multiple category classification problem or simply called polychotomizer where the number of classes is finite and small. As the number of classes is enormously large and almost infinite, these techniques are of no use and the problem is seemingly insurmountable. For this reason, we suggest to transform a large and intractable polychotomizer to a simple dichotomizer, a classifier that places a pattern in one of only two categories: distance data between two writings of the same author and those of two different authors. In this model, we state the problem as follows; given two randomly selected handwritten documents, the writer identification problem is to determine whether the two documents were written by the same person with two types of confusion error probabilities. Experimental results with 571 writers with three sample documents per writer, using 11 feature distances, results in 97% accuracy, 3.5% type I and 2.1% type II errors.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-151.pdf,
157,2000,Student Abstracts,Using Anytime Planning for Centralized Coordination of Multiple Robots in Real-Time Dynamic Environments,"Gabriel J. Ferrer, Glenn S. Wasson, James P. Gunderson, and Worthy N. Martin, University of Virginia","We are investigating the use of planning in multi-robot, real-time, dynamic environments. Our paper discusses an anytime planning algorithm we have devised for the particular problem of replanning. Our anytime algorithm begins by repairing a restricted part of the plan without altering the rest of the plan. The part of the plan that can be replanned is then progressively increased until the algorithm is interrupted or the entire plan has been replanned.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-152.pdf,
158,2000,Student Abstracts,MURDOCH: Publish/Subscribe Task Allocation for Heterogeneous Agents,"Brian P. Gerkey and Maja J. Mataric, University of Southern California","In this paper, we describe a novel approach to the problem of dynamic task allocation among groups of heterogeneous agents. Specifically, we advocate the use of publish/subscribe messaging, a well-researched and commercially proven message brokering paradigm that is readily applicable to distributed control. We present Murdoch, an implemented publish-subscribe system, and explain how it can facilitate multi-robot coordination. The system allows the user a high-level interface for posing tasks to a group of autonomous homogeneous or heterogenous robots. Rather than assigning a task to an individual or a group, the user simply poses the task to the system as a whole (with no knowledge of individual agents).",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-153.pdf,
159,2000,Student Abstracts,Domain-Specific Knowledge Acquisition Using WordNet,"Roxana Girju, Southern Methodist University","In many knowledge intensive applications, it is necessary to have extensive domain-specific knowledge in addition to general-purpose knowledge. This paper presents a methodology for discovering domain-specific concepts and relationships in an attempt to extend WordNet. The method was tested on five seed concepts selected from the financial domain: interest rate, stock market, inflation, economic growth, and employment. Queries were formed with each of these concepts and a corpus of 1000 sentences/seed was extracted automatically from the Internet and the TREC-8 corpora. The system discovered a total of 362 new concepts and 62 new relationships while working in an interactive mode.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-154.pdf,
160,2000,Student Abstracts,Graph Based Concept Learning,"Jesus A. Gonzalez, Lawrence B. Holder, and Diane J. Cook, University of Texas at Arlington","In this paper, we introduce the graph based concept learner SubdueCL, which is an extension to the Subdue system. We describe in a general way how it works and we mention some results gotten from a comparison of SubdueCL with the two Inductive Logic Programming systems FOIL and Progol.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-155.pdf,
161,2000,Student Abstracts,An Adaptive Planner Based on Learning of Planning Performance,"Kreshna Gopal and Thomas R. Ioerger, Texas A&M University","Saving and reusing previously constructed plans is largely regarded as a promising approach to deal with the intractability of domain-independent planning. But it has been shown that syntactically matching a new problem with a candidate case is NP-hard, and modifying a plan to suit a new problem can be strictly more difficult than generating a plan from scratch. We present a case-based planning system that does not involve any plan modification and performs case matching very efficiently. The planning performance of a default planner is learned in a training phase, and given a new problem, the learned knowledge is exploited to retrieve a good case from the library, and thereby reducing the initial problem to two simpler ones, which should be computationally less expensive to solve. The effectiveness of the system hinges mainly on the learning strategy used and on extraction of relevant problem features.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-156.pdf,
162,2000,Student Abstracts,"Knowledge Representation on the Internet: Achieving Interoperability in a Dynamic, Distributed Environment","Jeff Heflin, University of Maryland","The Internet’s explosive growth is making it harder and harder to harness its potential. However, the field of knowledge representation, particularly the subfield of ontologies, can provide techniques for improving the ability of agents to work with Internet information. SHOE (Simple HTML Ontology Extensions) is a semantic markup language designed specifically for the Internet. It includes features that allow knowledge representation in distributed enviroments, and since the Internet is dynamic, allows ontologies to evolve in a controlled way.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-157.pdf,
163,2000,Student Abstracts,Using Pattern Databases to Find Macro Operators,"István T. Hernádvölgyi, University of Ottawa",We use automatically generated memory based heuristics to search for macro operators. We demonstrate the power of our technique by obtaining optimal macro tables for the Rubik’s Cube with modest size pattern databases.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-158.pdf,
164,2000,Student Abstracts,Autonomous Multi-Agent Docking Using Color Segmentation,"Jeffrey Hyams, University of South Florida","This abstract presents a work in progress of an autonomous multi-agent scheme for egocentric docking. The work attempts to make use of color segmentation of a fiducial and affordance in reactive behaviors to autonomously dock a mobile robot agent. A real-time solution is needed, and this work tries to accomplish this.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-159.pdf,
165,2000,Student Abstracts,Ontology Integration in XML,"Euna Jeong, National Taiwan University; Chun-Nan Hsu, Academia Sinica","We study the problem of automatically generating an integrated schema for different XML DTDs with similar document types. We describe an algorithm for approximate typing of XML DTDs and clustering them, a method for inferring general rules to describe source DTDs in the same class, and an algorithm for optimizing the learned rules. Introducing a novel view inference approach, we shows that the set of views and source descriptions can be automatically derived.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-160.pdf,
166,2000,Student Abstracts,Graph-Based Hierarchical Conceptual Clustering in Structural Databases,"Istvan Jonyer, Lawrence B. Holder, and Diane J. Cook, University of Texas at Arlington","Hierarchical conceptual clustering has been proven to be a useful, although greatly under-explored data mining technique. A graph-based representation of structural information combined with a substructure discovery technique has been shown to be successful in knowledge discovery. The SUBDUE substructure discovery system provides the advantages of both approaches. This work presents a new algorithm that uses SUBDUE to build conceptual clustering hierarchies. An example is used to illustrate the validity of the approach.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-161.pdf,
167,2000,Student Abstracts,Situation Awareness with the Limited Visual Attention,"Youngjun Kim, Randall W. Hill, Jr., and Jonathan Gratch, University of Southern California","Situation awareness (SA) is the perception of the elements in the environment within a volume of time and space, the comprehension of their meaning, and the projection of their status in the near future. Although the impact of situation awareness and assessment on humans in complex systems is clear, no one theory for SA has been developed. A critical aspect of the SA problem is that agents must construct an overall view of a dynamically changing world using limited sensor channels. For instance, a (virtual) pilot, who visually tracks the location and direction of several vehicles that he cannot see simultaneously, must shift its visual field of view to scan the environment and to sense the situation involved. How he directs his attention, for how long, and how he efficiently reacquires targets is the central question we address in this paper. We describe the perceptual coordination that helps a virtual pilot efficiently track one or more objects",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-162.pdf,
168,2000,Student Abstracts,Language Learning in Large Parameter Spaces,"Karen T. Kohl, MIT Artificial Intelligence Laboratory","The existence of parameters has been proposed in models of linguistic theory to account for differences among natural languages. In addition to the problem of defining parameters, we have the problem of a child’s acquisition of the settings of these parameters. Several algorithms have been proposed to describe how a child learns the parameter settings for her target adult language, but these algorithms need to be analyzed in greater depth. We used an implentation of one proposed algorithm of parameter setting to study its predictions in a more realistic setting. It was necessary to implement this algorithm for large parameter spaces in order to see that its problems were serious and that the problem of parameter setting cannot easily be solved.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-163.pdf,
169,2000,Student Abstracts,Reinforcement Learning for Algorithm Selection,"Michail G. Lagoudakis, Duke University; Michael L. Littman, AT&T Labs -- Research and Duke University","Many computational problems can be solved by multiple algorithms, with different algorithms fastest for different problem sizes, input distributions, and hardware characteristics. We consider the problem of algorithm selection: dynamically choose an algorithm to attack an instance of a problem with the goal of minimizing the overall execution time. We formulate the problem as a kind of Markov decision process (MDP), and use ideas from reinforcement learning to solve it. The well known Q-learning algorithm is adapted for this case in a way that combines both Monte-Carlo and Temporal Difference methods. Our initial experiments focus on the problem of order statistic selection. The encouraging results reveal the potential of applying learning methods to traditional computational problems.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-164.pdf,
170,2000,Student Abstracts,Tracing Dependencies of Strategy Selections in Agent Design,"Dung N. Lam and K. S. Barber, University of Texas at Austin","Given the diverse multi-agent system (MAS) implementations developed for various domains, there has been a lack of a comprehensive method for analyzing and evaluating the assortment of multi-agent architectures and technology resident in those architectures. This research proposes that the first step in providing a formal analysis method is to decompose an agent into its core competencies (CC), which define the major functionalities of an agent. For each CC, the designer chooses to implement a core competency strategy from a library of existing strategies. Inherent dependencies exist between CCs and the selected strategies must serve to satisfy those dependencies. The designer must recognize that selection of one strategy can constrain or eliminate the consideration of strategies for other needed CCs. With a fundamental understanding of how and why certain combinations of strategies produce specific agent-level and system-level behaviors, a method to analyze agents at an abstract level can be developed for MAS designers to investigate the system-level implications of selecting strategies that have dependencies spanning across multiple CCs and across agents resident in the system.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-165.pdf,
171,2000,Student Abstracts,Programming Robot Behavior Primitives through Human Demonstration,"Amy Larson and Richard Voyles, University of Minnesota","Robotic systems are capable of complex behavior by sequencing simpler skills called primitives. A primitive is a sensor/actuator mapping robust enough to perform appropriately in various situations. Coding both the primitives and the sequencing of primitives can be tedious and requires an accurate translation of human knowledge to machine code. Programming by human demonstration addresses these problems of acquiring and combining primitives. Programming by demonstration can be implemented with a supervised learning technique such as artificial neural networks (ANN). Problems exist with such techniques, however, including creating a training set which is comprehensive and concise. Here, we present a method for nonexpert users to collect ""good"" training data from an intuitive understanding of task behavior, not from knowledge of the underlying learning mechanism.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-166.pdf,
172,2000,Student Abstracts,An Implementation of the Combinatorial Auction Problem in ECLiPSe,"Robert Menke and Rina Dechter, University of California, Irvine","Combinatorial auctions allow bidders to bid upon multiple items simultaneously. This type of auction is attractive because for many bidders the individual items increase in value when held in conjunction with other items. Unfortunately, searching the entire space of the problem is intractable. By taking advantage of the sparsity of bids, a solution can be found in reasonable time. One such implementation of this concept is the Bidtree algorithm by Sandholm. The Bidtree algorithm was implemented in the constraint programming language ECLiPSe and its performance was compared to searches using other heuristics.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-167.pdf,
173,2000,Student Abstracts,A Semi-Complete Disambiguation Algorithm for Open Text,"Rada Mihalcea, Southern Methodist University","In this paper, we present an iterative algorithm for Word Sense Disambiguation. It combines two sources of information: WordNet and a semantic tagged corpus, for the purpose of identifying the correct sense of the words in a given text. It differs from other standard approaches in that the disambiguation process is performed in an iterative manner: starting from free text, a set of disambiguated words is built, using various methods; new words are sense tagged based on their relation to the already disambiguated words, and then added to the set. This iterative process allows us to identify, in the original text, a set of words which can be disambiguated with high precision; 55% of the verbs and nouns are disambiguated with an accuracy of 92%.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-168.pdf,
174,2000,Student Abstracts,Combining Classification and Temporal Learning,"Matthew Winston Mitchell, Monash University",This paper introduces TRACA (Temporal Reinforcement-learning and Classification Architecture). TRACA is a connectionist system designed to learn incrementally in environments with irrelevant attributes and hidden-state. A unique method of representing NOT and XOR is used to reduce the complexity of the internal structures developed. TRACA’s network representation is created dynamically during learning avoiding requirements to predetermine network size and topology.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-169.pdf,
175,2000,Student Abstracts,Deriving and Using Abstract Representation in Behavior-Based Systems,"Monica N. Nicolescu and Maja J. Mataric, University of Southern California","We present a representation that addresses two current limitations of the behavior-based systems (BBS) (Mataric 1992), (Arkin 1998): the lack of abstract representation within behaviors (which makes them hard to use in complex, sequential problems) and the need for behavior redesign even for tasks that use subsets of the same behavior set. We introduce the concept of behavior networks, based on the abstract behaviors representation described below. We distinguish the following two types of behavior preconditions: world preconditions (activate the behaviors based on the state of the environment) and sequential preconditions (task-dependent conditions, often postconditions of other existing behaviors). In standard BBS behaviors, both types of preconditions are tested together, thus hard-coding a particular solution. The key step in adapting specialized behaviors to more general use is in the separation of the execution conditions from the outputs or actions, which allows for a more general set of activation conditions. The pairing of a behavior’s conditions and its effects, without the specification of its inner workings, constitutes an abstract behavior. Intuitively, this is simply an explicit specification of the behavior’s execution conditions (i.e., preconditions) and its effects (i.e., postconditions). The result is an abstract and general operator much like those used in classical deliberative systems. The behaviors that do the work that achieves the specified effects under the given conditions are called it primitive behaviors, and may involve one or an entire collection of sequential or concurrently executing behaviors, as is typical for BBS. Behavior networks are a means of specifying strategies or general ""plans"" in a way that merges the advantages of both abstract representations and behavior-based systems. The nodes in the networks are abstract behaviors, and the links between them represent precondition and postcondition dependencies. The task plan or strategy is represented as a network of such behaviors. We have implemented the proposed concepts on a physical mobile robot (Pioneer 2-DX) given an object delivery task in an enclosed, 2-section environment. The robot successfully finds a box, which may be in either section, goes with it through the door and pushes it to the delivery point. The solution makes use of two behavior networks and captures the important aspects of the proposed concepts: abstract representation, behavior reuse, behavior networks and the importance of relying on real embedded behaviors. As a next goal, we seek to automate the behavior network generation and to use the representation to address human-robot interaction. The abstract representation should allow us to employ simple communication mechanisms which would enable the robots to benefit from the human and also learn from and share their acquired knowledge and experiences. The abstract behavior representation we are proposing combines the advantages of deliberative, STRIPS-like architectures (Fikes and Nilsson 1971), and those of BBS' capability to operate in dynamically changing environments. However, it is important to note that we are not describing a hybrid architecture. Our work is related to the approaches of Kaelbling and Rosenschein (1990) (the situated automata model) and of Lyons and Arbib (1989) who developed a robot schema model of computation for sensory-based robot programming. However, their implementations do not allow generalization and reuse of the compiled high level circuitry and respectively the robot schemas to multiple tasks.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-170.pdf,
176,2000,Student Abstracts,Model-Based-Diagnosis for Fault Management in Telecommunications Networks,"Aomar Osmani, LIPN","We propose in this paper a model-based approach to diagnose fault situations in greatest French telecommunication networks: TRANSPAC. This approach is based on two steps: (1) Off-line step: The first step to studying faults management is to build a model. This construction is done using two abstraction levels: structural abstraction where components of the network are modeled by temporal graph and behavioral model where each component is modeled by temporal and communicating finite state machines.When the model is built, single and multiple faults are simulated in the model. Corresponding to the two level abstraction We have proposed two kind of algorithm: propagating algorithm associated to the structural level and deducting algorithm associated to the behavioral level. At the end of simulation a learning database of fault situationsis built. This database is used by discrimination module to classify given fault in the space of sequences of alarms; (2) On-line step: the expert system generated by the off-line step is used to recognize on-fly fault situations from the stream of alarms arriving at the supervisor.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-171.pdf,
177,2000,Student Abstracts,Representation and Evolution of Lego-Based Assemblies,"Maxim Peysakhov, Vlada Galinskaya, and William C. Regli, Drexel University","This research presents an approach to the automatic generation of electro-mechanical engineering designs. Our approach is to apply Messy Genetic Algorithm optimization techniques to the evolution of assemblies composed of Lego elements. Each design is represented as a labeled assembly graph. Designs are evaluated based on a set of behavior and structural equations, which we are trying to optimize. Our eventual goal is to introduce simulation of electro-mechanical devices into our evaluation functions. Initial populations are generated at random, with design candidates for subsequent generations produced by a user-specified selection technique. Crossovers are applied by using cut and splice operators at random points of the chromosomes; random mutations are applied with a specified low probability to modify the graph. This cycle continues until a suitable design is found. The research contributions in this work include the development of a new GA encoding scheme for mechanical assemblies (Legos), as well as the creation of selection criteria for this domain. We believe that this research creates a foundation for future work and can be used to apply GA techniques to the evolution of more complex and realistic electro-mechanical structures.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-172.pdf,
178,2000,Student Abstracts,Intelligent Monitoring in a Robotic Assistant for the Elderly,"Sailesh Ramakrishnan and Martha E. Pollack, University of Pittsburgh","The NurseBot project is developing a mobile robot that is intended to assist elderly people suffering from mild cognitive disorders in their everyday life (see http://www.cs.cmu.edu/~nursebot). One of the main components of the project is intelligent reminding, which is useful when an elderly person has mild memory problems. A key aspect of intelligent reminding is to identify which activities should be monitored and/or which reminders to issue. The intelligent monitoring system we are developing learns which activities need to be monitored, and when reminders need to be issued. It does this by representing the system’s belief about when the elderly person will perform various activities by means of a Bayesian Belief Net and running simulations of the future using this net.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-173.pdf,
179,2000,Student Abstracts,Towards Efficient Negotiation Mechanisms for Collaboration,"Timothy Rauenbusch, Harvard University","This paper addresses the problem of resolving disagreements among groups of self-interested, rational agents that are engaged in a collaborative activity. It argues that current AI approaches to negotiation do not adequately accommodate important features of collaborative planning. For collaborative groups, efficiency of outcomes and the consideration of costs associated with calculating preferences in disagreements are more important than the common game-theoretic design goal of strategy stability. A new mechanism, Blind Mediation, that makes the tradeoff between efficiency and the cost of calculating preferences explicit and that accommodates privacy concerns is presented. By experiment, Blind Mediation is shown to perform significantly better than full revelation of preferences and negotiations among people.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-174.pdf,
180,2000,Student Abstracts,Behavior Acquisition and Classification: A Case Study in Robotic Soccer,"Patrick Riley and Manuela Veloso, Carnegie Mellon University","Increasingly in domains with multiple intelligent agents, each agent must be able to identify what the other agents are doing. This is especially important when there are adversarial agents inferring with the accomplishment of goals. Once identified, the agents can then respond to recent strategies and adapt to improve performance. We present an approach to doing adaptation which relies on classification of the current adversary into predefined adversary classes. For feature extraction, we present a windowing technique to abstract useful but not overly complicated features. The feature extraction and classification steps are fully implemented in the domain of simulated robotic soccer, and experimental results are presented.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-175.pdf,
181,2000,Student Abstracts,"Small-World"" Networks of Mobile Robots","Stergios I. Roumeliotis and Maja J. Mataric, University of Southern California","In this paper we propose a new communication architecture aimed to support and facilitate cooperative behavior and work within colonies of mobile robots. As the number of robots in the group increases, the performance of a broadcasting (one-to-all) based communication system degrades due to the information overflow. Different schemas of local communication (one-to-a few) can be applied instead. We examine a new communication topology for a group of mobile robots inspired by the ""small-world"" network connectivity. The main advantages of this new type of communication network are: 1. The communication overload that each of the robots would experience if all of them were connected on the same network (1 Ethernet, one-to-all communication) is obviated, 2. The amount of clustering for local teams of robots is high and thus relevant information produced within this team is quickly shared amongst its members, and 3. The characteristic path length is small compared to the case of a regular (lattice-like) network, therefore facilitating the fast diffusion of information across the colony when this is necessary for a global task.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-176.pdf,
182,2000,Student Abstracts,Towards Approximately Optimal Poker,"Jiefu Shi and Michael Littman, Duke University","Abstraction is a method one often applies to keep the combinatorial explosion under control and to solve problems of large complexity. Here, we apply this technique in approximating optimal strategies for large stochastic imperfect-information games. The specific game investigated is a two-player version of poker.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-177.pdf,
183,2000,Student Abstracts,Team-Aware Multirobot Strategy for Cooperative Path Clearing,"Gita Sukthankar, Carnegie Mellon University","In this paper, we present a simulated version of a demining problem in which robotic minesweepers clear a battle area of anti-tank mines to enable troops to breach the field. The demining problem is modeled as a distributed optimization problem in which the robots strive to minimize an abstract cost function. Robots were simulated using the Java based simulator, TeamBots (www.teambots.org).",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-178.pdf,
184,2000,Student Abstracts,Interfacing Issues for Information Extraction,"Peter Vanderheyden and Robin Cohen, University of Waterloo","Traditional approaches to information extraction assume that many elements of the task are static --- the user’s query, and the description of domain and corpus, for example. We seek to extend current approaches for information extraction to handle dynamic elements of the problem. We consider such issues as: - appropriate ""modalities"" for an interface to large amounts of natural language text; - appropriate opportunities when the system or user should take initiative to interact with one another or to modify the current state; - features for knowledge representation; - features for machine learning. We intend to investigate how such choices affect performance. Specifically, our initial focus will be on how best to support evolving information models (query and domain) interactively.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-179.pdf,
185,2000,Student Abstracts,Clustering with Instance-Level Constraints,"Kiri Wagstaff and Claire Cardie, Cornell University","We posit that problem-specific constraints can be incorporated into clustering algorithms to increase accuracy and decrease runtime. In experiments with a partitioning variant of COBWEB, we show marked improvements with surprisingly few constraints on three of four data sets. We also identify different types of constraints as appropriate in different settings.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-180.pdf,
186,2000,Student Abstracts,An ILP Method Based on Instance Graph,"Runqi Zhang, State University of New York at Buffalo","Learning systems that express theories in first-order logic must ensure that the theories are executable and, in particular, they do not lead to infinite recursion. We introduce instance graph H(R,E), which is a type of directed hypergraph, and instance order to clarify the relationship between a (recursive) ruleset R and the instance space E of the corresponding target predicate. Based on these concepts, we put forward a new ILP algorithm, FOILBIG, which guarantees executability of learned rulesets, and does not substantially raise computational complexity compared to FOIL. FOILBIG has no restriction of ordering, and hence makes it possible to complete more learning tasks in ILP context. The method based on instance graph could also be used by any learning system that grows elements from ground facts by repeated specialization. FOILBIG has been implemented roughly and preliminary experiments show that it can solve problems beyond the scope of FOIL. In addition, unlike the method used by FOIL, our method can be extended to Multiple Predicate Learning with the extension of instance graph.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-181.pdf,
187,2000,SIGART/AAAI Doctoral Consortium,Helping Children Learn Vocabulary during Computer Assisted Oral Reading,"Greg Aist, Carnegie Mellon University","Vocabulary is fundamental to reading. As elementary students cross over from learning to read into reading to learn, vocabulary knowledge becomes increasingly important. The massive amount of vocabulary a student must learn precludes large amounts of time spent on any single word, except perhaps for some words that the student will read and write many times over the course of a lifetime. Therefore students must learn vocabulary from text. Project LISTEN’s Reading Tutor listens to children read aloud, and helps them learn to read. The Reading Tutor shows the child a story one sentence at a time, listens to the child read all or part of the sentence out loud, and responds with help in recorded human voices. When the Reading Tutor has heard the student read every content word, the Reading Tutor shows the next sentence. Besides reading, the student may click Go to see the next sentence, Back to move back, on a word or on Help to hear the word read by the Tutor or get other help, or Goodbye to log out. To learn new words from interacting with the Reading Tutor, a student must: 1. spend time reading, 2. read new material hard enough to have new words, and 3. learn the meaning of new words when encountered. We excluded the first factor -- time on task -- as outside the scope of this thesis. We addressed the second factor by modifying the Reading Tutor to take turns picking stories with students, to expose students to more new material than they would have read if they picked all the stories themselves. We addressed the third factor by designing, implementing, and evaluating ways to augment stories with extra help -- such as synonyms or glossary definitions -- to make the most of encounters with novel words. Results were as follows: Taking turns picking resulted in students reading more new material than with a previous version of the Reading Tutor that allowed only the student to pick. Augmenting stories with WordNet-derived synonyms made most sense for single-sense words, and resulted in improved learning on rare words. We discuss these results and what remains to examine.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-182.pdf,
188,2000,SIGART/AAAI Doctoral Consortium,Adaptive Learning Systems: A Model for Business Entrepreneurs to Implement IT,"Dessa David, City University of New York","Adaptive learning systems offer promise in revolutionizing the way we interact with computers. Realizing its full potential will involve development of these systems in everyday tools. This paper describes a progress toward this end: the development of an agent as a means of an active decision support tool for business entrepreneurs during the IT implementation process. The system features ALSTA, a personal assistant who augments the users perceptions as they make decision regarding IT implementation",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-183.pdf,
189,2000,SIGART/AAAI Doctoral Consortium,Automatic Generation of Memory Based Search Heuristics,"István T. Hernádvölgyi, University of Ottawa",This paper discusses the automatic generation of memory based search heuristics. We use a simple production system to describe the search spaces. Simple syntactic transformations (domain abstraction) result in an abstract space which can be used to obtain admissible and monotonic heuristic values. We exeamine properties of heuristics obtained by our method.,https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-184.pdf,
190,2000,SIGART/AAAI Doctoral Consortium,Reasoning and Acting in Time,"Haythem O. Ismail, State University of New York at Buffalo","A natural language competent embodied cognitive agent should satisfy two requirements. First, it should interleave reasoning and acting in a changing world where errors and interrupts may occur. Second, it should be able to communicate in natural language about the past, present, and future states of its environment. This imposes certain restrictions on the logic and reasoning engine used by the agent. The logical language needs to be suitable for representing natural language utterances, knowledge about acts, and perceptual information. In addition, it should include a representation of the notion of the present that reflects the semantics of the English ""now"". In our model, the present is represented by a NOW pointer that moves whenever the agent senses a change in the world. Reasoning problems emerge when the agent is reasoning about NOW, and the very process of reasoning results in NOW moving.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-185.pdf,
191,2000,SIGART/AAAI Doctoral Consortium,Ontology Integration in XML,"Euna Jeong, National Taiwan University, Chun-Nan Hsu, Academia Sinica","We study the problem of automatically generating an integrated schema for XML DTDs. Introducing a novel view inference approach, we show that the set of views and source descriptions can be automatically derived.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-186.pdf,
192,2000,SIGART/AAAI Doctoral Consortium,Belief Revision in a Deductively Open Belief Space,"Frances L. Johnson, State University of New York at Buffalo","I am researching the traditional belief revision integrity constraints and postulates, which are designed for deductively closed belief spaces, and revising them so that they are applicable to implemented knowledge representation and reasoning systems with deductively open belief spaces (DOBS). I plan to offer a DOBS version of the AGM postulates, Hansson’s base contraction postulates, and postulates proposed for ranked beliefs, and to provide brief comments regarding postulate adherence for paraconsistent logics and incomplete systems. Using these postulates, I hope to develop a theory for comparing systems, so that implementers will be able to (a) evaluate how well their systems meet the standards of the postulates and (b) compare their systems to other systems.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-187.pdf,
193,2000,SIGART/AAAI Doctoral Consortium,Selective Sampling with Co-Testing: Preliminary Results,"Ion Muslea, Steven Minton, and Craig A. Knoblock, University of Southern California","We present a novel approach to selective sampling, co-testing, which can be applied to problems with redundant views (i.e., problems with multiple disjoint sets of attributes that can be used for learning). The main idea behind co-testing consists of selecting the queries among the unlabeled examples on which the existing views disagree.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-188.pdf,
194,2000,SIGART/AAAI Doctoral Consortium,Grounding State Representations in Sensory Experience for Reasoning and Planning by Mobile Robots,"Daniel Nikovski, Carnegie Mellon University","We are addressing the problem of learning probabilistic models of the interaction between a mobile robot and its environment and using these models for task planning. This requires modifying the state-of-the-art reinforcement learning algorithms to deal with hidden state and high-dimensional observation spaces of continuous variables. Our approach is to identify hidden states by means of the trajectories leading into and out of them, and perform clustering in this embedding trajectory space in order to compile a partially observable Markov decision process (POMDP) model, which can be used for approximate decision-theoretic planning. The ultimate objective of our work is to develop algorithms that learn POMDP models with discrete hidden states defined (grounded) directly into continuous sensory variables such as sonar and infrared readings.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-189.pdf,
195,2000,SIGART/AAAI Doctoral Consortium,Online Ensemble Learnin,"Nikunj C. Oza, University of California, Berkeley","Within the machine learning community, ensemble learning methods---methods that combine multiple learned models---are gaining popularity because they tend to have better generalization performance than single models. However, ensemble models have so far only been learned in batch mode---all of the training examples are processed as a set multiple times. Online learning attempts to learn models by processing the training examples only once in order. My thesis will present a framework combining online learning and ensemble learning. To that end, I have so far developed two online ensemble learning algorithms--- online versions of the popular bagging and boosting algorithms. I have shown empirically that both online algorithms converge to the same prediction performance as the batch versions and proved this convergence for online bagging. My online ensemble learning framework will enable ensemble learning algorithms to be usable in data mining tasks where datasets are often too large for batch algorithms to handle.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-190.pdf,
196,2000,SIGART/AAAI Doctoral Consortium,Learning Landmarks for Robot Localization,"Robert Sim and Gregory Dudek, McGill University","Our work addresses the problem of learning a set of visual landmarks for mobile robot localization. The learning framework is designed to be applicable to a wide range of environments, and allows for different approaches to computing a pose estimate. Initially, each landmark is detected using a model of visual attention and is matched to observations from other poses using principal components analysis. Attributes of the observed landmarks can be parameterized using a generic parameterization method and then evaluated in terms of their utility for pose estimation. We discuss the status of the work to date, and future directions.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-191.pdf,
197,2000,SIGART/AAAI Doctoral Consortium,Refining Inductive Bias in Unsupervised Learning via Constraints,"Kiri Wagstaff, Cornell University","We propose the use of constraints as a technique for refining the inductive bias of unsupervised learning algorithms. Our previous work with a clustering algorithm and instance-level hard constraints has demonstrated that the use of constraints can both increase accuracy and decrease runtime. We here outline the other kinds of algorithms and constraints we intend to investigate. In addition, we present our intended method for evaluating constraint-based techniques.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-192.pdf,
198,2000,SIGART/AAAI Doctoral Consortium,Artificial Intelligence-Based Computer Modeling Tools for Controlling Slag Foaming in Electric Furnaces,"Eric Wilson, University of Alabama","Due to increased competition in a world economy, steel companies are currently interested in developing techniques that will allow for the improvement of the steelmaking process, either by increasing output efficiency or by improving the quality of their product, or both. Slag foaming is one practice that has been shown to contribute to both these goals. This paper describes an effort in progress to both model and control the slag foaming process using neural networks in tandem with genetic algorithms and fuzzy logic.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-193.pdf,
199,2000,Intelligent Systems Demos,Sensible Agents: Demonstration of Dynamic Adaptive Autonomy,"K. S. Barber, A. Goel, D. C. Han, J. Kim, D. N. Lam, T. H. Liu, C. E. Martin, and R. McKay, The University of Texas at Austin","The analysis and design of large, complex systems mandates a formal methodology and supporting tools to assist system development teams throughout the system lifecycle. The multitude of personnel, the diversity of viewpoints, and the transient nature of personnel and technology in relation to the system lifecycle constrains the process by which 1) application domain requirements are acquired, analyzed and modeled, 2) a system architecture is derived from those requirements, 3) technology decisions are made and implementation progresses, and 4) the system is tested and maintained. A formal methodology for the entire lifecycle keeps team members coordinated and offers a mechanism to gauge progress. Large projects with many personnel responsible for making decisions require a formal process and automated support to assist team members in documenting their decisions. Traceability of decisions and documentation rationale is key to understanding the impact of decisions related to modeling, design, implementation, test, and maintenance. The SEPA effort proposes both a methodology and supporting tool suite (leveraging various knowledge representation and reasoning schemes) to facilitate development of object-oriented designs from evolving requirements. SEPA creates traceable, comprehensible, and extensible system design specifications based on requirements from system clients and domain experts. The funnel abstraction is chosen to represent the narrowing, refining, and structuring of user requirements into a system design. User inputs are refined by: (1) merging inputs from multiple sources, (2) distinguishing between inputs relating to system requirements and those relating to general domain knowledge, (3) constructing an object-oriented architecture, (4) mapping requirements to technology solutions, and (5) providing a framework for evaluating system design.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-194.pdf,
200,2000,Intelligent Systems Demos,The Systems Engineering Process Activities (SEPA) Methodology and Tool Suite,"K. Suzanne Barber, Thomas Graser, Paul Grisham, Stephen Jernigan, and Sutirtha Bhattacharya, The University of Texas at Austin","The Sensible Agent Testbed allows users to perform controlled and repeatable experiments on the performance of Sensible Agents in a distributed simulation environment. The testbed uses CORBA(R) and IDL(R) to connect modules running in C++, ModSim, Java, and Lisp on WindowsNT and Linux platforms. Users can perform initialization, monitoring, and logging of the environment or individual Sensible Agent performance as the simulation progresses. Several different scenarios are presented to demonstrate the capabilities of Sensible Agents in a Naval Radar Frequency Management domain. Sensible Agents can use Dynamic Adaptive Autonomy (DAA) to adapt the structure of their problem-solving organizations in order to handle the complex and dynamic nature of this domain. Users can view this adaptation and monitor related system and agent performance variables as the simulation runs. This technology has the potential to provide advanced multi-agent capabilities to legacy planners with a minimal recoding effort.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-195.pdf,
201,2000,Intelligent Systems Demos,Qualitative Spatial Interpretation of Course-of-Action Diagrams,"Ronald W. Ferguson, Northwestern University; Robert A. Rasch, Jr., Battle Command Battle Lab (BCBL); William Turmel and Kenneth D. Forbus, Northwestern University","This paper demonstrates qualitative spatial reasoning techniques in a real-world diagrammatic reasoning task: Course-of-Action (COA) diagrams. COA diagrams are military planning diagrams that depict units’ movements and tasks within a given region. COA diagrams provide a useful test bed for diagram understanding because they have large, composable symbology used across many types of military planning. Using a qualitative spatial reasoning engine, GeoRep, we built two reasoning systems for COA diagrams. The first system was a prototype showing the viability of using GeoRep to interpret individual COA glyphs. The second system, which built upon the techniques of the first, allowed diagram glyphs to be identified by a knowledge-based reasoner, and then provided a geographic interpretation of relationships between those glyphs. This system was evaluated as a geographic knowledge server in a recent DARPA initiative, during which it answered dozens of geographic queries about many different COA diagrams.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-196.pdf,
202,2000,Intelligent Systems Demos,TV Content Recommender System,"Srinivas Gutta, Kaushal Kurapati, KP Lee, Jacquelyn Martino, John Milanski, J. David Schaffer, and John Zimmerman, Philips Research","The plethora of content available to the consumer has become overwhelming. Increasing amounts of information are being disseminated through terrestrial broadcast, satellite, and cable leading to an information overload. Common modes of searching for TV programs currently in existence include: TV-guide, PreVue channel and rudimentary search tools available through satellite dish TV programming service. These tools are general-purpose in nature and are not specifically tailored to the individual viewer’s taste. Towards that end we demonstrate a prototype recommender system that searches for TV programs based on their likes/dislikes through implicit personalization techniques.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-197.pdf,
203,2000,Intelligent Systems Demos,The Chimaera Ontology Environment,"Deborah L. McGuinness and Richard Fikes, Stanford University; James Rice, CommerceOne; Steve Wilder, Stanford University","Ontologies have become central components in many applications including search, e-commerce, configuration and, arguably, every large web site (at least for organization and navigation). As ontologies become larger, more distributed, and longer-lived, the need for ontology creation and maintenance environments grows. In our work with ontologies and tool environments over the last few years, we have observed growing needs for automated support of two tasks: (1) merging multiple ontologies and (2) diagnosing (and evolving) ontologies. Chimaera is an ontology tool environment aimed supporting these two tasks.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-198.pdf,
204,2000,Intelligent Systems Demos,Matchmaking to Support Intelligent Agents for Portfolio Management,"Massimo Paolucci, Zhendong Niu, Katia Sycara, Constantine Domashnev, Sean Owens, and Martin Van Velsen, Carnegie Mellon University","A-Match is a matchmaking system that allows agents to enter and exit the system dynamically. It employs a Matchmaker to support agents in the system in their exchange of services. A-Match lets human users interact with the Matchmaker: through the A-Match users find agents that can provide needed services or advertise new agents. The functionality of the A-Match is displayed in the context of the Warren System, a system that supports the user to manage its own stock portfolio.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-199.pdf,
205,2000,Intelligent Systems Demos,Adaptive User Interfaces through Dynamic Design Automation,"Robin R. Penner and Erik S. Steinmetz, University of Minnesota; Christopher L. Johnson, Honeywell Technology Center","The inherent difficulty in supporting human usability in large control systems--such as building environmental and security systems--derives from the large diversity of components and users within each domain. As a result, applying traditional methods of interface design to these systems is insufficient. Designers end up handcrafting each diagram required by each type of user, the effort needed to add new functionality quickly bloats, and users end up juggling multiple disparate applications. We have begun to deploy a tool called DIG (Dynamic Interaction Generation) that addresses this difficulty. DIG uses models of domain, task, and presentation knowledge to automatically design and present interfaces specialized to a user’s current role and task, the current situation, and the capabilities of the current display hardware. In this demonstration, DIG will convert a real-life building management configuration into a dynamic interface that building managers can operate using either a standard PC or a Palm Pilot.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-200.pdf,
206,2000,Intelligent Systems Demos,User Interface Softbots,"Robert St. Amant and Luke S. Zettlemoyer, North Carolina State University","An interface softbot, or ibot, controls an interactive system through the graphical user interface, as human users do, without relying on an application programming interface (API) or access to source code. Our work has produced a programmable substrate for ibots, containing sensors, effectors, and skeleton controllers. Sensor modules take pixel-level input from the display, run the data through image processing algorithms, and build a representation of visible interface objects. Effector modules generate mouse and keyboard gestures to manipulate these objects. These sensors and effectors act as eyes and hands to be managed by a controller appropriate for an application domain. This demonstration will show ibots interacting with several unmodified, off-the-shelf software applications, carrying out tasks that we might find useful in everyday computer use.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-201.pdf,
207,2000,Intelligent Systems Demos,O-Plan: A Web-Based AI Planning Agent,"Austin Tate, Jeff Dalton, and John Levine, The University of Edinburgh","In these demonstrations we show O-Plan, an AI planning agent working over the WWW. There are a number of demonstrations ranging from a simple ""single shot"" generation of Unix systems administration scripts through to comprehensive use of AI technologies across the whole planning lifecycle in military and civilian crisis situations The applications are derived from actual user requirements and domain knowledge. The AI planning technologies demonstrated include: * Domain knowledge elicitation * Rich plan representation and use * Hierarchical Task Network Planning * Detailed constraint management * Goal structure-based plan monitoring * Dynamic issue handling * Plan repair in low and high tempo situations * Interfaces for users with different roles * Management of planning and execution workflow The featured demonstrations, and others, are available at",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-202.pdf,
208,2000,Intelligent Systems Demos,Customer Coalitions in the Electronic Marketplace,"M. Tsvetovat, K. Sycara, Y. Chen, and J. Ying, Carnegie Mellon University","In the last few years, the electronic marketplace has witnessed an exponential growth in worth and size, and projections are for this trend to intensify in coming years. While the Internet offers great possiblities for creation of spontaneous communities, this potential has not yet been explored as a means for creating economies of scale among similar-minded customers. This demonstration illustrates the economic incentives behind formation of buying clubs and achivement of effect of economies of scale within temporary agent coalitions. The demonstration also focuses on coalition formation mechanisms for creation of such buying clubs.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-203.pdf,
209,2000,Intelligent Systems Demos,Non-Axiomatic Reasoning System (Version 4.1),"Pei Wang, Intelligenesis Corporation and Indiana University","NARS (Non-Axiomatic Reasoning System) is an intelligent reasoning system. It can answer questions according to the knowledge originally provided by its user. What makes it different from conventional reasoning systems is its ability to learn from its experience and to work with insufficient knowledge and resources. The NARS 4.1 demo is a Java applet. It comes with help information and simple examples to show how the system does deduction, induction, abduction, analogy, belief revision, membership evaluation, relational inference, backward inference, new concept formation, and so on, in a unified manner. The demo also allows the user to create new examples to test the system, as well as to see the internal structure and process when the system is running. The on-line help information contains links to relevant publications.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-204.pdf,
210,2000,Intelligent Systems Demos,Untangle: A New Ontology for Card Catalog Systems,"Christopher Welty and Jessica Jenkins, Vassar College","The ontology used by most card catalog and bibliographic systems is based on a now outdated assumption that users of the systems would be looking for books on shelves, and therefore only books were first-class objects, with people. organizations, etc. as simple attributes. This limited the ability of a user to browse. A new ontology for card catalog systems is proposed that suggests that persons, organizations, conferences, etc., should be first-class objects with attributes and relations of their own, creating a rich space of background information that helps users find what they are looking for. This new ontology has been implemented in a knowledge-based system called Untangle, which demonstrates two key advantages of this rich information space: it enables automatic augmentation of the data through reasoning, and it enables a new paradigm for search that combines querying and browsing.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-205.pdf,
211,2000,Robot Competition and Exhibition,Symbol Recognition and Artificial Emotion for Making an Autonomous Robot Attend the AAAI Conference,"François Michaud, Dominic Létourneau, Jonathan Audet, and François Bélanger, Université de Sherbrooke","This paper describes the use of a symbol recognition approach on a autonomous mobile robot, which also uses artificial emotion to manage its goals, for the Robot Challenge, attempting to attend AAAI Conference. The goal is to use signs to guide the robot to the registration desk, to let the robot move around in the crowd, recognize dignitaries and possibly recharging itself if required, and go to a conference room and give a short presentation, using Internet and HTML, about what the whole experience.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-206.pdf,
212,2000,Robot Competition and Exhibition,The Blue Swarm,"Dan Stormont, Utah State University","There are a number of robotics applications that require covering a large area thoroughly and in a minimum amount of time. For these types of applications, a swarm of robots can be an ideal solution. The Utah State University entry in the Urban Search and Rescue competition is the Blue Swarm, named after the Utah State University mascot, ""Big Blue"". This swarm was developed as part of a two year engineering project, so the swarm being developed for the AAAI 2000 Robotics Competition is just an interim capability. This paper describes the current and planned capabilities for the Blue Swarm.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-207.pdf,
213,2000,Invited Talks,Decision Making under Uncertainty: Operations Research Meets AI (Again),"Craig Boutilier, University of Toronto","Models for sequential decision making under uncertainty (e.g., Markov decision processes, or MDPs) have been studied in operations research for decades. The recent incorporation of ideas from many areas of AI, including planning, probabilistic modeling, machine learning, and knowledge representation) have made these models much more widely applicable. I briefly survey recent advances within AI in the use of fully- and partially-observable MDPs as a modeling tool, and the development of computationally-manageable solution methods. I will place special emphasis on factored problem representations such as Bayesian networks and algorithms that exploit the structure inherent in these representations.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-208.pdf,
214,2000,Invited Talks,Why Do We Need a Body Anyway?,"Justine Cassell, MIT Media Lab","Embodiment is all the rage: humanoid agents, robots with eyelashes. It brings back those glory days of AI when ""human-like"" was a goal in and of itself. And yet, the trend is towards smart environments, disappearing computers, intelligent rooms. These systems are said to allow people to interact with the room ""as they interact with another person"". In this talk I will agree with Harry Potter that one should ""never trust anything that can think for itself, if you can’t see where it keeps its brain"". I’ll argue that humans need to locate intelligence, and that this issue poses problems for the disappearing computer. Bodies are the best possible example of located intelligence, of course, and interacting with another person is best done when there is another person to interact with. On this basis of this discussion, I will support the use of embodiment in certain AI domains and demonstrate with a series of implemented systems, including some new work on ""shared reality"" -- a paradigm in which both human and computer share a real physical space within which to make hand gestures, facial displays, body movements, and real physical objects that can be passed back and forth between the real and virtual world. But I will claim that unless we understand the ""affordances"" of the body -- for face-to-face conversation, for situating intelligence, for establishing trust and other kinds of interactional glue -- then neither embodied systems nor invisible computers will ever be more than just another Cheshire Cat face.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-209.pdf,
215,2000,Invited Talks,"Structure, Duality, and Randomization: Common Themes in AI and OR","Carla P. Gomes, Cornell University","Both the Artificial Intelligence (AI) community and the Operations Research (OR) community are interested in developing techniques for solving hard combinatorial problems. OR has relied heavily on mathematical programming formulations such as integer and linear programming, while AI has developed constrained-based search and inference methods. Recently, we have seen a convergence of ideas, drawing on the individual strengths of these paradigms. Furthermore, there is a great deal of overlap in research on local search and meta-heuristics by both communities. Problem structure, duality, and randomization are overarching themes in the study of AI/OR approaches. I will compare and contrast the different views from AI and OR on these topics, highlighting potential synergistic benefits.1",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-210.pdf,
216,2000,Invited Talks,Modeling High-Dimensional Data by Combining Simple Experts,"Geoffrey E. Hinton, University College London","It is possible to combine multiple non-linear probabilistic models of the same data by multiplying the probability distributions together and then renormalizing. A ""product of experts"" is a very efficient way to model data that simultaneously satisfies many different constraints. It is difficult to fit a product of experts to data using maximum likelihood because the gradient of the log likelihood is intractable, but there is an efficient way of optimizing a different objective function and this produces good models of high-dimensional data.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-211.pdf,
217,2000,Invited Talks,Recent Progress in the Design and Analysis of Admissible Heuristic Functions,"Richard E. Korf, University of California, Los Angeles","In the past several years, significant progress has been made in finding optimal solutions to combinatorial problems. In particular, random instances of both Rubik’s Cube, with over 1019 states, and the 5 x 5 sliding-tile puzzle, with almost 1025 states, have been solved optimally. This progress is not the result of better search algorithms, but more effective heuristic evaluation functions. In addition, we have learned how to accurately predict the running time of admissible heuristic search algorithms, as a function of the solution depth and the heuristic evaluation function. One corollary of this analysis is that an admissible heuristic function reduces the effective depth of search, rather than the effective branching factor.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-212.pdf,
218,2000,Invited Talks,Human-Level AI’s Killer Application: Interactive Computer Games,"John E. Laird and Michael van Lent, University of Michigan","Although one of the fundamental goals of AI is to understand and develop intelligent systems that have all of the capabilities of humans, there is little active research directly pursuing that goal. We propose that AI for interactive computer games is an emerging application area in which this goal of human-level AI can successfully be pursued. Interactive computer games have increasingly complex and realistic worlds and increasingly complex and intelligent computer-controlled characters. In this paper, we further motivate our proposal of using interactive computer games, review previous research on AI and games, and present the different game genres and the roles that human-level AI could play within these genres. We then describe the research issues and AI techniques that are relevant to each of these roles. Our conclusion is that interactive computer games provide a rich environment for incremental research on human-level AI.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-213.pdf,
219,2000,Invited Talks,The Games Computers (and People) Play,"Jonathan Schaeffer, University of Alberta","The development of high-performance game-playing pro-grams has been one of the major successes of artificial intelligence research. The results have been outstanding but, with one notable exception (Deep Blue), they have not been widely disseminated. This talk will discuss the past, present, and future of the development of games-playing programs. Case studies for backgammon, bridge, checkers, chess, go, hex, Othello, poker, and Scrabble will be used. The research emphasis of the past has been on high performance (synonymous with brute-force search) for two-player perfect-information games. The research emphasis of the present encompasses multi-player imperfect/non-deterministic information games. And what of the future? There are some surprising changes of direction occurring that will result in games being more of an experimental testbed for mainstream AI research, with less emphasis on building world-championship-caliber programs.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-214.pdf,
220,2000,Invited Talks,Conceptual Indexing: Practical Large-Scale AI for Efficient Information Access,"William A. Woods, Sun Microsystems Laboratories","Finding information is a problem shared by people and intelligent systems. This paper describes an experiment combining both human and machine aspects in a knowledge-based system to help people find information in text. Unlike many previous attempts, this system demonstrates a substantial improvement in search effectiveness by using linguistic and world knowledge and exploiting sophisticated knowledge representation techniques. It is also an example of practical subsumption technology on a large scale and with domain-independent knowledge. Results from this experiment are relevant to general problems of knowledge-based reasoning with large-scale knowledge bases.",https://aaai.org/Library/AAAI/2000/../../../Papers/AAAI/2000/AAAI00-215.pdf,
