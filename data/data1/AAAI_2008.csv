,conference_year,category,title,author,abstract,download_url,keywords
0,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Memetic Networks: Analyzing the Effects of Network Properties in Multi-Agent Performance,"Ricardo M Araujo, Luis C. Lamb","We explore the relationship between properties of the network defined by connected agents and the global system performance. This is achieved by means of a novel class of optimization algorithms. This new class makes explicit use of an underlying network that structures the information flow between multiple agents performing local searches. We show that this new class of algorithms is competitive with respect to other population-based optimization techniques. Finally, we demonstrate by numerical simulations that changes in the way the network is built leads to variations in the system's performance. In particular, we show how constrained hubs — highly connected agents — can be beneficial in particular optimization problems.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-001.pdf,Subjects: 7. Distributed AI; 7.1 Multi-Agent Systems
1,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Physical Search Problems Applying Economic Search Models,"Yonatan Aumann, Noam Hazon, Sarit Kraus, David Sarne","This paper considers the problem of an agent searching for a resource or a tangible good in a physical environment, where at each stage of its search it observes one source where this good can be found. The cost of acquiring the resource or good at a given source is uncertain (a-priori), and the agent can observe its true value only when physically arriving at the source. Sample applications involving this type of search include agents in exploration and patrol missions (e.g., an agent seeking to find the best location to deploy sensing equipment along its path). The uniqueness of these settings is that the expense of observing the source on each step of the process derives from the last source the agent explored. We analyze three variants of the problem, differing in their objective: minimizing the total expected cost, maximizing the success probability given an initial budget, and minimizing the budget necessary to obtain a given success probability. For each variant, we first introduce and analyze the problem with a single agent, either providing a polynomial solution to the problem or proving it is NP-Complete. We also introduce an innovative fully polynomial time approximation scheme algorithm for the minimum budget variant. Finally, the results for the single agent case are generalized to multi-agent settings.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-002.pdf,Subjects: 7.1 Multi-Agent Systems; 15.5 Decision Theory
2,2008,"Agents, Game Theory, Auctions, and Mechanism Design",A Theory of Expressiveness in Mechanisms,"Michael Benisch, Norman Sadeh, Tuomas Sandholm","A key trend in (electronic) commerce is a demand for higher levels of expressiveness in the mechanisms that mediate interactions. We develop a theory that ties the expressiveness of mechanisms to their efficiency in a domain-independent manner. We introduce two new expressiveness measures, 1) maximum impact dimension, which captures the number of ways that an agent can impact the outcome, and 2) shatterable outcome dimension, which is based on the concept of shattering from computational learning theory. We derive an upper bound on the expected efficiency of any mechanism under its most efficient Nash equilibrium. Remarkably, it depends only on the mechanism’s expressiveness. We prove that the bound increases strictly as we allow more expressiveness. We also show that in some cases a small increase in expressiveness yields an arbitrarily large increase in the bound. Finally, we study channel-based mechanisms, which subsume most combinatorial auctions, multi-attribute mechanisms, and the Vickrey-Clarke-Groves scheme. We show that our domain-independent measures of expressiveness appropriately relate to the natural measure of expressiveness of channel-based mechanisms: the number of channels allowed. Using this bridge, our general results yield interesting implications. For example, any (channel-based) multi-item auction that does not allow rich combinatorial bids can be arbitrarily inefficient—unless agents have no private information.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-003.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
3,2008,"Agents, Game Theory, Auctions, and Mechanism Design","Multiagent Graph Coloring: Pareto Efficiency, Fairness and Individual Rationality","Yaad Blum, Jeffrey S. Rosenschein","We consider a multiagent extension of single-agent graph coloring. Multiple agents hold disjoint autonomous subgraphs of a global graph, and every color used by the agents in coloring the graph has associated cost. In this multiagent graph coloring scenario, we seek a minimum legal coloring of the global graph's vertices, such that the coloring is also Pareto efficient, socially fair, and individual rational. We analyze complexity of individual-rational solutions in special graph classes where classical coloring algorithms are known. Multiagent graph coloring has application to a wide variety of multiagent coordination problems, including multiagent scheduling.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-004.pdf,Subjects: 7.1 Multi-Agent Systems; 15.2 Constraint Satisfaction
4,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Expressive Banner Ad Auctions and Model-Based Online Optimization for Clearing,"Craig Boutilier, David C. Parkes, Tuomas Sandholm, William E. Walsh",We present the design of a banner advertising auction which is considerably more expressive than current designs. We describe a general model of expressive ad contracts/bidding and an allocation model that can be executed in real time through the assignment of fractions of relevant ad channels to specific advertiser contracts. The uncertainty in channel supply and demand is addressed by the formulation of a stochastic combinatorial optimization problem for channel allocation that is rerun periodically. We solve this in two different ways: fast deterministic optimization with respect to expectations; and a novel online sample-based stochastic optimization method—that can be applied to continuous decision spaces—which exploits the deterministic optimization as a black box. Experiments demonstrate the importance of expressive bidding and the value of stochastic optimization.,https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-005.pdf,Subjects: 1. Applications; 7.1 Multi-Agent Systems
5,2008,"Agents, Game Theory, Auctions, and Mechanism Design",A Computational Analysis of the Tournament Equilibrium Set,"Felix Brandt, Felix Fischer, Paul Harrenstein, Maximilian Mair","A recurring theme in AI and multiagent systems is how to select the ""most desirable"" elements given a binary dominance relation on a set of alternatives. Schwartz's tournament equilibrium set (TEQ) ranks among the most intriguing, but also among the most enigmatic, tournament solutions proposed so far in this context. Due to its unwieldy recursive definition, little is known about TEQ. In particular, its monotonicity remains an open problem to date. Yet, if TEQ were to satisfy monotonicity, it would be a very attractive solution concept refining both the Banks set and Dutta's minimal covering set. We show that the problem of deciding whether a given alternative is contained in TEQ is NP-hard. Furthermore, we propose a heuristic that significantly outperforms the naive algorithm for computing TEQ. Early experimental results support the conjecture that TEQ is indeed monotonic.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-006.pdf,Subjects: 7.1 Multi-Agent Systems; 9.2 Computational Complexity
6,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Approximability of Manipulating Elections,"Eric Brelsford, Piotr Faliszewski, Edith Hemaspaandra, Henning Schnoor, Ilka Schnoor","In this paper, we set up a framework to study approximation of manipulation, control, and bribery in elections. We show existence of approximation algorithms (even fully polynomial time approximation schemes) as well as obtain inapproximability results.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-007.pdf,
7,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Efficient Metadeliberation Auctions,"Ruggiero Cavallo, David C. Parkes","Imagine a resource allocation scenario in which the interested parties can, at a cost, individually research ways of using the resource to be allocated, potentially increasing the value they would achieve from obtaining it. Each agent has a private model of its research process and obtains a private realization of its improvement in value, if any. From a social perspective it is optimal to coordinate research in a way that strikes the right tradeoff between value and cost, ultimately allocating the resource to one party—thus this is a problem of multi-agent metadeliberation. We provide a reduction of computing the optimal deliberation-allocation policy to computing Gittins indices in multi-armed bandit worlds, and apply a modification of the dynamic-VCG mechanism to yield truthful participation in an ex post equilibrium. Our mechanism achieves equilibrium implementation of the optimal policy even when agents have the capacity to deliberate about other agents' valuations, and thus addresses the problem of strategic deliberation.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-008.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
8,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Achieving Cooperation in a Minimally Constrained Environment,"Steven Damer, Maria Gini","We describe a simple environment to study cooperation between two agents and a method of achieving cooperation in that environment. The environment consists of randomly generated normal form games with uniformly distributed payoffs. Agents play multiple games against each other, each game drawn independently from the random distribution. In this environment cooperation is difficult. Tit-for-Tat cannot be used because moves are not labeled as cooperate"" or ""defect"", fictitious play cannot be used because the agent never sees the same game twice, and approaches suitable for stochastic games cannot be used because the set of states is not finite. Our agent identifies cooperative moves by assigning an attitude to its opponent and to itself. The attitude determines how much a player values its opponents payoff, i.e how much the player is willing to deviate from strictly self-interested behavior. To cooperate, our agent estimates the attitude of its opponent by observing its moves and reciprocates by setting its own attitude accordingly. We show how the opponent's attitude can be estimated using a particle filter, even when the opponent is changing its attitude.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-009.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
9,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Generalized Point Based Value Iteration for Interactive POMDPs,"Prashant Doshi, Dennis Perez","We develop a point based method for solving finitely nested interactive POMDPs approximately. Analogously to point based value iteration (PBVI) in POMDPs, we maintain a set of belief points and form value functions composed of those value vectors that are optimal at these points. However, as we focus on multiagent settings, the beliefs are nested and computation of the value vectors relies on predicted actions of others. Consequently, we develop a novel interactive generalization of PBVI applicable to multiagent settings.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-010.pdf,Subjects: 7.1 Multi-Agent Systems; 15.5 Decision Theory
10,2008,"Agents, Game Theory, Auctions, and Mechanism Design",On the Dimensionality of Voting Games,"Edith Elkind, Leslie Ann Goldberg, Paul Goldberg, Michael Wooldridge","In a yes/no voting game, a set of voters must determine  whether to accept or reject a given alternative. Weighted   voting games are a well-studied subclass of yes/no voting games,  in which each voter has a weight, and an alternative is accepted if  the total weight of its supporters exceeds a certain threshold.  Weighted voting games are naturally extended to k-vector weighted  voting games, which are intersections of k different weighted  voting games: a coalition wins if it wins in every component game.  The dimensionality, k, of a k-vector weighted voting game can be  understood as a measure of the complexity of the game. In this  paper, we analyse the dimensionality of such games from the point of  view of complexity theory. We consider the problems of  equivalence, (checking whether two given voting games have  the same set of winning coalitions), and minimality,  (checking whether a given k-vector voting game can be simplified  by deleting one of the component games, or, more generally, is  equivalent to a k'-weighted voting game with k'<k). We show  that these problems are computationally hard, even if k=1 or all  weights are 0 or 1. However, we provide efficient algorithms for  cases where both k is small and the weights are polynomially  bounded. We also study the notion of monotonicity in voting  games, and show that monotone yes/no voting games are essentially as  hard to represent and work with as general games.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-011.pdf,Subjects: 7.1 Multi-Agent Systems; 9.2 Computational Complexity
11,2008,"Agents, Game Theory, Auctions, and Mechanism Design",First-Order Algorithm with O(ln(1/epsilon)) Convergence for epsilon-Equilibrium in Two-Person Zero-Sum Games,"Andrew Gilpin, Javier Pena, Tuomas Sandholm","We propose an iterated version of Nesterov's first-order smoothing method for the two-person zero-sum game equilibrium problem. This formulation applies to matrix games as well as sequential games. Our new algorithmic scheme computes an ε-equilibrium to this min-max problem in O(K(A) ln (1/ε)) first-order iterations, where K(A) is a certain condition measure of the matrix A.This improves upon the previous first-order methods which required O(1/ε) iterations, and it matches the iteration complexity bound of interior-point methods in terms of the algorithm's dependence on ε.Unlike the interior-point methods that are inapplicable to large games due to their memory requirements, our algorithm retains the small memory requirements of prior first-order methods.Our scheme supplements a variant of Nesterov's algorithm with an outer loop that lowers the target ε between iterations (this target affects the amount of smoothing in the inner loop). We find it surprising that such a simple modification yields an exponential speed improvement. Finally, computational experiments both in matrix games and sequential games show that a significant speed improvement is obtained in practice as well, and the relative speed improvement increases with the desired accuracy (as suggested by the complexity bounds).",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-012.pdf,Subjects: 7.1 Multi-Agent Systems; 8. Enabling Technologies
12,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Agent Organized Networks Redux,"Robin Glinton, Katia Sycara, Paul Scerri","Individual robots or agents will often need to form coalitions to accomplish shared tasks, e.g., in sensor networks or markets. Furthermore, in most real systems it is infeasible for entities to interact with all peers. The presence of a social network can alleviate this problem by providing a neighborhood system within which entities interact with a reduced number of peers. Previous research has shown that the topology of the underlying social network has a dramatic effect on the quality of coalitions formed and consequently on system performance. It has also been shown that it is feasible to develop agents which dynamically alter connections to improve an organization's ability to form coalitions on the network. However those studies have not analyzed the network topologies that result from connectivity adaptation strategies. In this paper the resulting network topologies were analyzed and it was found that high performance and rapid convergence were attained because scale free networks were being formed. However it was observed that organizational performance is not impacted by limiting the number of links per agent to the total number of skills available within the population, implying that bandwidth was wasted by previous approaches. We used these observations to inform the design of a token based algorithm that attains higher performance using an order of magnitude less messages for both uniform and non-uniform distributions of skills.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-013.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
13,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Reasoning about the Appropriateness of Proponents for Arguments,Anthony Hunter,"Formal approaches to modelling argumentation provide ways to present arguments and counterarguments, and to evaluate which arguments are, in a formal sense, warranted. While these proposals allow for evaluating object-level arguments and counterarguments, they do not give sufficient consideration to evaluating the proponents of the arguments. Yet in everyday life we consider both the contents of an argument and its proponent. So if we do not trust a proponent, we may choose to not trust their arguments. Or if we are faced with an argument that we do not have the expertise to assess (for example when deciding whether to agree to having a particular surgical operation), we tend to agree to an argument by someone who is an expert. In general, we see that for each argument, we need to determine the appropriateness of the proponent for it. So for an argument about our health, our doctor is normally an appropriate proponent, but for an argument about our investments, our doctor is normally not an appropriate proponent. In this way, a celebrity is rarely an appropriate proponent for an argument, and a liar is not necessarily an inappropriate proponent for an argument. In this paper, we provide a logic-based framework for evaluating arguments in terms of the appropriateness of the proponents.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-014.pdf,Subjects: 11. Knowledge Representation; 7.1 Multi-Agent Systems
14,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Bayesian Coalitional Games,"Samuel Ieong, Yoav Shoham","We introduce Bayesian Coalitional Games (BCGs), a generalization of classical coalitional games to settings with uncertainties. We define the semantics of BCG using the partition model, and generalize the notion of payoffs to contracts among agents. To analyze these games, we extend the solution concept of the core under three natural interpretations—ex ante, ex interim, and ex post—which coincide with the classical definition of the core when there is no uncertainty. In the special case where agents are risk-neutral, we show that checking for core emptiness under all three interpretations can be simplified to linear feasibility problems similar to that of their classical counterpart.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-015.pdf,Subjects: 7.1 Multi-Agent Systems; 3.4 Probabilistic Reasoning
15,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Agent Coordination with Regret Clearing,"Sven Koenig, Craig Tovey, Richard Borie, Philip Kilby, Vangelis Markakis, Pinar Keskinocak","Sequential single-item auctions can be used for the distributed allocation of tasks to cooperating agents. We study how to improve the team performance of sequential single-item auctions while still controlling the agents in real time. Our idea is to assign that task to agents during the current round whose regret is large, where the regret of a task is defined as the difference of the second-smallest and smallest team costs resulting from assigning the task to the second-best and best agent, respectively. Our experimental results show that sequential single-item auctions with regret clearing indeed result in smaller team costs than standard sequential single-item auctions for three out of four combinations of two different team objectives and two different capacity constraints (including no capacity constraints).",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-016.pdf,Subjects: 7.1 Multi-Agent Systems; 17. Robotics
16,2008,"Agents, Game Theory, Auctions, and Mechanism Design",An Expressive Auction Design for Online Display Advertising,"Sebastien Lahaie, David C. Parkes, David M. Pennock","We propose an expressive auction design that allows advertisers to specify the kinds of demographics and websites they wish to target within an advertising network. The design allows the network to differentiate impressions according to relevant attributes (e.g., geographic location of the user, topic of the webpage). Advertisers can place bids for different kinds of impressions according to their attributes, and can also specify volume constraints to control exposure. The novelty of the design is a bidding language that admits scalable allocation and pricing algorithms. We discuss the incentive properties of different pricing approaches. We also propose a bidder feedback mechanism to mitigate the complexity of expressive bidding.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-017.pdf,Subjects: 1. Applications; 7.1 Multi-Agent Systems
17,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Computer-Aided Proofs of Arrow's and Other Impossibility Theorems,"Fangzhen Lin, Pingzhong Tang","Arrow's Impossibility Theorem is one of the landmark results in social choice theory. Over the years since the theorem was proved in 1950, quite a few alternative proofs have been put forward. In this paper, we propose yet another alternative proof of the theorem. The basic idea is to use induction to reduce the theorem to the base case with 3 alternatives and 2 agents and then use computers to verify the base case. This turns out to be an effective approach for proving other impossibility theorems such as Sen's and Muller-Satterthwaite's theorems as well. Furthermore, we believe this new proof opens an exciting prospect of using computers to discover similar impossibility or even possibility results.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-018.pdf,Subjects: 7.1 Multi-Agent Systems; 11. Knowledge Representation
18,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Resource Constrained Distributed Constraint Optimization with Virtual Variables,"Toshihiro Matsui, Marius Silaghi,Katsutoshi Hirayama,Makoto Yokoo,Hiroshi Matsuo","Cooperative problem solving with resource constraints are important in practical multi-agent systems. Resource constraints are necessary to handle practical problems including distributed task scheduling with limited resource availability. A dedicated framework called Resource Constrained DCOP (RCDCOP) has recently been proposed. RCDCOP models objective functions and resource constraints separately. A resource constraint is an n-ary constraint that represents the limit on the number of resources of a given type available to agents. Previous research addressing RCDCOPs employs the Adopt algorithm, which is an efficient solver for DCOPs. An important graph structure for Adopt is the pseudo-tree for constraint networks. A pseudo-tree implies a partial ordering of variables. In this variable ordering, n-ary constrained variables are placed on a single path of the tree. Therefore, resource constraints that have large arity augment the depth of the pseudo-tree. This also reduces the parallelism, and therefore the efficiency of Adopt. In this paper we propose another version of the Adopt algorithm for RCDCOP using a pseudo-tree that is generated ignoring resource constraints. The proposed method reduces the previous limitations in the construction of RCDCOP pseudo-trees. The key ideas of our work are as follows: (i) The pseudo-tree is generated ignoring resource constraints. (ii) Virtual variables are introduced, representing the usage of resources. These virtual variables are used to share resources among sub-trees. However, the addition of virtual variables increases the search space. To handle this problem, influence of placement of virtual variables/resources constraints in the pseudo tree is considered. Moreover the search is pruned using the bounds defined by the resource constraints if possible. These ideas are used to extend Adopt. The efficiency of our technique depends on the class of problems being considered, and we describe the obtained experimental results.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-019.pdf,Subjects: 7.1 Multi-Agent Systems; 15.2 Constraint Satisfaction
19,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Strategyproof Classification Under Constant Hypotheses: A Tale of Two Functions,"Reshef Meir, Ariel D. Procaccia, Jeffrey S. Rosenschein","We consider the following setting: a decision maker must make a decision based on reported data points with binary labels. Subsets of data points are controlled by different selfish agents, which might misreport the labels in order to sway the decision in their favor. We design mechanisms (both deterministic and randomized) that reach an approximately optimal decision and are strategyproof, i.e., agents are best off when they tell the truth. We then recast our results into a classical machine learning classification framework, where the decision maker must make a decision (choose between the constant positive hypothesis and the constant negative hypothesis) based only on a sampled subset of the agents' points.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-020.pdf,Subjects: 7.1 Multi-Agent Systems; 9. Foundational Issues
20,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Argument Theory Change Applied to Defeasible Logic Programming,"Martin Moguillansky, Nicolas Rotstein, Marcelo Falappa, Alejandro Garcia, Guillermo Simari","In this article we work on certain aspects of the belief change theory in order to make them suitable for argumentation systems. This approach is based on Defeasible Logic Programming as the argumentation formalism from which we ground the definitions. The objective of our proposal is to define an argument revision operator that inserts a new argument into a defeasible logic program in such a way that this argument ends up undefeated after the revision, thus warranting its conclusion. In order to ensure this warrant, the defeasible logic program has to be changed in concordance with a minimal change principle. Finally, we present an algorithm that implements the argument revision operation.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-021.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 15.1 Belief Revision
21,2008,"Agents, Game Theory, Auctions, and Mechanism Design",The Impact of Vertical Specialization on Hierarchical Multi-Agent Systems,"Steven Okamoto, Paul Scerri, Katia Sycara","Hierarchies are one of the most common organizational structures observed in multi-agent systems. In this paper we study vertical specialization as a reason for hierarchical structures. In vertically specialized systems, more highly skilled agents are also more costly. By using less capable agents to initially process tasks and forwarding only exceptional tasks to more capable agents, such systems may be able to economize on the number of highly capable agents. The result is a hierarchical structure with least capable agents at the bottom. However, such a structure increases the delay in completing some tasks, because they must pass through multiple levels of control. Thus, vertical specialization presents a tradeoff between economizing on skilled agents and increasing task completion time. We find that for a wide range of settings, vertical specialization induces an optimal hierarchy of height at most three. This suggests that a multi-agent system designer interested in exploiting vertical specialization needs to use at most three levels of specialization in order to reap most of the benefits.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-022.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
22,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Coordination and Multi-Tasking Using EMT,"Zinovi Rabinovich, Nir Pochter, Jeffrey S. Rosenschein","We introduce a multi-model variant of the EMT-based control  algorithm. The new algorithm, MM-EMT, is capable of balancing  several control tasks expressed using separate dynamic models with a  common action space. Such multiple models are common in both  single-agent environments, when the agent has multiple tasks to  achieve, and in team activities, when agent actions affect both the  local agent's task as well as the overall team's coordination.  To demonstrate the behaviour that MM-EMT engenders, several  experimental setups were devised. Simulation results support the  effectiveness of the approach, which in the multi-agent scenario is  expressed in the MM-EMT algorithm's ability to balance local and  team-coordinated motion requirements.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-023.pdf,Subjects: 7.1 Multi-Agent Systems; 17. Robotics
23,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Pareto Optimality in Abstract Argumentation,"Iyad Rahwan, Kate Larson","Since its introduction in the mid-nineties, Dung's theory of abstract argumentation frameworks has been influential in artificial intelligence. Dung viewed arguments as abstract entities with a binary defeat relation among them. This enabled extensive analysis of different (semantic) argument acceptance criteria. However, little attention was given to comparing such criteria in relation to the preferences of self-interested agents who may have conflicting preferences over the final status of arguments. In this paper, we define a number of agent preference relations over argumentation outcomes. We then analyse different argument evaluation rules taking into account the preferences of individual agents. Our framework and results inform the mediator (e.g. judge) to decide which argument evaluation rule (i.e. semantics) to use given the type of agent population involved.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-024.pdf,Subjects: 7. Distributed AI; 7.1 Multi-Agent Systems
24,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Coalition Structure Generation: Dynamic Programming Meets Anytime Optimization,"Talal Rahwan, Nicholas R. Jennings","Coalition structure generation involves partitioning a set of agents into exhaustive and disjoint coalitions so as to maximize the social welfare. What makes this such a challenging problem is that the number of possible solutions grows exponentially as the number of agents increases. To date, two main approaches have been developed to solve this problem, each with its own strengths and weaknesses. The state of the art in the first approach is the Improved Dynamic Programming (IDP) algorithm, due to Rahwan and Jennings, that is guaranteed to find an optimal solution in O(3^n), but which cannot generate a solution until it has completed its entire execution. The state of the art in the second approach is an anytime algorithm called IP, due to Rahwan et al., that provides worst-case guarantees on the quality of the best solution found so far, but which is O(n^n). In this paper, we develop a novel algorithm that combines both IDP and IP, resulting in a hybrid performance that exploits the strength of both algorithms and, at the same, avoids their main weaknesses. Our approach is also significantly faster (e.g. given 25 agents, it takes only 28% of the time required by IP, and 0.3% of the time required by IDP).",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-025.pdf,Subjects: 7.1 Multi-Agent Systems; 15. Problem Solving
25,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Partially-Synchronized DEC-MDPs in Dynamic Mechanism Design,"Sven Seuken, Ruggiero Cavallo, David C. Parkes","Consider a multi-agent system with agents that have local actions, rewards, and states, all private and also with a central coordinator (the ""center"") that has its own actions, rewards, and states. Agents can never communicate with each other and are periodically inaccessible to the center. When accessible to the center, agents can report their local state (and models) and receive recommendations from the center about local policies to follow for the present period and also, should they become inaccessible, until becoming accessible again. The actions of the center also affect the reward and state of agents, when accessible. This provides a rich new problem class for decentralized Markov decision processes (DEC-MDPs), the partially-synchronized DEC-MDPs. But we also allow for self-interested agents, and are able to bridge to methods of dynamic mechanism design, aligning incentives so that agents report local state when accessible and choose to follow the prescribed policy of the center.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-026.pdf,Subjects: 7.1 Multi-Agent Systems; 3.4 Probabilistic Reasoning
26,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Mathematical Modeling and Convergence Analysis of Trail Formation,"Sameena Shah, Ravi Kothari, Jayadeva, Suresh Chandra","An ant deposits pheromone along the path that it travels and is more likely to choose a path with a higher concentration of pheromone. The sensing and dropping of pheromone makes it easy to understand the trail forming behavior of ants. The reinforcement tendency of pheromone following behavior ensures selection of the shortest path from a set of paths. The reinforcement tendency of pheromone following behavior also ensures a biased selection of the initially followed paths over a path, which is shorter but discovered through chance at a later point in time. Under what conditions and limits can this \textit{initial bias be reversed}? In this paper, we answer this question based on a theoretical analysis of the trail forming behavior of ants. We believe our results to contribute to the overall area of understanding how to build scalable systems that evolve to solve complex problems (e.g. point covering or the traveling salesman problem) without the necessity of central command-and-control.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-027.pdf,Subjects: 1.2 Artificial Life; 7.1 Multi-Agent Systems
27,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Semantical Considerations on Dialectical and Practical Commitments,Munindar P. Singh,"This paper studies commitments in multiagent systems. A dialectical commitment corresponds to an agent taking a position about a putative fact, including for the sake of argument. A practical commitment corresponds to an agent being obliged to another to bring about a condition. Although commitments have been used in many works, an adequate formal semantics and axiomatization for them does not yet exist. This paper presents a logic of commitments that illustrates the commonalities and differences of the two kinds of commitments. In this manner, it generalizes the developments of previous papers,precisely delineates the meanings of commitments, and identifies important postulates used informally or semiformally in previous work. Subjects: 7.1 Multi-Agent Systems; 9.3 Mathematical Foundations Submitted: Apr 15, 2008    This page is copyrighted by AAAI. All rights reserved. Your use of this site constitutes acceptance of all of AAAI's terms and conditions and privacy policy.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-028.pdf,Subjects: 7.1 Multi-Agent Systems; 9.3 Mathematical Foundations
28,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Bidding Strategies for Realistic Multi-Unit Sealed-Bid Auctions,"Ioannis A. Vetsikas, Nicholas R. Jennings","When autonomous agents decide on their bidding strategies in real world auctions, they have a number of concerns that go beyond the models that are normally analyzed in traditional auction theory. Oftentimes, the agents have budget constraints and the auctions have a reserve price, both of which restrict the bids the agents can place. In addition, their attitude need not be risk-neutral and they may have uncertainty about the value of the goods they are buying. Some of these issues have been examined individually for single-unit sealed-bid auctions. In this paper, we extend this analysis to the multi-unit case, and also analyze the multi-unit sealed-bid auctions in which a combination of these issues are present, for unit-demand bidders. This analysis constitutes the main contribution of this paper. We then demonstrate the usefulness in practice of this analysis; we show in simulations that taking into account all these issues allows the bidders to maximize their utility. Furthermore, using this analysis allows a seller to improve her revenue, i.e. by selecting the optimal reserve price.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-029.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
29,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Optimal False-Name-Proof Voting Rules with Costly Voting,"Liad Wagman, Vincent Conitzer","One way for agents to reach a joint decision is to vote over the alternatives. In open, anonymous settings such as the Internet, an agent can vote more than once without being detected. A voting rule is false-name-proof if no agent ever benefits from casting additional votes. Previous work has shown that all false-name-proof voting rules are unresponsive to agents' preferences. However, that work implicitly assumes that casting additional votes is costless. In this paper, we consider what happens if there is a cost to casting additional votes. We characterize the optimal (most responsive) false-name-proof-with-costs voting rule for 2 alternatives. In sharp contrast to the costless setting, we prove that as the voting population grows larger, the probability that this rule selects the majority winner converges to 1. We also characterize the optimal group false-name-proof rule for 2 alternatives, which is robust to coalitions of agents sharing the costs of additional votes. Unfortunately, the probability that this rule chooses the majority winner as the voting population grows larger is relatively low. We derive an analogous rule in a setting with 3 alternatives, and provide bounding results and computational approaches for settings with 4 or more alternatives.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-030.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
30,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Determining Possible and Necessary Winners under Common Voting Rules Given Partial Orders,"Lirong Xia, Vincent Conitzer","Usually a voting rule or correspondence requires agents to give their preferences as linear orders. However, in some cases it is impractical for an agent to give a linear order over all the alternatives. It has been suggested to let agents submit partial orders instead. Then, given a profile of partial orders and a candidate c, two important questions arise: first, is c guaranteed to win, and second, is it still possible for c to win? These are the  necessary winner and  possible winner problems, respectively.  We consider the setting where the number of alternatives is unbounded and the votes are unweighted. We prove that for Copeland, maximin, Bucklin, and ranked pairs, the possible winner problem is NP-complete; also, we give a sufficient condition on scoring rules for the possible winner problem to be NP-complete (Borda satisfies this condition). We also prove that for Copeland and ranked pairs, the necessary winner problem is coNP-complete. All the hardness results hold even when the number of undetermined pairs in each vote is no more than a constant. We also present polynomial-time algorithms for the necessary winner problem for scoring rules, maximin, and Bucklin. Subjects: 7.1 Multi-Agent Systems; 9.2 Computational Complexity Submitted: Apr 15, 2008    This page is copyrighted by AAAI. All rights reserved. Your use of this site constitutes acceptance of all of AAAI's terms and conditions and privacy policy.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-031.pdf,Subjects: 7.1 Multi-Agent Systems; 9.2 Computational Complexity
31,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Voting on Multiattribute Domains with Cyclic Preferential Dependencies,"Lirong Xia, Vincent Conitzer, Jerome Lang","In group decision making, often the agents need to decide on multiple attributes at the same time, so that there are exponentially many alternatives. In this case, it is unrealistic to ask agents to communicate a full ranking of all the alternatives. To address this, earlier work has proposed decomposing such voting processes by using local voting rules on the individual attributes. Unfortunately, the existing methods work only with rather severe domain restrictions, as they require the voters' preferences to extend acyclic CP-nets compatible with a common order on the attributes. We first show that this requirement is very restrictive, by proving that the number of linear orders extending an acyclic CP-net is exponentially smaller than the number of all linear orders. Then, we introduce a very general methodology that allows us to aggregate preferences when voters express CP-nets that can be cyclic. There does not need to be any common structure among the submitted CP-nets. Our methodology generalizes the earlier, more restrictive methodology. We study whether properties of the local rules transfer to the global rule, and vice versa. We also address how to compute the winning alternatives.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-032.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
32,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Value-Based Policy Teaching with Active Indirect Elicitation,"Haoqi Zhang, David Parkes","Many situations arise in which an interested party's utility is dependent on the actions of an agent; e.g., a teacher is interested in a student learning effectively and a firm is interested in a consumer's behavior. We consider an environment in which the interested party can provide incentives to affect the agent's actions but cannot otherwise enforce actions. In value-based policy teaching, we situate this within the framework of sequential decision tasks modeled by Markov Decision Processes, and seek to associate limited rewards with states that induce the agent to follow a policy that maximizes the total expected value of the interested party. We show value-based policy teaching is NP-hard and provide a mixed integer program formulation. Focusing in particular on environments in which the agent's reward is unknown to the interested party, we provide a method for active indirect elicitation wherein the agent's reward function is inferred from observations about its response to incentives. Experimental results suggest that we can generally find the optimal incentive provision in a small number of elicitation rounds.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-033.pdf,Subjects: 12.1 Reinforcement Learning; 9.3 Mathematical Foundations
33,2008,"Agents, Game Theory, Auctions, and Mechanism Design",Manipulating the Quota in Weighted Voting Games,"Michael Zuckerman, Piotr Faliszewski, Yoram Bachrach, Edith Elkind","Weighted voting games provide a popular model of decision making in multiagent systems. Such games are described by a set of players, a list of players' weights, and a quota; a coalition of the players is said to be winning if the total weight of its members meets or exceeds the quota. The power of a player in such games is traditionally identified with her Shapley--Shubik index or her Banzhaf index, two classical power measures that reflect the player's marginal contributions under different coalition formation scenarios. In this paper, we investigate by how much the central authority can change a player's power, as measured by these indices, by modifying the quota. We provide tight upper and lower bounds on the changes in the individual player's power that can result from a change in quota. We also study how the choice of quota can affect the relative power of the players. From the algorithmic perspective, we provide an efficient algorithm for determining whether there is a value of the quota that makes a given player a {\em dummy}, i.e., reduces his power (as measured by both indices) to 0. On the other hand, we show that checking which of the two values of the quota makes this player more powerful is computationally hard, namely, complete for the complexity class PP, which is believed to be significantly more powerful than NP.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-034.pdf,Subjects: 1.8 Game Playing; 7.1 Multi-Agent Systems
34,2008,"Constraints, Satisfiability, and Search",Measuring the Hardness of SAT Instances,"Carlos Ansótegui, María Luisa Bonet, Jordi Levy, Felip Manyà","The search of a precise measure of what hardness of SAT instances means for state-of-the-art solvers is a relevant research question. Among others, the space complexity of tree-like resolution (also called hardness), the minimal size of strong backdoors and of cycle-cutsets, and the treewidth can be used for this purpose. We propose the use of the tree-like space complexity as a solid candidate to be the best measure for solvers based on DPLL. To support this thesis we provide a comparison with the other mentioned measures. We also conduct an experimental investigation to show how the proposed measure characterizes the hardness of random and industrial instances.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-035.pdf,Subjects: 15.9 Theorem Proving; 15.2 Constraint Satisfaction
35,2008,"Constraints, Satisfiability, and Search",A New Incomplete Method for CSP Inconsistency Checking,"Belaïd Benhamou, Mohamed Réda Saïdi","Checking CSP consistency is shown, in theory, to be an NP-complete problem. There is two families of methods for CSP consistency checking. The first family holds the complete methods which make an exhaustive search on the solution space. These methods have the advantage to prove CSP inconsistency, but their complexity grows exponentially when the problem size increases. The second family includes the incomplete methods that make a local search on the solution space. These methods have been efficiently used to find solutions for large size consistent CSPs that complete methods can not solve. One major drawback of the incomplete methods, is their inability to prove CSP inconsistency. One of the challenges that have been put forward by the CP community (Selman et al. 1997) is to provide incomplete methods that can deal with CSP inconsistency efficiently. The work that we present here, is a contribution towards an answer to this hard challenge. We introduce a new incomplete method for CSP inconsistency checking that is based on both a new notion of dominance between CSPs and a coloration of the CSP micro-structure. We experimented the method on randomly generated CSP instances and the results obtained are very promising.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-036.pdf,Subjects: 15. Problem Solving; 15.2 Constraint Satisfaction
36,2008,"Constraints, Satisfiability, and Search",The Parameterized Complexity of Global Constraints,"Christian Bessiere, Emmanuel Hebrard, Brahim Hnich, Zeynep Kiziltan, Claude-Guy Quimper, Toby Walsh","We argue that parameterized complexity is a useful tool with which to study global constraints. In particular, we show that many global constraints which are intractable to propagate completely have natural parameters which make them fixed-parameter tractable and which are easy to compute. This tractability tends either to be the result of a simple dynamic program or of a decomposition which has a strong backdoor of bounded size. This strong backdoor is often a cycle cutset. We also show that parameterized complexity can be used to study other aspects of constraint programming like symmetry breaking. For instance, we prove that value symmetry is fixed-parameter tractable to break in the number of symmetries. Finally, we argue that parameterized complexity can be used to derive results about the approximability of constraint propagation.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-037.pdf,Subjects: 15.2 Constraint Satisfaction; 9.2 Computational Complexity
37,2008,"Constraints, Satisfiability, and Search",Protein Structure Prediction on the Face Centered Cubic Lattice by Local Search,"Manuel Cebrian, Ivan Dotu, Pascal Van Hentenryck, Peter Clote","Ab initio protein structure prediction is an important problem  for which several algorithms have been developed. Algorithms  differ by how they represent 3D protein conformations  (on-lattice, off-lattice, coarse-grain or fine-grain model), by  the energy model they consider,  and whether they are heuristic or exact algorithms.  This paper presents a local search algorithm to  find the native state for the Hydrophobic-Polar (HP) model  on the Face Centered Cubic (FCC) lattice; i.e. a self-avoiding  walk on the FCC lattice with maximum number of H-H contacts.  The algorithm  relies on a randomized, structured initialization, a novel fitness  function to guide the search, and efficient data structures to  obtain self-avoiding walks. Experimental results on benchmark  instances show the efficiency and excellent performance of our algorithm,  and illustrate the biological pertinence of the",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-038.pdf,Subjects: 15.2 Constraint Satisfaction; 3.2 Geometric Or Spatial Reasoning
38,2008,"Constraints, Satisfiability, and Search",Relaxed Survey Propagation: A Sum-Product Algorithm for Max-SAT,"Hai Leong Chieu, Wee Sun Lee","The survey propagation (SP) algorithm has been shown to work well on large instances of the random 3-SAT problem near its phase transition. It was shown that SP estimates marginals over covers, using joker states to represent clusters of configurations. The SP-y algorithm generalizes SP to work on the Max-SAT problem, but the cover interpretation of SP does not generalize to SP-y. Recently, a relaxed survey propagation (RSP) algorithm has been proposed for inference in Markov random fields (MRF). RSP for MRFs assigns zero probability to joker states, and hence the cover interpretation is also inapplicable. We adapt RSP to solve Max-SAT problems, and show that it has an interpretation of estimating marginals over covers violating a minimum number of clauses. This naturally generalizes the cover interpretation of SP. Empirically, we show that RSP outperforms SP-y and other state-of-the-art solvers on random as well as benchmark instances of Max-SAT.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-039.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
39,2008,"Constraints, Satisfiability, and Search",Virtual Arc Consistency for Weighted CSP,"Martin Cooper, Simon de Givry, Marti Sanchez, Thomas Schiex, Matthias Zytnicki","Optimizing a combination of local cost functions on discrete variables is a central problem in many formalisms such as in probabilistic networks, maximum satisfiability, weighted CSP or factor graphs. Recent results have shown that maintaining a form of local consistency in a Branch and Bound search provides bounds that are strong enough to solve many practical instances. In this paper, we introduce Virtual Arc Consistency (VAC) which iteratively identifies and applies sequences of cost propagation over rational costs that are guaranteed to transform a WCSP in another WCSP with an improved constant cost. Although not as strong as Optimal Soft Arc Consistency, VAC is faster and powerful enough to solve submodular problems. Maintaining VAC inside branch and bound leads to important improvements in efficiency on large difficult problems and allowed us to close two famous frequency assignment problem instances.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-040.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
40,2008,"Constraints, Satisfiability, and Search",Simulation-Based Approach to General Game Playing,"Hilmar Finnsson, Yngvi Björnsson","The aim of General Game Playing (GGP) is to create intelligent agents that automatically learn how to play many different games at an expert level without any human intervention. The most successful GGP agents in the past have used traditional game-tree search combined with an automatically learned heuristic function for evaluating game states. In this paper we describe a GGP agent that instead uses a Monte Carlo/UCT simulation technique for action selection, an approach recently popularized in computer Go. Our GGP agent has proven its effectiveness by winning last year’s AAAI GGP Competition. Furthermore, we introduce and empirically evaluate a new scheme for automatically learning search-control knowledge for guiding the simulation playouts, showing that it offers significant benefits for a variety of games.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-041.pdf,Subjects: 1.8 Game Playing; 15.7 Search
41,2008,"Constraints, Satisfiability, and Search",Phase Transitions and Complexity of Weighted Satisfiability and Other Intractable Parameterized Problems,Yong Gao,"The study of random instances of NP complete and coNP complete problems has had much impact on our understanding of the nature of hard problems. In this work, we initiate an effort to extend this line of research to random instances of intractable parameterized problems. We propose random models for a representative intractable parameterized problem, the weighted d-CNF satisfiability, and its generalization to the constraint satisfaction problem. The exact threshold for the phase transition of the proposed models is determined. Lower bounds on the time complexity of variants of the DPLL algorithm for these parameterized problems are also established. In particularly, we show that random instances of the weighted 2-CNF satisfiability, already an intractable parameterized problem, are typically easy in both of the satisfiable and unsatisfiable regions by exploiting an interesting connection between the unsatisfiability of a weighted 2-CNF formula and the existence of a Hamiltonian-cycle-like global structure.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-042.pdf,Subjects: 9.2 Computational Complexity; 15.2 Constraint Satisfaction
42,2008,"Constraints, Satisfiability, and Search",Studies in Solution Sampling,"Vibhav Giridhar Gogate, Rina Dechter","We introduce novel algorithms for generating random solutions from a uniform distribution over the solutions of a boolean satisfiability problem. Our algorithms operate in two phases. In the first phase, we use a recently introduced SampleSearch scheme to generate biased samples while in the second phase we correct the bias by using either Sampling Importance Resampling or the Metropolis-Hastings method. Unlike state of the art algorithms, our algorithms guarantee convergence in the limit. Our empirical results demonstrate the superior performance of our new algorithms over several competing schemes.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-043.pdf,Subjects: 15. Problem Solving; 15.2 Constraint Satisfaction
43,2008,"Constraints, Satisfiability, and Search",On Range of Skill,"Thomas D. Hansen, Peter Bro Miltersen, Troels Bjerre Sørensen","At AAAI'07, Zinkevich, Bowling and Burch introduced the Range of Skill measure of a two-player game and used it as a parameter in the analysis of the running time of an algorithm for finding approximate solutions to such games. They suggested that the Range of Skill of a typical natural game is a small number, but only gave heuristic arguments for this. In this paper, we provide the first methods for rigorously estimating the Range of Skill of a given game. We provide some general, asymptotic bounds that imply that the Range of Skill of a perfectly balanced game tree is almost exponential in its size (and doubly exponential in its depth). We also provide techniques that yield concrete bounds for unbalanced game trees and apply these to estimate the Range of Skill of Tic-Tac-Toe and Heads-Up Limit Texas Hold'em Poker. In particular, we show that the Range of Skill of Tic-Tac-Toe is more than 100,000.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-044.pdf,Subjects: 1.8 Game Playing; 9.2 Computational Complexity
44,2008,"Constraints, Satisfiability, and Search",Clause Learning Can Effectively P-Simulate General Propositional Resolution,"Philipp Hertel, Fahiem Bacchus, Toniann Pitassi, Allen Van Gelder","Currently, the most effective complete SAT solvers are based on the DPLL algorithm augmented by clause learning. These solvers can handle many real-world problems from application areas like verification, diagnosis, planning, and design. Without clause learning, however, DPLL loses most of its effectiveness on real world problems. Recently there has been some work on obtaining a deeper understanding of the technique of clause learning. In this paper we utilize the idea of effective p-simulation, which is a new way of comparing clause learning with general resolution and other proof systems. We then show that pool proofs, a previously used characterization of clause learning, can effectively p-simulate general resolution. Furthermore, this result holds even for the more restrictive class of greedy, unit propagating, pool proofs, which more accurately characterize clause learning as it is used in practice. This result is surprising and indicates that clause learning is significantly more powerful than was previously known.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-045.pdf,Subjects: 15.2 Constraint Satisfaction; 3. Automated Reasoning
45,2008,"Constraints, Satisfiability, and Search",Piecewise Linear Dynamic Programming for Constrained POMDPs,"Joshua D. Isom, Sean P. Meyn, Richard D. Braatz","We describe an exact dynamic programming update for constrained partially observable Markov decision processes (CPOMDPs).  State-of-the-art exact solution of unconstrained POMDPs relies on implicit enumeration of the vectors in the piecewise linear value function, and pruning operations to obtain a minimal representation of the updated value function. In dynamic programming for CPOMDPs, each vector takes two valuations, one with respect to the objective function and another with respect to the constraint function.  The dynamic programming update consists of finding, for each belief state, the vector that has the best objective function valuation while still satisfying the constraint function. Whereas the pruning operation in an unconstrained POMDP requires solution of a linear program, the pruning operation for CPOMDPs requires solution of a mixed integer linear program.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-046.pdf,Subjects: 15. Problem Solving; 15.2 Constraint Satisfaction
46,2008,"Constraints, Satisfiability, and Search",Efficient Memoization for Dynamic Programming with Ad-Hoc Constraints,"Joxan Jaffar, Andrew E. Santosa, Razvan Voicu","We address the problem of effective reuse of subproblem solutions in dynamic programming. In dynamic programming, a memoed solution of a subproblem can be reused for another if the latter’s context is a special case of the former. Our objective is to generalize the context of the memoed subproblem such that more subproblems can be considered subcases and hence enhance reuse. Toward this goal we propose a generalization of context that 1) does not add better solutions than the subproblem’s optimal, yet 2) requires that subsumed subproblems preserve the optimal solution. In addition, we also present a general technique to search for at most k ≥ 1 optimal solutions. We provide experimental results on resource-constrained shortest path (RCSP) benchmarks and program’s exact worst-case execution time (WCET) analysis.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-047.pdf,Subjects: 15.7 Search; 15. Problem Solving
47,2008,"Constraints, Satisfiability, and Search",On the Power of Top-Down Branching Heuristics,"Matti Järvisalo, Tommi Junttila","We study the relative best-case performance of DPLL-based structure-aware SAT solvers in terms of the power of the underlying proof systems. The systems result from (i) varying the style of branching and (ii) enforcing dynamic restrictions on the decision heuristics. Considering DPLL both with and without clause learning, we present a relative efficiency hierarchy for refinements of DPLL resulting from combinations of decision heuristics (top-down restricted, justification restricted, and unrestricted heuristics) and branching styles (typical DPLL-style and ATPG-style branching). An an example, for DPLL without clause learning, we establish a strict hierarchy, with the ATPG-style, justification restricted branching variant as the weakest system.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-048.pdf,Subjects: 15.2 Constraint Satisfaction; 3. Automated Reasoning
48,2008,"Constraints, Satisfiability, and Search",Efficient Context-Free Grammar Constraints,"Serdar Kadioglu, Meinolf Sellmann","With the introduction of constraints based on finite automata a new line of research has opened where constraints are based on formal languages. Recently, constraints based on grammars higher up in the Chomsky hierarchy were introduced. We devise a time- and space-efficient incremental arc-consistency algorithm for context-free grammars. Particularly, we show how to filter a sequence of monotonically tightening problems in cubic time and quadratic space. Experiments on a scheduling problem show orders of magnitude improvements in time and space consumption.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-049.pdf,Subjects: 15.2 Constraint Satisfaction; 9.2 Computational Complexity
49,2008,"Constraints, Satisfiability, and Search",Minimizing Disk I/O in Two-Bit Breadth-First Search,Richard E. Korf,"We present a breadth-first search algorithm, two-bit breadth-first search (TBBFS), which requires only two bits for each state in the problem space. TBBFS can be parallelized in several ways, and can store its data on magnetic disk. Using TBBFS, we perform complete breadth-first searches of the original pancake problem with 14 and 15 pancakes, and the burned pancake problem with 11 and 12 pancakes, determining the diameter of these problem spaces for the first time. We also perform the first complete breadth-first search of the subspace of Rubik's Cube determined by the edge cubies.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-050.pdf,Subjects: 15.7 Search; 15. Problem Solving
50,2008,"Constraints, Satisfiability, and Search",H-DPOP: Using Hard Constraints for Search Space Pruning in DCOP,"Akshat Kumar, Adrian Petcu, Boi Faltings","In distributed constraint optimization problems, dynamic programming methods have been recently proposed (e.g. DPOP). In dynamic programming many valuations are grouped together in fewer messages, which produce much less networking overhead than search. Nevertheless, these messages are exponential in size. The basic DPOP always communicates all possible assignments, even when some of them may be inconsistent due to hard constraints. Many real problems contain hard constraints that significantly reduce the space of feasible assignments. This paper introduces H-DPOP, a hybrid algorithm that is based on DPOP, which uses Constraint Decision Diagrams (CDD) to rule out infeasible assignments, and thus compactly represent UTIL messages. Experimental results show that H-DPOP requires several orders of magnitude less memory than DPOP, especially for dense and tightly-constrained problems.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-051.pdf,Subjects: 15.2 Constraint Satisfaction; 7. Distributed AI
51,2008,"Constraints, Satisfiability, and Search",Online Learning with Expert Advice and Finite-Horizon Constraints,"Branislav Kveton, Jia Yuan Yu, Georgios Theocharous, Shie Mannor","In this paper, we study a sequential decision making problem. The objective is to maximize the average reward accumulated over time subject to temporal cost constraints. The novelty of our setup is that the rewards and constraints are controlled by an adverse opponent. To solve our problem in a practical way, we propose an expert algorithm that guarantees both a vanishing regret and a sublinear number of violated constraints. The quality of this solution is demonstrated on a real-world power management problem. Our results support the hypothesis that online learning with convex cost constraints can be performed successfully in practice.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-052.pdf,Subjects: 12. Machine Learning and Discovery; 16. Real-Time Systems
52,2008,"Constraints, Satisfiability, and Search",Exploiting Causal Independence Using Weighted Model Counting,"Wei Li, Pascal Poupart, Peter van Beek","Previous studies have demonstrated that encoding a Bayesian network into a SAT-CNF formula and then performing weighted model counting using a backtracking search algorithm can be an effective method for exact inference in Bayesian networks. In this paper, we present techniques for improving this approach for Bayesian networks with noisy-OR and noisy-MAX relations—two relations which are widely used in practice as they can dramatically reduce the number of probabilities one needs to specify. In particular, we present two space efficient CNF encodings for noisy-OR and explore alternative search ordering heuristics. These encodings can be easily extended to noisy-MAX. We experimentally evaluated our techniques on large-scale real and randomly generated Bayesian networks. On these benchmarks, our techniques gave speedups of up to two orders of magnitude over the best previous approaches and scaled up to networks with larger numbers of random variables.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-053.pdf,Subjects: 3.4 Probabilistic Reasoning; 3. Automated Reasoning
53,2008,"Constraints, Satisfiability, and Search",R* Search,"Maxim Likhachev, Anthony Stentz","Optimal heuristic searches such as A* search are widely used for planning but can rarely scale to large complex problems. The suboptimal versions of heuristic searches such as weighted A* search can often scale to much larger planning problems by trading off the quality of the solution for efficiency. They do so by relying more on the ability of the heuristic function to guide them well towards the goal. For complex planning problems, however, the heuristic function may often guide the search into a large local minimum and make the search examine most of the states in the minimum before proceeding. In this paper, we propose a novel heuristic search, called R* search, which depends much less on the quality of the heuristic function. The search avoids local minima by solving the whole planning problem with a series of short-range and easy-to-solve searches, each guided by the heuristic function towards a randomly chosen goal. In addition, R* scales much better in terms of memory because it can discard a search state-space after each of its searches. On the theoretical side, we derive probabilistic guarantees on the sub-optimality of the solution returned by R*. On the experimental side, we show that R* can scale to large complex problems.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-054.pdf,Subjects: 15.7 Search; 1.11 Planning
54,2008,"Constraints, Satisfiability, and Search",Within-problem Learning for Efficient Lower Bound Computation in Max-SAT Solving,"Han Lin, Kaile Su, Chu-Min Li","This paper focuses on improving branch-and-bound Max-SAT solvers by speeding up the lower bound computation. We notice that the existing propagation-based computing methods and the resolution-based computing methods, which have been studied intensively, both suffer from several drawbacks. In order to overcome these drawbacks, we propose a new method with a nice property that guarantees the increment of lower bounds. The new method exploits within-problem learning techniques. More specifically, at each branch point in the search-tree, the current node is enabled to inherit inconsistencies from its parent and learn information about effectiveness of the lower bound computing procedure from previous nodes. Furthermore, after branching on a new variable, the inconsistencies may shrink by applying unit propagation to them, and such process increases the probability of getting better lower bounds. We graft the new techniques into maxsatz and the experimental results demonstrate that the new solver outperforms the best state-of-the-art solvers on a wide range of instances including random and structured ones.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-055.pdf,Subjects: 15. Problem Solving; 15.7 Search
55,2008,"Constraints, Satisfiability, and Search",Learning from Multiple Heuristics,"Mehdi Samadi, Ariel Felner, Jonathan Schaeffer","Heuristic functions for single-agent search applications estimate the cost of the optimal solution. When multiple heuristics exist, taking their maximum is an effective way to combine them. A new technique is introduced for combining multiple heuristic values. Inspired by the evaluation functions used in two-player games, the different heuristics in a single-agent application are treated as features of the problem domain. An ANN is used to combine these features into a single heuristic value. This idea has been implemented for the sliding-tile puzzle and the 4-peg Towers of Hanoi, two classic single-agent search domains. Experimental results show that this technique can lead to a large reduction in the search effort at a small cost in the quality of the solution obtained.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-056.pdf,Subjects: 15.7 Search; 14. Neural Networks
56,2008,"Constraints, Satisfiability, and Search",Backdoor Trees,"Marko Samer, Stefan Szeider","The surprisingly good performance of modern satisfiability (SAT) solvers is usually explained by the existence of a certain ""hidden structure'' in real-world instances. We introduce the notion of backdoor trees as an indicator for the presence of a hidden structure. Backdoor trees refine the notion of strong backdoor sets, taking into account the relationship between backdoor variables. We present theoretical and empirical results. Our theoretical results are concerned with the computational complexity of detecting small backdoor trees. With our empirical results we compare the size of backdoor trees against the size of backdoor sets for real-world SAT instances and random 3SAT instances of various density. The results indicate that backdoor trees amplify the properties that have been observed for backdoor sets.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-057.pdf,Subjects: 15.7 Search; 9.2 Computational Complexity
57,2008,"Constraints, Satisfiability, and Search",A Global Constraint for Bin-Packing with Precedences: Application to the Assembly Line Balancing Problem.,"Pierre Schaus, Yves Deville","Assembly line balancing problems (ALBP) are of capital importance for the industry since the first assembly line for the Ford T by Henry Ford. Their objective is to optimize the design of production lines while satisfying the various constraints. Precedence constraints among the tasks are always present in ALBP. The objective is then to place the tasks among various workstations such that the production rate is maximized. This problem can be modeled as a bin packing problem with precedence constraints (BPPC) where the bins are the workstations and the items are the tasks. Paul Shaw introduced a global constraint for bin-packing (without precedence). Unfortunately this constraint does not capture the precedence constraints of BPPC. In this paper, we first introduce redundant constraints for BPPC combining the precedences and the bin-packing, allowing to solve instances which are otherwise intractable in constraint programming. We also design a global constraint for BPPC, introducing even more pruning in the search tree. We finally used our CP model for BPPC to solve ALBP. We propose two search heuristics, and show the efficiency of our approach on standard ALBP benchmarks. Compared to standard non CP approaches, our method is more flexible as it can handle new constraints that might appear in real applications.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-058.pdf,Subjects: 15.7 Search; 1.12 Scheduling
58,2008,"Constraints, Satisfiability, and Search",Bound Consistency for Binary Length-Lex Set Constraints,"Pascal Van Hentenryck, Justin Yip, Carmen Gervet, Gregoire Dooms","The length-lex representation has been recently proposed for representing sets in Constraint Satisfaction Problems. The length-lex representation directly captures cardinality information, provides a total ordering for sets, and allows bound consistency on unary constraints to be enforced in time O(c log c), where c is the cardinality of the set. However, no algorithms were given to enforce bound consistency on binary constraints. This paper addresses this open issue. It presents algorithms to enforce bound consistency on disjointness and cardinality constraints in time O(c^3). Moreover, it presents a generic bound-consistency algorithm for any binary constraint S which requires O(c^2) calls to a feasibility subroutine for S.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-059.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
59,2008,"Constraints, Satisfiability, and Search",Predicting the Performance of IDA* with Conditional Distributions,"Uzi Zahavi, Ariel Felner, Neil Burch, Robert C. Holte","(Korf, Reid, and Edelkamp 2001) introduced a formula to predict the number of nodes IDA* will expand given the static distribution of heuristic values. Their formula proved to be very accurate but it is only accurate under the following limitations: (1) the heuristic must be consistent; (2) the prediction is for a large random sample of start states. In this paper we generalize the static distribution to a conditional distribution of heuristic values. We then propose a new formula for predicting the performance of IDA* that works well for inconsistent heuristics (Zahavi et al. 2007) and for any set of start states, not just a random sample. We also show how the formula can be enhanced to work well for single start states. Experimental results demonstrate the accuracy of our method in all these situations.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-060.pdf,Subjects: 15.7 Search; 15.7 Search
60,2008,"Constraints, Satisfiability, and Search",Reasoning with Cardinal Directions: An Efficient Algorithm,"Xiaotong Zhang, Weiming Liu, Sanjiang Li, Mingsheng Ying","Direction relations between extended spatial objects are important commonsense knowledge. Recently, Goyal and Egenhofer proposed a formal model, called Cardinal Direction Calculus (CDC), for representing direction relations between connected plane regions. CDC is perhaps the most expressive qualitative calculus for directional information, and has attracted increasing interest from areas such as artificial intelligence, geographical information science, and image retrieval. Given a network of CDC constraints, the consistency problem is deciding if the network is realizable by connected regions in the real plane. This paper provides a cubic algorithm for checking consistency of basic CDC constraint networks. As one byproduct, we also show that any consistent network of CDC constraints has a canonical realization in digital plane. The cubic algorithm can also been adapted to cope with disconnected regions, in which case the current best algorithm is of time complexity O(n5).",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-061.pdf,Subjects: 15.2 Constraint Satisfaction; 11. Knowledge Representation
61,2008,"Constraints, Satisfiability, and Search",Anytime Local Search for Distributed Constraint Optimization,Roie Zivan,"Most former studies of Distributed Constraint Optimization Problems (DisCOPs) search considered only complete search algorithms, which are practical only for relatively small problems. Distributed local search algorithms can be used for solving DisCOPs. However, because of the differences between the global evaluation of a system’s state and the private evaluation of states by agents, agents are unaware of the global best state which is explored by the algorithm. Previous attempts to use local search algorithms for solving DisCOPs reported the state held by the system at the termination of the algorithm, which was not necessarily the best state explored. A general framework for implementing distributed local search algorithms for DisCOPs is proposed. The proposed framework makes use of a BFS-tree in order to accumulate the costs of the system’s state in its different steps and to propagate the detection of a new best step when it is found. The resulting framework enhances local search algorithms for DisCOPs with the anytime property. The proposed framework does not require additional network load. Agents are required to hold a small (linear) additional space (beside the requirements of the algorithm in use). The proposed framework preserves privacy at a higher level than complete Dis-COP algorithms which make use of a pseudo-tree (ADOPT, DPOP).",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-062.pdf,Subjects: 7. Distributed AI; 15.2 Constraint Satisfaction
62,2008,"Knowledge Representation, Logic, and Information Systems",On the Decidability of Role Mappings between Modular Ontologies,"Jie Bao, George Voutsadakis, Giora Slutzki, Vasant Honavar",Many semantic web applications require support for mappings between roles (or properties) defined in multiple independently developed ontology modules. Distributed Description Logics (DDL) and Package-based Description Logics (P-DL) offer two alternative logical formalisms that support such mappings. We prove that (a) variants of DDL that allow negated roles or cardinality restrictions in bridge rules or inverse bridge rules that connect $\logic{ALC}$ ontologies are undecidable; (b) a variant of P-DL $\logic{ALCHIO(\neg)P}$ that supports role mappings between ontology modules expressed in $\logic{ALCHIO(\neg)}$ is decidable.,https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-063.pdf,Subjects: 11.1 Description Logics; 11.2 Ontologies
63,2008,"Knowledge Representation, Logic, and Information Systems",Non-monotonic Temporal Logics that Facilitate Elaboration Tolerant Revision of Goals,"Chitta Baral, Jicheng Zhao","Temporal logics are widely used in specifying goals of agents. We noticed that when directing agents, humans often revise their requirements for the agent, especially as they gather more knowledge about the domain. However, all existing temporal logics, except one, do not focus on the revision of goals in an elaboration tolerant manner. Thus formal temporal logics that can allow elaboration tolerant revision of goals are needed. As non-monotonic languages are often used for elaboration tolerant specification, we propose to explore non-monotonic temporal logics for goal specification. Recently, a non-monotonic temporal logic, N-LTL, was proposed with similar aims. In N-LTL, goal specifications could be changed via strong and weak exceptions. However, in N-LTL, one had to a-priori declare whether exceptions will be weak or strong exceptions. We propose a new non-monotonic temporal logic, that not only overcomes this, but is also able to express exception to exceptions, strengthen and weaken preconditions, and revise and replace consequents; all in an elaboration tolerant manner.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-064.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
64,2008,"Knowledge Representation, Logic, and Information Systems",Prime Implicate Normal Form for ALC Concepts,Meghyn Bienvenu,"In this paper, we present a normal form for concept expressions in the description logic ALC which is based on a recently introduced notion of prime implicate for the modal logic K. We show that concepts in prime implicate normal form enjoy a number of desirable properties which make prime implicate normal form interesting from the viewpoint of knowledge compilation. In particular, we prove that subsumption between ALC concepts in prime implicate normal form can be carried out in polynomial time using a simple structural subsumption algorithm reminiscent of those used for less expressive description logics. Of course, in order to take advantage of these properties, we need a way to transform concepts into equivalent concepts in prime implicate normal form. We provide a sound and complete algorithm for putting concepts into prime implicate normal form, and we investigate the spatial complexity of this transformation, showing there to be an at most doubly-exponential blowup in concept length. At the end of the paper, we compare prime implicate normal form to two other normal forms for ALC concepts, discussing the relative merits of the different approaches.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-065.pdf,Subjects: 11.1 Description Logics; 3. Automated Reasoning
65,2008,"Knowledge Representation, Logic, and Information Systems",Credulous Resolution for Answer Set Programming,"Piero Bonatti, Enrico Pontelli, Tran Cao Son","The paper presents a calculus based on resolution for credulous reasoning in Answer Set Programming. The new approach allows a top-down and goal directed resolution, in the same spirit as traditional SLD-resolution. The proposed credulous resolution can be used in query-answering with non-ground queries and with non-ground, and possibly infinite, programs. Soundness and completeness results for the resolution procedure are proved for large classes of logic programs. The resolution procedure is also extended to handle some traditional syntactic extensions used in Answer Set Programming, such as choice rules and constraints. The paper also describes an initial implementation of a system for credulous reasoning in Answer Set Programming.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-066.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 8. Enabling Technologies
66,2008,"Knowledge Representation, Logic, and Information Systems",Manifold Integration with Markov Random Walks,"Heeyoul Choi, Seungjin Choi, Yoonsuck Choe","Most manifold learning methods consider only one similarity matrix to induce a low-dimensional manifold embedded in data space. In practice, however, we often use multiple sensors at a time so that each sensory information yields different similarity matrix derived from the same objects. In such a case, manifold integration is a desirable task, combining these similarity matrices into a compromise matrix that faithfully reflects multiple sensory information. A small number of methods exists for manifold integration, including a method based on reproducing kernel Krein space (RKKS) or DISTATIS, where the former is restricted to the case of only two manifolds and the latter considers a linear combination of normalized similarity matrices as a compromise matrix. In this paper we present a new manifold integration method, Markov random walk on multiple manifolds (RAMS), which integrates transition probabilities defined on each manifold to compute a compromise matrix. Numerical experiments confirm that RAMS finds more informative manifolds with a desirable projection property.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-067.pdf,Subjects: 12. Machine Learning and Discovery; 4. Cognitive Modeling
67,2008,"Knowledge Representation, Logic, and Information Systems",Parallel Belief Revision,"James Delgrande, Yi Jin","A recalcitrant problem in approaches to iterated belief revision is that, after first revising by a formula and then by a formula that is inconsistent with the first formula, all information in the original formula is lost. As noted by various researchers, this phenomenon is made explicit in the second postulate (C2) of the well-known Darwiche-Pearl framework, and so this postulate has been a point of criticism of this and related approaches. In contrast, we argue that the true culprit of this problem arises from a basic assumption of the AGM framework, that new information is represented by a single formula. We propose a more general framework for belief revision (called parallel belief revision) in which individual items of new information are represented by a set of formulas. In this framework, if one revises by a set of formulas, and then by the negation of some members of this set, then other members of the set are still believed after the revision. Hence the aforecited problem is discharged. We present first a basic approach to parallel belief revision, and next an approach that combines the basic approach with that of Jin and Thielscher. Postulates and semantic conditions characterizing these approaches are given, and representation results provided.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-068.pdf,Subjects: 11. Knowledge Representation; 15.1 Belief Revision
68,2008,"Knowledge Representation, Logic, and Information Systems",Efficient Haplotype Inference with Answer Set Programming,"Esra Erdem, Ferhan Ture","Identifying maternal and paternal inheritance is essential to be able to find the set of genes responsible for a particular disease. However, due to technological limitations, we have access to genotype data (genetic makeup of an individual), and determining haplotypes (genetic makeup of the parents) experimentally is a costly and time consuming procedure. With these biological motivations, we study a computational problem, called Haplotype Inference by Pure Parsimony (HIPP), that asks for the minimal number of haplotypes that form a given set of genotypes. HIPP has been studied using integer linear programming, branch and bound algorithms, SAT-based algorithms, or pseudo-boolean optimization methods. We introduce a new approach to solving HIPP, using Answer Set Programming (ASP). According to our experiments with a large number of problem instances (some automatically generated and some real), our ASP-based approach solves the most number of problems compared with other approaches. Due to the expressivity of the knowledge representation language of ASP, our approach allows us to solve variations of HIPP, e.g., with additional domain specific information, such as patterns/parts of haplotypes observed for some gene family, or with some missing genotype information. In this sense, the ASP-based approach is more general than the existing approaches to haplotype inference.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-069.pdf,Subjects: 11. Knowledge Representation; 1. Applications
69,2008,"Knowledge Representation, Logic, and Information Systems","Extending the Knowledge Compilation Map: Krom, Horn, Affine and Beyond","Hélène Fargier, Pierre Marquis","We extend the knowledge compilation map introduced by Darwiche and Marquis with three influential propositional fragments, the Krom CNF one (also known as the bijunctive fragment), the Horn CNF fragment and the affine fragment (also known as the biconditional fragment) as well as seven additional languages based on them, and composed respectively of Krom or Horn CNF formulas, renamable Horn CNF formulas, disjunctions of Krom CNF formulas, disjunctions of Horn CNF formulas, disjunctions of Krom or Horn CNF formulas, disjunctions of renamable Horn CNF formulas, and disjunction of affine formulas. Each fragment is evaluated w.r.t. several criteria, including the complexity of basic queries and transformations, and its spatial efficiency is also analyzed.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-070.pdf,Subjects: 3. Automated Reasoning; 11. Knowledge Representation
70,2008,"Knowledge Representation, Logic, and Information Systems",A Meta-Programming Technique for Debugging Answer-Set Programs,"Martin Gebser, Jörg Pührer, Torsten Schaub, Hans Tompits","Answer-set programming (ASP) is widely recognised as a viable tool for declarative problem solving. However, there is currently a lack of tools for developing answer-set programs. In particular, providing tools for debugging answer-set programs has recently been identified as a crucial prerequisite for a wider acceptance of ASP. In this paper, we introduce a meta-programming technique for debugging in ASP. The basic question we address is why interpretations expected to be answer sets are not answer sets of the program to debug. We thus deal with finding semantical errors of programs. The explanations provided by our method are based on an intuitive scheme of errors that relies on a recent characterisation of the answer-set semantics. Furthermore, as we are using a meta-programming technique, debugging queries are expressed in terms of answer-set programs themselves, which has several benefits: For one, we can directly use ASP solvers for processing debugging queries. Indeed, our technique can easily be implemented, and we devised a corresponding prototype debugging system. Also, our approach respects the declarative nature of ASP, and the capabilities of the system can easily be extended to incorporate differing debugging features.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-071.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 11. Knowledge Representation
71,2008,"Knowledge Representation, Logic, and Information Systems",From Qualitative to Quantitative Proofs of Security Properties: Using First-Order Conditional Logic,Joseph Y. Halpern,"A first-order conditional logic is considered, with semantics given by a variant of epsilon-semantics, where p -> q means that \Pr(p | q) approaches 1 super-polynomially—faster than any inverse polynomial. This type of convergence is needed for reasoning about  security protocols. A complete axiomatization is provided for this semantics, and it is  shown how a qualitative proof of the correctness of a security protocol can be automatically converted to a quantitative proof appropriate for reasoning about concrete security.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-072.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 11. Knowledge Representation
72,2008,"Knowledge Representation, Logic, and Information Systems",Nonmonotonic modes of inference,Victor Jauregui,"In this paper we investigate nonmonotonic 'modes of inference'. Our approach uses modal (conditional) logic to establish a uniform framework in which to study nonmonotonic consequence. We consider a particular mode of inference which employs a majority-based account of default reasoning—one which differs from the more familiar preferential accounts—and show how modal logic supplies a framework which facilitates analysis of, and comparison with more traditional formulations of nonmonotonic consequence.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-073.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 11. Knowledge Representation
73,2008,"Knowledge Representation, Logic, and Information Systems",Horn Complements: Towards Horn-to-Horn Belief Revision,"Marina Langlois, Robert H. Sloan, Balazs Szorenyi, Gyorgy Turan","Horn-to-Horn belief revision asks for the revision of a Horn knowledge base such that the revised knowledge base is also Horn. Horn knowledge bases are important whenever one is concerned with efficiency—of computing inferences, of knowledge acquisition, etc. Horn-to-Horn belief revision could be of interest, in particular, as a component of any efficient system requiring large commonsense knowledge bases that may need revisions because, for example,  new contradictory information is acquired.  Recent results on belief revision for general logics show that the existence of a belief contraction operator satisfying the generalized AGM postulates is equivalent to the existence of a complement. Here we provide a first step towards efficient Horn-to-Horn belief revision, by characterizing the existence of a complement of a Horn consequence of a Horn knowledge base. A complement exists if and only if the Horn consequence is not the consequence of a modified knowledge base obtained from the original by an operation called body building. This characterization leads to the efficient construction of a complement whenever it exists. Subjects: 15.1 Belief Revision; 9.3 Mathematical Foundations Submitted: Apr 15, 2008    This page is copyrighted by AAAI. All rights reserved. Your use of this site constitutes acceptance of all of AAAI's terms and conditions and privacy policy.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-074.pdf,Subjects: 15.1 Belief Revision; 9.3 Mathematical Foundations
74,2008,"Knowledge Representation, Logic, and Information Systems",A Reductive Semantics for Counting and Choice in Answer Set Programming,"Joohyung Lee, Vladimir Lifschitz, Ravi Palla","In a recent paper, Ferraris, Lee and Lifschitz conjectured that the concept of a stable model of a first-order formula can be used to treat some answer set programming expressions as abbreviations. We follow up on that suggestion and introduce an answer set programming language that defines the meaning of counting and choice by reducing these constructs to first-order formulas. For the new language, the concept of a safe program is defined, and its semantic role is investigated. We compare the new language with the concept of a disjunctive program with aggregates introduced by Faber, Leone and Pfeifer, and discuss the possibility of implementing a fragment of the language by translating it into the input language of the answer set solver DLV. The language is also compared with cardinality constraint programs defined by Syrjanen.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-075.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
75,2008,"Knowledge Representation, Logic, and Information Systems",Abductive Logic Programming by Nonground Rewrite Systems,"Fangzhen Lin, Jia-Huai You","Logic programming with negation offers a compelling approach to abductive reasoning. This paper shows a simple view of abduction in this context for the completion semantics, under which  the problem of abduction becomes one of solving quantified equations and disequations. By this way of treating abduction, the problems with nonground negative queries in the previous approaches no longer exist. We show the soundness and completeness results for our approach.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-076.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 3. Automated Reasoning
76,2008,"Knowledge Representation, Logic, and Information Systems",A Formalization of Program Debugging in the Situation Calculus,Yongmei Liu,"Program debugging is one of the most time-consuming parts of the software development cycle. In recent years, automatic debugging has been an active research area in software engineering; it has also attracted attention from the AI community. However, existing approaches are mostly experiential; moreover, those model-based approaches are based on abstract models of programs, which lends an experiential flavor to the approaches, due to the heuristic nature of choosing an abstract model. We believe that it is necessary to establish a precise theoretical foundation for debugging from first principles. In this paper, we present a first step towards this foundation: using Reiter's theoretical framework of model-based diagnosis, we give a clean formalization of the program debugging task in the situation calculus, a logical language suitable for describing dynamic worlds. Examples are given to illustrate our formalization.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-077.pdf,
77,2008,"Knowledge Representation, Logic, and Information Systems",Minimal Contraction of Preference Relations,"Denis Mindolin, Jan Chomicki","Changing preferences is very common in real life. The expressive power of the operations of preference change introduced so far in the literature is limited to adding new information about preference and equivalence. Here, we discuss the operation of discarding preferences: preference contraction. We argue that the property of minimality and the preservation of strict partial orders are crucial for contractions. Contractions can be further constrained by specifying which preferences should not be contracted. We provide algorithms for computing minimal and minimal preference-protecting contraction. We also show some preference query optimization techniques which can be used in the presence of contraction.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-078.pdf,Subjects: 11. Knowledge Representation; 15. Problem Solving
78,2008,"Knowledge Representation, Logic, and Information Systems",A First-Order Theory of Stanislavskian Scene Analysis,Leora Morgenstern,"At the turn of the last century, Constantin Stanislavski developed an innovative system of acting that replaced the mannered gestures and forced emotion then common in the world of theatre with a more natural style of acting. The cornerstone of Stanislavski’s system is the process of scene analysis: a process by which an actor fleshes out the circumstances of a play and hypothesizes enough facts, consistent with the play, to make it sufficiently specific to the actor. A complete scene analysis includes a backstory for a character — a description and history of the character that entail the character’s objectives — and a set of actions that is intended to further the character’s objectives. This paper explores the relationship between Stanislavski’s concept of scene analysis and formal AI theories of action and planning. The paper presents a first-order theory of Stanislavskian scene analysis, in which one can define the end product of a scene analysis and characterize the conditions under which a given scene analysis is coherent. Given a scene SC, consisting of a set of characters and a sequence of mostly locutionary actions, and a scene analysis SA, consisting of a backstory, a set of objectives, a dramatic history, and a mapping between the dramatic history and the locutionary actions of a play, this first-order theory supports inferences of the form “SA is coherent with respect to SC.”",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-079.pdf,Subjects: 11. Knowledge Representation; 5. Common Sense Reasoning
79,2008,"Knowledge Representation, Logic, and Information Systems",Worst-case Optimal Conjunctive Query Answering for an Expressive Description Logic without Inverses,"Magdalena Ortiz, Mantas Simkus, Thomas Eiter","Answering conjunctive queries (CQs) has been recognized as a key task for the usage of Description Logics (DLs) in a number of applications, and has thus been studied by many authors. In this paper, we present an algorithm for this problem in the DL ALCH which works in exponential time. It improves over previous algorithms which require double exponential time and is worst-case optimal, as already satisfiability testing in ALC is ExpTime-complete. Furthermore, it shows that inverse roles cause an exponential jump in complexity; as recently shown, the problem is 2ExpTime-complete for ALCI. The algorithm is based on a technique that compiles knowledge bases into sets of trees of depth 1. It is in coNP under data complexity (i.e., if the taxonomy part and the query are fixed), thus worst-case optimal. An extension from ALCH to DLs with further constructs is possible.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-080.pdf,Subjects: 11.1 Description Logics; 9.2 Computational Complexity
80,2008,"Knowledge Representation, Logic, and Information Systems",An AGM-Based Belief Revision Mechanism for Probabilistic Spatio-Temporal Logics,"Austin Parker, Guillaume Infantes, VS Subrahmanian, John Grant","There is now extensive interest in reasoning about moving objects. A PST   knowledge base is a set of PST-atoms which are statements of the form   ""Object o is/was/will be at location L at time t with probability in the   interval [L,U]"". In this paper, we study mechanisms for belief revision in   PST-KBs. We propose multiple methods for revising PST-KBs. These methods   involve finding maximally consistent subsets, as well as changing the   spatial, temporal, and probabilistic components of the atoms.   We show that some methods   cannot satisfy the AGM axioms for belief revision, while   others do but are coNP-hard. Finally we present an algorithm for revision   through probability change which runs in polynomial time and   satisfies the AGM axioms.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-081.pdf,Subjects: 3.2 Geometric Or Spatial Reasoning; 3.4 Probabilistic Reasoning
81,2008,"Knowledge Representation, Logic, and Information Systems",New Compilation Languages Based on Structured Decomposability,"Knot Pipatsrisawat, Adnan Darwiche","We introduce in this paper two new, complete propositional languages and study their properties in terms of (1) their support for polytime operations and (2) their ability to represent boolean functions compactly. The new languages are based on a structured version of decomposability—a property that underlies a number of tractable languages. The key characteristic of structured decomposability is its support for a polytime conjoin operation, which is known to be intractable for unstructured decomposability. We show that any CNF can be compiled into formulas in the new languages, whose size is only exponential in the treewidth of the CNF. Our study also reveals that one of the languages we identify is as powerful as OBDDs in terms of answering key inference queries, yet is more succinct than OBDDs.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-082.pdf,Subjects: 11. Knowledge Representation; 3. Automated Reasoning
82,2008,"Knowledge Representation, Logic, and Information Systems",A Semantic Approach for Iterated Revision in Possibilistic Logic,Guilin Qi,"In this paper, we propose a new approach for iterated revision in possibilistic logic by applying a one-step revision operator. We first argue that the set of KM postulates for revision is too strong to define a practical one-step revision operator and some of them should be weakened. We then present a semantic approach for iterated revision in possibilistic logic using a one-step revision operator. The computation of the semantic approach is given. We show that our revision approach satisfies almost all the DP postulates for iterated revision and some other important logical properties.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-083.pdf,Subjects: 15.1 Belief Revision; 5. Common Sense Reasoning
83,2008,"Knowledge Representation, Logic, and Information Systems",Terminological Reasoning in SHIQ with Ordered Binary Decision Diagrams,"Sebastian Rudolph, Markus Krotzsch, Pascal Hitzler","We present a new algorithm for reasoning in the description logic SHIQ, which is the most prominent fragment of the Web Ontology Language OWL. The algorithm is based on ordered binary decision diagrams (OBDDs) as a datastructure for storing and operating on large model representations. We thus draw on the success and the proven scalability of OBDD-based systems. To the best of our knowledge, we present the very first agorithm for using OBDDs for reasoning with general Tboxes.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-084.pdf,Subjects: 11.1 Description Logics; 3. Automated Reasoning
84,2008,"Knowledge Representation, Logic, and Information Systems",A Scalable Jointree Algorithm for Diagnosability,"Anika Schumann, Jinbo Huang","Diagnosability is an essential property that determines how accurate any diagnostic reasoning can be on a system given any sequence of observations. An unobservable fault event in a discrete-event system is diagnosable iff its occurrence can always be deduced once sufficiently many subsequent observable events have occurred. A classical approach to diagnosability checking constructs a finite state machine known as a twin plant for the system, which has a critical path iff some fault event is not diagnosable. Recent work attempts to avoid the often impractical construction of the global twin plant by exploiting system structure. Specifically, local twin plants are constructed for components of the system, and synchronized with each other until diagnosability is decided. Unfortunately, synchronization of twin plants can remain a bottleneck for large systems; in the worst case, in particular, all local twin plants would be synchronized, again producing the global twin plant. We solve the diagnosability problem in a way that exploits the distributed nature of realistic systems. In our algorithm consistency among twin plants is achieved by message passing on a jointree. Scalability is significantly improved as the messages computed are generally much smaller than the synchronized product of the twin plants involved. Moreover we use an iterative procedure to search for a subset of the jointree that is sufficient to decide diagnosability. Finally, our algorithm is scalable in practice: it provides an approximate and useful solution if the computational resources are not sufficient.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-085.pdf,Subjects: 1.5 Diagnosis; 3. Automated Reasoning
85,2008,"Knowledge Representation, Logic, and Information Systems",Factored Models for Probabilistic Modal Logic,"Afsaneh Shirazi, Eyal Amir","Modal logic represents knowledge that agents have about other agents' knowledge. Probabilistic modal logic further captures probabilistic beliefs about probabilistic beliefs. Models in those logics are useful for understanding and decision making in conversations, bargaining situations, and competitions. Unfortunately, probabilistic modal structures are impractical for large real-world applications because they represent their state space explicitly. In this paper we scale up probabilistic modal structures by giving them a factored representation. This representation applies conditional independence for factoring the probabilistic aspect of the structure (as in Bayesian Networks (BN)). We also present two exact and one approximate algorithm for reasoning about the truth value of probabilistic modal logic queries over a model encoded in a factored form. The first exact algorithm applies inference in BNs to answer a limited class of queries. Our second exact method applies a variable elimination scheme and is applicable without restrictions. Our approximate algorithm uses sampling and can be used for applications with very large models. Given a query, it computes an answer and its confidence level efficiently.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-086.pdf,Subjects: 11. Knowledge Representation; 3.4 Probabilistic Reasoning
86,2008,"Knowledge Representation, Logic, and Information Systems",AnalogySpace: Reducing the Dimensionality of Common Sense Knowledge,"Robyn Speer, Catherine Havasi, Henry Lieberman","We are interested in the problem of reasoning over very large common sense knowledge bases. When such a knowledge base contains noisy and subjective data, it is important to have a method for making rough conclusions based on similarities and tendencies, rather than absolute truth. We present AnalogySpace, which accomplishes this by forming the analogical closure of a semantic network through dimensionality reduction. It self-organizes concepts around dimensions that can be seen as making distinctions such as ""good vs. bad"" or ""easy vs. hard"", and generalizes its knowledge by judging where concepts lie along these dimensions. An evaluation demonstrates that users often agree with the predicted knowledge, and that its accuracy is an improvement over previous techniques.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-087.pdf,Subjects: 5. Common Sense Reasoning; 12. Machine Learning and Discovery
87,2008,"Knowledge Representation, Logic, and Information Systems",An Extended Interpreted System Model for Epistemic Logics,"Kaile Su, Abdul Sattar","The interpreted system model offers a computationally grounded model, in terms of the states of computer processes, to S5 epistemic logics. This paper extends the interpreted system model, and provides a computationally grounded one, called the interpreted perception system model, to those epistemic logics other than S5. It is usually assumed, in the interpreted system model, that those parts of the environment that are visible to an agent are correctly perceived by the agent as a whole. The essential idea of the interpreted perception system model is that an agent may have incorrect perception or observations to the visible parts of the environment and the agent may not be aware of this. The notion of knowledge can be defined so that an agent knows a statement iff the statement holds in those states that the agent can not distinguish (from the current state) by using only her correct observations. We establish a logic of knowledge and certainty, called KC logic, with a sound and complete proof system. The knowledge modality in this logic is S4 valid. It becomes S5 if we assume an agent always has correct observations; and more interestingly, it can be S4.2 or S4.3 under other natural constraints on agents and their sensors to the environment.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-088.pdf,Subjects: 3. Automated Reasoning; 7. Distributed AI
88,2008,"Knowledge Representation, Logic, and Information Systems",Hyperequivalence of Logic Programs with Respect to Supported Models,"Miroslaw Truszczynski, Stefan Woltran","Recent research in nonmonotonic logic programming has focused on program equivalence relevant for program optimization and modular programming. So far, most results concern the stable-model semantics. However, other semantics for logic programs are also of interest, especially the semantics of supported models which, when properly generalized, is closely related to the autoepistemic logic of Moore. In this paper, we consider a framework of equivalence notions for logic programs under the supported (minimal) model-semantics and provide characterizations for this framework in model-theoretic terms. We use these characterizations to derive complexity results concerning testing hyperequivalence of logic programs with respect to supported (minimal) models.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-089.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 11. Knowledge Representation
89,2008,"Knowledge Representation, Logic, and Information Systems",Generating Application-Specific Benchmark Models for Complex Systems,"Jun Wang, Gregory Provan","Automated generators for synthetic models and data can play a crucial role in designing new algorithms/model-frameworks, given the sparsity of benchmark models for empirical analysis and the cost of generating models by hand. We describe an automated generator for benchmark models that is based on using a compositional modeling framework and employs random-graph models for the system topology. We choose the system topology that best matches the topology of the real-world system using a domain-analysis algorithm. To show the range of models for which this approach is applicable, we demonstrate our model-generation process using two examples of model generation optimized for a specific domain: (1) model-based diagnosis for discrete Boolean circuits, and (2) E.coli TRN networks for simulating gene expression.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-090.pdf,Subjects: 1.6.1 Automated Device Modeling; 11. Knowledge Representation
90,2008,"Knowledge Representation, Logic, and Information Systems",Grounding with Bounds,"Johan Wittocx, Maarten Mariën, Marc Denecker","Grounding is the task of reducing a first-order theory to an equivalent propositional one. Typical grounders work on a sentence-by-sentence level, substituting variables by domain elements and simplifying where possible. In this work, we propose a method for reasoning on the first-order theory as a whole to optimize the grounding process. Concretely, we develop an algorithm that computes bounds for subformulas. Such bounds indicate for which tuples the subformulas are certainly true and for which they are certainly false. These bounds can then be used by standard grounding algorithms to substantially reduce grounding sizes, and consequently also grounding times. We have implemented the method, and demonstrate its practical applicability.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-091.pdf,Subjects: 11. Knowledge Representation; 15. Problem Solving
91,2008,"Knowledge Representation, Logic, and Information Systems",Towards Automatic Animated Storyboarding,"Patrick Ye, Timothy Baldwin","In this paper, we propose a machine learning-based NLP system for automatically creating animated storyboards using the action descriptions of movie scripts. We focus particularly on the importance of verb semantics when generating graphics commands, and find that semantic role labelling boosts performance and is relatively robust to the effects of unseen verbs.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-092.pdf,Subjects: 13. Natural Language Processing; 6.4 Virtual Reality
92,2008,"Knowledge Representation, Logic, and Information Systems",Loop Formulas for Logic Programs with Arbitrary Constraint Atoms,"Jia-Huai You, Guohua Liu","We formulate loop formulas for logic programs with arbitrary constraint atoms, for the semantics based on conditional satisfaction. This provides a method for answer set computation by computing models of completion. One particular attractive candidate for the latter task is pseudo-boolean constraint solvers. To strengthen this connection, we show examples of compact encoding of aggregates and global constraints by pseudo-boolean constraints.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-093.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
93,2008,"Knowledge Representation, Logic, and Information Systems",Revising Imprecise Probabilistic Beliefs in the Framework of Probabilistic Logic Programming,"Anbu Yue, Weiru Liu","Probabilistic logic programming is a powerful technique to represent and reason with imprecise probabilistic knowledge. A probabilistic logic program (PLP) is a knowledge base which contains a set of conditional events with probability intervals.  In this paper, we investigate the issue of revising such a PLP in light of receiving new information. We propose postulates for revising PLPs when a new piece of evidence is also a probabilistic conditional event. Our postulates lead to Jeffrey's rule and Bayesian conditioning when the original PLP defines a single probability distribution. Furthermore, we prove that our postulates are extensions to Darwiche and Pearl (DP) postulates when new evidence is a propositional formula. We also give the representation theorem for the postulates and provide an instantiation of revision operators satisfying the proposed postulates.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-094.pdf,Subjects: 15.1 Belief Revision; 3.4 Probabilistic Reasoning
94,2008,Machine Learning,Distance Metric Learning VS. Fisher Discriminant Analysis,"Babak Alipanahi, Michael Biggs, Ali Ghodsi","There has been much recent attention to the problem of learning an appropriate distance metric, using class labels or other side information. Some proposed algorithms are iterative and computationally expensive. In this paper, we show how to solve one of these methods with a closed-form solution, rather than using semidefinite programming. We provide a new problem setup in which the algorithm performs better or as well as some standard methods, but without the computational complexity. Furthermore, we show a strong relationship between these methods and the Fisher Discriminant Analysis.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-095.pdf,Subjects: 12. Machine Learning and Discovery; Please choose a second document classification
95,2008,Machine Learning,Potential-based Shaping in Model-based Reinforcement Learning,"John Asmuth, Michael L. Littman, Robert Zinkov","Potential-based shaping was designed as a way of introducing background knowledge into model-free reinforcement-learning algorithms. By identifying states that are likely to have high value, this approach can decrease experience complexity—the number of trials needed to find near-optimal behavior. An orthogonal way of decreasing experience complexity is to use a model-based learning approach, building and exploiting an explicit transition model. In this paper, we show how potential-based shaping can be redefined to work in the model-based setting to produce an algorithm that shares the benefits of both ideas.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-096.pdf,Subjects: 12.1 Reinforcement Learning; Please choose a second document classification
96,2008,Machine Learning,Sparse Projections on Graph,"Deng Cai, Xiaofei He, Jiawei Han","Recent study has shown that canonical algorithms such as Principal Component Analysis (PCA) and Linear Discriminant Analysis (LDA) can be obtained from graph based dimensionality reduction framework. However, these algorithms yield projective maps which are linear combination of {\it all} the original features. The results are difficult to be interpreted psychologically and physiologically. This paper presents a novel technique for learning a sparse projection over graphs. The data in the reduced subspace is represented as a linear combination of a subset of the most relevant features. Comparing to PCA and LDA, the results obtained by sparse projection are often easier to be interpreted. Our algorithm is based on a graph embedding model, which encodes the discriminating and geometrical structure in terms of the data affinity. Once the embedding results are obtained, we then apply regularized regression for learning a set of sparse basis functions. Specifically, by using a $L_1$-norm regularizer (e.g. {\em lasso}), the sparse projections can be efficiently computed. Experimental results on two document databases demonstrate the effectiveness of our method.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-097.pdf,Subjects: 12. Machine Learning and Discovery; 11. Knowledge Representation
97,2008,Machine Learning,Clustering via Random Walk Hitting Time on Directed Graphs,"Mo Chen, Jianzhuang Liu, Xiaoou Tang","In this paper, we present a general data clustering algorithm which is based on the asymmetric pairwise measure of Markov random walk hitting time on directed graphs. Unlike traditional graph based clustering methods, we do not explicitly calculate the pairwise similarities between points. Instead, we form a transition matrix ofMarkov random walk on a directed graph directly from the data. Our algorithm constructs the probabilistic relations of dependence between local sample pairs by studying the local distributions of the data. Such dependence relations are asymmetric, which is a more general measure of pairwise relations than the similarity measures in traditional undirected graph based methods in that it considers both the local density and geometry of the data. The probabilistic relations of the data naturally result in a transition matrix of Markov random walk. Based on the random walk viewpoint, we compute the expected hitting time for all sample pairs, which explores the global information of the structure of the underlying directed graph. An asymmetric measure based clustering algorithm, called K-destinations, is proposed for partitioning the nodes of the directed graph into disjoint sets. By utilizing the local distribution information of the data and the global structure information of the directed graph, our method is able to conquer some limitations of traditional pairwise similarity based methods. Experimental results are provided to validate the effectiveness of the proposed approach.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-098.pdf,
98,2008,Machine Learning,Integrating Multiple Learning Components Through Markov Logic,"Thomas G. Dietterich, Xinlong Bao","This paper addresses the question of how statistical learning algorithms can be integrated into a larger AI system both from a practical engineering perspective and from the perspective of correct representation, learning, and reasoning. Our goal is to create an integrated intelligent system that can combine observed facts, hand-written rules, learned rules, and learned classifiers to perform joint learning and reasoning. Our solution, which has been implemented in the CALO system, integrates multiple learning components with a Markov Logic inference engine, so that the components can benefit from each other's predictions. We introduce two designs of the learning and reasoning layer in CALO: the MPE Architecture and the Marginal Probability Architecture. The architectures, interfaces, and algorithms employed in our two designs are described, followed by experimental evaluations of the performance of the two designs. We show that by integrating multiple learning components through Markov Logic, the performance of the system can be improved and that the Marginal Probability Architecture performs better than the MPE Architecture.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-099.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
99,2008,Machine Learning,A Case Study on the Critical Role of Geometric Regularity in Machine Learning,"Jason Gauci, Kenneth O. Stanley","An important feature of many problem domains in machine learning is their geometry. For example, adjacency relationships, symmetries, and Cartesian coordinates are essential to any complete description of board games, visual recognition, or vehicle control. Yet many approaches to learning ignore such information in their representations, instead inputting flat parameter vectors with no indication of how those parameters are situated geometrically. This paper argues that such geometric information is critical to the ability of any machine learning approach to effectively generalize; even a small shift in the configuration of the task in space from what was experienced in training can go wholly unrecognized unless the algorithm is able to learn the regularities in decision-making across the problem geometry. To demonstrate the importance of learning from geometry, three variants of the same evolutionary learning algorithm (NeuroEvolution of Augmenting Topologies), whose representations vary in their capacity to encode geometry, are compared in checkers. The result is that the variant that can learn geometric regularities produces a significantly more general solution. The conclusion is that it is important to enable machine learning to detect and thereby learn from the geometry of its problems.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-100.pdf,Subjects: 14. Neural Networks; 12. Machine Learning and Discovery
100,2008,Machine Learning,Semi-Supervised Ensemble Ranking,"Steven C. H. Hoi, Rong Jin","Ranking plays a central role in many Web search and information retrieval applications. Ensemble ranking, sometimes called meta-search, aims to improve the retrieval performance by combining the outputs from multiple ranking algorithms. Many ensemble ranking approaches employ supervised learning techniques to learn appropriate weights for combining multiple rankers. The main shortcoming with these approaches is that the learned weights for ranking algorithms are query independent. This is suboptimal since a ranking algorithm could perform well for certain queries but poorly for others. In this paper, we propose a novel semi-supervised ensemble ranking (SSER) algorithm that learns query-dependent weights when combining multiple rankers in document retrieval. The proposed SSER algorithm is formulated as an SVM-like quadratic program (QP), and therefore can be solved efficiently by taking advantage of optimization techniques that were widely used in existing SVM solvers. We evaluated the proposed technique on a standard document retrieval testbed and observed encouraging results by comparing to a number of state-of-the-art techniques.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-101.pdf,Subjects: 1.10 Information Retrieval; 12. Machine Learning and Discovery
101,2008,Machine Learning,Instance-level Semi-supervised Multiple Instance Learning,"Yangqing Jia, Changshui Zhang","Multiple instance learning (MIL) is a branch of machine learning that attempts to learn information from bags of instances. Many real-world applications such as localized content-based image retrieval and text categorization can be viewed as MIL problems. In this paper, we propose a new graph-based semi-supervised learning approach for multiple instance learning. By defining an instance-level graph on the data, we first propose a new approach to construct an optimization framework for multiple instance semi-supervised learning, and derive an efficient way to overcome the non-convexity of MIL. We empirically show that our method outperforms state-of-the-art MIL algorithms on several real-world data sets.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-102.pdf,Subjects: 12. Machine Learning and Discovery; 12. Machine Learning and Discovery
102,2008,Machine Learning,Zero-data Learning of New Tasks,"Hugo Larochelle, Dumitru Erhan, Yoshua Bengio","We introduce the problem of zero-data learning, where a model must generalize to classes or tasks for which no training data are available and only a description of the classes or tasks are provided. Zero-data learning is useful for problems where the set of classes to distinguish or tasks to solve is very large and is not entirely covered by the training data. The main contributions of this work lie in the presentation of a general formalization of zero-data learning, in an experimental analysis of its properties and in empirical evidence showing that generalization is possible and significant in this context. The experimental work of this paper addresses two classification problems of character recognition and a multi-task ranking problem in the context of drug discovery. Finally, we conclude by discussing how this new framework could lead to a novel perspective on how to extend machine learning towards AI, where an agent can be given a specification for a learning problem before attempting to solve it (with very few or even zero examples).",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-103.pdf,Subjects: 14. Neural Networks; 12. Machine Learning and Discovery
103,2008,Machine Learning,Dimension Amnesic Pyramid Match Kernel,"Yi Liu, Xu-Lei Wang, Hongbin Zha","With the success of local features in object recognition, feature-set representations are widely used in computer vision and related domains. Pyramid match kernel (PMK) is an efficient approach to quantifying the similarity between two unordered feature-sets, which allows well established kernel machines to learn with such representations. However, the approximation of PMK to the optimal feature matches deteriorates linearly with the dimension of local features, which prohibits the direct use of high dimensional features. In this paper, we propose a general, data-independent kernel to quantify the feature-set similarities, which gives an upper bound of approximation error independent of the dimension of local features. The key idea is to employ the technique of normal random projection to construct a number of low dimensional subspaces, and perform the original PMK algorithm therein. By leveraging on the invariance property of p-stable distributions, our approach achieves the desirable dimension-free property. Extensive experiments on the ETH-80 image database solidly demonstrate the advantage of our approach to high dimensional features.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-104.pdf,Subjects: 12. Machine Learning and Discovery; 12.2 Scientific Discovery
104,2008,Machine Learning,Clustering on Complex Graphs,"Bo Long, Zhongfei Zhang, Philip S. Yu,  Tianbing Xue","Complex graphs, in which multi-type nodes are linked to each other, frequently arise in many important applications, such as Web mining, information retrieval, bioinformatics, and epidemiology. In this study, We propose a general framework for clustering on complex graphs. Under this framework, we derive a family of clustering algorithms including both hard and soft versions,  which are capable of learning cluster patterns from complex graphs with various structures and statistical properties. We also establish the connections between the proposed framework and the traditional graph partitioning approaches. The experimental evaluation provides encouraging results to validate the proposed framework and algorithms.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-105.pdf,Subjects: 12. Machine Learning and Discovery; 1.10 Information Retrieval
105,2008,Machine Learning,From Comparing Clusterings to Combining Clusterings,"Zhiwu Lu, Yuxin Peng, Jianguo Xiao","This paper presents a fast simulated annealing framework for combining multiple clusterings (i.e. clustering ensemble) based on some measures of agreement between partitions, which are originally used to compare two clusterings (the obtained clustering vs. a ground truth clustering) for the evaluation of a clustering algorithm. Though we can follow a greedy strategy to optimize these measures as objective functions of clustering ensemble, some local optima may be obtained and simultaneously the computational cost is too large. To avoid the local optima, we then consider a simulated annealing optimization scheme that operates through single label changes. Moreover, for these measures between partitions based on the relationship (joined or separated) of pairs of objects such as Rand index, we can update them incrementally for each label change, which makes sure the simulated annealing optimization scheme is computationally feasible. The simulation and real-life experiments then demonstrate that the proposed framework can achieve superior results.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-106.pdf,Subjects: 12. Machine Learning and Discovery; 9.3 Mathematical Foundations
106,2008,Machine Learning,Trace Ratio Criterion for Feature Selection,"Feiping Nie, Feiping Nie, Shiming Xiang, Yangqing Jia, Changshui Zhang, Shuicheng Yan","Fisher score and Laplacian score are two popular feature selection algorithms, both of which belong to the general graph-based feature selection framework. In this framework, a feature subset is selected based on the corresponding score (subset-level score), which is calculated in a trace ratio form. Since the number of all possible feature subsets is very huge, it is often prohibitively expensive in computational cost to search in a brute force manner for the feature subset with the maximum subset-level score. Instead of calculating the scores of all the feature subsets, traditional methods calculate the score for each feature, and then select the leading features based on the rank of these feature-level scores. However, selecting the feature subset based on the feature-level score cannot guarantee the optimum of the subset-level score. In this paper, we directly optimize the subset-level score, and propose a novel algorithm to efficiently find the global optimal feature subset such that the subset-level score is maximized. Extensive experiments demonstrate the effectiveness of our proposed algorithm in comparison with the traditional methods for feature selection.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-107.pdf,Subjects: 12. Machine Learning and Discovery; 9. Foundational Issues
107,2008,Machine Learning,Transfer Learning via Dimensionality Reduction,"Sinno Jialin Pan, James T. Kwok, Qiang Yang","Transfer learning addresses the problem of how to utilize plenty of labeled data in a source domain to solve related but different problems in a target domain, even when the training and testing problems have different distributions or features. In this paper, we consider transfer learning via dimensionality reduction. To solve this problem, we learn a low-dimensional latent feature space where the distributions between the source domain data and the target domain data are the same or close to each other. Onto this latent feature space, we project the data in related domains where we can apply standard learning algorithms to train classification or regression models. Thus, the latent feature space can be treated as a bridge of transferring knowledge from the source domain to the target domain. The main contribution of our work is that we propose a new dimensionality reduction method to find a latent space, which minimizes the distance between distributions of the data in different domains in a latent space. The effectiveness of our approach to transfer learning is verified by experiments in two real world applications: indoor WiFi localization and binary text classification.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-108.pdf,Subjects: 12. Machine Learning and Discovery; Please choose a second document classification
108,2008,Machine Learning,Active Learning for Pipeline Models,"Dan Roth, Kevin Small","For many machine learning solutions to complex applications, there are significant performance advantages to decomposing the overall task into several simpler sequential stages, commonly referred to as a pipeline model. Typically, such scenarios are also characterized by high sample complexity, motivating the study of active learning for these situations. While most active learning research examines single predictions, we extend such work to applications which utilize pipelined predictions. Specifically, we present an adaptive strategy for combining local active learning strategies into one that minimizes the annotation requirements for the overall task. Empirical results for a three-stage entity and relation extraction system demonstrate a significant reduction in supervised data requirements when using the proposed method.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-109.pdf,Subjects: 12. Machine Learning and Discovery; 13. Natural Language Processing
109,2008,Machine Learning,Economic Hierarchical Q-Learning,"Erik G Schultink, Ruggiero Cavallo, David C. Parkes","Hierarchical state decompositions address the curse-of-dimensionality in Q-learning methods for reinforcement learning (RL) but can suffer from suboptimality. In addressing this, we introduce the Economic Hierarchical Q-Learning (EHQ) algorithm for hierarchical RL. The EHQ algorithm uses subsidies to align interests such that agents that would otherwise converge to a recursively optimal policy will instead be motivated to act hierarchically optimally. The essential idea is that a parent will pay a child for the relative value to the rest of the system for ""returning the world"" in one state over another state. The resulting learning framework is simple compared to other algorithms that obtain hierarchical optimality. Additionally, EHQ encapsulates relevant information about value tradeoffs faced across the hierarchy at each node and requires minimal data exchange between nodes. We provide no theoretical proof of hierarchical optimality but are able demonstrate success with EHQ in empirical results.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-110.pdf,Subjects: 12.1 Reinforcement Learning; 7.1 Multi-Agent Systems
110,2008,Machine Learning,Markov Blanket Feature Selection for Support Vector Machines,"Jianqiang Shen, Lida Li, Weng-Keen Wong","Based on Information Theory, optimal feature selection should be carried out by searching Markov blankets. In this paper, we formally analyze the current Markov blanket discovery approach for support vector machines and propose to discover Markov blankets by performing a fast heuristic Bayesian network structure learning. We give a sufficient condition that our approach will improve the performance. Two major factors that make it prohibitive for learning Bayesian networks from high-dimensional data sets are the large search space and the expensive cycle detection operations. We propose to restrict the search space by only considering the promising candidates and detect cycles using an online topological sorting method. Experimental results show that we can efficiently reduce the feature dimensionality while preserving a high degree of classification accuracy.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-111.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
111,2008,Machine Learning,On-Line Case-Based Plan Adaptation for Real-Time Strategy Games,"Neha Sugandh, Santiago Ontañón, Ashwin Ram","Traditional artificial intelligence techniques do not perform well in applications such as real-time strategy games because of the extensive search spaces which need to be explored. In addition, this exploration must be carried out on-line during performance time; it cannot be precomputed. We have developed on-line case-based planning techniques that are effective in such domains. In this paper, we extend our earlier work using ideas from traditional planning to inform the real-time adaptation of plans. In our framework, when a plan is retrieved, a plan dependency graph is inferred to capture the relations between actions in the plan. The plan is then adapted in real-time using its plan dependency graph. This allows the system to create and adapt plans in an efficient and effective manner while performing the task. The approach is evaluated using WARGUS , a well-known real-time strategy game.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-112.pdf,Subjects: 3.1 Case-Based Reasoning; 1.11 Planning
112,2008,Machine Learning,Adapting ADtrees for High Arity Features,Robert Van Dam,"ADtrees, a data structure useful for caching sufficient statistics, have been successfully adapted to grow lazily when memory is limited and to update sequentially with an incrementally updated dataset. For low arity symbolic features, ADtrees trade a slight increase in query time for a reduction in overall tree size. Unfortunately, for high arity features, the same technique can often result in a very large increase in query time and a nearly negligible tree size reduction. In the dynamic (lazy) version of the tree, both query time and tree size can increase for some applications. Here we present two modifications to the ADtree which can be used separately or in combination to achieve the originally intended space-time tradeoff in the ADtree when applied to datasets containing very high arity features.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-113.pdf,Subjects: 12. Machine Learning and Discovery; 13. Natural Language Processing
113,2008,Machine Learning,Efficient Learning of Action Schemas and Web-Service Descriptions,"Thomas J Walsh, Michael L. Littman","This work addresses the problem of efficiently learning action schemas using a bounded number of samples (interactions with the environment). We consider schemas in two languages— traditional STRIPS, and a new language STRIPS+WS that extends STRIPS to allow for the creation of new objects when an action is executed. This modification allows STRIPS+WS to model web services and can be used to describe web-service composition (planning) problems. We show that general STRIPS operators cannot be efficiently learned through raw experience, though restricting the size of action preconditions yields a positive result. We then show that efficient learning is possible without this restriction if an agent has access to a ""teacher"" that can provide solution traces on demand. We adapt this learning algorithm to efficiently learn web-service descriptions in STRIPS+WS.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-114.pdf,Subjects: 12. Machine Learning and Discovery; 15.3 Control
114,2008,Machine Learning,On Discriminative Semi-Supervised Classification,"Fei Wang, Changshui Zhang","The recent years have witnessed a surge of interests in semi-supervised learning methods. A common strategy for these algorithms is to require that the predicted data labels should be sufficiently smooth with respect to the intrinsic data manifold. In this paper, we argue that rather than penalizing the label smoothness, we can directly punish the discriminality of the classification function to achieve a more powerful predictor, and we derive two specific algorithms: Semi-Supervised Discriminative Regularization (SSDR) and Semi-parametric Discriminative Semi-supervised Classification (SDSC). Finally many experimental results are presented to show the effectiveness of our method.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-115.pdf,Subjects: 12. Machine Learning and Discovery; 15. Problem Solving
115,2008,Machine Learning,Semi-supervised Classification Using Local and Global Regularization,"Fei Wang, Tao Li, Gang Wang, Changshui Zhang","In this paper, we propose a semi-supervised learning (SSL) algorithm based on local and global regularization. In the local regularization part, our algorithm constructs a regularized classifier for each data point using its neighborhood, while the global regularization part adopts a Laplacian regularizer to smooth the data labels predicted by those local classifiers. We show that some existing SSL algorithms can be derived from our framework. Finally we present some experimental results to show the effectiveness of our method.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-116.pdf,Subjects: 12. Machine Learning and Discovery; 15. Problem Solving
116,2008,Machine Learning,Learning Hidden Curved Exponential Family Models to Infer Face-to-Face Interaction Networks from Situated Speech Data,"Danny Wyatt, Tanzeem Choudhury, Jeff Bilmes","In this paper, we present a novel probabilistic framework for recovering global, latent social network structure from local, noisy observations. We extend curved exponential random graph models to include two types of variables: hidden variables that capture the structure of the network and observational variables that capture the behavior between actors in the network. We develop a novel combination of informative and intuitive conversational (local) and structural (global) features to specify our model. The model learns, in an unsupervised manner, the relationship between observable behavior and hidden social structure while simultaneously learning properties of the latent structure itself. We present empirical results on both synthetic data and a real world dataset of face-to-face conversations collected from 24 individuals using wearable sensors over the course of 6 months.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-117.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
117,2008,Machine Learning,Hidden Dynamic Probabilistic Models for Labeling Sequence Data,"Xiaofeng Yu, Wai Lam","We propose a new discriminative framework, namely Hidden Dynamic Conditional Random Fields (HDCRFs), for building probabilistic models which can capture both internal and external class dynamics to label sequence data. We introduce a small number of hidden state variables to model the sub-structure of a observation sequence and learn dynamics between different class labels. An HDCRF offers several advantages over previous discriminative models and is attractive both, conceptually and computationally. We performed experiments on three well-established sequence labeling tasks in natural language, including part-of-speech tagging, noun phrase chunking, and named entity recognition. The results demonstrate the validity and competitiveness of our model. In addition, our model compares favorably with current state-of-the-art sequence labeling approach, Conditional Random Fields (CRFs), which can only model the external dynamics.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-118.pdf,Subjects: 12. Machine Learning and Discovery; 13. Natural Language Processing
118,2008,Machine Learning,Classification by Discriminative Regularization,"Bin Zhang, Fei Wang, Ta-Hsin Li, Wen jun Yin, Jin Dong","Classification is one of the most fundamental problems in machine learning, which aims to separate the data from different classes as far away as possible. A common way to get a good classification function is to minimize its empirical prediction loss or structural loss. In this paper, we point out that we can also enhance the discriminality of those classifiers by further incorporating the discriminative information contained in the data set as a prior into the classifier construction process. In such a way, we will show that the constructed classifiers will be more powerful, and this will also be validated by the final empirical study on several benchmark data sets.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-119.pdf,Subjects: 12. Machine Learning and Discovery; 15. Problem Solving
119,2008,Machine Learning,Multi-View Local Learning,"Dan Zhang, Fei Wang, Changshui Zhang, Tao Li","The idea of local learning, i.e., classifying a particular example based on its neighbors, has been successfully applied to many semi-supervised and clustering problems recently. However, the local learning methods developed so far are all devised for single-view problems. In fact, in many real-world applications, examples are represented by multiple sets of features. In this paper, we extend the idea of local learning to multi-view problem, design a multi-view local model for each example, and propose a Multi-View Local Learning Regularization (MVLL-Reg) matrix. Both its linear and kernel version are given. Experiments are conducted to demonstrate the superiority of the proposed method over several state-of-the-art ones.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-120.pdf,Subjects: 12. Machine Learning and Discovery; Please choose a second document classification
120,2008,Machine Learning,Constraint Projections for Ensemble Learning,"Daoqiang Zhang, Songcan Chen, Zhi-Hua Zhou, Qiang Yang","It is well-known that diversity among base classifiers is crucial for constructing a strong ensemble. Most existing ensemble methods obtain diverse individual learners through resampling the instances or features. In this paper, we propose an alternative way for ensemble construction by resampling pairwise constraints that specify whether a pair of instances belongs to the same class or not. Using pairwise constraints for ensemble construction is challenging because it remains unknown how to influence the base classifiers with the sampled pairwise constraints. We solve this problem with a two-step process. First, we transform the original instances into a new data representation using projections learnt from pairwise constraints. Then, we build the base classifiers with the new data representation. We propose two methods for resampling pairwise constraints following the standard Bagging and Boosting algorithms, respectively. Extensive experiments validate the effectiveness of our method.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-121.pdf,Subjects: 12. Machine Learning and Discovery; Please choose a second document classification
121,2008,Multidisciplinary Topics and Applications,Automating To-Do Lists for Users: Interpretation of To-Dos for Selecting and Tasking Agents,"Yolanda Gil, Varun Ratnakar","To-do lists have been found to be the most popular personal information management tools, yet there is no automated system to interpret and act upon them when appropriate on behalf of the user. Automating to-do lists is challenging, not only because they are specified as free text but also because most items contain abbreviated tasks, many do not specify an action to be performed, and often refer to unrelated (personal) items. This paper presents our approach and an implemented system to process to-do list entries and map them to tasks that can be automated for the user by a set of agents. Since the format of to-do entries is not very amenable to natural language processing tools that can parse and create a structured interpretation, our approach is to exploit paraphrases of the target tasks that the agents can perform and that specify how the free-text maps to the task arguments. As users manually assign to-do to agents for automation, our system improves its performance by learning new paraphrases. We show an evaluation of our approach in a corpus of 2100 to-do entries collected from users of an office assistant multi-agent system.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-122.pdf,Subjects: 6.3 User Interfaces; 7.2 Software Agents
122,2008,Multidisciplinary Topics and Applications,Proactive Intrusion Detection,"Benjamin Liebald, Dan Roth, Neelay Shah, Vivek Srikumar","Machine learning systems are deployed in many adversarial conditions like intrusion detection, where a classifier has to decide whether a sequence of actions come from a legitimate user or not. However, the attacker, being an adversarial agent, could reverse engineer theclassifier and successfully masquerade as a legitimate user. In this paper, we propose the notion of a Proactive Intrusion Detection System (IDS) that can counter such attacks by incorporating feedback into the process. A proactive IDS influences the user's actions and observes them in different situations to decide whether the user is an intruder. We present a formal analysis of proactive intrusion detection and extend the adversarial relationship between the IDS and the attacker to present a game theoretic analysis. Finally, we present experimental results on real and synthetic data that confirm the predictions of the analysis.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-123.pdf,Subjects: 1. Applications; 12. Machine Learning and Discovery
123,2008,Multidisciplinary Topics and Applications,Speech-enabled Card Games for Language Learners,"Ian McGraw, Stephanie Seneff","This paper debuts a novel application of speech recognition to foreign language learning. We present a generic framework for developing user-customizable card games designed to aid learners in the difficult task of vocabulary acquisition. We also describe a prototype game built on this framework that, using a Mandarin speech recognizer, provides a student of Chinese with opportunities to speak vocabulary items in a meaningful context. The system dynamically loads only the necessary vocabulary for each game in an effort to maintain robust recognition performance without limiting the lexical domain. To assess the Sentence Error Rate (SER) of our prototype, we asked college-age students from various universities in the United States and beyond to participate in a Web-based user study. The three central concepts in the game were recognized with a SER of 16.02%, illustrating the feasibility of deploying this system in a university curriculum via the Internet. Finally, to ensure that our recognizer is behaving appropriately with regard to learner speech, we perform a rigorous analysis of the recognition errors to determine their underlying causes.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-124.pdf,Subjects: 1.3 Computer-Aided Education; 18. Speech Understanding
124,2008,Multidisciplinary Topics and Applications,Exposing Parameters of a Trained Dynamic Model for Interactive Music Creation,"Dan Morris, Ian Simon, Sumit Basu","As machine learning (ML) systems emerge in end-user applications, learning algorithms and classifiers will need to be robust to an increasingly unpredictable operating environment. In many cases, the parameters governing a learning system cannot be optimized for every user scenario, nor can users typically manipulate parameters defined in the space and terminology of ML. Conventional approaches to user-oriented ML systems have typically hidden this complexity from users by automating parameter adjustment. We propose a new paradigm, in which model and algorithm parameters are exposed directly to end-users with intuitive labels, suitable for applications where parameters cannot be automatically optimized or where there is additional motivation – such as creative flexibility – to expose, rather than fix or automatically adapt, learning parameters. In our CHI 2008 paper, we introduced and evaluated MySong, a system that uses a Hidden Markov Model to generate chords to accompany a vocal melody. The present paper formally describes the learning underlying MySong and discusses the mechanisms by which MySong’s learning parameters are exposed to users, as a case study in making ML systems user-configurable. We discuss the generalizability of this approach, and propose that intuitively exposing ML parameters is a key challenge for the ML and human-computer-interaction communities.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-125.pdf,Subjects: 1.1 Art And Music; 12. Machine Learning and Discovery
125,2008,Multidisciplinary Topics and Applications,Another Look at Search-Based Drama Management,"Mark J. Nelson, Michael Mateas","A drama manager (DM) monitors an interactive experience, such as a computer game, and intervenes to shape the global experience so it satisfies the author's expressive goals without decreasing a player's interactive agency. In declarative optimization-based drama management (DODM), the author declaratively specifies desired properties of the experience; the DM optimizes its interventions to maximize that metric. The initial DODM approach used online search to optimize an experience-quality function. Subsequent work questioned whether online search could perform well in general, and proposed alternative optimization frameworks such as reinforcement learning. Recent work on targeted trajectory distribution Markov decision processes (TTD-MDPs) replaced the experience-quality metric with a metric and associated algorithm based on targeting experience distributions. We argue that optimizing an experience-quality function does not destroy interactive agency, as has been claimed, and that in fact it can capture that goal directly. We further show that, though apparently quite different on the surface, the original search approach and TTD-MDPs actually use variants of the same underlying search algorithm, and that offline cached search, as is done by the TTD-MDP algorithm, allows the search-based systems to achieve similar results to TTD-MDPs.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-126.pdf,Subjects: 1. Applications; 15.7 Search
126,2008,Multidisciplinary Topics and Applications,Learning to Analyze Binary Computer Code,"Nathan Rosenblum, Xiaojin Zhu, Barton Miller, Karen Hunt","We present a novel application of structured classification: identifying function entry points (FEPs, the starting byte of each function) in program binaries. Such identification is the crucial first step in analyzing many malicious, commercial and legacy software, which lack full symbol information that specifies FEPs. Existing pattern-matching FEP detection techniques are insufficient due to variable instruction sequences introduced by compiler and link-time optimizations. We formulate the FEP identification problem as structured classification using Conditional Random Fields. Our Conditional Random Fields incorporate both idiom features to represent the sequence of instructions surrounding FEPs, and control flow structure features to represent the interaction among FEPs. These features allow us to jointly label all FEPs in the binary. We perform feature selection and present an approximate inference method for massive program binaries. We evaluate our models on a large set of real-world test binaries, showing that our models dramatically outperform two existing, standard disassemblers.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-127.pdf,Subjects: 1.6 Engineering And Science; 12. Machine Learning and Discovery
127,2008,Multidisciplinary Topics and Applications,Prediction and Change Detection In Sequential Data for Interactive Applications,"Li Cheng, Jun Zhou, Walter Bischof","We consider the problems of sequential prediction and change detection that arise often in interactive applications: A semi-automatic predictor is applied to a time-series and is expected to make proper predictions and request new human input when change points are detected. Motivated by the Transductive Support Vector Machines, we propose an online framework that naturally addresses these problems in a unified manner. Our empirical study with a synthetic dataset and a road tracking dataset demonstrates the efficacy of the proposed approach.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-128.pdf,Subjects: 6. Computer-Human Interaction; 12. Machine Learning and Discovery
128,2008,Multidisciplinary Topics and Applications,Using Knowledge Driven Matrix Factorization to Reconstruct Modular Gene Regulatory Network,"Yang Zhou, Li Zheng, Xuerui Yang, Zhang Linxia, Shireesh Srivastava, Rong Jin, Christina Chan","Reconstructing gene networks from micro-array data can provide information on the mechanisms that govern cellular processes. Numerous studies have been devoted to addressing this problem. A popular method is to view the gene network as a Bayesian inference network, and to apply structure learning methods to determine the topology of the gene network. There are, however, several shortcomings with the Bayesian structure learning approach for reconstructing gene networks. They include high computational cost associated with analyzing a large number of genes and inefficiency in exploiting prior knowledge of co-regulation that could be derived from Gene Ontology (GO) information. In this paper, we present a knowledge driven matrix factorization (KMF) framework for reconstructing modular gene networks that addresses these shortcomings. In KMF, gene expression data is initially used to estimate the correlation matrix. The gene modules and the interactions among the modules are derived by factorizing the correlation matrix. The prior knowledge in GO is integrated into matrix factorization to help identify the gene modules. An alternating optimization algorithm is presented to efficiently find the solution. Experiments show that our algorithm performs significantly better in identifying gene modules than several state-of-the-art algorithms, and the interactions among the modules uncovered by our algorithm are proved to be biologically meaningful.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-129.pdf,Subjects: 12. Machine Learning and Discovery; Please choose a second document classification
129,2008,Natural-Language Processing,Using Answer Set Programming and Lambda Calculus to Characterize Natural Language Sentences with Normatives and Exceptions,"Chitta Baral, Juraj Dzifcak, Tran Cao Son","One way to solve the knowledge acquisition bottleneck is to have ways to translate natural language sentences and discourses to a formal knowledge representation language, especially ones that are appropriate to express domain knowledge in sciences, such as Biology. While there have been several proposals, including by Montague (1970), to give model theoretic semantics for natural language and to translate natural language sentences and discourses to classical logic, none of these approaches use knowledge representation languages that can express domain knowledge involving normative statements and exceptions. In this paper we take a first step to illustrate how one can automatically translate natural language sentences about normative statements and exceptions to representations in the knowledge representation language Answer Set Programming (ASP). To do this, we use $\lambda$-calculus representation of words and their composition as dictated by a CCG grammar.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-130.pdf,Subjects: 13. Natural Language Processing; 5. Common Sense Reasoning
130,2008,Natural-Language Processing,Automatic Semantic Relation Extraction with Multiple Boundary Generation,"Brandon Beamer, Alla Rozovskaya, Roxana Girju","This paper addresses the task of automatic classification of semantic relations between nouns. We present an improved WordNet-based learning model which relies on the semantic information of the constituent nouns. The representation of each noun's meaning captures conceptual features which play a key role in the identification of the semantic relation. We report substantial improvements over previous WordNet-based methods on the 2007 SemEval data. Moreover, our experiments show that WordNet's IS-A hierarchy is better suited for some semantic relations compared with others. We also compute various learning curves and show that our model does not need a large number of training examples.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-131.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
131,2008,Natural-Language Processing,Importance of Semantic Representation: Dataless Classification,"Ming-Wei Chang, Lev Ratinov, Dan Roth, Vivek Srikumar","Traditionally, text categorization has been studied as the problem of training of a classifier using labeled data. However, people can categorize documents into named categories without any explicit training because we know the meaning of category names. In this paper, we introduce Dataless Classification, a learning protocol that uses world knowledge to induce classifiers without the need for any labeled data. Like humans, a dataless classifier interprets a string of words as a set of semantic concepts. We propose a model for dataless classification and show that the label name alone is often sufficient to induce classifiers. Using Wikipedia as our source of world knowledge, we get 85.29% accuracy on tasks from the 20 Newsgroup dataset and 88.62% accuracy on tasks from a Yahoo! Answers dataset without any labeled or unlabeled data from the datasets. With unlabeled data, we can further improve the results and show quite competitive performance to a supervised learning algorithm that uses 100 labeled examples.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-132.pdf,Subjects: 12. Machine Learning and Discovery; 13. Natural Language Processing
132,2008,Natural-Language Processing,Discourse Topic and Gestural Form,"Jacob Eisenstein, Regina Barzilay, Randall Davis","Coverbal gesture provides a channel for the visual expression of ideas. While some gestural emblems have culturally predefined forms (e.g., ""thumbs up""), the relationship between gesture and meaning is, in general, not conventionalized. It is natural to ask whether such gestures can be interpreted in a speaker-independent way, or whether gestural form is determined by the speaker’s idiosyncratic view of the discourse topic. We address this question using an audiovisual dataset across multiple speakers and topics. Our analysis employs a hierarchical Bayesian author-topic model, in which gestural patterns are stochastically generated by a mixture of speaker-specific and topic-specific priors. These gestural patterns are characterized using automatically extracted visual features, based on spatio-temporal interest points. This framework detects significant cross-speaker patterns in gesture that are governed by the discourse topic, suggesting that even unstructured gesticulation can be interpreted across speakers. In addition, the success of this approach shows that the semantic characteristics of gesture can be detected via a low-level, interest point representation.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-133.pdf,Subjects: 13. Natural Language Processing; 13.1 Discourse
133,2008,Natural-Language Processing,Text Categorization with Knowledge Transfer from Heterogeneous Data Sources,"Rakesh Gupta, Lev Ratinov","Multi-category classification of short dialogues is a common task performed by humans. When assigning a question to an expert, a customer service operator tries to classify the customer query into one of N different classes for which experts are available. Similarly, questions on the web (for example questions at Yahoo Answers) can be automatically forwarded to a restricted group of people with a specific expertise. Typical questions are short and assume background world knowledge for correct classification. With exponentially increasing amount of knowledge available, with distinct properties (labeled vs unlabeled, structured vs unstructured), no single knowledge-transfer algorithm such as transfer learning, multi-task learning or selftaught learning can be applied universally. In this work we show that bag-of-words classifiers performs poorly on noisy short conversational text snippets. We present an algorithm for leveraging heterogeneous data sources and algorithms with significant improvements over any single algorithm, rivaling human performance. Using different algorithms for each knowledge source we use mutual information to aggressively prune features. With heterogeneous data sources including Wikipedia, Open Directory Project (ODP), and Yahoo Answers, we show 89.4% and 96.8% correct classification on Google Answers corpus and Switchboard corpus using only 200 features/class. This reflects a huge improvement over bag of words approaches and 48-65% error reduction over previously published state of art (Gabrilovich et. al. 2006).",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-134.pdf,Subjects: 13. Natural Language Processing
134,2008,Natural-Language Processing,Cross-lingual Propagation for Morphological Segmentation,"Benjamin Snyder, Regina Barzilay","Multilingual parallel text corpora provide a powerful means for propagating linguistic knowledge across languages. We present a model which jointly learns linguistic structure for each language while inducing links between them. Our model supports fully symmetrical knowledge transfer, utilizing any combination of supervised and unsupervised data across language barriers. The proposed non-parametric Bayesian model effectively combines cross-lingual alignment with target language predictions. This architecture is a potent alternative to projection methods which decompose these decisions into two separate stages. We apply this approach to the task of morphological segmentation, where the goal is to separate a word into its individual morphemes. When tested on a parallel corpus of Hebrew and Arabic, our joint bilingual model effectively incorporates all available evidence from both languages, yielding significant performance gains.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-135.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
135,2008,Natural-Language Processing,Single Document Keyphrase Extraction Using Neighborhood Knowledge,"Xiaojun Wan, Jianguo Xiao","Existing methods for single document keyphrase extraction usually make use of only the information contained in the specified document. This paper proposes to use a small number of nearest neighbor documents to provide more knowledge to improve single document keyphrase extraction. A specified document is expanded to a small document set by adding a few neighbor documents close to the document, and the graph-based ranking algorithm is then applied on the expanded document set to make use of both the local information in the specified document and the global information in the neighbor documents. Experimental results demonstrate the good effectiveness and robustness of our proposed approach.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-136.pdf,Subjects: 13. Natural Language Processing; 1.10 Information Retrieval
136,2008,Natural-Language Processing,Using Wiktionary for Computing Semantic Relatedness,"Torsten Zesch, Christof Müller, Iryna Gurevych","We introduce Wiktionary as an emerging lexical semantic resource that can be used as a substitute for expert-made resources in AI applications. We evaluate Wiktionary on the pervasive task of computing semantic relatedness for English and German by means of correlation with human rankings and solving word choice problems. For the first time, we apply a concept vector based measure to a set of different concept representations like Wiktionary pseudo glosses, the first paragraph of Wikipedia articles, English WordNet glosses, and GermaNet pseudo glosses. We show that: (i) Wiktionary is the best lexical semantic resource in the ranking task and performs comparably to other resources in the word choice task, and (ii) the concept vector based approach yields the best results on all datasets in both evaluations.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-137.pdf,Subjects: 13. Natural Language Processing; 8. Enabling Technologies
137,2008,"Reasoning about Plans, Processes, and Actions",Optimal Scheduling of Contract Algorithms with Soft Deadlines,"Spyros Angelopoulos, Alejandro Lopez-Ortiz, Angele Hamel","A contract algorithm is an algorithm which is given, as part of its input, a specified amount of allowable computation time. In contrast, interruptible algorithms may be interrupted throughout their execution, at which point they must report their current solution. Simulating interruptible algorithms by means of schedules of executions of contract algorithms in parallel processors is a well-studied problem with significant applications in AI. In the classical case, the interruptions are hard deadlines in which a solution must be reported immediately at the time the interruption occurs. In this paper we study the more general setting of scheduling contract algorithms at the presence of soft deadlines. This is motivated by the observation of practitioners that soft deadlines are as common an occurrence as hard deadlines, if not more common. In our setting, at the time t of interruption the algorithm is given an additional window of time w(t) < ct to continue the contract or, indeed, start a new contract (for some fixed constant c). We explore this variation using the acceleration ratio, which is the canonical measure of performance for these schedules, and derive schedules of optimal acceleration ratio for all functions w.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-138.pdf,Subjects: 1.12 Scheduling; 16. Real-Time Systems
138,2008,"Reasoning about Plans, Processes, and Actions",Optimal Metric Planning with State Sets in Automata Representation,"Bjoern Borowsky, Stefan Edelkamp","This paper proposes an optimal approach to infinite-state action planning exploiting automata theory. State sets and actions are characterized by Presburger formulas and represented using minimized finite state machines. The exploration that contributes to the planning via model checking paradigm applies symbolic images in order to compute the deterministic finite automaton for the sets of successors. A large fraction of metric planning problems can be translated into Presburger arithmetic, while derived predicates are simply compiled away. We further propose three algorithms for computing optimal plans; one for uniform action costs, one for the additive cost model, and one for linear plan metrics. Furthermore, an extension for infinite state sets is discussed.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-139.pdf,Subjects: 1.11 Planning; 15.7 Search
139,2008,"Reasoning about Plans, Processes, and Actions",PBA*: Using Proactive Search to Make A* Robust to Unplanned Deviations,"Paul Breimyer, Peter R. Wurman","Many path planning algorithms leverage A* to determine optimal paths. However, when an actor deviates from the optimal path, a typical application of A* executes a new search from the deviation point to the goal. This approach redundantly calculates paths that may have been examined during the initial search, rather than leveraging previous information. We introduce Plan-B A* (PBA*), which uses A* for the initial search, and substantially reduces the number of searched states during all subsequent searches, while incurring minimal space overhead. PBA* not only remembers certain states it has examined, it proactively creates solution paths for the most likely deviations. In our experiments, PBA* searches only 10% of the A* search space when recovering from execution errors by storing a limited amount of search history.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-140.pdf,Subjects: 15.7 Search; 1.11 Planning
140,2008,"Reasoning about Plans, Processes, and Actions",Fast Planning by Search in Domain Transition Graphs,"Yixin Chen, Ruoyun Huang, Weixiong Zhang","Recent advances in classical planning have used the SAS+ formalism, and several effective heuristics have been developed based on the SAS+ formalism. Comparing to the traditional STRIPS/ADL formalism, SAS+ is capable of capturing vital information such as domain transition structures and causal dependencies. In this paper, we propose a new SAS+ based incomplete planning approach. Instead of using SAS+ to derive heuristics within a heuristic search planner, we directly search in domain transition graphs (DTGs) and causal graphs (CGs) derived from the SAS+ formalism. The new method is efficient because the SAS+ representation is often much more compact than STRIPS. The CGs and DTGs provide rich information of domain structures that can effectively guide the search towards solutions. Experimental results show strong performance of the proposed planner on recent international planning competition domains.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-141.pdf,Subjects: 1.11 Planning; Please choose a second document classification
141,2008,"Reasoning about Plans, Processes, and Actions",Planning with Problems Requiring Temporal Coordination,"Andrew Coles, Maria Fox, Derek Long, Amanda Smith","We present the first planner capable of reasoning with both the full semantics of PDDL2.1 (level 3) temporal planning and with numeric resources. Our planner, CRIKEY3, employs heuristic forward search, using the start-and-end semantics of PDDL2.1 to manage temporal actions. The planning phase is interleaved with a scheduling phase, using a Simple Temporal Network, in order to ensure that temporal constraints are met. To guide search, we introduce a new temporal variant of the Relaxed Planning Graph heuristic that is capable of reasoning with the features of this class of domains, along with the Timed Initial Literals of PDDL2.2. CRIKEY3 extends the state-of-the-art in handling the full temporal expressive power of PDDL2.1, including numeric temporal domains.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-142.pdf,Subjects: 1.11 Planning; 1.12 Scheduling
142,2008,"Reasoning about Plans, Processes, and Actions",Partitioned External-Memory Value Iteration,"Peng Dai, Mausam, Daniel S. Weld","Dynamic programming methods (including value iteration, LAO*, RTDP, and derivatives) are popular algorithms for solving Markov decision processes (MDPs). Unfortunately, however, these techniques store the MDP model extensionally in a table and thus are limited by the amount of main memory available. Since the required space is exponential in the number of domain features, these dynamic programming methods are ineffective for large problems. To address this problem, Edelcamp et al. devised the external memory value iteration (EMVI) algorithm, which uses a clever sorting scheme to efficiently move parts of the model between disk and main memory. While EMVI can handle larger problems than previously addressed, the need to repeatedly perform external sorts still limits scalability. This paper proposes a new approach. We partition an MDP into smaller pieces (blocks), keeping just the relevant blocks in memory and performing Bellman backups block by block. Experiments show that our algorithm is able to solve large MDPs an order of magnitude faster than EMVI.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-143.pdf,Subjects: 1.11 Planning; Please choose a second document classification
143,2008,"Reasoning about Plans, Processes, and Actions",Error Classification in Action Descriptions: A Heuristic Approach,"Thomas Eiter, Michael Fink, Ján Senko","Action languages allow to formally represent and reason about actions in a highly declarative manner. In recent work, revision and management of conflicts for domain descriptions in such languages wrt. semantic integrity constraints have been considered, in particular their reconciliation. However, merely ad hoc tests and methods have been presented to aid the user in analyzing and correcting a flawed description. We go beyond this and present a methodology on top of such tests for identifying a possible error, which works in several stages. The issue of such a methodology for action languages is novel and has not been addressed before, but is important for building tools and engineering action descriptions in practice.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-144.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
144,2008,"Reasoning about Plans, Processes, and Actions",Computing Minimal Diagnoses by Greedy Stochastic Search,"Alexander Feldman, Gregory Provan, Arjan van Gemund","Most algorithms for computing diagnoses within a model-based diagnosis framework are deterministic. Such algorithms guarantee soundness and completeness, but their hardness is in the second class of the polynomial hierarchy. To overcome this complexity problem, which prohibits the computation of high-cardinality diagnoses for large systems, we propose a novel approximation approach for multiple-fault diagnosis, based on a greedy stochastic algorithm called SAFARI (StochAstic Fault diagnosis AlgoRIthm). We prove that SAFARI can be configured to compute diagnoses which are of guaranteed minimality under subsumption. We analytically model SAFARI search as a Markov chain, and show a probabilistic bound on the minimality of its minimal diagnosis approximations. We have applied this algorithm to the 74XXX and ISCAS85 suites of benchmark combinatorial circuits, demonstrating order-of-magnitude speedups over two state-of-the-art deterministic algorithms, CDA* and HA*, for multiple-fault diagnoses.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-145.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 1.5 Diagnosis
145,2008,"Reasoning about Plans, Processes, and Actions",Computing Observation Vectors for Max-Fault Min-Cardinality Diagnoses,"Alexander Feldman, Gregory Provan, Arjan van Gemund","Model-Based Diagnosis (MBD) typically focuses on diagnoses, minimal under some minimality criterion, e.g., the minimal-cardinality set of faulty components that explain an observation. However, for different observations there may be minimal-cardinality diagnoses of differing cardinalities, and several applications (such as test pattern generation and benchmark model analysis) need to identify the observation leading to the max-cardinality diagnosis amongst them. We denote this problem as a Max-Fault Min-Cardinality (MFMC) problem. This paper considers the generation of observations that lead to MFMC diagnoses. We present a near-optimal, stochastic algorithm, called MIRANDA (Max-fault mIn-caRdinAlity observatioN Deduction Algorithm), that computes MFMC observations. Compared to optimal, deterministic approaches such as ATPG, the algorithm has very low cost, allowing us to generate observations corresponding to high-cardinality faults. Experiments show that MIRANDA delivers optimal results on the 74XXX circuits, as well as good MFMC cardinality estimates on the larger ISCAS85 circuits.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-146.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 1.5 Diagnosis
146,2008,"Reasoning about Plans, Processes, and Actions",Finding State Similarities for Faster Planning,Christian Fritz,"In many planning applications one can find actions with overlapping effects. If for optimally reaching the goal all that matters is within this overlap, there is no need to consider all these actions — for the task at hand they are equivalent. Using this structure for speed-up has previously been proposed in the context of least commitment planning. Of a similar spirit is the approach for improving best-first search based planning we present here: intuitively, given a set of start states, reachable from the initial state, we plan in parallel for all of them, exploiting the similarities between them to gain computational savings. Since the similarity of two states is problem specific, we explicitly infer it by regressing all relevant entities, goal, heuristic function, action preconditions and costs, over the action sequences considered in planning. If the resulting formulae mention only fluents whose values the two states have in common, it suffices to evaluate the formulae in one of them. This leads to computational savings over conventional best-first search.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-147.pdf,Subjects: 15.7 Search; 11. Knowledge Representation
147,2008,"Reasoning about Plans, Processes, and Actions",Reasoning about Large Taxonomies of Actions,"Yilan Gu, Mikhail Soutchanski","We design a representation based on the situation calculus to facilitate development, maintenance and elaboration of very large taxonomies of actions. This representation leads to more compact and modular basic action theories (BATs) for reasoning about actions than currently possible. We compare our representation with Reiter's BATs and prove that our representation inherits all useful properties of his BATs. Moreover, we show that our axioms can be more succinct, but extended Reiter's regression can still be used to solve the projection problem (this is the problem of whether a given logical expression will hold after executing a sequence of actions). We also show that our representation has significant computational advantages. For taxonomies of actions that can be represented as finitely branching trees, the regression operator can work exponentially faster with our theories than it works with Reiter's BATs. Finally, we propose general guidelines on how a taxonomy of actions can be constructed from the given set of effect axioms in a domain.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-148.pdf,Subjects: 11. Knowledge Representation; 5. Common Sense Reasoning
148,2008,"Reasoning about Plans, Processes, and Actions",How Good is Almost Perfect?,"Malte Helmert, Gabriele Röger","Heuristic search using algorithms such as A* and IDA* is the prevalent method for obtaining optimal sequential solutions for classical planning tasks. Theoretical analyses of these classical search algorithms, such as the well-known results of Pohl, Gaschnig and Pearl, suggest that such heuristic search algorithms can obtain better than exponential scaling behaviour, provided that the heuristics are accurate enough. Here, we show that for a number of common planning benchmark domains, including ones that admit optimal solution in polynomial time, general search algorithms such as A* must necessarily explore an exponential number of search nodes even under the optimistic assumption of almost perfect heuristic estimators, whose heuristic error is bounded by a small additive constant. Our results shed some light on the comparatively bad performance of optimal heuristic search approaches in ""simple"" planning domains such as GRIPPER. They suggest that in many applications, further improvements in run-time require changes to other parts of the search algorithm than the heuristic estimator. Subjects: 1.11 Planning; 15.7 Search Submitted: Apr 15, 2008    This page is copyrighted by AAAI. All rights reserved. Your use of this site constitutes acceptance of all of AAAI's terms and conditions and privacy policy.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-149.pdf,Subjects: 1.11 Planning; 15.7 Search
149,2008,"Reasoning about Plans, Processes, and Actions",Accuracy of Admissible Heuristic Functions in Selected Planning Domains,"Malte Helmert, Robert Mattmüller","The efficiency of optimal planning algorithms based on heuristic search crucially depends on the accuracy of the heuristic function used to guide the search. Often, we are interested in domain-independent heuristics for planning. In order to assess the limitations of domain-independent heuristic planning, we analyze the (in)accuracy of common domain-independent planning heuristics in the IPC benchmark domains. For a selection of these domains, we analytically investigate the accuracy of the h+ heuristic, the h^m family of heuristics, and certain (additive) pattern database heuristics, compared to the perfect heuristic h*. Whereas h+ and additive pattern database heuristics usually return cost estimates proportional to the true cost, non-additive h^m and non-additive pattern-database heuristics can yield results underestimating the true cost by arbitrarily large factors.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-150.pdf,Subjects: 1.11 Planning; 15.7 Search
150,2008,"Reasoning about Plans, Processes, and Actions",HTN-MAKER: Learning HTNs with Minimal Additional Knowledge Engineering Required,"Chad M. Hogg, Hector Munoz-Avila, Ugur Kuter","We describe HTN-MAKER, an algorithm for learning hierarchical planning knowledge in the form of decomposition methods for Hierarchical Task Networks (HTNs). HTN-MAKER takes as input the initial states from a set of classical planning problems in a planning domain and solutions to those problems, as well as a set of semantically-annotated tasks to be accomplished. The algorithm analyzes this semantic information in order to determine which portions of the input plans accomplish a particular task and constructs HTN methods based on those analyses. Our theoretical results show that HTN-MAKER is sound and complete. We also present a formalism for a class of planning problems that are more expressive than classical planning. These planning problems can be represented as HTN planning problems. We show that the methods learned by HTN-MAKER enable an HTN planner to solve those problems. Our experiments confirm the theoretical results and demonstrate convergence in three well-known planning domains toward a set of HTN methods that can be used to solve nearly any problem expressible as a classical planning problem in that domain, relative to a set of goals.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-151.pdf,Subjects: 1.11 Planning; 12. Machine Learning and Discovery
151,2008,"Reasoning about Plans, Processes, and Actions","Generating Plans in Concurrent, Probabilistic, Over-Subscribed Domains","Li Li, Nilufer Onder","Planning in realistic domains involves reasoning under uncertainty, operating under time and resource constraints, and finding the optimal set of goals to be achieved. In this paper, we provide an AO* based algorithm that can deal with durative actions, concurrent execution, over-subscribed goals, and probabilistic outcomes in a unified way. We explore plan optimization by introducing two novel aspects to the model. First, we introduce parallel steps that serve the same goal and increase the probability of success in addition to parallel steps that serve different goals and decrease execution time. Second, we introduce plan steps to terminate concurrent steps that are no longer useful so that resources can be conserved. Our algorithm called CPOAO* (Concurrent, Probabilistic, Oversubscription AO*) can deal with the aforementioned extensions and relies on the AO* framework to reduce the size of the search space using informative heuristic functions. We describe our framework, implementation, the heuristic functions we use, the experimental results, and potential research on heuristics that can further reduce the size of search space.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-152.pdf,Subjects: 15. Problem Solving; 15.7 Search
152,2008,"Reasoning about Plans, Processes, and Actions",Unknown Rewards in Finite-Horizon Domains,"Colin McMillen, Manuela Veloso","""Human computation"" is a recent approach that extracts information from large numbers of Web users. reCAPTCHA is a human computation project that improves the process of digitizing books by getting humans to read words that are difficult for OCR algorithms to read (von Ahn et al. 2008). In this paper, we address an interesting strategic control problem inspired by the reCAPTCHA project: given a large set of words to transcribe within a time deadline, how can we choose the difficulty level such that we maximize the probability of successfully transcribing a document on time? Our approach is inspired by previous work on timed, zero-sum games, as we face an analogous timed policy decision on the choice of words to present to users. However, our Web-based word transcribing domain is particularly challenging as the reward of the actions is not known; i.e., there is no knowledge if the spelling provided by a human is actually correct. We contribute an approach to solve this problem by checking a small fraction of the answers at execution time, obtaining an estimate of the cumulative reward. We present experimental results showing how the number of samples and time between samples affects the probability of success. We also investigate the choice of aggressive or conservative actions with regard to the bounds produced by sampling. We successfully apply our algorithm to real data gathered by the reCAPTCHA project.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-153.pdf,Subjects: 1.11 Planning; 1. Applications
153,2008,"Reasoning about Plans, Processes, and Actions",Route Planning under Uncertainty: The Canadian Traveller Problem,"Evdokia Nikolova, David R. Karger","The Canadian Traveller problem is a stochastic shortest paths problem in which one learns the cost of an edge only when arriving at one of its endpoints. The goal is to find an optimal policy that minimizes the expected cost of travel. The problem is known to be #P-hard. Since there has been no significant progress on approximation algorithms for several decades, we have chosen to seek out special cases for which exact solutions exist, in the hope of demonstrating techniques that could lead to further progress. Applying a mix of techniques from algorithm analysis and the theory of Markov Decision Processes, we provide efficient exact algorithms for directed acyclic graphs and (undirected) graphs of disjoint paths from source to destination with random two-valued edge costs.  We also give worst-case performance analysis and experimental data for two natural heuristics.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-154.pdf,Subjects: 9.3 Mathematical Foundations; 1.11 Planning
154,2008,"Reasoning about Plans, Processes, and Actions",Landmarks Revisited,"Silvia Richter, Malte Helmert, Matthias Westphal","Landmarks for propositional planning tasks are variable assignments that must occur at some point in every solution plan. We propose a novel approach for using landmarks in planning by deriving a pseudo-heuristic and combining it with other heuristics in a search framework. The incorporation of landmark information is shown to improve success rates and solution qualities of a heuristic planner. We furthermore show how additional landmarks and orderings can be found using the information present in multi-valued state variable representations of planning tasks. Compared to previously published approaches, our landmark extraction algorithm provides stronger guarantees of correctness for the generated landmark orderings, and our novel use of landmarks during search solves more planning tasks and delivers considerably better solutions.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-155.pdf,Subjects: 1.11 Planning; 15.7 Search
155,2008,"Reasoning about Plans, Processes, and Actions",Fusing Procedural and Declarative Planning Goals for Nondeterministic Domains,"Dzmitry Shaparau, Marco Pistore, Paolo Traverso","While in most planning approaches goals and plans are different objects, it is often useful to specify goals that combine declarative conditions with procedural plans. In this paper, we propose a novel language for expressing temporally extended goals for planning in nondeterministic domains. The key feature of this language is that it allows for an arbitrary combination of declarative goals expressed in temporal logic and procedural goals expressed as plan fragments. We provide a formal definition of the language and its semantics, and we propose an approach to planning with this language in nondeterministic domains. We implement the planning framework and perform a set of experimental evaluations that show the potentialities of our approach.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-156.pdf,Subjects: 1.11 Planning; 3. Automated Reasoning
156,2008,"Reasoning about Plans, Processes, and Actions",Learning Generalized Plans Using Abstract Counting,"Siddharth Srivastava, Neil Immerman, Shlomo Zilberstein","Given the complexity of planning, it is often beneficial to create plans that work for a wide class of problems. This facilitates reuse of existing plans for different instances drawn from the same problem or from an infinite family of similar problems. We define a class of such planning problems called generalized planning problems and present a novel approach for transforming classical plans into generalized plans. These algorithm-like plans include loops and work for problem instances having varying numbers of objects that must be manipulated to reach the goal. Our approach takes as input a classical plan for a certain problem instance. It outputs a generalized plan along with a classification of the problem instances where it is guaranteed to work. We illustrate the utility of our approach through results of a working implementation on various practical examples.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-157.pdf,Subjects: 1.11 Planning; 11. Knowledge Representation
157,2008,"Reasoning about Plans, Processes, and Actions",Hypothesis Pruning and Ranking for Large Plan Recognition Problems,"Gita Sukthankar, Katia Sycara","This paper addresses the problem of plan recognition for multi-agent teams. Complex multi-agent tasks typically require dynamic teams where the team membership changes over time. Teams split into subteams to work in parallel, merge with other teams to tackle more demanding tasks, and disband when plans are completed. We introduce a new multi-agent plan representation that explicitly encodes dynamic team membership and demonstrate the suitability of this formalism for plan recognition. From our multi-agent plan representation, we extract local temporal dependencies that dramatically prune the hypothesis set of potentially-valid team plans. The reduced plan library can be efficiently processed to obtain the team state history. Naive pruning can be inadvisable when low-level observations are unreliable due to sensor noise and classification errors. In such conditions, we eschew pruning in favor of prioritization and show how our scheme can be extended to rank-order the hypotheses. Experiments show that this robust pre-processing approach ranks the correct plan within the top 10%, even under conditions of severe noise.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-158.pdf,Subjects: 7.1 Multi-Agent Systems; 1.11 Planning
158,2008,"Reasoning about Plans, Processes, and Actions",On the Progression of Situation Calculus Basic Action Theories: Resolving a 10-year-old Conjecture,"Stavros Vassos, Hector J. Levesque","In a seminal paper, Lin and Reiter introduced a model-theoretic definition for the progression of the initial knowledge base of a basic action theory. This definition comes with a strong negative result, namely that for certain kinds of action theories, first-order logic is not expressive enough to correctly characterize this form of progression, and second-order axioms are necessary. However, Lin and Reiter also considered an alternative definition for progression which is always first-order definable. They conjectured that this alternative definition is incorrect in the sense that the progressed theory is too weak and may sometimes lose information. This conjecture, and the status of first-order definable progression, has remained open since then. In this paper we present two significant results about this alternative definition of progression. First, we prove the Lin and Reiter conjecture by presenting a case where the progressed theory indeed does lose information. Second, we prove that the alternative definition is nonetheless correct for reasoning about a large class of sentences, including some that quantify over situations. In this case the alternative definition is a preferred option due to its simplicity and the fact that it is always first-order.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-159.pdf,Subjects: 11. Knowledge Representation; 17. Robotics
159,2008,"Reasoning about Plans, Processes, and Actions",Probabilistic Planning via Determinization in Hindsight,"Sungwook Yoon, Alan Fern, Robert Givan, Subbarao Kambhampati","This paper investigates hindsight optimization as an approach for leveraging the significant advances in deterministic planning for action selection in probabilistic domains. Hindsight optimization is an online technique that evaluates the onestep-reachable states by sampling future outcomes to generate multiple non-stationary deterministic planning problems which can then be solved using search. Hindsight optimization has been successfully used in a number of online scheduling applications; however, it has not yet been considered in the substantially different context of goal-based probabilistic planning. We describe an implementation of hindsight optimization for probabilistic planning based on deterministic forward heuristic search and evaluate its performance on planning-competition benchmarks and other probabilistically interesting problems. The planner is able to outperform a number of probabilistic planners including FFReplan on many problems. Finally, we investigate conditions under which hindsight optimization is guaranteed to be effective with respect to goal achievement, and also illustrate examples where the approach can go wrong.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-160.pdf,Subjects: 1.11 Planning; 15.5 Decision Theory
160,2008,Uncertainty in AI,CRF-OPT: An Efficient High-Quality Conditional Random Solver,"Minmin Chen, Yixin Chen, Michael R. Brent","Conditional random field (CRF) is a popular graphical model for sequence labeling. The flexibility of CRF poses significant computational challenges for training. Using existing optimization packages often leads to long training time and unsatisfactory results. In this paper, we develop CRF-OPT, a general CRF training package, to improve the efficiency and quality for training CRFs. We propose two improved versions of the forward-backward algorithm that exploit redundancy and reduce the time by several orders of magnitudes. Further, we propose an exponential transformation that enforces sufficient step sizes for quasi-Newton methods. The technique improves the convergence quality, leading to better training results. We evaluate CRF-OPT on a gene prediction task on pathogenic DNA sequences, and show that it is faster and achieves better prediction accuracy than both the HMM models and the original CRF model without exponential transformation.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-161.pdf,Subjects: 12. Machine Learning and Discovery; 9.2 Computational Complexity
161,2008,Uncertainty in AI,Many-Pairs Mutual Information for Adding Structure to Belief Propagation Approximations,"arthur choi, adnan darwiche","We consider the problem of computing mutual information between many pairs of variables in a Bayesian network. This task is relevant to a new class of Generalized Belief Propagation (GBP) algorithms that characterizes Iterative Belief Propagation (IBP) as a polytree approximation found by deleting edges in a Bayesian network. By computing, in the simplified network, the mutual information between variables across a deleted edge, we can estimate the impact that recovering the edge might have on the approximation. Unfortunately, it is computationally impractical to compute such scores for networks over many variables having large state spaces. So that edge recovery can scale to such networks, we propose in this paper an approximation of mutual information which is based on a soft extension of d-separation (a graphical test of independence in Bayesian networks). We focus primarily on polytree networks, which are sufficient for the application we consider, although we discuss potential extensions of the approximation to general networks as well. Empirically, we show that our proposal is often as effective as mutual information for the task of edge recovery, with orders of magnitude savings in computation time in larger networks. Our results lead to a concrete realization of GBP, admitting improvements to IBP approximations with only a modest amount of computational effort.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-162.pdf,Subjects: 3.4 Probabilistic Reasoning; 3. Automated Reasoning
162,2008,Uncertainty in AI,Focusing Generalizations of Belief Propagation on Targeted Queries,"arthur choi, adnan darwiche","A recent formalization of Iterative Belief Propagation (IBP) has shown that it can be understood as an exact inference algorithm on an approximate model that results from deleting every model edge. This formalization has led to (1) new realizations of Generalized Belief Propagation (GBP) in which edges are recovered incrementally to improve approximation quality, and (2) edge-recovery heuristics that are motivated by improving the approximation quality of all node marginals in a graphical model. In this paper, we propose new edge-recovery heuristics, which are focused on improving the approximations of targeted node marginals. The new heuristics are based on newly-identified properties of edge deletion, and in turn IBP, which guarantee the exactness of edge deletion in simple and idealized cases. These properties also suggest new improvements to IBP approximations which are based on performing edge-by-edge corrections on targeted marginals, which are less costly than improvements based on edge recovery.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-163.pdf,Subjects: 3.4 Probabilistic Reasoning; 3. Automated Reasoning
163,2008,Uncertainty in AI,Preference Aggregation with Graphical Utility Models,"Christophe Gonzales, Patrice Perny, Sergio Queiroz",This paper deals with preference representation and aggregation in the context of multiattribute utility theory. We consider a set of alternatives having a combinatorial structure. We assume that preferences are compactly represented by graphical utility models derived from generalized additive decomposable (GAI) utility functions. Such functions enable to model interactions between attributes while preserving some decomposability property. We address the problem of finding a compromise solution from several GAI utilities representing different points of view on the alternatives. This scheme can be applied both to multicriteria decision problems and to collective decision making problems over combinatorial domains. We propose a procedure using graphical models for the fast determination of a Pareto-optimal solution achieving a good compromise between the conflicting utilities. The procedure relies on a ranking algorithm enumerating solutions according to the sum of all the GAI utilities until a boundary condition is reached. Numerical experiments are provided to highlight the practical efficiency of our procedure.,https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-164.pdf,Subjects: 15.5 Decision Theory; 15.7 Search
164,2008,Uncertainty in AI,Exploiting Symmetries in POMDPs for Point-Based Algorithms,Kee-Eung Kim,"We extend the model minimization technique for partially observable Markov decision processes (POMDPs) to handle symmetries in the joint space of states, actions, and observations. The POMDP symmetry we define in this paper cannot be handled by the model minimization techniques previously published in the literature. We formulate the problem of finding the symmetries as a graph automorphism (GA) problem, and although not yet known to be tractable, we experimentally show that the sparseness of the graph representing the POMDP allows us to quickly find symmetries. We show how the symmetries in POMDPs can be exploited for speeding up point-based algorithms. We experimentally demonstrate the effectiveness of our approach.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-165.pdf,Subjects: 1.11 Planning; 3.4 Probabilistic Reasoning
165,2008,Uncertainty in AI,Towards Faster Planning with Continuous Resources in Stochastic Domains,"Janusz Marecki, Milind Tambe","Agents often have to construct plans that obey resource limits for continuous resources whose consumption can only be characterized by probability distributions. While Markov Decision Processes (MDPs) with a state space of continuous and discrete variables are popular for modeling these domains, current algorithms for such MDPs can exhibit poor performance with a scale-up in their state space. To remedy that we propose an algorithm called DPFP. DPFP's key contribution is its exploitation of the dual space cumulative distribution functions. This dual formulation is key to DPFP's novel combination of three features. First, it enables DPFP's membership in a class of algorithms that perform forward search in a large (possibly infinite) policy space. Second, it provides a new and efficient approach for varying the policy generation effort based on the likelihood of reaching different regions of the MDP state space. Third, it yields a bound on the error produced by such approximations. These three features conspire to allow DPFP's superior performance and systematic trade-off of optimality for speed. Our experimental evaluation shows that, when run stand-alone, DPFP outperforms other algorithms in terms of its any-time performance, whereas when run as a hybrid, it allows for a significant speedup of a leading continuous resource MDP solver.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-166.pdf,Subjects: 15.5 Decision Theory; 3.4 Probabilistic Reasoning
166,2008,Uncertainty in AI,A Variance Analysis for POMDP Policy Evaluation,"Mahdi Milani Fard, Peng Sun, Joelle Pineau","Partially Observable Markov Decision Processes have been studied widely as a model for decision making under uncertainty, and a number of methods have been developed to find the solutions for such processes. Such studies often involve calculation of the value function of a specific policy, given a model of the transition and observation probabilities, and the reward. These models can be learned using labeled samples of on-policy trajectories. However, when using empirical models, some bias and variance terms are introduced into the value function as a result of imperfect models. In this paper, we propose a method for estimating the bias and variance of the value function in terms of the statistics of the empirical transition and observation model. Such error terms can be used to meaningfully compare the value of different policies. This is an important result for sequential decision-making, since it will allow us to provide more formal guarantees about the quality of the policies we implement. To evaluate the precision of the proposed method, we provide supporting experiments on problems from the field of robotics and medical decision making.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-167.pdf,Subjects: 12.1 Reinforcement Learning; 12. Machine Learning and Discovery
167,2008,Uncertainty in AI,Lifted Probabilistic Inference with Counting Formulas,"Brian Milch, Luke S. Zettlemoyer, Kristian Kersting, Michael Haimes, Leslie Pack Kaelbling","Lifted inference algorithms exploit repeated structure in probabilistic models to answer queries efficiently. Previous work such as de Salvo Braz et al.'s first-order variable elimination (FOVE) has focused on the sharing of potentials across interchangeable random variables. In this paper, we also exploit interchangeability within individual potentials by introducing counting formulas, which indicate how many of the random variables in a set have each possible value. We present a new lifted inference algorithm, C-FOVE, that not only handles counting formulas in its input, but also creates counting formulas for use in intermediate potentials. C-FOVE can be described succinctly in terms of six operators, along with heuristics for when to apply them. Because counting formulas capture dependencies among large numbers of variables compactly, C-FOVE achieves asymptotic speed improvements compared to FOVE.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-168.pdf,Subjects: 3.4 Probabilistic Reasoning; 3. Automated Reasoning
168,2008,Uncertainty in AI,Optimal Testing of Structured Knowledge,"Michael Munie, Yoav Shoham","Adopting a decision-theoretic perspective, we investigate the problem of optimal testing of structured knowledge — the canonical example being a qualifying examination of a graduate student. The setting is characterized by several factors: examinee's knowledge structured around several inter-dependent topics, a limited “budget” of questions available to the examiner, a decision to be made (pass/fail), and an utility for good and bad decisions. The existence of multiple professors brings up additional issues such as committee formation, and the existence of multiple students brings up issues such as fairness.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-169.pdf,Subjects: 7.1 Multi-Agent Systems; 15.5 Decision Theory
169,2008,Uncertainty in AI,A General Method for Reducing the Complexity of Relational Inference and its Application to MCMC,"Hoifung Poon, Pedro Domingos, Marc Sumner","Many real-world problems are characterized by complex relational structure, which can be succinctly represented in first-order logic. However, many relational inference algorithms proceed by first fully instantiating the first-order theory and then working at the propositional level. The applicability of such approaches is severely limited by the exponential time and memory cost of propositionalization. Singla and Domingos (2006) addressed this by developing a ``lazy'' version of the WalkSAT algorithm, which grounds atoms and clauses only as needed. In this paper we generalize their ideas to a much broader class of algorithms, including other types of SAT solvers and probabilistic inference methods like MCMC. Lazy inference is potentially applicable whenever variables and functions have default values (i.e., a value that is much more frequent than the others). In relational domains, the default is false for atoms and true for clauses. We illustrate our framework by applying it to MC-SAT, a state-of-the-art MCMC algorithm. Experiments on a number of real-world domains show that lazy inference reduces both space and time by several orders of magnitude, making probabilistic relational inference applicable in previously infeasible domains.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-170.pdf,Subjects: 3.4 Probabilistic Reasoning; 15.2 Constraint Satisfaction
170,2008,Uncertainty in AI,Dormant Independence,"Ilya Shpitser, Judea Pearl","The construction of causal graphs from non-experimental data rests on a set of constraints that the graph structure imposes on all probability distributions compatible with the graph. These constraints are of two types: conditional independencies and algebraic constraints, first noted by Verma. While conditional independencies are well studied and frequently used in causal induction algorithms, Verma constraints are still poorly understood, and rarely applied. In this paper we examine a special subset of Verma constraints which are easy to understand, easy to identify and easy to apply; they arise from ``dormant independencies,'' namely, conditional independencies that hold in interventional distributions. We give a complete algorithm for determining if a dormant independence between two sets of variables is entailed by the causal graph, such that this independence is identifiable, in other words if it resides in an interventional distribution that can be predicted without resorting to interventions. We further show the usefulness of dormant independencies in model testing and induction by giving an algorithm that uses constraints entailed by dormant independencies to prune extraneous edges from a given causal graph.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-171.pdf,Subjects: 9.1 Causality; 3.4 Probabilistic Reasoning
171,2008,Uncertainty in AI,Symbolic Heuristic Search Value Iteration for Factored POMDPs,"Hyeong Seop Sim, Kee-Eung Kim, Jin Hyung Kim, Du-Seong Chang, Myoung-Wan Koo","We propose Symbolic heuristic search value iteration (Symbolic HSVI) algorithm, which extends the heuristic search value iteration (HSVI) algorithm in order to handle factored partially observable Markov decision processes (factored POMDPs). The idea is to use algebraic decision diagrams (ADDs) for compactly representing the problem itself and all the relevant intermediate computation results in the algorithm. We leverage Symbolic Perseus for computing the lower bound of the optimal value function using ADD operators, and provide a novel ADD-based procedure for computing the upper bound. Experiments on a number of standard factored POMDP problems show that we can achieve an order of magnitude improvement in performance over previously proposed algorithms.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-172.pdf,Subjects: 1.11 Planning; 3.4 Probabilistic Reasoning
172,2008,Uncertainty in AI,Lifted First-Order Belief Propagation,"Parag Singla, Pedro Domingos","Unifying first-order logic and probability is a long-standing goal of AI, and in recent years many representations combining aspects of the two have been proposed. However, inference in them is generally still at the level of propositional logic, creating all ground atoms and formulas and applying standard probabilistic inference methods to the resulting network. Ideally, inference should be lifted as in first-order logic, handling whole sets of indistinguishable objects together, in time independent of their cardinality. Poole (2003) and Braz et al. (2005, 2006) developed a lifted version of the variable elimination algorithm, but it is extremely complex, generally does not scale to realistic domains, and has only been applied to very small artificial problems. In this paper we propose the first lifted version of a scalable probabilistic inference algorithm, belief propagation (loopy or not). Our approach is based on first constructing a lifted network, where each node represents a set of ground atoms that all pass the same messages during belief propagation. We then run belief propagation on this network. We prove the correctness and optimality of our algorithm. Experiments show that it can greatly reduce the cost of inference.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-173.pdf,Subjects: 3.4 Probabilistic Reasoning; 3. Automated Reasoning
173,2008,Uncertainty in AI,Bounding the False Discovery Rate in Local Bayesian Network Learning,"Ioannis Tsamardinos, Laura E. Brown","Modern Bayesian Network learning algorithms are time-efficient, scalable and produce high-quality models; these algorithms feature prominently in decision support model development, variable selection, and causal discovery. The quality of the models, however, has often only been empirically evaluated; the available theoretical results typically guarantee asymptotic correctness (consistency) of the algorithms. This paper describes theoretical bounds on the quality of a fundamental Bayesian Network local-learning task in the finite sample using theories for controlling the False Discovery Rate. The behavior of the derived bounds is investigated across various problem and algorithm parameters. Empirical results support the theory which has immediate ramifications in the design of new algorithms for Bayesian Network learning, variable selection and causal discovery.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-174.pdf,Subjects: 9.1 Causality; 12. Machine Learning and Discovery
174,2008,Uncertainty in AI,Hybrid Markov Logic Networks,"Jue Wang, Pedro Domingos","Markov logic networks (MLNs) combine first-order logic and Markov networks, allowing us to handle the complexity and uncertainty of real-world problems in a single consistent framework. However, in MLNs all variables and features are discrete, while most real-world applications also contain continuous ones. In this paper we introduce hybrid MLNs, in which continuous properties (e.g., the distance between two objects) and functions over them can appear as features. Hybrid MLNs have all distributions in the exponential family as special cases (e.g., multivariate Gaussians), and allow much more compact modeling of non-i.i.d. data than propositional representations like hybrid Bayesian networks. We also introduce inference algorithms for hybrid MLNs, by extending the MaxWalkSAT and MC-SAT algorithms to continuous domains. Experiments in a mobile robot mapping domain — involving joint classification, clustering and regression — illustrate the power of hybrid MLNs as a modeling language, and the accuracy and efficiency of the inference algorithms.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-175.pdf,Subjects: 12. Robotics; 3.4 Probabilistic Reasoning
175,2008,Uncertainty in AI,Latent Tree Models and Approximate Inference in Bayesian Networks,"Yi Wang, Nevin L. Zhang, Tao Chen","We propose a novel method for approximate inference in Bayesian networks (BNs). The idea is to sample data from a BN, learn a latent tree model (LTM) from the data offline, and when online, make inference with the LTM instead of the original BN. Because LTMs are tree-structured, inference takes linear time. In the meantime, they can represent complex relationship among leaf nodes and hence the approximation accuracy is often good. Empirical evidence shows that our method can achieve good approximation accuracy at low online computational cost.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-176.pdf,Subjects: 3.4 Probabilistic Reasoning; 12. Machine Learning and Discovery
176,2008,Uncertainty in AI,A General Framework for Generating Multivariate Explanations in Bayesian Networks,"Changhe Yuan, Tsai-Ching Lu","Many existing explanation methods in Bayesian networks, such as Maximum a Posteriori (MAP) assignment and Most Probable Explanation (MPE), generate complete assignments for target variables. A priori, the set of target variables is often large, but only a few of them may be most relevant in explaining given evidence. Generating explanations with all the target variables is hence not always desirable. This paper addresses the problem by proposing a new framework called Most Relevant Explanation (MRE), which aims to automatically identify the most relevant target variables. We will also discuss in detail a specific instance of the framework that uses generalized Bayes factor as the relevance measure. Finally we will propose an approximate algorithm based on Reversible Jump MCMC and simulated annealing to solve MRE. Empirical results show that the new approach typically finds much more concise explanations than existing methods.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-177.pdf,Subjects: 3.4 Probabilistic Reasoning; 1.5 Diagnosis
177,2008,Special Track on Artificial Intelligence and the Web,On the Enactability of Business Protocols,"Nirmit Desai, Munindar P. Singh","Protocols specifying business interactions among autonomous parties enable reuse and promote interoperability. A protocol is specified from a global viewpoint, but enacted in a distributed manner by agents playing different roles. An ill-specified protocol may yield roles that fail to produce correct enactments of the protocol. Existing approaches lack a formal and comprehensive treatment of this problem. Building on recent work on declaratively specifying a protocol as a set of rules of causal logic, this paper formally defines the enactability of protocols. It presents necessary and sufficient conditions for the enactability of a protocol as well as a decision procedure for extracting correct roles from enactable protocols.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-178.pdf,Subjects: 7. Distributed AI; 1.4 Design
178,2008,Special Track on Artificial Intelligence and the Web,Concept-Based Feature Generation and Selection for Information Retrieval,"Ofer Egozi, Evgeniy Gabrilovich, Shaul Markovitch","Traditional information retrieval systems use query words to identify relevant documents. In difficult retrieval tasks, however, one needs access to a wealth of background knowledge. We present a method that uses Wikipedia-based feature generation to improve retrieval performance. Intuitively, we expect that using extensive world knowledge is likely to improve recall but may adversely affect precision. High quality feature selection is necessary to maintain high precision, but here we do not have the labeled training data for evaluating features, that we have in supervised learning. We present a new feature selection method that is inspired by pseudo-relevance feedback. We use the top-ranked and bottom-ranked documents retrieved by the bag-of-words method as representative sets of relevant and non-relevant documents. The generated features are then evaluated and filtered on the basis of these sets. Experiments on TREC data confirm the superior performance of our method compared to the previous state of the art.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-179.pdf,Subjects: 1.10 Information Retrieval; 11. Knowledge Representation
179,2008,Special Track on Artificial Intelligence and the Web,Linking Social Networks on the Web with FOAF: A Semantic Web Case Study,"Jennifer Golbeck, Matthew Rothstein","One of the core goals of the Semantic Web is to store data in distributed locations, and use ontologies and reasoning to aggregate it. Social networking is a large movement on the web, and social networking data using the Friend of a Friend (FOAF) vocabulary makes up a significant portion of all data on the Semantic Web. Many traditional web-based social networks share their members' information in FOAF format. While this is by far the largest source of FOAF online, there is no information about whether the social network models from each network overlap to create a larger unified social network, or whether they are simply isolated components. If there are intersections, it is evidence that Semantic Web representations and technologies are being used to create interesting, useful data models. In this paper, we present a study of the intersection of FOAF data found in many online social networks. Using the semantics of the FOAF ontology and applying Semantic Web reasoning techniques, we show that a significant percentage of profiles can be merged from multiple networks. We present results on how this affects network structure and what it says about the success of the Semantic Web.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-180.pdf,Subjects: 7. Distributed AI; 11. Knowledge Representation
180,2008,Special Track on Artificial Intelligence and the Web,Mining Translations of Web Queries from Web Click-through Data,"Rong Hu, Weizhu Chen, Jian Hu, Yansheng Lu, Zheng Chen, Qiang Yang","Query translation for Cross-Lingual Information Retrieval (CLIR) has gained increasing attention in the research area. Previous work mainly used machine translation systems, bilingual dictionaries, or web corpora to perform query translation. However, most of these approaches require either expensive language resources or complex language models, and cannot achieve timely translation for new queries. In this paper, we propose a novel solution to automatically acquire query translation pairs from the knowledge hidden in the click-through data, that are represented by the URL a user clicks after submitting a query to a search engine. Our proposed solution consists of two stages: identifying bilingual URL pair patterns in the click-through data and matching query translation pairs based on user click behavior. Experimental results on a real dataset show that our method not only generates existing query translation pairs with high precision, but also generates many timely query translation pairs that could not be obtained by previous methods. A comparative study between our system and two commercial online translation systems shows the advantage of our proposed method.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-181.pdf,Subjects: 10. Knowledge Acquisition; 12. Machine Learning and Discovery
181,2008,Special Track on Artificial Intelligence and the Web,Hierarchical Location and Topic Based Query Expansion,"Shu Huang, Qiankun Zhao, Prasenjit Mitra, C. Lee Giles","In this paper, we propose a novel approach to expand queries by exploring both location information and topic information of the queries. Users at different locations tend to have different vocabularies, while the different expressions coming from different vocabularies may relate to the same topics. Thus these expressions are identified as location sensitive and can be used for query expansion. We propose a hierarchical query expansion model, which employs a two-level SVM classification model to classify queries as location sensitive or location non-sensitive, where the former are further classified into same location sensitive and different location sensitive. For the location sensitive queries, we propose an LDA based topic-level query similarity measure to rank the list of similar queries. Experiments with 2G raw log data from CiteSeer and Excite show that our hierarchical classification model predicts the query location sensitivity with more than 80% precision and that the final search result is significantly better than existing query expansion methods.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-182.pdf,Subjects: 1. Applications; 1.10 Information Retrieval
182,2008,Special Track on Artificial Intelligence and the Web,Semi-Supervised Learning for Blog Classification,"Daisuke Ikeda, Hiroya Takamura, Manabu Okumura","Blog classification (e.g., identifying bloggers' gender or age) is one of the most interesting current problems in blog analysis. Although this problem is usually solved by applying supervised learning techniques, the large labeled dataset required for training is not always available. In contrast, unlabeled blogs can easily be collected from the web. Therefore, a semi-supervised learning method for blog classification, effectively using unlabeled data, is proposed. In this method, entries from the same blog are assumed to have the same characteristics. With this assumption, the proposed method captures the characteristics of each blog, such as writing style and topic, and uses these characteristics to improve the classification accuracy.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-183.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
183,2008,Special Track on Artificial Intelligence and the Web,Generating Useful Network-based Features for Analyzing Social Networks,"Jun Karamon, Yutaka Matsuo, Mitsuru Ishizuka","Recently, many Web services such as social networking services, blogs, and collaborative tagging have become widely popular. Many attempts are being made to investigate user interactions by analyzing social networks among users. However, analyzing a social network with attributional data is often not an easy task because numerous ways exist to define features through aggregation of different tables. In this study, we propose an algorithm to identify important network-based features systematically from a given social network to analyze user behavior efficiently and to expand the services. We apply our method for link-based classification and link prediction tasks with two different datasets, i.e., an @cosme (an online viral marketing site) dataset and a Hatena Bookmark (collaborative tagging service) dataset, to demonstrate the usefulness of our algorithm. Our algorithm is general and can provide useful network-based features for social network analyses.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-184.pdf,Subjects: 12. Machine Learning and Discovery; 15.7 Search
184,2008,Special Track on Artificial Intelligence and the Web,Automatic Extraction of Data Points and Text Blocks from 2-Dimensional Plots in Digital Documents,"Saurabh Kataria, William Browuer, Prasenjit MItra, C. Lee Giles","Two dimensional plots (2-D) in digital documents on the web are an important source of information that is largely under-utilized. In this paper, we outline how data and text can be extracted automatically from these 2-D plots, thus eliminating a time consuming manual process. Our information extraction algorithm identifies the axes of the figures, extracts text blocks like axes-labels and legends and identifies data points in the figure. It also extracts the units appearing in the axes labels and segments the legends to identify the different lines in the legend, the different symbols and their associated text explanations. Our algorithm also performs the challenging task of separating out overlapping text and data points effectively. Our experiments indicate that these techniques are computationally efficient and provide acceptable accuracy.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-185.pdf,Subjects: 1. Applications; 1.10 Information Retrieval
185,2008,Special Track on Artificial Intelligence and the Web,Minimizing the Spread of Contamination by Blocking Links in a Network,"Masahiro Kimura, Kazumi Saito, Hiroshi Motoda","We address the problem of minimizing the propagation of undesirable things, such as computer viruses or malicious rumors, by blocking a limited number of links in a network, a dual problem to the influence maximization problem of finding the most influential nodes in a social network for information diffusion. This minimization problem is another approach to the problem of preventing the spread of contamination by removing nodes in a network. We propose a method for efficiently finding a good approximate solution to this problem based on a naturally greedy strategy. Using large real networks, we demonstrate experimentally that the proposed method significantly outperforms conventional link-removal methods. We also show that unlike the strategy of removing nodes, blocking links between nodes with high out-degrees is not necessarily effective.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-186.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
186,2008,Special Track on Artificial Intelligence and the Web,A Utility-Theoretic Approach to Privacy and Personalization,"Andreas Krause, Eric Horvitz","Online services such as web search, news portals, and e-commerce applications face the challenge of providing high-quality experiences to a large, heterogeneous user base. Recent efforts have highlighted the potential to improve performance by personalizing services based on special knowledge about users. For example, a user's location, demographics, and search and browsing history may be useful in enhancing the results offered in response to web search queries. However, reasonable concerns about privacy by both users, providers, and government agencies acting on behalf of citizens, may limit access to such information. We introduce and explore an economics of privacy in personalization, where people can opt to share personal information in return for enhancements in the quality of an online service. We focus on the example of web search and formulate realistic objective functions for search efficacy and privacy. We demonstrate how we can identify a near-optimal solution to the utility-privacy tradeoff. We evaluate the methodology on data drawn from a log of the search activity of volunteer participants. We separately assess users' preferences about privacy and utility via a large-scale survey, aimed at eliciting preferences about peoples' willingness to trade the sharing of personal data in returns for gains in search efficiency. We show that a significant level of personalization can be achieved using only a small amount of information about users.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-187.pdf,Subjects: 12. Machine Learning and Discovery; 1. Applications
187,2008,Special Track on Artificial Intelligence and the Web,Query-URL Bipartite Based Approach to Personalized Query Recommendation,"Lin Li, Zhenglu Yang, Ling Liu, Masaru Kitsuregawa","Query recommendation is considered an effective assistant in enhancing keyword based queries in search engines and Web search software. Conventional approach to query recommendation has been focused on query-term based analysis over the user access logs. In this paper, we argue that utilizing the connectivity of a query-URL bipartite graph to recommend relevant queries can significantly improve the accuracy and effectiveness of the conventional query-term based query recommendation systems. We refer to the Query-URL Bipartite based query reCommendation approach as QUBiC. The QUBiC approach has two unique characteristics. First, instead of operating on the original bipartite graph directly using biclique based approach or graph clustering, we extract an affinity graph of queries from the initial query-URL bipartite graph. The affinity graph consists of only queries as its vertices and its edges are weighted according to a query-URL vector based similarity (distance) measure. By utilizing the query affinity graph, we are able to capture the propagation of similarity from query to query by inducing an implicit topical relatedness between queries. We devise a novel rank mechanism for ordering the related queries based on the merging distances of a hierarchical agglomerative clustering. We compare our proposed ranking algorithm with both naive ranking that uses the query-URL similarity measure directly, and the single-linkage based ranking method. In addition, we make it possible for users to interactively participate in the query recommendation process, to bridge the gap between the determinacy of actual similarity values and the indeterminacy of users' information needs, allowing the lists of related queries to be changed from user to user and query to query, thus personalizing the query recommendation on demand. The experimental results from two query collections demonstrate the effectiveness and feasibility of our approach.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-188.pdf,Subjects: 1.10 Information Retrieval; Please choose a second document classification
188,2008,Special Track on Artificial Intelligence and the Web,Extracting Relevant Snippets for Web Navigation,"Qing Li, S. K. Candan, Yan Qi","Search engines present fix-sized passages from documents ranked by relevance against the query. In this paper, we present and compare novel, language-model based methods for extracting variable length document snippets by real-time processing of documents using the query issued by the user. With this extra level of information, the returned snippets are considerably more informative. Unlike previous work in passage retrieval which rely on searching relevant segments for filtering of preoccupied passages, we focus on query-informed segmentation to extract context-aware relevant snippets with variable length. In particular, we show that, when informed through an appropriate relevance language model, curvature analysis and Hidden Markov model (HMM) based content segmentation techniques can help extract relevant document snippets.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-189.pdf,Subjects: 13. Natural Language Processing; 13.1 Discourse
189,2008,Special Track on Artificial Intelligence and the Web,Intelligent Output Interface for Intelligent Medical Search Engine,Gang Luo,"To facilitate ordinary people to search medical information, we have built an intelligent medical Web search engine called iMed. iMed uses medical knowledge and an interactive questionnaire to find multiple diseases serving as queries. The search results of these queries are combined together and returned to the searcher in a traditional sequential order. Nevertheless, searchers still frequently miss desired information, because the traditional search result output interface cannot capture the internal structures of medical search results. This paper presents a new, intelligent search result output interface devoted to intelligent medical search. The new output interface automatically offers searchers what they want instead of waiting until they ask explicitly. It structures all the search results into a multi-level hierarchy with explicitly marked medical meanings. In this way, searchers can efficiently navigate among all the search results and quickly obtain desired information. We demonstrate the effectiveness of our techniques through an evaluation using USMLE medical exam cases.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-190.pdf,Subjects: 1.10 Information Retrieval; 6.3 User Interfaces
190,2008,Special Track on Artificial Intelligence and the Web,Neural Network based Constraint Satisfaction in Ontology Mapping,"Ming Mao, Yefei Peng, Michael Spring","Ontology mapping seeks to find semantic correspondences between similar elements of different ontologies. Ontology mapping is critical to achieve semantic interoperability in the WWW. Due to the fact that ubiquitous constraints (e.g., hierarchical restrictions in RDFS) caused by the characteristics of ontologies and their representations exist in ontologies, constraints satisfaction has become an intriguing research problem in ontology mapping area. Though different techniques have been examined to find mappings, little work is made to solve constraint satisfaction problem for ontology mapping. Currently most approaches simply validate ontology constraints using isolate heuristic rules instead of comprehensively considering them in a global view. This paper proposes a neural network based approach to search for a global optimal solution that can satisfy ontology constraints as many as possible. Experimental results on OAEI benchmark tests #248-#266 show the approach is promising. It dramatically improves the performance of preliminary mapping results.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-191.pdf,Subjects: 11.2 Ontologies; 14. Neural Networks
191,2008,Special Track on Artificial Intelligence and the Web,Supporting Manual Mapping Revision using Logical Reasoning,"Christian Meilicke, Heiner Stuckenschmidt, Andrei Tamilin","Finding correct semantic correspondences between ontologies is one of the most challenging problems in the area of semantic web technologies. Experiences with benchmarking matching systems revealed that even the manual revision of automatically generated mappings is a very difficult problem because it has to take the semantics of the ontologies as well as interactions between correspondences into account. In this paper, we propose methods for supporting human experts in the task of revising automatically created mappings. In particular, we present non-standard reasoning methods for detecting and propagating implications of expert decisions on the correctness of a mapping. We show that the use of these reasoning methods significantly reduces the effort of mapping revision in terms of the number of decisions that have to be made by the expert.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-192.pdf,Subjects: 11.2 Ontologies; 1.5 Diagnosis
192,2008,Special Track on Artificial Intelligence and the Web,Decoding Wikipedia Categories for Knowledge Acquisition,"Vivi Nastase, Michael Strube","This paper presents an approach to acquire knowledge from Wikipedia categories and the category network. Many Wikipedia categories have complex names which reflect human classification and organizing instances, and thus encode knowledge about class attributes, taxonomic and other semantic relations. We decode the names and refer back to the network to induce relations between concepts in Wikipedia represented through pages or categories. The category structure allows us to propagate a relation detected between constituents of a category name to numerous concept links. The results of the process are evaluated against ResearchCyc and a subset also by human judges. The results support the idea that Wikipedia category names are a rich source of useful and accurate knowledge.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-193.pdf,Subjects: 10. Knowledge Acquisition; 13. Natural Language Processing
193,2008,Special Track on Artificial Intelligence and the Web,Turning Web Text and Search Queries into Factual Knowledge: Hierarchical Class Attribute Extraction,Marius Pasca,"A seed-based framework for textual information extraction allows for weakly supervised acquisition of open-domain class attributes over conceptual hierarchies, from a combination of Web documents and query logs. Automatically-extracted labeled classes, consisting of a label (e.g., painkillers) and an associated set of instances (e.g., vicodin, oxycontin), are linked under existing conceptual hierarchies (e.g., brain disorders and skin diseases are linked under the concepts BrainDisorder and SkinDisease respectively). Attributes extracted for the labeled classes are propagated upwards in the hierarchy, to determine the attributes of hierarchy concepts (e.g., Disease) from the attributes of their subconcepts (e.g., BrainDisorder and SkinDisease).",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-194.pdf,Subjects: 13. Natural Language Processing; 10. Knowledge Acquisition
194,2008,Special Track on Artificial Intelligence and the Web,Question Utility: A Novel Static Ranking of Question Search,"Young-In Song, Chin-Yew Lin, Yunbo Cao, Hae-Chang Rim","In this paper, we propose a notion of question utility for studying usefulness of questions and show how question utility can be integrated into question search as static ranking. To measure question utility, we examine three methods: (a) a method of employing the language model to estimate the probability that a question is generated from a question collection and then using the probability as question utility; (b) a method of using the LexRank algorithm to evaluate centrality of questions and then using the centrality as question utility; and (c) the combination of (a) and (b). To use question utility in question search, we employ a log linear model for combining relevance score in question search and utility score regarding question utility. Our experimental results with the questions about travel from Yahoo! Answers show that question utility can be effective in boosting up ranks of generally useful questions.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-195.pdf,Subjects: 1.10 Information Retrieval; 13. Natural Language Processing
195,2008,Special Track on Artificial Intelligence and the Web,Metalevel Information in Ontology-Based Applications,"Thanh Tran, Peter Haase, Boris Motik, Bernardo Cuenca Grau, Ian Horrocks","Applications of Semantic Web technologies often require the management of metalevel information—that is, information that provides additional detail about domain-level information, such as provenance or access rights policies. Existing OWL-based tools provide little or no support for the representation and management of metalevel information. To fill this gap, we propose a framework based on metaviews— ontologies that describe facts in the application domain. We have implemented our framework in the KAON2 reasoner, and have successfully applied it in a nontrivial scenario.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-196.pdf,Subjects: 11. Knowledge Representation; 11.2 Ontologies
196,2008,Special Track on Artificial Intelligence and the Web,"Finding Cars, Goddesses and Enzymes: Parametrizable Acquisition of Labeled Instances for Open-Domain Information Extraction","Benjamin Van Durme, Marius Pasca","A method is given for the extraction of large numbers of semantic classes along with their corresponding instances. Based on the recombination of elements clustered through distributional similarity, experimental results show the procedure allows for a parametric trade-off between high precision and expanded recall.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-197.pdf,Subjects: 10. Knowledge Acquisition; 13. Natural Language Processing
197,2008,Special Track on Artificial Intelligence and the Web,An Unsupervised Approach for Product Record Normalization across Different Web Sites,"Tak-Lam Wong, Tik-Shun Wong, Wai Lam","An unsupervised probabilistic learning framework for normalizing product records across different retailer Web sites is presented. Our framework decomposes the problem into two tasks to achieve the goal. The first task aims at extracting attribute values of products from different sites and normalizing them into appropriate reference attributes. This task is challenging because the set of reference attributes is unknown in advance. Besides, the layout formats are different in different Web sites. The second task is to conduct product record normalization aiming at identifying product records referring to the same reference product based on the results of the first task. We develop a graphical model for the generation of text fragments in Web pages to accomplish the two tasks. One characteristic of our model is that the product attributes to be extracted are not required to be specified in advance and an unlimited number of previously unseen product attributes can be handled. We compare our framework with existing methods. Extensive experiments using over 300 Web pages from over 150 real-world Web sites from three different domains have been conducted demonstrating the effectiveness of our framework.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-198.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
198,2008,Special Track on Artificial Intelligence and the Web,A user-oriented webpage ranking algorithm based on user attention time,"Songhua Xu, Yi Zhu, Hao Jiang, Francis C.M. Lau","We propose a new webpage ranking algorithm which is personalized. Our idea is to rely on the attention time spent on a document by the user as the essential clue for producing the user-oriented webpage ranking. The prediction of the attention time of a new webpage is based on the attention time of other previously browsed pages by this user. To acquire the attention time of the latter webpages, we developed a browser plugin which is able to record the time a user spends reading a certain webpage and then automatically send that data to a server. Once the user attention time is acquired, we calibrate it to account for potential repetitive occurrences of the webpage before using it in the prediction process. After the user's attention times of a collection of documents are known, our algorithm can predict the user's attention time of a new document through document content similarity analysis, which is applied to both texts and images. We evaluate the webpage ranking results from our algorithm by comparing them with the ones produced by Google's Pagerank algorithm.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-199.pdf,Subjects: 1.10 Information Retrieval; 1. Applications
199,2008,Special Track on Artificial Intelligence and the Web,Efficient Querying Relaxed Dominant Relationship between Product Items based on Rank Aggregation,"Zhenglu Yang, Lin Li, Masaru Kitsuregawa","Current search engines cannot effectively rank those relational data, which exists on dynamic websites supported by online databases. In this study, to rank such structured data, we propose a new model, Relaxed Dominant Relationship (RDR), which extends the state-of-the-art work by incorporating rank aggregation methods. We propose efficient strategies on building compressed data structure to encode the core part of RDR between items. Efficient querying approaches are devised to facilitate the ranking process and to answer the RDR query. Extensive experiments are conducted and the results illustrate the effectiveness and efficiency of our methods.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-200.pdf,Subjects: 1. Applications; 1.10 Information Retrieval
200,2008,Special Track on Integrated Intelligence,Spatial Scaffolding for Sociable Robot Learning,"Cynthia Breazeal, Matt Berlin","Spatial scaffolding is a naturally occurring human teaching behavior, in which teachers use their bodies to spatially structure the learning environment to direct the attention of the learner. Robotic systems can take advantage of simple, highly reliable spatial scaffolding cues to learn from human teachers. We present an integrated robotic architecture that combines social attention and machine learning components to learn tasks effectively from natural spatial scaffolding interactions with human teachers. We evaluate the performance of this architecture in comparison to human learning data drawn from a novel study of the use of embodied cues in human task learning and teaching behavior. This evaluation provides quantitative evidence for the utility of spatial scaffolding to learning systems. In addition, this evaluation supported the construction of a novel, interactive demonstration of a humanoid robot taking advantage of spatial scaffolding cues to learn from natural human teaching behavior.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-201.pdf,Subjects: 12. Machine Learning and Discovery; 6. Computer-Human Interaction
201,2008,Special Track on Integrated Intelligence,POIROT — Integrated Learning of Web Service Procedures,"Mark Burstein, Robert Laddaga, David McDonald, Michael Cox, Brett Benyo, Paul Robertson, Talib Hussain, Marshall Brinn, Drew McDermott","POIROT is an integration framework for combining machine learning mechanisms to learn hierarchical models of web services procedures from a single or very small set of demonstration examples. The system is organized around a shared representation language for communications with a central hypothesis blackboard. Component learning systems share semantic representations of their hypotheses (generalizations) and inferences about demonstration traces. To further the process, components may generate learning goals for other learning components. POIROT's learners or hypothesis formers develop workflows that include order dependencies, subgoals, and decision criteria for selecting or prioritizing subtasks and service parameters. Hypothesis evaluators, guided by POIROT's meta-control component, plan experiments to confirm or disconfirm hypotheses extracted from these learning products. Collectively, they create methods that POIROT can use to reproduce the demonstration and solve similar problems. After its first phase of development, POIROT has demonstrated it can learn some moderately complex hierarchical task models from semantic traces of user-generated service transaction sequences at a level that is approaching human performance on the same learning task.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-202.pdf,Subjects: 12. Machine Learning and Discovery; 2. Architectures
202,2008,Special Track on Integrated Intelligence,An Integrated Reasoning Approach to Moral Decision-Making,"Morteza Dehghani, Emmett Tomai, Ken Forbus, Matthew Klenk","We present a computational model, MoralDM, which integrates several AI techniques in order to model recent psychological findings on moral decision-making. Current theories of moral decision-making extend beyond pure utilitarian models by relying on contextual factors that vary with culture. MoralDM uses a natural language system to produce formal representations from psychological stimuli, to reduce tailorability. The impacts of secular versus sacred values are modeled via qualitative reasoning, using an order of magnitude representation. MoralDM uses a combination of first-principles reasoning and analogical reasoning to determine consequences and utilities when making moral judgments. We describe how MoralDM works and show that it can model psychological results and improve its performance via accumulating examples.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-203.pdf,Subjects: 4. Cognitive Modeling; 2. Architectures
203,2008,Special Track on Integrated Intelligence,RADAR: A Personal Assistant that Learns to Reduce Email Overload,"Michael Freed, Jaime Carbonell, Geoff Gordon, Jordan Hayes, Brad Myers, Daniel Siewiorek, Stephen Smith, Aaron Steinfeld, Anthony Tomasic","Email client software is widely used for personal task management, a purpose for which it was not designed and is poorly suited. Past attempts to remedy the problem have focused on adding task management features to the client UI. RADAR uses an alternative approach modeled on a trusted human assistant who reads mail, identifies task-relevant message content, and helps manage and execute tasks. This paper describes the integration of diverse AI technologies and presents results from human evaluation studies comparing RADAR user performance to unaided COTS tool users and users partnered with a human assistant. As machine learning plays a central role in many system components, we also compare versions of RADAR with and without learning.  Our tests show a clear advantage for learning-enabled RADAR over all other test conditions.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-204.pdf,Subjects: 7.2 Software Agents; 12. Machine Learning and Discovery
204,2008,Special Track on Integrated Intelligence,The PELA architecture: integrating planning and learning to improve execution,"Sergio Jiménez Celorrio, Fernando Fernández, Daniel Borrajo","Building architectures for autonomous rational behavior requires the integration of several AI components, such as planning, learning and execution monitoring. In most cases, the techniques used for planning and learning are tailored to the specific integrated architecture, so they could not be replaced by other equivalent techniques. Also, in order to solve tasks that require lookahead reasoning under uncertainty, these architectures need an accurate domain model to feed the planning component. But the manual definition of these models is a difficult task. In this paper, we propose an architecture that uses off-the-shelf interchangeable planning and learning components to solve tasks that require flexible planning under uncertainty. We show how a relational learning component can be applied to automatically obtain accurate probabilistic action models from executions of plans. These models can be used by any classical planner that handles metric functions, or, alternatively, by any decision theoretic planner. We also show how these components can be integrated to solve tasks continuously, under an online relational learning scheme.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-205.pdf,Subjects: 1.11 Planning; 2. Architectures
205,2008,Special Track on Integrated Intelligence,Incorporating Mental Simulation for a More Effective Robotic Teammate,"William Kennedy, Magdalena D. Bugajska, William Adams, Alan Schultz, Gregory Trafton","How can we facilitate human-robot teamwork? The teamwork literature has identified the need to know the capabilities of teammates. How can we integrate the knowledge of another agent’s capabilities for a justifiably intelligent teammate? This paper describes extensions to the cognitive architecture, ACT-R, and the use of artificial intelligence (AI) and cognitive science approaches to produce a more cognitively-plausible, autonomous robotic system that ""mentally"" simulates the decision-making of its teammate. The extensions to ACT-R added capabilities to interact with the real world through the robot’s sensors and effectors and simulate the decision-making of its teammate. The AI applications provided visual sensor capabilities by methods clearly different than those used by humans. The integration of these approaches into intelligent team-based behavior is demonstrated on a mobile robot. Our ""TeamBot"" matches the descriptive work and theories on human teamwork. We illustrate our approach in a spatial, team-oriented task of a guard force responding appropriately to an alarm condition that requires the human and robot team to ""man"" two guard stations as soon as possible after the alarm.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-206.pdf,Subjects: 2. Architectures; 4. Cognitive Modeling
206,2008,Special Track on Integrated Intelligence,Pervasive Diagnosis: The Integration of Diagnostic Goals into Production Plans,"Lukas Kuhn, Bob Price, Johan de Kleer, Minh Do, Rong Zhou","In model-based control, a planner uses a system description to create a plan that achieves production goals. The same description can be used by modelbased diagnosis to infer the condition of components in a system from partially informative sensors. Prior work has demonstrated that diagnosis can be used to adapt the control of a system to changes in its components. However diagnosis must either make inferences from passive observations of production, or production must be halted to take diagnostic actions. We observe that the declarative nature of model-based control allows the planner to achieve production goals in multiple ways. This flexibility can be exploited with a novel paradigm we call pervasive diagnosis which produces diagnostic production plans that simultaneously achieve production goals while uncovering additional information about component health. We present an efficient heuristic search for these diagnostic production plans and show through experiments on a model of an industrial digital printing press that the theoretical increase in information can be realized on practical real-time systems. We obtain higher long-run productivity than a decoupled combination of planning and diagnosis.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-207.pdf,Subjects: 1.5 Diagnosis; 1.11 Planning
207,2008,Special Track on Integrated Intelligence,An Integrated Agent for Playing Real-Time Strategy Games,"Josh McCoy, Michael Mateas","We present a real-time strategy (RTS) game AI agent that integrates multiple specialist components to play a complete game. Based on an analysis of how skilled human players conceptualize RTS gameplay, we partition the problem space into domains of competence seen in expert human play. This partitioning helps us to manage and take advantage of the large amount of sophisticated domain knowledge developed by human players. We present results showing that incorporating expert high-level strategic knowledge allows our agent to consistently defeat established scripted AI players. In addition, this work lays the foundation to incorporate tactics and unit micro-management techniques developed by both man and machine.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-208.pdf,Subjects: 1.8 Game Playing; 2. Architectures
208,2008,Special Track on Integrated Intelligence,Adaptive Control for Autonomous Underwater Vehicles,"Conor McGann, Frederic Py, Kanna Rajan, John Ryan, Richard Henthorn","We describe a novel integration of Planning with Probabilistic State Estimation and Execution resulting in a unified representational and computational framework based on declarative models and constraint-based temporal plans. The work is motivated by the need to explore the oceans more cost-effectively through the use of Autonomous Underwater Vehicles (AUV), requiring them to be goal-directed, perceptive, adaptive and robust in the context of dynamic and uncertain conditions. The novelty of our approach is in integrating deliberation and reaction over different temporal and functional scopes within a single model, and in breaking new ground in oceanography by allowing for precise sampling within a feature of interest using an autonomous robot. The system is general-purpose and adaptable to other ocean going and terrestrial platforms.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-209.pdf,Subjects: 1.11 Planning; 17. Robotics
209,2008,Special Track on Integrated Intelligence,Achieving Far Transfer in an Integrated Cognitive Architecture,"Daniel Shapiro, Tolga Konik, Paul O'Rorke","Transfer is the ability to employ knowledge acquired in one task to improve performance in another. We study transfer in the context of the ICARUS cognitive architec-ture, which supplies diverse capabilities for execution, inference, planning, and learning. We report on an exten-sion to ICARUS called representation mapping that trans-fers structured skills and concepts between disparate tasks that may not even be expressed with the same symbol set. We show that representation mapping is naturally integrated into ICARUS’ cognitive processing loop, resulting in a system that addresses a qualitatively new class of problems by considering the relevance of past experience to current goals.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-210.pdf,Subjects: 2. Architectures; 12. Machine Learning and Discovery
210,2008,Special Track on Integrated Intelligence,Bimodal Spatial Reasoning with Continuous Motion,"Samuel Wintermute, John E. Laird","Symbolic AI systems typically have difficulty reasoning about motion in continuous environments, such as determining whether a cornering car will clear a close obstacle. Bimodal systems, integrating a qualitative symbolic system with a quantitative diagram-like spatial representation, are capable of solving this sort of problem, but questions remain of how and where knowledge about fine-grained motion processes is represented, and how it is applied to the problem. In this paper, we argue that forward simulation of motion is an appropriate method, and introduce continuous motion models to enable this simulation. These motion-specific models control behavior of objects at the spatial level, while general mechanisms in the higher qualitative level control and monitor them. This interaction of low- and high-level activity allows for problem solving that is both precise in individual problems and general across multiple problems. In addition, this approach allows perception and action mechanisms to be reused in reasoning about hypothetical motion problems and abstract non-motion problems, and points to how symbolic AI can become more grounded in the real world. We demonstrate implemented systems that solve problems in diverse domains, and connections to action control are discussed.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-211.pdf,Subjects: 3.2 Geometric Or Spatial Reasoning; 2. Architectures
211,2008,Special Track on Physically Grounded Artificial Intelligence,Planning for Human-Robot Interaction Using Time-State Aggregated POMDPs,"Frank Broz, Illah Nourbakhsh, Reid Simmons","In order to interact successfully in social situations, a robot must be able to observe others' actions and base its own behavior on its beliefs about their intentions. Many interactions take place in dynamic environments, and the outcomes of people's or the robot's actions may be time-dependent.  In this paper, such interactions are modeled as a POMDP with a time index as part of the state, resulting in a fully Markov model with a potentially very large state space. The complexity of finding even an approximate solution often limits POMDP's practical applicability for large problems.  This difficulty is addressed through the development of an algorithm for aggregating states in POMDPs with a time-indexed state space. States that represent the same physical configuration of the environment at different times are chosen to be combined using reward-based metrics, preserving the structure of the original model while producing a smaller model that is faster to solve. We demonstrate that solving the aggregated model produces a policy with performance comparable to the policy from the original model. The example domains used are a simulated elevator-riding task and a simulated driving task based on data collected from human drivers.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-212.pdf,Subjects: 1.11 Planning; 3.6 Temporal Reasoning
212,2008,Special Track on Physically Grounded Artificial Intelligence,The Hidden Permutation Model and Location-based Activity Recognition,"Hung H. Bui, Dinh Phung, Svetha Venkatesh, Hai Phan","Permutation modeling is challenging because of the combinatorial nature of the problem. However, such modeling is often required in many real-world applications, including activity recognition where sub-activities are often permuted and partially ordered. This paper introduces a novel Hidden Permutation Model (HPM) that can learn the partial ordering constraints in permuted state sequences. The HPM is parameterized as an exponential family distribution and is flexible so that it can encode constraints via different feature functions. A chain-flipping Metropolis-Hastings Markov chain Monte Carlo (MCMC) is employed for inference to overcome the $O(n!)$ complexity. Gradient-based maximum likelihood parameter learning is presented for two cases when the permutation is known and when it is hidden. The HPM is evaluated using both simulated and real data from a location-based activity recognition domain. Experimental results indicate that the HPM performs far better than other baseline models, including the naive Bayes classifier, the HMM classifier, and Kirshner's multinomial permutation model. Our presented HPM is generic and can potentially be utilized in any problem where the modeling of permuted states from noisy data is needed.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-213.pdf,Subjects: 12. Machine Learning and Discovery; 1.6 Engineering And Science
213,2008,Special Track on Physically Grounded Artificial Intelligence,Adaptive Importance Sampling with Automatic Model Selection in Value Function Approximation,"Hirotaka Hachiya, Takayuki Akiyama, Masashi Sugiyama, Jan Peters","Off-policy reinforcement learning is aimed at efficiently reusing data samples gathered in the past, which is an essential problem for physically grounded AI as experiments are usually prohibitively expensive. A common approach is to use importance sampling techniques for compensating for the bias caused by the difference between data-sampling policies and the target policy. However, existing off-policy methods do not often take the variance of value function estimators explicitly into account and therefore their performance tends to be unstable. To cope with this problem, we propose using an adaptive importance sampling technique which allows us to actively control the trade-off between bias and variance. We further provide a method for optimally determining the trade-off parameter based on a variant of cross-validation. We demonstrate the usefulness of the proposed approach through simulations.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-214.pdf,Subjects: 12.1 Reinforcement Learning; 15.3 Control
214,2008,Special Track on Physically Grounded Artificial Intelligence,Anticipatory Perceptual Simulation for Human-Robot Joint Practice: Theory and Application Study,"Guy Hoffman, Cynthia Breazeal","With the aim of fluency and efficiency in human-robot teams, we have developed a cognitive architecture based on the neuro-psychological principles of anticipation and perceptual simulation through top-down biasing. An instantiation of this architecture was implemented on a non-anthropomorphic robotic lamp, performing in a human-robot collaborative task.  In a human-subject study, in which the robot works on a joint task with untrained subjects, we find our approach to be significantly more efficient and fluent than in a comparable system without anticipatory perceptual simulation. We also show the robot and the human to be increasingly contributing at a similar rate. Through self-report, we find significant differences between the two conditions in the sense of team fluency, the team's improvement over time, and the robot's contribution to the efficiency and fluency. We also find difference in verbal attitudes towards the robot: most notably, subjects working with the anticipatory robot attribute more positive and more human qualities to the robot, but display increased self-blame and self-deprecation.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-215.pdf,Subjects: 4. Cognitive Modeling; 17. Robotics
215,2008,Special Track on Physically Grounded Artificial Intelligence,CIGAR: Concurrent and Interleaving Goal and Activity Recognition,"Derek Hao Hu, Qiang Yang","In artificial intelligence and pervasive computing research, inferring users’ high-level goals from activity sequences is an important task. A major challenge in goal recognition is that users often pursue several high-level goals in a concurrent and interleaving manner, where the pursuit of goals may spread over different parts of an activity sequence and may be pursued in parallel. Existing approaches to recognizing multiple goals often formulate this problem either as a single-goal recognition problem or in a deterministic way, ignoring uncertainty. In this paper, we propose CIGAR (Concurrent and Interleaving Goal and Activity Recognition) - a novel and simple two-level probabilistic framework for multiple-goal recognition where we can recognize both concurrent and interleaving goals. We use skip-chain conditional random fields (SCCRF) for modeling interleaving goals and we model concurrent goals by adjusting inferred probabilities through a correlation graph, which is a major advantage in that we are able to reason about goal interactions explicitly through the correlation graph. The two-level framework also avoids the high training complexity when modeling concurrency and interleaving together in a unified CRF model. Experimental results show that our method can effectively improve recognition accuracies on several real-world datasets collected from various wireless and sensor networks.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-216.pdf,Subjects: 1. Applications; Please choose a second document classification
216,2008,Special Track on Physically Grounded Artificial Intelligence,Efficient optimization of information-theoretic exploration in SLAM,"Thomas Kollar, Nicholas Roy","We present a novel method for information-theoretic exploration, leveraging recent work on mapping and localization. We describe exploration as the constrained optimization problem of computing a trajectory to minimize posterior map error, subject to the constraints of traveling through a set of sensing locations to ensure map coverage. This trajectory is found by reducing the map to a skeleton graph and searching for a minimum entropy tour through the graph. We describe how a specific factorization of the map covariance allows the re-use of EKF updates during the optimization, giving an efficient gradient ascent search for the maximum information gain tour through sensing locations, where each tour naturally incorporates revisiting well-known map regions. By generating incrementally larger tours as the exploration finds new regions of the environment, we demonstrate that our approach can perform autonomous exploration with improved accuracy.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-217.pdf,Subjects: 17. Robotics; 15.7 Search
217,2008,Special Track on Physically Grounded Artificial Intelligence,An Efficient Motion Planning Algorithm for Stochastic Dynamic Systems with Constraints on Probability of Failure,"Masahiro Ono, Brian C. Williams","When controlling dynamic systems, such as mobile robots in uncertain environments, there is a trade off between risk and reward. For example, a race car can turn a corner faster by taking a more challenging path. This paper proposes a new approach to planning a control sequence with a guaranteed risk bound. Given a stochastic dynamic model, the problem is to find a control sequence that optimizes a performance metric, while satisfying chance constraints i.e. constraints on the upper bound of the probability of failure. We propose a two-stage optimization approach, with the upper stage optimizing the risk allocation and the lower stage calculating the optimal control sequence that maximizes reward. In general, the upper-stage is a non-convex optimization problem, which is hard to solve. We develop a new iterative algorithm for this stage that efficiently computes the risk allocation with a small penalty to optimality. The algorithm is implemented and tested on the autonomous underwater vehicle (AUV) depth planning problem, and demonstrates a substantial improvement in computation cost and suboptimality, compared to the prior arts.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-218.pdf,Subjects: 3.4 Probabilistic Reasoning; 17. Robotics
218,2008,Special Track on Physically Grounded Artificial Intelligence,Transferring Localization Models Across Space,"Sinno Jialin Pan, Dou Shen, Qiang Yang, James T. Kwok","Machine learning approaches to indoor WiFi localization involve an offline phase and an online phase. In the offline phase, data are collected from an environment to build a localization model, which will be applied to new data collected in the online phase for location estimation. However, collecting the labeled data across an entire building would be too time consuming. In this paper, we present a novel approach to transferring the learning model trained on data from one area of a building to another. We learn a mapping function between the signal space and the location space by solving an optimization problem based on manifold learning techniques. A low-dimensional manifold is shared between data collected in different areas in an environment as a bridge to propagate the knowledge across the whole environment. With the help of the transferred knowledge, we can significantly reduce the amount of labeled data which are required for building the localization model. We test the effectiveness of our proposed solution in a real indoor WiFi environment.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-219.pdf,Subjects: 1. Applications; 12. Machine Learning and Discovery
219,2008,Special Track on Physically Grounded Artificial Intelligence,Structure Learning on Large Scale Common Sense Statistical Models of Human State,"William Pentney, Matthai Philipose, Jeff Bilmes","Research has shown promise in the design of large scale common sense probabilistic models to infer human state from environmental sensor data. These models have made use of mined and preexisting common sense data and traditional probabilistic machine learning techniques to improve recognition of the state of everyday human life. In this paper, we demonstrate effective techniques for structure learning on graphical models designed for this domain, improving the SRCS system of (Pentney et al 2007) by learning additional dependencies between variables. Because the models used for common sense reasoning typically involve a large number of variables, issues of scale arise in searching for additional dependencies; we discuss how we use data mining techniques to address this problem. We show experimentally that these techniques improve the accuracy of state prediction, and that, with a good prior model, the use of a common sense model with structure learning provides better prediction of unlabeled variables as well as labeled variables. The results also demonstrate that it is possible to collect new common sense information about daily life using such a statistical model and labeled data.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-220.pdf,Subjects: 5. Common Sense Reasoning; 12. Machine Learning and Discovery
220,2008,Special Track on Physically Grounded Artificial Intelligence,Reducing Particle Filtering Complexity for 3D Motion Capture using Dynamic Bayesian Networks,"Cedric Rose, Jamal Saboune, Francois Charpillet",Particle filtering algorithms can be used for the monitoring of dynamic systems with continuous state variables and without any constraints on the form of the probability distributions. The dimensionality of the problem remains a limitation of these approaches due to the growing number of particles required for the exploration of the state space. Computer vision problems such as 3D motion tracking are an example of complex monitoring problems which have a high dimensional state space and observation functions with high computational cost. In this article we focus on reducing the required number of particles in the case of monitoring tasks where the state vector and the observation function can be factored. We introduce a particle filtering algorithm based on the Dynamic Bayesian Network (DBN) formalism which takes advantage of a factored representation of the state space for efficiently weighting and selecting the particles. We illustrate the approach on a simulated and a realworld 3D motion tracking tasks.,https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-221.pdf,Subjects: 3.4 Probabilistic Reasoning; 19. Vision
221,2008,Special Track on Physically Grounded Artificial Intelligence,A Fast Data Collection and Augmentation Procedure for Object Recognition,"Benjamin Sapp, Ashutosh Saxena, Andrew Y. Ng","When building an application that requires object class recognition, having enough data to learn from is critical for good performance, and can easily determine the success or failure of the system. However, it is typically extremely labor-intensive to collect data, as the process usually involves acquiring the image, then manual cropping and hand-labeling. Preparing large training sets for object recognition has already become one of the main bottlenecks for such emerging applications as mobile robotics and object recognition on the web. This paper focuses on a novel and practical solution to the dataset collection problem. Our method is based on using a green screen to rapidly collect example images; we then use a probabilistic model to rapidly synthesize a much larger training set that attempts to capture desired invariants in the object's foreground and background. We demonstrate this procedure on our own mobile robotics platform, where we achieve 135x savings in the time/effort needed to obtain a training set. Our data collection method is agnostic to the learning algorithm being used, and applies to any of a large class of standard object recognition methods. Given these results, we suggest that this method become a standard protocol for developing scalable object recognition systems. Further, we used our data to build reliable classifiers that enabled our robot to visually recognize an object in an office environment, and thereby fetch an object from an office in response to a verbal request.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-222.pdf,Subjects: 17. Robotics; 19. Vision
222,2008,Special Track on Physically Grounded Artificial Intelligence,Multimodal People Detection and Tracking in Crowded Scenes,"Luciano Spinello, Rudolph Triebel, Roland Siegwart","This paper presents a novel people detection and tracking method based on a multi-modal sensor fusion approach that utilizes 2D laser range and camera data. The data points in the laser scans are clustered using a novel graph-based method and an SVM based version of the cascaded AdaBoost classifier is trained with a set of geometrical features of these clusters. In the detection phase, the classified laser data is projected into the camera image to define a region of interest for the vision-based people detector. This detector is a fast version of the Implicit Shape Model (ISM) that learns an appearance codebook of local SIFT descriptors from a set of hand-labeled images of pedestrians and uses them in a voting scheme to vote for centers of detected people. The extension consists in a fast and detailed analysis of the spatial distribution of voters per detected person. Each detected person is tracked using a greedy data association method and multiple Extended Kalman Filters that use different motion models. This way, the filter can cope with a variety of different motion patterns. The tracker is asynchronously updated by the detections from the laser and the camera data. Experiments conducted in real-world outdoor scenarios with crowds of pedestrians demonstrate the usefulness of our approach.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-223.pdf,Subjects: 17. Robotics; 19.1 Perception
223,2008,Special Track on Physically Grounded Artificial Intelligence,Feature Selection for Activity Recognition in Multi-Robot Domains,"Douglas L. Vail, Manuela M. Veloso","In multi-robot settings, activity recognition allows a robot to respond intelligently to the other robots in its environment. Conditional random fields are temporal models that are well suited for activity recognition because they can robustly incorporate rich, non-independent features computed from sensory data. In this work, we explore feature selection in conditional random fields for activity recognition to choose which features should be included in the final model. We compare two feature selection methods, grafting, a greedy forward-selection strategy, and L1 regularization, which simultaneously smoothes the model and selects a subset of the features. We use robot data recorded during four games of the Small Size League of the RoboCup'07 robot soccer world championship to empirically compare the performance of the two feature selection algorithms in terms of accuracy of the final model, the number of features selected in the final model, and the time required to train the final model.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-224.pdf,Subjects: 17. Robotics; 12. Machine Learning and Discovery
224,2008,Special Track on Physically Grounded Artificial Intelligence,Transferring Localization Models Over Time,"Vincent Wenchen Zheng, Evan Wei Xiang, Qiang Yang, Dou Shen","Learning-based localization methods typically consist of an offline phase to collect the wireless signal data to build a statistical model, and an online phase to apply the model on new data. Many of these methods treat the training data as if their distributions are fixed across time. However, due to complex environmental changes such as temperature changes and multi-path fading effect, the signals can significantly vary from time to time, causing the localization accuracy to drop. We address this problem by introducing a novel semi-supervised Hidden Markov Model (HMM) to transfer the learned model from one time period to another. This adaptive model is referred to as transferred HMM (TrHMM), in which we aim to transfer as much knowledge from the old model as possible to reduce the calibration effort for the current time period. Our contribution is that we can successfully transfer out-of-date model to fit a current model through learning, even though the training data have very different distributions. Experimental results show that the TrHMM method can greatly improve the localization accuracy while saving a great amount of the calibration effort.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-225.pdf,Subjects: 1. Applications; 17. Robotics
225,2008,Special Track on Physically Grounded Artificial Intelligence,Transferring Multi-device Localization Models using Latent Multi-task Learning,"Vincent Wenchen Zheng, Sinno Jialin Pan, Qiang Yang and Jeffrey Junfeng Pan","In this paper, we propose a latent multi-task learning algorithm to solve the multi-device indoor localization problem. Traditional indoor localization systems often assume that the collected signal data distributions are fixed, and thus the localization model learned on one device can be used on other devices without adaptation. However, by empirically studying the signal variation over different devices, we found this assumption to be invalid in practice. To solve this problem, we treat multiple devices as multiple learning tasks, and propose a multi-task learning algorithm. Different from algorithms assuming that the hypotheses learned from the original data space for related tasks can be similar, we only require the hypotheses learned in a latent feature space are similar. To establish our algorithm, we employ an alternating optimization approach to iteratively learn feature mappings and multi-task regression models for the devices. We apply our latent multi-task learning algorithm to real-world indoor localization data and demonstrate its effectiveness.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-226.pdf,Subjects: 1. Applications; 17. Robotics
226,2008,Special Track on Physically Grounded Artificial Intelligence,Maximum Entropy Inverse Reinforcement Learning,"Brian D. Ziebart, Andrew Maas, J. Andrew Bagnell, Anind K. Dey","Recent research has shown the benefit of framing problems of imitation learning as solutions to Markov Decision Problems. This approach reduces learning to the problem of recovering a utility function that makes the behavior induced by a near-optimal policy closely mimic demonstrated behavior. In this work, we develop a probabilistic approach based on the principle of maximum entropy. Our approach provides a well-defined, globally normalized distribution over decision sequences, while providing the same performance guarantees as existing methods. We develop our technique in the context of modeling real-world navigation and driving behaviors where collected data is inherently noisy and imperfect. Our probabilistic approach enables modeling of route preferences as well as a powerful new approach to inferring destinations and routes based on partial trajectories.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-227.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
227,2008,Short Papers,Interaction Structure and Dimensionality Reduction in Decentralized MDPs,"Martin Allen, Marek Petrik, Shlomo Zilberstein","Decentralized Markov Decision Processes are a powerful general model of decentralized, cooperative multi-agent problem solving. The high complexity of the general problem leads to a focus on restricted models. While worst-case hardness of such reduced problems is often better, less is known about the actual difficulty of given instances. We show tight connections between the structure of agent interactions and the essential dimensionality of various problems. Bounds are placed on problem difficulty, given restrictions on the type and number of interactions between agents. These bounds arise from a bilinear programming formulation of the problem; from such a formulation, a more compact reduced form can be automatically generated, and the original problem rewritten to take advantage of the reduction.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-228.pdf,Subjects: 7.1 Multi-Agent Systems; 1.11 Planning
228,2008,Short Papers,Generating Hard SAT/CSP Instances Using Expander Graphs,"Carlos Ansótegui, Ramón Béjar, Cèsar Fernández, Carles Mateu","In this paper we provide a new method to generate hard k-SAT instances. We incrementally construct a high girth bipartite incidence graph of the k-SAT instance. Having high girth assures high expansion for the graph, and high expansion implies high resolution width. We have extended this approach to generate hard n-ary CSP instances and we have also adapted this idea to increase the expansion of the system of linear equations used to generate XORSAT instances, being able to produce harder satisfiable instances than former generators.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-229.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
229,2008,Short Papers,An Effective and Robust Method for Short Text Classification,"Victoria Bobicev, Marina Sokolova","Classification of texts potentially containing a complex and specific terminology requires the use of learning methods that do not rely on extensive feature engineering. In this work we use prediction by partial matching ( PPM), a method that compresses texts to capture text features and creates a language model adapted to a particular text. We show that the method achieves a high accuracy of text classification and can be used as an alternative to state-of-art learning algorithms.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-230.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
230,2008,Short Papers,Hybrid Constraint Tightening for Solving Hybrid Scheduling Problems,"James Boerkoel, Edmund Durfee","Hybrid Scheduling Problems (HSPs) contain both temporal and finite-domain variables, as well as constraints between them. A hybrid constraint over temporal and finite-domain variables often models situations where different assignments to a subset of finite-domain variables result in different bounds on temporal constraints. The insight we examine in this paper is that some temporal constraint propagation is possible even before finite-domain variables are assigned, by giving the temporal constraint the tightest bound consistent with all (remaining) feasible finite-domain variable values. We describe a hybrid constraint-tightening algorithm that can proactively prune the search space of HSPs and is run as a preprocessing step independently of the search algorithm used. We examine the efficiency of this algorithm analytically, and give preliminary results showing that it reduces the expected runtime of search by a significant mar-gin in the kinds of HSPs we are studying.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-231.pdf,Subjects: 15.2 Constraint Satisfaction; 1.12 Scheduling
231,2008,Short Papers,Data-Driven Programming and Behavior for Autonomous Virtual Characters,"Jonathan Dinerstein, Parris K. Egbert, Dan Ventura, Michael Goodrich","We present a novel technique for behavioral animation through data-driven behavior synthesis that provides realistic and natural character behavior and has a programming-by-demonstration interface. The demonstrator's high-level behavior is recorded as a sequence of discrete actions. The virtual character synthesizes novel behavior by concatenating segments of action sequences, guided by simulations that predict fitness (thus producing a deliberative cognitive behavioral model). We empirically show that our O(log n) technique is scalable, robust, general, produces effective behavior, and is faster than a traditional cognitive model.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-232.pdf,Subjects: 7.2 Software Agents; 6.1 Life-Like Characters
232,2008,Short Papers,Limits and Possibilities of BDDs for State Space Search,"Stefan Edelkamp, Peter Kissmann","The idea of using BDDs for optimal sequential planning is to reduce the memory requirements for the state sets as problem sizes increase. State variables are encoded binary and ordered along their causal graph dependencies. Sets of planning states are represented in form of Boolean functions, and actions are formalized as transition relations. This allows to compute the successor state set, which determines all states reached by applying one action to the states in the input set. Iterating the process (starting with the representation of the initial state) yields a symbolic implementation of breadth-first search. This paper studies the causes for good and bad BDD performance by providing lower and upper bounds for BDD growth in various domains. Besides general applicability to planning benchmarks, our approach covers different cost models; it applies to step-optimal propositional planning as well as planning with additive action costs.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-233.pdf,Subjects: 15.7 Search; 1.11 Planning
233,2008,Short Papers,Expectation-Based Versus Potential-Aware Automated Abstraction in Imperfect Information Games: An Experimental Comparison Using Poker,"Andrew Gilpin, Tuomas Sandholm","Automated abstraction algorithms for sequential imperfect information games have recently emerged as a key component in developing competitive game theory-based agents. The existing literature has not investigated the relative performance of different abstraction algorithms. Instead, agents whose construction has used automated abstraction have only been compared under confounding effects: different granularities of abstraction and equilibrium-finding algorithms that yield different accuracies when solving the abstracted game. This paper provides the first systematic evaluation of abstraction algorithms. Two families of algorithms have been proposed. The distinguishing feature is the measure used to evaluate the strategic similarity between game states. One algorithm uses the probability of winning as the similarity measure. The other uses a potential-aware similarity measure based on probability distributions over future states. We conduct experiments on Rhode Island Hold'em poker. We compare the algorithms against each other, against optimal play, and against each agent's nemesis. We also compare them based on the resulting game's value. Interestingly, for very coarse abstractions the expectation-based algorithm is better, but for moderately coarse and fine abstractions the potential-aware approach is superior. Furthermore, agents constructed using the expectation-based approach are highly exploitable beyond what their performance against the game's optimal strategy would suggest.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-234.pdf,Subjects: 7.1 Multi-Agent Systems; 1.8 Game Playing
234,2008,Short Papers,Learning to Identify Reduced Passive Verb Phrases with a Shallow Parser,"Sean Igo, Ellen Riloff","Our research is motivated by the observation that NLP systems frequently mislabel passive voice verb phrases as being in the active voice when there is no auxiliary verb (e.g., ""The man arrested had a long record""). These errors directly impact thematic role recognition and NLP applications that depend on it. We present a learned classifier that can accurately identify reduced passive voice constructions in shallow parsing environments.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-235.pdf,Subjects: 13. Natural Language Processing; 13.3 Syntax
235,2008,Short Papers,The Re-Representation Problem in a Logic-Based Framework for Analogy Making,"Ulf Krumnack, Helmar Gust, Kai-Uwe Kühnberger, Angela Schwering","Analogical reasoning plays an important role for cognitively demanding tasks. The comparison of parallel structures in two different domains allows the transfer of knowledge and thereby yields to new insights. A major challenge in computing analogies concerns the problem of adapting the representation of the domains in a way that the analogous structures become obvious, i.e. finding and, in certain circumstances, generating appropriate representations that allow for computing an analogical relation. We propose to resolve this re-representation problem of analogy making in a logical framework based on the anti-unification of logical theories. The approach is exemplified using an example from a domain of qualitative reasoning (naive physics).",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-236.pdf,Subjects: 5. Common Sense Reasoning; 11. Knowledge Representation
236,2008,Short Papers,Dynamic Distributed Constraint Reasoning,"Robert N. Lass, Evan A. Sultanik, William C. Regli","What local action can agents take, without the benefit of global knowledge, to produce the best global solution? Many dynamic distributed systems can be modeled using techniques from distributed constraint reasoning, however, existing work in the distributed constraint reasoning community does not address the true dynamism inherent in many real-world systems. This paper describes a formal model for dynamic distributed constraint reasoning, presents an example of a dynamic distributed system, and shows how the model could be applied to the example. Finally, a new algorithm and a classification scheme for algorithms solving these problems are proposed.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-238.pdf,Subjects: 7.1 Multi-Agent Systems; 15.2 Constraint Satisfaction
237,2008,Short Papers,Ensemble Forecasting for Disease Outbreak Detection,"Thomas H. Lotze, Galit Shmueli","We describe a method to improve detection of disease outbreaks in pre-diagnostic time series data. The method uses multiple forecasters and learns the linear combination to minimize the expected squared error of the next day's forecast. This combination adaptively changes over time. This adaptive ensemble combination is used to generate a disease alert score for each day, using a separate multi-day combination method learned from examples of different disease outbreak patterns. These scores are used to generate an alert for the epidemiologist practitioner. Several variants are also proposed and compared. Results from the International Society for Disease Surveillance (ISDS) technical contest are given, evaluating this method on three syndromic series with representative outbreaks.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-239.pdf,Subjects: 1. Applications; 12. Machine Learning and Discovery
238,2008,Short Papers,Fast Spectral Learning using Lanczos Eigenspace Projections,Sridhar Mahadevan,"The core computational step in spectral learning — finding the projection of a function onto the eigenspace of a symmetric operator, such as a graph Laplacian — generally incurs a cubic computational complexity. This paper describes the use of Lanczos eigenspace projections for accelerating spectral projections, which reduces the complexity to quadratic in the number of distinct eigenvalues. This approach is based on diagonalizing the restriction of the operator to the Krylov space spanned by the operator and a projected function. Even further savings can be accrued by constructing an approximate Lanczos tridiagonal representation of the Krylov-space restricted operator. A key novelty of this paper is the use of Krylov-subspace modulated Lanczos acceleration for multi-resolution wavelet analysis. A challenging problem of learning to control a robot arm is used to test the proposed approach.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-240.pdf,Subjects: 12. Machine Learning and Discovery; 12.1 Reinforcement Learning
239,2008,Short Papers,Efficiently Exploiting Dependencies in Local Search for SAT,"Duc-Nghia Pham, John Thornton, Abdul Sattar","We propose a new local search platform that splits a CNF formula into three sub-components: i) a minimal dependency lattice (representing the core connections between logic gates), ii) a conjunction of equivalence clauses, and iii) the remaining clauses. We also adopt a new hierarchical cost function that focuses on solving the core components of the problem first. We then show experimentally that our platform not only significantly outperforms existing local search approaches but is also competitive with modern systematic solvers on highly structured problems.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-241.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
240,2008,Short Papers,Towards Synthesizing Optimal Coordination Modules for Distributed Agents,"Manh Tung Pham, Kiam Tian Seow","In a discrete-event framework, we define the concept of a coordinable language and show that it is the necessary and sufficient existence condition of coordination modules for distributed agents to achieve conformance to a given inter-agent constraint language. We also present a synthesis algorithm to compute near optimal coordination modules.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-242.pdf,Subjects: 7.1 Multi-Agent Systems; 9.3 Mathematical Foundations
241,2008,Short Papers,A New Clause Learning Scheme for Efficient Unsatisfiability Proofs,"Knot Pipatsrisawat, Adnan Darwiche","We formalize in this paper a key property of asserting clauses (the most common type of clauses learned by SAT solvers). We show that the formalized property, which is called empowerment, is not exclusive to asserting clauses, and introduce a new class of learned clauses which can also be empowering. We show empirically that (1) the new class of clauses tends to be much shorter and induce further backtracks than asserting clauses and (2) an empowering subset of this new class of clauses significantly improves the performance of the Rsat solver on unsatisfiable problems.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-243.pdf,Subjects: 15.2 Constraint Satisfaction; 3. Automated Reasoning
242,2008,Short Papers,Bayes-Relational Learning of Opponent Models from Incomplete Information in No-Limit Poker,"Marc Ponsen, Jan Ramon,Tom Croonenborghs,Kurt Driessens,Karl Tuyls","We propose an opponent modeling approach for No-Limit Texas Hold'em poker that starts from a (learned) prior, i.e., general expectations about opponent behavior and learns a relational regression tree-function that adapts these priors to specific opponents. An important asset is that this approach can learn from incomplete information (i.e. without knowing all players' hands in training games).",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-244.pdf,Subjects: 12. Machine Learning and Discovery; 7.1 Multi-Agent Systems
243,2008,Short Papers,Multi-HDP: A Non Parametric Bayesian Model for Tensor Factorization,"Ian Porteous, Evgeniy Bart, Max Welling","Matrix factorization algorithms are frequently used in the machine learning community to find low dimensional representations of data. We introduce a novel generative Bayesian probabilistic model for unsupervised matrix and tensor factorization. The model consists of several interacting LDA models, one for each modality. We describe an efficient collapsed Gibbs sampler for inference. We also derive the nonparametric form of the model where interacting LDA models are replaced with interacting HDP models. Experiments demonstrate that the model is useful for prediction of missing data with two or more modalities as well as learning the latent structure in the data.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-245.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
244,2008,Short Papers,Learning Grasp Strategies with Partial Shape Information,"Ashutosh Saxena, Lawson L.S. Wong, Andrew Y. Ng","We consider the problem of grasping novel objects in cluttered environments. If a full 3-d model of the scene were available, one could use the model to estimate the stability and robustness of different grasps (formalized as form/force-closure, etc); in practice, however, a robot facing a novel object will usually be able to perceive only the front (visible) faces of the object. In this paper, we propose an approach to grasping that estimates the stability of different grasps, given only noisy estimates of the shape of visible portions of an object, such as that obtained from a depth sensor. By combining this with a kinematic description of a robot arm and hand, our algorithm is able to compute a specific positioning of the robot's fingers so as to grasp an object. We test our algorithm on two robots (with very different arms/manipulators, including one with a multi-fingered hand). We report results on the task of grasping objects of significantly different shapes and appearances than ones in the training set, both in highly cluttered and in uncluttered environments. We also apply our algorithm to the problem of unloading items from a dishwasher.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-246.pdf,Subjects: 17. Robotics; 19.1 Perception
245,2008,Short Papers,Incremental Algorithms for Approximate Compilation,"Alberto Venturini, Gregory Provan","Compilation is an important approach to a range of inference problems, since it enables linear-time inference in the size S of the compiled representation. However, the main drawback is that S can be exponentially larger than the size of the original function. To address this issue, we propose an incremental, approximate compilation technique that guarantees a sound and space-bounded compilation for weighted boolean functions, at the expense of query completeness. In particular, our approach selectively compiles all solutions exceeding a particular threshold, given a range of weighting functions, without having to perform inference over the full solution-space. We describe incremental, approximate algorithms for the prime implicant and DNNF compilation languages, and provide empirical evidence that these algorithms enable space reductions of several orders-of-magnitude over the full compilation, while losing relatively little query completeness.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-247.pdf,Subjects: 11. Knowledge Representation; 1.5 Diagnosis
246,2008,Short Papers,Computing Reserve Prices and Identifying the Value Distribution in Real-World Auctions with Market Disruptions,"William E. Walsh, David C. Parkes, Tuomas Sandholm, Craig Boutilier","Single-good ascending auctions, including the English Auction and its close variants (e.g., eBay), are the most widely used type of auction. Effective strategies for buyers and sellers in these auctions can have an enormous economic impact. We present a system that, relying on minimal assumptions, computes reserve prices for real-world ascending auctions by inferring the value distribution from past auction data. Our contributions include improvements on previous methods for estimating the bidder value distribution, and novel Bayesian methods for adapting to disruptions in market conditions. We demonstrate the effectiveness of our system in both simulated auctions and in real Internet auctions that we conducted in the domain of selling off returned merchandise.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-248.pdf,Subjects: 7.1 Multi-Agent Systems; 1. Applications
247,2008,Short Papers,Multi-Label Dimensionality Reduction via Dependency Maximization,"Yin Zhang, Zhi-Hua Zhou","Multi-label learning deals with data associated with multiple labels simultaneously. Like other machine learning and data mining tasks, multi-label learning also suffers from the \textit{curse of dimensionality}. Although dimensionality reduction has been studied for many years, multi-label dimensionality reduction remains almost untouched. In this paper, we propose a multi-label dimensionality reduction method, MDDM, which attempts to project the original data into a lowerdimensional feature space maximizing the dependence between the original feature description and the associated class labels. Based on the Hilbert-Schmidt Independence Criterion, we derive a closed-form solution which enables the dimensionality reduction process to be efficient. Experiments validate the performance of MDDM.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-249.pdf,Subjects: 12. Machine Learning and Discovery; 12.2 Scientific Discovery
248,2008,Short Papers,Online Learning in Monkeys,"Xiaojin Zhu, Michael Coen, Shelley Prudom, Ricki Colman, Joseph Kemnitz","We examine online learning in the context of the Wisconsin Card Sorting Task (WCST), a task for which the concept acquisition strategies for human and other primates are well documented. We describe a new WCST experiment in rhesus monkeys, comparing the monkeys' behaviors to that of online learning algorithms. Our expectation is that insights gained from this work and future research can lead to improved artificial learning systems.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-250.pdf,Subjects: 4. Cognitive Modeling; 12. Machine Learning and Discovery
249,2008,Nectar Papers,Beyond Classical Planning: Procedural Control Knowledge and Preferences in State-of-the-Art Planners,"Jorge A. Baier, Christian Fritz, Sheila A. McIlraith","Real-world planning problems can require search over thousands of actions and may yield a multitude of plans of differing quality. To solve such real-world planning problems, we need to exploit domain control knowledge that will prune the search space to a manageable size. And to ensure that the plans we generate are of high quality, we need to guide search towards generating plans in accordance with user preferences. Unfortunately, most state-of-the-art planners cannot exploit control knowledge, and most of those that can exploit user preferences require those preferences to only talk about the final state. Here, we report on a body of work that extends classical planning to incorporate procedural control knowledge and rich, temporally extended user preferences into the specification of the planning problem. Then to address the ensuing nonclassical planning problem, we propose a broadly-applicable \emph{compilation technique} that enables a diversity of state-of-the-art planners to generate such plans without additional machinery. While our work is firmly rooted in AI planning it has broad applicability to a variety of computer science problems relating to dynamical systems.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-251.pdf,Subjects: 1.11 Planning; 11. Knowledge Representation
250,2008,Nectar Papers,Learning and Inference with Constraints,"Lev Ratinov, Ming-Wei Chang,Nicholas Rizzolo, Dan Roth","Probabilistic modeling has been a dominant approach in Machine Learning research. As the field evolves, the problems of interest become increasingly challenging and complex. Making complex decisions in real world problems often involves assigning values to sets of interdependent variables where the expressive dependency structure can influence, or even dictate, what assignments are possible. However, incorporating non-local dependencies in a probabilistic model can lead to intractable training and inference. This paper presents Constraints Conditional Models (CCMs), a framework that augments probabilistic models with declarative constraints as a way to support decisions in an expressive output space while maintaining modularity and tractability of training. We further show that declarative constraints can be used to take advantage of unlabeled data when training the probabilistic model.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-252.pdf,Subjects: 13. Natural Language Processing; Please choose a second document classification
251,2008,Nectar Papers,On-line Planning and Scheduling: An Application to Controlling Modular Printers,"Minh B. Do, Wheeler Ruml, Rong Zhou","This paper summarizes recent work reported at ICAPS on applying artificial intelligence techniques to the control of production printing equipment. Like many other real-world applications, such as mobile robotics, this complex domain requires real-time autonomous decision-making and robust continual operation. To our knowledge, this work represents the first successful industrial application of embedded domain-independent temporal planning. At the heart of our system is an on-line algorithm that combines techniques from state-space planning and partial-order scheduling. For example, our planning-graph-based planning heuristic takes resource contention into account when estimating makespan remaining. We suggest that this general architecture may prove useful as more intelligent systems operate in continual, on-line settings. Our system has enabled a new product architecture for our industrial partner and has been used to drive several commercial prototypes. When compared with state-of-the-art off-line planners, our system is hundreds of times faster and often finds better plans.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-253.pdf,Subjects: 1.11 Planning; 16. Real-Time Systems
252,2008,Nectar Papers,Intelligent Email: Aiding Users with AI,"Mark Dredze, Hanna M. Wallach, Danny Puller, Tova Brooks, Josh Carroll, Joshua Magarick, John Blitzer, Fernando Pereira","Email occupies a central role in the modern workplace. This has led to a vast increase in the number of email messages that users are expected to handle daily. Furthermore, email is no longer simply a tool for asynchronous online communication — email is now used for task management, personal archiving, as well both synchronous and asynchronous online communication. This explosion can lead to 'email overload' — many users are overwhelmed by the large quantity of information in their mailboxes. In the human--computer interaction community, there has been much research on tackling email overload. Recently, similar efforts have emerged in the artificial intelligence (AI) and machine learning communities to form an area of research known as intelligent email. In this paper, we take a user-oriented approach to applying AI to email. We identify enhancements to email user interfaces and employ machine learning techniques to support these changes. We focus on three tasks — summary keyword generation, reply prediction and attachment prediction — and summarize recent work in these areas.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-254.pdf,Subjects: 12. Machine Learning and Discovery; 6. Computer-Human Interaction
253,2008,Nectar Papers,Magic Sets for Data Integration,"Wolfgang Faber, Gianluigi Greco, Nicola Leone","We present a generalization of the Magic Sets technique to Datalog^not programs with (possibly unstratified) negation under the stable model semantics. The technique optimizes Datalog^not programs by means of a rewriting algorithm that preserves query equivalence, under the proviso that the original program is consistent. The approach is motivated by recently proposed methods for query answering in data integration and inconsistent databases, which use cautious reasoning over consistent Datalog^not programs under the stable model semantics. In order to prove the correctness of our Magic Sets transformation, we have introduced a novel notion of modularity for Datalog^not under the stable model semantics, which is more suitable for query answering than previous module definitions, and which is also relevant per se. A module under this definition guarantees independent evaluation of queries if the full program is consistent. Otherwise, it guarantees soundness under cautious and completeness under brave reasoning.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-255.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 11. Knowledge Representation
254,2008,Nectar Papers,Decision-Theoretic User Interface Generation,"Krzysztof Z. Gajos, Daniel S. Weld, Jacob O. Wobbrock","For decades, researchers have debated the pros and cons of adaptive user interfaces with enthusiastic AI practitioners often confronting skeptical HCI experts. This paper summarizes the SUPPLE project’s six years of work analyzing the characteristics of successful adaptive interfaces and developing efficient algorithms for their automatic generation. We conclude that personalized user interfaces, which are adapted to a person’s devices, tasks, preferences and abilities, can improve user satisfaction and performance. Further, we demonstrate that automatic generation of these interfaces is computationally feasible.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-256.pdf,Subjects: 6. Computer-Human Interaction; 6.3 User Interfaces
255,2008,Nectar Papers,Achieving Master Level Play in 9x9 Computer Go,"Sylvain Gelly, David Silver","The UCT algorithm uses Monte-Carlo simulation to estimate the value of states in a search tree from the current state. However, the first time a state is encountered, UCT has no knowledge, and is unable to generalise from previous experience. We describe two extensions that address these weaknesses. Our first algorithm, heuristic UCT, incorporates prior knowledge in the form of a value function. The value function can be learned offline, using a linear combination of a million binary features, with weights trained by temporal-difference learning. Our second algorithm, UCT-RAVE, forms a rapid online generalisation based on the value of moves. We applied our algorithms to the domain of 9x9 Computer Go, using the program MoGo. Using both heuristic UCT and RAVE, MoGo became the first program to achieve human master level in competitive play.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-257.pdf,Subjects: 1.8 Game Playing; 15.7 Search
256,2008,Nectar Papers,Abduction with Bounded Treewidth: From Theoretical Tractability to Practically Efficient Computation,"Georg Gottlob, Reinhard Pichler, Fang Wei","Abductive diagnosis is an important method to identify explanations for a given set of observations. Unfortunately, most of the algorithmic problems in this area are intractable. We have recently shown that these problems become tractable if the underlying clausal theory has bounded treewidth. However, turning these theoretical tractability results into practically efficient algorithms turned out to be very problematical. In (Gottlog, Pichler, Wei 2007), we have established a new method based on monadic datalog which remedies this unsatisfactory situation. Specifically, we designed an efficient algorithm for a strongly related problem in the database area. In the current paper, we show that these favorable results can be carried over to logic-based abduction.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-258.pdf,Subjects: 9.2 Computational Complexity; 1.7 Expert Systems
257,2008,Nectar Papers,Explicit-State Abstraction: A New Method for Generating Heuristic Functions,"Malte Helmert, Patrik Haslum, Jörg Hoffmann","Many AI problems can be recast as finding an optimal path in a discrete state space. An abstraction defines an admissible heuristic function as the distances in a smaller state space where arbitrary sets of states are ""aggregated"" into single states. A special case are pattern database (PDB) heuristics, which aggregate states iff they agree on the state variables inside the pattern. Explicit-state abstraction is more flexible, explicitly aggregating selected pairs of states in a process that interleaves composition of abstractions with abstraction of the composites. The increased flexibility gains expressive power: sometimes, the real cost function can be represented concisely as an explicit-state abstraction, but not as a PDB. Explicit-state abstraction has been applied to planning and model checking, with highly promising empirical results.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-259.pdf,Subjects: 15.7 Search; 1.11 Planning
258,2008,Nectar Papers,Video Activity Recognition in the Real World,"Anthony Hoogs, A. G. Amitha Perera","With recent advances in motion detection and tracking in video, more efforts are being directed at higher-level video analysis such as recognizing actions, events and activities. One of the more challenging problems is recognizing activities that involve multiple people and/or vehicles, whose relationships change over time, when motion detection and tracking are unreliable, as commonly occurs in busy scenes. We describe an approach to this problem based on Dynamic Bayesian Networks, and show how DBNs can be extended to compensate for track failures. We also show that defining DBNs with semantic concepts improves robustness vs. direct observables, and discuss implications and ideas for incorporating semantic, symbolic knowledge into the perceptual domain of activity recognition.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-260.pdf,Subjects: 3.6 Temporal Reasoning; 19. Vision
259,2008,Nectar Papers,An Analysis of Transformational Analogy: General Framework and Complexity,"Vithal Kuchibatla , Hector Munoz-Avila","We present TransUCP, a formalism for Transformational Analogy in the context of classical domain-independent planning. TransUCP defines precisely possible plan modification operations for Transformational Analogy and covers a wide range of existing implementations. We use TransUCP to analyze the implications for Transformational Analogy of well-known results about the complexity of general plan adaptation.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-261.pdf,Subjects: 3.1 Case-Based Reasoning; 1.11 Planning
260,2008,Nectar Papers,Efficient Algorithms to Solve Bayesian Stackelberg Games for Security Applications,"Praveen Paruchuri, Jonathan P.Pearce, Janusz Marecki, Milind Tambe, Fernando Ordonez, Sarit Kraus",In a class of games known as Stackelberg games‚ one agent (the leader) must commit to a strategy that can be observed by the other agent (the adversary⁄follower) before the adversary chooses its own strategy. We consider Bayesian Stackelberg games‚ in which the leader is uncertain about the type of the adversary it may face. Such games are important in security domains‚ where‚ for example‚ a security agent (leader) must commit to a strategy of patrolling certain areas‚ and an adversary (follower) can observe this strategy over time before choosing where to attack. We present here two different MIP-formulations‚ ASAP (providing approximate policies with controlled randomization) and DOBSS (providing optimal policies) for Bayesian Stackelberg games. DOBSS is currently the fastest optimal procedure for Bayesian Stackelberg games and is in use by police at the Los Angeles International Airport(LAX) to schedule their activities.,https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-262.pdf,Subjects: 7.1 Multi-Agent Systems; 1. Applications
261,2008,Nectar Papers,Examining Difficulties Software Developers Encounter in the Adoption of Statistical Machine Learning,"Kayur Patel, James Fogarty, James A. Landay, Beverly Harrison","Statistical machine learning continues to show promise as a tool for addressing complex problems in a variety of domains. An increasing number of developers are therefore looking to use statistical machine learning algorithms within applications. We have conducted two initial studies examining the difficulties that developers encounter when creating a statistical machine learning component of a larger application. We first interviewed researchers with experience integrating statistical machine learning into applications. We then sought to directly observe and quantify some of the behavior described in our interviews using a laboratory study of developers attempting to build a simple application that uses statistical machine learning. This paper presents the difficulties we observed in our studies, discusses current challenges to developer adoption of statistical machine learning, and proposes potential approaches to better supporting developers creating statistical machine learning components of applications.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-263.pdf,Subjects: 6. Computer-Human Interaction; Please choose a second document classification
262,2008,Nectar Papers,Decompositions of Grammar Constraints,"Claude-Guy Quimper, Toby Walsh","A wide range of constraints can be compactly specified using automata or formal languages. In a sequence of recent papers, we have shown that an effective means to reason with such specifications is to decompose them into primitive constraints. We can then, for instance, use state of the art SAT solvers and profit from their advanced features like fast unit propagation, clause learning, and conflict-based search heuristics. This approach holds promise for solving combinatorial problems in scheduling, rostering, and configuration, as well as problems in more diverse areas like bioinformatics, software testing and natural language processing. In addition, decomposition may be an effective method to propagate other global constraints.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-264.pdf,Subjects: 15.2 Constraint Satisfaction; 11. Knowledge Representation
263,2008,Nectar Papers,Make3D: Depth Perception from a Single Still Image,"Ashutosh Saxena, Min Sun, Andrew Y. Ng","Humans have an amazing ability to perceive depth from a single still image; however, it remains a challenging problem for current computer vision systems. In this paper, we will present algorithms for estimating depth from a single still image. There are numerous monocular cues—such as texture variations and gradients, defocus, color/haze, etc.—that can be used for depth perception. Taking a supervised learning approach to this problem, in which we begin by collecting a training set of single images and their corresponding ground-truth depths, we learn the mapping from image features to the depths. We then apply these ideas to create 3-d models that are visually-pleasing as well as quantitatively accurate from individual images. We also discuss applications of our depth perception algorithm in robotic navigation, in improving the performance of stereovision, and in creating large-scale 3-d models given only a small number of images.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-265.pdf,Subjects: 19. Vision; 12. Machine Learning and Discovery
264,2008,Nectar Papers,Using Signals of Human Interest to Enhance Single-document Summarization,"Krysta M. Svore, Lucy Vanderwende, Christopher J.C. Burges","As the amount of information on the Web grows, the ability to retrieve relevant information quickly and easily is necessary. The combination of ample news sources on the Web, little time to browse news, and smaller mobile devices motivates the development of automatic highlight extraction from single news articles. Our system, NetSum, is the first system to produce highlights of an article and significantly outperform the baseline. Our approach uses novel information sources to exploit human interest for highlight extraction. In this paper, we briefly describe the novelties of NetSum, originally presented at EMNLP 2007, and embed our work in the AI context.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-266.pdf,Subjects: 13. Natural Language Processing; 14. Neural Networks
265,2008,Nectar Papers,Adaptive Management of Air Traffic Flow: A Multiagent Coordination Approach,"Kagan Tumer, Adrian Agogino","This paper summarizes recent advances in the application of multiagent coordination algorithms to air traffic flow management. Indeed, air traffic flow management is one of the fundamental challenges facing the Federal Aviation Administration (FAA) today. This problem is particularly complex as it requires the integration and/or coordination of many factors including: new data (e.g., changing weather info), potentially conflicting priorities (e.g., different airlines), limited resources (e.g., air traffic controllers) and very heavy traffic volume (e.g., over 40,000 flights over the US airspace). The multiagent approach assigns an agent to a navigational fix (a specific location in 2D space) and uses three separate actions to control the airspace: setting the separation between airplanes, setting ground holds that delay aircraft departures and rerouting aircraft. Agents then use reinforcement learning to learn the best set of actions. Results based on FACET (a commercial simulator) show that agents receiving personalized rewards reduce congestion by up to 80% over agents receiving a global reward and by up to 85% over a current industry approach (Monte Carlo estimation). These results show that with proper selection of agents, their actions and their reward structures, multiagent coordination algorithms can be successfully applied to complex real world domains.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-267.pdf,Subjects: 7.1 Multi-Agent Systems; 1. Applications
266,2008,Nectar Papers,Breaking Value Symmetry,Toby Walsh,"Symmetry is an important factor in solving many constraint satisfaction problems. One common type of symmetry is when we have symmetric values. In a recent series of papers, we have studied methods to break value symmetries . Our results identify computational limits on eliminating value symmetry. For instance, we prove that pruning all symmetric values is NP-hard in general. Nevertheless, experiments show that much value symmetry can be broken in practice. These results may be useful to researchers in planning, scheduling and other areas as value symmetry occurs in many different domains.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-268.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
267,2008,Senior Member Papers,An Interaction-Based Approach to Computational Epidemiology,"Christopher L. Barrett, Stephen Eubank and Madhav V. Marathe","We describe Simdemics: an interaction-based multi-agent approach to support epidemic planning for large urban regions. Simdemics is an example of a disaggregated modeling approach in which interactions between every pair of individuals is represented. It is based on the idea that a better understanding of the characteristics of the social contact network can give better insights into disease dynamics and intervention strategies for epidemic planning. It details the demographic and geographic distributions of disease and provides decision makers with information about (1) the consequences of a biological attack or natural outbreak, (2) the resulting demand for health services, and (3) the feasibility and effectiveness of response options. A unique feature of Simdemics is the size and scale of urban regions that can be analyzed using it. We can currently study realstic urban regions comprising 10-100 million individuals.  Simdemics is being developed over last 12 years. It was used in a number of user defined studies, including recent pandemic planning studies undertaken for DHS, DoD and DHHS. For e.g. at the request of federal agencies involved in preparing for an influenza pandemic, during Simdemics as a part of NIH funded MIDAS group analyzed combinations of strategies for responding to influenza. Results of the MIDAS analyses were reviewed in a Letter Report by the Institute of Medicine, Modeling Community Containment for Pandemic Influenza.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-269.pdf,Subjects: 1. Applications; 7.1 Multi-Agent Systems
268,2008,Senior Member Papers,What Is Answer Set Programming?,Vladimir Lifschitz,"Answer set programming (ASP) is a form of declarative programming oriented towards difficult search problems. As an outgrowth of research on the use of nonmonotonic reasoning in knowledge representation, it is particularly useful in knowledge-intensive applications. ASP programs consist of rules that look like Prolog rules, but the computational mechanisms used in ASP are different: they are based on the ideas that have led to the creation of fast satisfiability solvers for propositional logic.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-270.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
269,2008,Senior Member Papers,Learning to Connect Language and Perception,Raymond J. Mooney,"To truly understand language, an intelligent system must be able to connect words, phrases, and sentences to its perception of objects and events in the world. Current natural language processing and computer vision systems make extensive use of machine learning to acquire the probabilistic knowledge needed to comprehend linguistic and visual input. However, to date, there has been relatively little work on learning the relationships between the two modalities. In this talk, I will review some of the existing work on learning to connect language and perception, discuss important directions for future research in this area, and argue that the time is now ripe to make a concerted effort to address this important, integrative AI problem.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-271.pdf,Subjects: 13. Natural Language Processing; 19.1 Perception
270,2008,Senior Member Papers,Artificial Intelligence Needs Open-Access Knowledgebase Contents,Erik Sandewall,"A substantial knowledgebase is an important part of many A.I. applications as well as (arguably) in any system that is claimed to implement broad-range intelligence. Although this has been an accepted view in our field since very long, little progress has been made towards the establishment of large and sharable knowledgebases. Both basic research projects and applications projects have found it necessary to  construct special-purpose knowledgebases for their respective needs. This is obviously a problem: it would save work and speed up progress if the construction of a broadly sharable and broadly useful knowledgebase could be a joint undertaking for the field.   In this article I wish to discuss the possibilities and the obstacles  in this respect. I shall argue that the field of Knowledge Representation needs to adopt a new and very different paradigm in order for progress to be made, so that besides working as usual on logical  foundations and on algorithms, we should also devote substantial efforts to the systematic preparation of knowledgebase contents.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-272.pdf,Subjects: 10. Knowledge Acquisition; 8. Enabling Technologies
271,2008,Senior Member Papers,Game Theory Pragmatics: A Challenge for AI,Yoav Shoham,"Game theory has been playing an increasingly visible role in computer science in general and AI in particular, most notably in the area of multiagent systems. I briefly list the areas where most of the action has been in the past decade or so. I then suggest that going forward, the most dramatic interaction between computer science and game theory—with a special role for AI—could be around what might be called game theory pragmatics.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-273.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
272,2008,Senior Member Papers,Intelligence inWikipedia,"Daniel S. Weld, Fei Wu, Eytan Adar, Saleema Amershi,James Fogarty, Raphael Hoffmann, Kayur Patel, Michael Skinner","The Intelligence in Wikipedia project at the University of Washington is combining self-supervised information extraction (IE) techniques with a mixed initiative interface designed to encourage communal content creation (CCC). Since IE and CCC are each powerful ways to produce large amounts of structured information, they have been studied extensively — but only in isolation. By combining the two methods in a virtuous feedback cycle, we aim for substantial synergy. While previous papers have described the details of individual aspects of our endeavor, this report provides an overview of the project’s progress and vision.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-274.pdf,Subjects: 10. Knowledge Acquisition; 6. Computer-Human Interaction
273,2008,Student Abstracts,Using Reasoning Patterns to Simplify Games,"Dimitrios Antos, Avi Pfeffer","In complex strategic situations decision-making agents interact with many other agents and have access to many pieces of information throughout their play. This usually leads to game solving being a very complex, almost intractable procedure. Moreover, algorithms for solving games usually fail to explain how the various equilibria come about and how ``plausible"" they are. Reasoning patterns try to capture the strategic thinking of agents and formalize the usage of the various information or evidence they obtain during their interactions. Identifying reasoning patterns can lead to a significant refinement over the full range of equilibria, as well as considerable computational savings in solving the game. Here we present a polynomial-time algorithm that simplifies the original game by iteratively identifying non-effective (ignorable) decision nodes and removing redundant information edges. In some cases, this can lead to exponential-time savings in computing an equilibrium, yet some -potentially efficient- equilibria may be lost in the process.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-275.pdf,Subjects: 3.4 Probabilistic Reasoning; 15.5 Decision Theory
274,2008,Student Abstracts,Lexical and Grammatical Inference,"Tom Armstrong, Tim Oates","Children are facile at both discovering word boundaries and using those words to build higher-level structures in tandem. Current research treats lexical acquisition and grammar induction as two distinct tasks; doing so has led to unreasonable assumptions. State-of-the-art unsupervised results presuppose a perfectly segmented, noise-free lexicon, while largely ignoring how the lexicon is used. This paper combines both tasks in a novel framework for bootstrapping lexical acquisition and grammar induction.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-276.pdf,Subjects: 13.3 Syntax; 12. Machine Learning and Discovery
275,2008,Student Abstracts,The Benefits of an Ontological Patient Model in Clinical Decision-Support,"Mark Austin, Matthew Kelly, Mike Brady","In this paper we discuss an application integrating an ontological data model with an argumentation-based decisionsupport system, showing how the combination of leading technologies OWL, SPARQL and Jena can be used to achieve this. In the context of improving a decision support tool that is currently being trialled live in a clinical environment, we describe quantitatively how the incorporation of an ontology leads to an improvement over the existing software, highlighting the benefits of incorporating an ontology in medical applications. Data and clinical feedback is being collected from a live trial at the John Radcliffe hospital in Oxford, where we are able to test the original decision support tool, but also the ontology driven version, and thus will be able to demonstrate that any quantitative improvements in the efficacy of the software are a product of the ontological data model alone.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-277.pdf,Subjects: 1.7 Expert Systems; 11.2 Ontologies
276,2008,Student Abstracts,Using Clustering Methods for Discovering Event Structures,"Cosmin A Bejan, Sanda Harabagiu","In the process of understanding specific situations, domain experts manually build event models that provide the infrastructure for reasoning with events and for simulating event scenarios. Such kind of models are also encoded in document collections in which each document is represented as a sequence of events. When describing situations in texts, events do not operate independently, but rather they are inter-related with other events from the same scenario. For example, in a crime scenario, a person is accused of a crime, then that person is arrested and interrogated after which a trial is held. We define an event structure as a collection of events that interact with each other in a specific situation. Extracting event structures from texts allows us to perform various forms of inference over events. For example, given an event e from an event structure, we can determine which events are likely to happen after e happened. Another example is to compute the probability that an event e from an event structure s is likely to happen given the fact that a set of events from s and disjoint from e already happened in a text t. In this specific example, the event e is not required to be present in t. In general, if we know what events interact with each other in an event structure, we can build more complex inference models dealing with causality, intentionality or temporality of events.  Our goal is to provide a method that automatically extracts event structures from texts. In order to build event structures we need (1) to determine the set of events that belong to the same event structure and (2) to establish what relations exist between the events from the same structure. In this abstract, we describe the theoretical frameworks for solving both tasks, but we detail more the first task for which we also show our preliminary results.  The motivation of this work is in the same spirit with the work performed for solving Topic Detection and Tracking tasks (Allan 2002). However, instead of considering clusters as topically related bag of words like in a classic topic modeling approach, our goal is to build structured event representations and to interpret the event interactions that exist in these representations.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-278.pdf,Subjects: 13. Natural Language Processing; 13.1 Discourse
277,2008,Student Abstracts,Distributed Reasoning with Conflicts in a Multi-Context Framework,"Antonis Bikakis, Grigoris Antoniou","A Multi-Context System consists of a set of contexts and a set of inference rules (known as mapping or bridge rules) that enable information flow between different contexts. A context can be thought as a logical theory - a set of axioms and inference rules - that models local context knowledge. Different contexts are expected to use different languages and inference systems, and although each context may be locally consistent, global onsistency cannot be required or guaranteed. Reasoning with multiple contexts requires performing two types of reasoning; (a) ocal reasoning, based on the individual context theories; and (b) distributed reasoning, which combines the consequences of local theories using the mappings. The most critical challenges of ontextual reasoning are; (a) the heterogeneity of local context theories; and (b) the potential conflicts that may arise from the interaction of different contexts through the mappings. Our study mainly focuses on the second issue, by modeling the different contexts as peers in a P2P system, and performing some type of defeasible reasoning on the distributed peer theories.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-279.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 11. Knowledge Representation
278,2008,Student Abstracts,Conformant Planning Heuristics Based on Plan Reuse in Belief States,"Cai Dunbo, Jigui Sun, Minghao Yin","Conformant planning involves generating plans under the condition that the initial situation and action effects are undeterministic and sensing is unavailable during plan execution. Bonet and Geffner has shown that conformant planning can be transformed into a search problem in the space of belief states. Since then, heuristic based conformant planning has become a promising approach. Following the direction, some effective heuristics, such as those introduced in MBP, Conformant-FF and POND, were proposed. An additive heuristic that obtains the heuristic value of a given belief state by summing the heuristic value of each world state is sensitive to the progress of the search procedure and often guides a search algorithm efficiently. However, it suffers from the problem of overestimating the distances-to-goal of belief states and therefore leads to overlong plans generally. One of the reasons is that the additive heuristic does not take into account relationships between different world states in a belief state. For example, an action sequence for one world state may have progressive effects on others. In this work, we use plan reuse information to make the additive heuristic more reasonable. The information is discovered with the aid of a classical planning heuristic function and in a real time learning style. The resulted heuristic is tested on a conformant planning system that is implemented as an extension of the classical planner Fast Downward to the conformant setting. Preliminary results show that our heuristic is promising in getting better plans on tasks where plan reuse possibilities exist.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-280.pdf,Subjects: 1.11 Planning; 15. Problem Solving
279,2008,Student Abstracts,Personalized Reasoner Based on Belief Strengths of Information Sources,"Shu-Bin Cai, MING Zhong, LI Shi-Xian","BLDL is proposed by combining DL with annotated logic. The personalized reasoner, BLDL reasoner can produce different answers to the same satisfiability problem asked by different questioners in a practical time cost, by annotated formulas with different belief strengths, which are calculated from the semantic distance between information providers and questioners.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-281.pdf,Subjects: 11.1 Description Logics; 3. Automated Reasoning
280,2008,Student Abstracts,A neuro-fuzzy strategy for Web Personalization,"Giovanna Castellano, A.M. Fanelli, P. Plantamura, M.A. Torsello","In this paper, we propose the use of a neuro-fuzzy strategy to develop a Web personalization framework for the dynamic suggestion of URLs retained interesting for the currently connected users. In particular, a hybrid strategy exploiting the combination of the fuzzy logic with the neural paradigm is proposed in order to discover useful knowledge from session data identified from the analysis of log files and represent it in a set of fuzzy rules expressed in an interpretable form.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-282.pdf,Subjects: 14. Neural Networks; 10. Knowledge Acquisition
281,2008,Student Abstracts,Sketch Recognition based on Manifold Learning,"Heeyoul Choi, Tracy Hammond","Current feature-based methods for sketch recognition systems rely on human-selected features. Certain machine learning techniques have been found to be good nonlinear features extractors. In this paper, we apply a manifold learning method, kernel Isomap, with a new algorithm for multi-stroke sketch recognition, which significantly outperforms the standard feature-based techniques.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-283.pdf,Subjects: 6.3 User Interfaces; 12. Machine Learning and Discovery
282,2008,Student Abstracts,GLADDER: Combining Gesture and Geometric Sketch Recognition,"Paul Corey, Tracy Hammond","Sketch recognition systems usually recognize strokes either as stylistic gestures or geometric shapes. Both techniques have their advantages. This paper presents a method for integrating gesture-based and geometric recognition techniques, significantly outperforming either technique on its own.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-284.pdf,Subjects: 6. Computer-Human Interaction; 6.3 User Interfaces
283,2008,Student Abstracts,Distinguishing Between Sketched Scribble Look-Alikes,"Katie Dahmen, Tracy Hammond","In hand sketched drawings, nearly identical strokes may have different meanings to a user. For instance, a scribble could signify either that a shape should be filled in or that it should be deleted. This work describes a method for determining user intention in drawing scribbles in the context of a pen based computer sketch. Our study shows that given two strokes, a circle and a scribble, two features (bounding ratio and density) can quickly and effectively determine a user's intention.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-285.pdf,Subjects: 6. Computer-Human Interaction; 6.3 User Interfaces
284,2008,Student Abstracts,Perpetual Learning for Non-Cooperative Multiple Agents,Luke Dickens,"This paper examines, by argument, the dynamics of sequences of behavioural choices made, when non-cooperative restricted-memory agents learn in partially observable stochastic games. These sequences of combined agent strategies (joint-policies) can be thought of as a walk through the space of all possible joint-policies. We argue that this walk, while containing random elements, is also driven by each agent's drive to improve their current situation at each point, and posit a learning pressure field across policy space to represent this drive. Different learning choices may skew this learning pressure, and affect the simultaneous joint learning of multiple agents.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-286.pdf,Subjects: 12. Machine Learning and Discovery; 7.1 Multi-Agent Systems
285,2008,Student Abstracts,User Identification by Means of Sketched Stroke Features,"Brian D. Eoff, Tracy Hammond","We present preliminary results of using physical features of a user's sketching style, such as pen tilt and pressure, to identify a user from their sketched strokes.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-287.pdf,Subjects: 6. Computer-Human Interaction; 6.3 User Interfaces
286,2008,Student Abstracts,Unsupervised Categorization (Filtering) of Google Images Based on Visual Consistency,"Pooyan Fazli, Ara Bedrosian","The objective of this paper is to study the existing methods for unsupervised object recognition and image categorization and propose a model that can learn directly from the output of image search engines, e.g. Google Images, bypassing the need to manually collect large quantities of training data. This model can then be used to refine the quality of the image search, or to search through other sources of images. This integrated scheme has been implemented and optimized to be used in The Semantic Robot Vision Challenge as a new test-bed for research in the areas of image understanding and knowledge retrieval in large unstructured image databases.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-288.pdf,Subjects: 19. Vision; 17. Robotics
287,2008,Student Abstracts,Existentially Quantified Values for Queries and Updates of Facts in Transaction Logic Programs,"Paul Fodor, Existentially Quantified Values for Queries and Updates of Facts in Transaction Logic Programs","In several applications of logic programming and Transaction Logic, such as, planning, trust management and independent Semantic Web Services, an action might produce incomplete facts and leave existential values in an incrementally generated data structure. The same action or other producer or consumer actions might read, modify or communicate through these facts, making this technique a powerful communication technique. In this poster, we present a definite semantics for these existentially quantified values that occur only in facts, queries and updates of facts. Although this simple semantics applies only to facts and not to clauses, it is relevant to many applications, including artificial intelligence planning, workflow modeling and verification, and updates of facts in the Semantic Web.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-289.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 9.3 Mathematical Foundations
288,2008,Student Abstracts,Querying Sequential and Concurrent Horn Transaction Logic Programs using Tabling Techniques,Paul Fodor,"In this poster we describe the tabling techniques for Sequential and Concurrent Horn Transaction Logic. Horn Transaction Logic is an extension of classical logic programming with state updates and it has a SLD-style evaluation algorithm. This SLD-style algorithm enters into infinite loops when computing answers to many recursive programs when they change the underlying state of the knowledge base. We solve this problem by tabling (caching) the calls, call states and answers (unifications and return states) in a searchable structure for the Sequential Transaction Logic, or building a graph for the query and memoize the ""hot"" vertices (vertices, currently, possible to execute) for the Propositional Concurrent Transaction Logic, so that the same call is not re-executed ad infinum. With these techniques, we can efficiently compute queries to transaction logic programs, and when the underlying programs have the bounded term-depth property (Transaction Datalog) the techniques are guaranteed to terminate. The applications of these techniques promise termination and great improvements in the uses of transaction logic: state-changing systems, artificial intelligence planning, dynamic constraints on transaction execution, workflow modeling and verification, and systems involving financial transactions.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-290.pdf,Subjects: 9.3 Mathematical Foundations; 1.11 Planning
289,2008,Student Abstracts,Predicting Appropriate Semantic Web Terms from Words,"Lushan Han, Tim Finin","The Semantic Web language RDF was designed to unambiguously define and use ontologies to encode data and knowledge on the Web. Many people find it difficult, however, to write complex RDF statements and queries because doing so requires familiarity with the appropriate ontologies and the terms they define. We describe a system that suggests appropriate RDF terms given semantically related English words and general domain and context information. We use the Swoogle Semantic Web search engine to provide RDF term and namespace statistics, the WorldNet lexical ontology to find semantically related words, and a naive Bayes classifier to suggest terms. A customized graph data structure of related namespaces is constructed from Swoogle's database to speed up the classifier model learning and prediction time.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-291.pdf,Subjects: 11. Knowledge Representation; 12. Machine Learning and Discovery
290,2008,Student Abstracts,Improving a Plan Library for Real-time Systems Using Nearly Orthogonal Latin Hypercube Sampling,Robert Holder,"Computing solutions to intractable planning problems is particularly problematic within real-time domains. One approach to this challenge includes off-line computation, such as precomputing a plan library. However, because complex domains preclude creating a comprehensive library, a system must choose a subset of all possible plans to include in the library. Strategic selections will reduce the probability that a system encounters a situation for which it does not have an appropriate plan in the library to either apply directly or adapt. Choosing variable values using Latin hypercubes is a technique used to reduce the number of test cases required in order to validate complex systems. Here we discuss the application of a variation of this technique, nearly orthogonal Latin hypercubes, to planning spaces in order reduce the number of plans a system must cache in its library.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-292.pdf,Subjects: 1.11 Planning; 16. Real-Time Systems
291,2008,Student Abstracts,Text Beautifier: An Affective-Text Tool to Tailor Written Text,"Fahim Kawsar, Mostafa Al Masum Shaikh, Ishizuka Mitsuru","We have spelling and grammar checking tools available on today’s word processors. But what they are missing is a tool that can recommend several possibilities of a given written sentence to assist a user to write better sentences. There-fore, we aim to develop a linguistic tool to beautify text by applying our developed lexical resources regarding textual affect sensing. The developed tool will allow a user to beau-tify an input sentence in terms of tuning it on different scales like valence, affect, prospect, and praise. For example using such a tool one may get the recommendations like, “Your lovely email makes me very glad”, or “I become glad to read your email”, or “I am very happy to obtain your nice email” for the input sentence “I am happy to receive your email” after scaling up the input sentence on affective, or prospective, or valence scale respectively. Such tool will be especially helpful to the non-native English speakers to write better English.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-293.pdf,Subjects: 13. Natural Language Processing; 5. Common Sense Reasoning
292,2008,Student Abstracts,A Self-organizing Multi-agent System for Adaptive Continuous Unsupervised Learning in Complex Uncertain Environments,"Igor Kiselev, Reda Alhajj","In order to be effective in solving time-critical problems in complex dynamic environments with higher levels of uncertainty, an intelligent system must continuously adapt parameters of its learning system to variations in the incoming signals generated by the non-stationary environment in a real-time fashion. The task of continuous online unsupervised learning of streaming data in complex dynamic environments under conditions of uncertainty requires the maximizing (or minimizing) of a certain similarity-based objective function defining an optimal segmentation of the input data set into clusters, which is an NP-hard optimization problem in a general metric space and is computationally intractable for real-world problems of practical interest. This paper describes the developed adaptive multi-agent approach to continuous online clustering of streaming data, which is originally sensitive to environmental variations and provides a fast dynamic response with event-driven incremental improvement of optimization results, trading-off operating time and result quality. Our two main contributions include a computationally efficient market-based algorithm of continuous agglomerative hierarchical clustering of streaming data and a knowledge-based self-organizing multi-agent system for implementing it. Experimental results demonstrate the strong performance of the implemented multi-agent learning system for continuous online clustering of both synthetic datasets and datasets from the RoboCup Soccer and Rescue domains. Further research on extending the adaptive learning approach to support online semi-supervised classification by continuously deducing semantic-based classification rules from clustering results and performing automatic rule-based classification at run-time is outlined.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-294.pdf,Subjects: 7.1 Multi-Agent Systems; 12. Machine Learning and Discovery
293,2008,Student Abstracts,Loop Calculus for Satisfiability,"Lukas Kroc, Michael Chertkov","Loop Calculus is a new technique to incrementally improve approximations computed by Loopy Belief Propagation (LBP), with the ability to eventually make them exact. In this extended abstract, we give a brief overview of this technique, and show its relevance to the AI community. We consider the problem of Boolean Satisfiability (SAT) and use LBP with Loop Calculus corrections to perform probabilistic inference about the problem. In this preliminary work, we focus on identifying the main issues encountered when applying Loop Calculus, and include initial empirical results in the SAT domain.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-295.pdf,Subjects: 3.4 Probabilistic Reasoning; 15.2 Constraint Satisfaction
294,2008,Student Abstracts,Constrained Classification on Structured Data,"Chi-Hoon Lee, Matthew Brown, Russell Greiner, ShoajunWang, Albert Murtha","Most standard learning algorithms, such as Logistic Regression (LR) and the Support Vector Machine (SVM), are designed to deal with i.i.d. (independent and identically distributed) data. They therefore do not work effectively for tasks that involve non-i.i.d. data, such as ""region segmentation"". (Eg, the ""tumor vs non-tumor"" labels in a medical image are correlated, in that adjacent pixels typically have the same label.) This has motivated the work in random fields, which has produced classifiers for such non-i.i.d. data that are significantly better than standard i.i.d.-based classifiers. However, these random field methods are often too slow to be trained for the tasks they were designed to solve. This paper presents a novel variant, Pseudo Conditional Random Fields (PCRFs), that is also based on i.i.d. learners, to allow efficient training but also incorporates correlations, like random fields. We demonstrate that this system is as accurate as other random fields variants, but significantly faster to train.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-296.pdf,Subjects: 12. Machine Learning and Discovery; 19. Vision
295,2008,Student Abstracts,Chatting Activity Recognition in Social Occasions Using Factorial Conditional Random Fields with Iterative Classification,"Chia-chun Lian, Jane Yung-jen Hsu","Recognizing chatting activities occurring in social occasions plays an important role of building human social network. Among the various types of social interactions, chatting with others is a significant indicator. However, the main challenge of chatting activity recognition in public occasions is the existence of multiple people involved in multiple activities. That is, several conversations may take place concurrently, such that different combinations of multi-activity states will impact the final observations, causing a lot of confusion for the recognition of multiple chatting activities. To address this problem, we advocate using Factorial Conditional Random Fields (FCRFs) model to accommodate co-temporal relationships between multi-activity states. In addition, to avoid the use of inefficient Loopy Belief Propagation (LBP) algorithm, we propose using Iterative Classification Algorithm (ICA) as inference method to help accelerate learning and inferring process. We designed experiments to compare our FCRFs model with Linear Chain Condition Random Fields (LCRFs) in learning and performing inference with the 3-hour audio streams data set collected by 4 participants. The experimental results show that FCRFs models outperform the LCRFs model in the presence of multiple concurrent chatting activities, and the FCRFs model using ICA inference approach takes much less time to do learning process than LBP method.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-297.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
296,2008,Student Abstracts,Discover Relevant Environment Feature Using Concurrent Reinforcement Learning,"Zhihui Luo, David Bell, Barry McCollum","When a robot observes its environment, there are two im-portant characteristics of the perceived information. One is the relevance of information and the other is redundancy. The irrelevant and redundant features which commonly exist within an environment, commonly leads to state ex-plosion and associated high computational cost within the robot’s learning process. 	We present a method concerning the relevance of infor-mation in order to improve the learning of a reinforcement learning robot. We introduce a new concurrent online learning algorithm to calculate the contribution C(s) and relevance degree I(s) to quantify the relevancy of features with respect to a desired learning task. Our analysis shows that the correlation relationship of the environment features can be extracted and projected to concurrent learning threads. By comparing the contribution of these learning threads, we can evaluate the relevance degree of a feature when performing a particular learning task. 	We demonstrate the method on the chase object domain. Our validation results show that, using the concurrent learning method, we can efficiently detect relevant features from the environment on sequential tasks, and therefore improve the learning speed.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-298.pdf,Subjects: 12.1 Reinforcement Learning; 17. Robotics
297,2008,Student Abstracts,2-Dimensional Cellular Automata Approach for Robot Grid Formations,"Ross Mead, Jerry B. Weinberg","One potentially cost-effective approach to harvesting solar power from space is the use of thousands of individual robots moving in formation, each with a piece of solar panel attached, to form a solar panel array. In previous work, we demonstrated an algorithm that treats a group of robots as a 1-dimensional cellular automaton, which is able to establish formations defined by a single mathematical function. We now extend the algorithm to establish grid formations.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-299.pdf,Subjects: 17. Robotics; 15.4 Reactive Control
298,2008,Student Abstracts,Hierarchical Voting Experts: An Unsupervised Algorithm for Segmenting Hierarchically Structured Sequences,"Matthew Miller, Alexander Stoytchev","This paper extends the Voting Experts (VE) algorithm to segment hierarchically structured sequences. The original algorithm was tested on text segmentation, and made use of two proposed characteristics of chunks, namely low internal entropy and high boundary entropy of segments. VE looks for these two properties, and uses them to segment sequences of tokens. It is surprisingly powerful given its simplicity, suggesting that the principle of segmenting based on low internal entropy and high boundary entropy is promising. Real world data often exhibits an inherently hierarchical structure, and it is well known that humans tend to chunk the world hierarchically. It is therefore interesting to explore the applicability of a modified version of VE on hierarchically structured data. We show that VE can be generalized to work on hierarchical data, and also that the higher order models can be used to improve the accuracy of the segmentation at lower levels.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-300.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
299,2008,Student Abstracts,The Swarm Application Framework,"Don Miner, Marie desJardins, Peter Hamilton","The Swarm Application Framework (SAF) is a tool that makes the development of swarm applications more intuitive. Traditionally, swarm applications are created by programming several low-level rules. This approach leads to several problems in designing and testing swarms, which serve as inspiration for the features of SAF. SAF encourages a new paradigm for designing swarm applications: engineers can interact with a swarm at the abstract (swarm) level instead of the individual (agent) level. In this paper, we discuss the design of the framework, how agents and rules in SAF operate, and a planned rule abstraction feature.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-301.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
300,2008,Student Abstracts,ADROIT: Automatic Discourse Relation Organizer of Internet-based Text,"A. S. M. Mahbub Morshed, Mitsuru Ishizuka","The ADROIT system that we are developing allows automatic discourse analysis of information rich natural language texts extracted directly from the web. We use guidelines and relations of Rhetorical Structure Theory (RST) to decompose texts into elementary segments and to perform the discourse parsing between them. In this paper, we present version 1.0 of ADROIT and focus on the noble technique of cue-phrase disambiguation and machine learning for identification and organization of discourse relations.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-302.pdf,Subjects: 13. Natural Language Processing; 13.1 Discourse
301,2008,Student Abstracts,NP-Completeness of Outcome Optimization for Partial CP-Nets,"Keith Purrington, Edmund H. Durfee","Partial CP-nets extend the standard CP-nets framework to allow users to express indifference about the values of some variables. Prior work has suggested that linear-time ""forward-sweep"" algorithms for outcome optimization in classic CP-nets can also be used with partial CP-nets. However, in this paper we prove that, in the general case where evidence is present, outcome optimization in partial CP-nets is, unfortunately, NP-complete. Fortunately, we are able to describe a linear-time ""backward-sweep"" algorithm that finds optimal outcomes for a restricted class of polytree- like partial CP-net structures. Furthermore, by comparison to a GSAT-style random-walk algorithm, we empirically demonstrate that the backward-sweep algorithm finds approximately optimal outcomes for general partial CP-nets.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-303.pdf,Subjects: 3.5 Qualitative Reasoning; 15.5 Decision Theory
302,2008,Student Abstracts,Toward Autonomous Learning of an Ontology of Tool Affordances by a Robot,"Jivko Sinapov, Alexander Stoytchev","The problem of autonomous learning of affordances typically requires a robot to learn the types of changes it can induce and detect in its environment. In sufficiently complex environments, however, it is impossible to know in advance the exact nature and number of possible environmental outcomes that the robot can induce through its behaviors. In addition, the changes that the robot can detect are often high-dimensional, making it difficult to use standard machine learning algorithms. This work addresses this problem by proposing a framework in which the robot learns a taxonomy for the types of perceivable changes produced by its own behaviors. The proposed method also allows the robot to incrementally update the taxonomy and to conceptualize new types of observed outcomes. In addition, the robot solves a hierarchical classification task by learning a model that predicts the future outcome of its behaviors in relation to the learned taxonomy. Thus, the robot builds an affordance ontology consisting of an outcome class taxonomy and a predictive model grounded in the robot's perceptual and behavioral repertoire.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-304.pdf,Subjects: 17. Robotics; 19.1 Perception
303,2008,Student Abstracts,The Validity of Providing Automated Hints in an ITS Using a MDP,"John Stamper, Tiffany Barnes","In building intelligent tutoring systems, it is critical to be able to understand and diagnose student responses in interactive problem solving. However, building this understanding into the tutor is a time-intensive process usually conducted by subject experts. Much of this time is spent in building production rules that model all the ways a student might solve a problem. In our prior work, we have proposed a novel application of Markov decision processes (MDPs), to automatically generate hints for an intelligent tutor that learns. We demonstrate the feasibility of this approach by extracting MDPs from four semesters of student solutions in a logic proof tutor, and calculating the probability that we may be able to generate hints for students. Our results indicate that extracted MDPs will be able to provide over 80% of students with hints while working problems.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-305.pdf,Subjects: 1.3 Computer-Aided Education; 12.1 Reinforcement Learning
304,2008,Student Abstracts,Using a Geometric-Based Sketch Recognition Approach to Sketch Chinese Radicals,"Paul Taele, Tracy Hammond","One approach to query a Chinese character involves referencing its subset called a radical, but sketching that character’s radical for querying is a function not supported by existing systems. Using the geometric-based LADDER sketching language and a Sezgin recognizer, we were able to construct an application which can first recognize handwritten sketches of Chinese radical, and then output candidate Chinese characters which contain that radical. Thus, we were able to demonstrate that a geometric-based sketch recognition approach can be used to easily build applications for recognizing symbols related to Chinese characters while working with few resources, requiring no training, and having reasonable recognition rates.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-306.pdf,Subjects: 6.3 User Interfaces; 6. Computer-Human Interaction
305,2008,Student Abstracts,Efficient Haplotype Inference with Answer Set Programming,"Ferhan Ture, Esra Erdem","Identifying maternal and paternal inheritance is essential to be able to find the set of genes responsible for a particular disease. Although we have access to genotype data (genetic makeup of an individual), determining haplotypes (genetic makeup of the parents) experimentally is a costly and time consuming procedure due to technological limitations. With these biological motivations, we study a computational problem, called Haplotype Inference with Pure Parsimony (HIPP), that asks for the minimal number of haplotypes that form a given set of genotypes. We introduce a novel approach to solving HIPP, using Answer Set Programming (ASP). According to our experiments with a large number of problem instances (some automatically generated and some real), our ASP-based approach solves the most number of problems compared to other approaches based on, e.g., integer linear programming, branch and bound algorithms, SAT-based algorithms, or pseudo-boolean optimization methods.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-307.pdf,Subjects: 11. Knowledge Representation; 1. Applications
306,2008,Student Abstracts,Eliminating False Positives During Corner Finding by Merging Similar Segments,"Aaron Wolin, Brandon Paulson, Tracy Hammond",We present a new corner finding algorithm based on merging like stroke segmentations together in order to eliminate false positive corners. We compare our system to two benchmark corner finders with substantial improvements in both polyline and complex fits.,https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-308.pdf,Subjects: 6. Computer-Human Interaction; 6.3 User Interfaces
307,2008,Student Abstracts,Visualization of Large-Scale Weighted Clustered Graph: A Genetic Approach,"Jiayu Zhou, Youfang Lin, Xi Wang","In this paper, a bottom-up hierarchical genetic algorithm is proposed to visualize clustered data into a planar graph. To achieve global optimization by accelerating local optimization process, we introduce sub-graph rotating and scaling processes into the genetic algorithm. Compared with existing methods, the proposed approach is more feasible and promising, with more accurate graph layout and more satisfiable computationally efficient performance, as demonstrated by the experimental results.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-309.pdf,Subjects: 1.9 Genetic Algorithms; 11. Knowledge Representation
308,2008,Doctoral Consortium Abstracts,The Relational Push-Pull Model: A Generative Model for Relational Data Clustering,Adam Anthony,"We present a new generative model for relational data in which relations between objects can have either a binding or a separating effect. For example, in a group of students separated into gender clusters, a ""dating"" relation would appear most frequently between the clusters, but a ""roommate"" relation would appear more often within clusters. In visualizing these relations, one can imagine that the ""dating"" relation effectively pushes clusters apart, while the ""roommate"" relation pulls clusters into tighter formations. A unique aspect of the model is that an edge's existence is dependent on both the clusters to which the two connected objects belong and the features of the connected objects. We use simulated annealing to search for optimal values of the unknown model parameters, where the objective function is a Bayesian score derived from the generative model. This paper provides a short description of the research, including a brief discussion of future directions.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-310.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
309,2008,Doctoral Consortium Abstracts,Towards Answer Set Prolog Based Architectures for Intelligent Agents,Sandeep Chintabathina,The goal of our proposed work is to make new contributions towards ongoing work on development of Answer Set Prolog (ASP) based agent architectures. The architecture we consider is based on the agent's Observe-Think-Act-loop in which various tasks of the agent are reduced to computing answer sets of ASP programs. We accomplish this by describing agent's knowledge using theories written in specific action languages and then translating these theories in to ASP programs.,https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-311.pdf,Subjects: 11. Knowledge Representation; 5. Common Sense Reasoning
310,2008,Doctoral Consortium Abstracts,Unstructured Audio Classification for Environment Recognition,Selina Chu,"My thesis aims to contribute towards building autonomous agents that are able to understand their surrounding environment through the use of both audio and visual information. To capture a more complete description of a scene, the fusion of audio and visual information can be advantageous in enhancing the system’s context awareness. The goal of this work is on the characterization of unstructured environmental sounds for understanding and predicting the context surrounding of an agent. Most research on audio recognition has focused primarily on speech and music. Less attention has been paid to the challenges and opportunities for using audio to characterize unstructured environments. Unlike speech and music, which have formantic structures and harmonic structures, environmental sounds are considered unstructured since they are variably composed from different sound sources. My research will investigate challenging issues in characterizing environmental sounds such as the development of appropriate features extraction algorithm and learning techniques for modeling the dynamics of the environment. A final aspect of my research will consider the decision making of an autonomous agent based on the fusion of visual and audio information.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-312.pdf,Subjects: 12. Machine Learning and Discovery; 17. Robotics
311,2008,Doctoral Consortium Abstracts,An Architecture and Formalism for Handling Modular Ontologies,Faezeh Ensan,"The goal of my ongoing work is to provide an architecture for developing and manipulating modular ontologies in such a way that each ontology module can plug into or unplug from an ontology. This architecture builds on top of a fundamental formalism for modular ontologies. Through this formalism we are able to define mechanisms for integrating different modules and develop algorithms for reasoning over the integrated modules. The resolution of inconsistencies arisen by conflicting axioms in different modules as well as the investigation of the impact of changes in a module on the other ontology modules are two important issues that need to be taken into consideration during the development of the formalism. Here, we briefly review the overall structure of the research work that I intended to conduct.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-313.pdf,Subjects: 11.2 Ontologies; 2. Architectures
312,2008,Doctoral Consortium Abstracts,Optimizations and Extensions for the Horn Transaction Logic Programs,Paul Fodor,"My thesis describes optimization techniques and extensions for the Horn Transaction Logic. The Horn Transaction Logic is an extension of the classical logic programming with state updates and it has a SLD-style evaluation algorithm. This SLD-style algorithm enters into infinite loops when computing answers to many recursive programs when they change the underlying state of the knowledge base. We solve this problem by tabling the calls, states and answers in a searchable structure, so that the same call is not re-executed ad infinitum. With these techniques, we can efficiently compute queries to transaction logic programs, and when the underlying programs have the bounded term-depth property, these techniques are guaranteed to terminate. I also present extensions to Transaction Logic, for instance a definite semantics for the existentially quantified values that occur in facts, queries and updates of facts. The applications of these techniques promise great improvements in the uses of transaction logic: state-changing systems, artificial intelligence planning, dynamic constraints on transaction execution, workflow modeling and verification, and systems involving financial transactions.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-314.pdf,Subjects: 9.3 Mathematical Foundations; 1.11 Planning
313,2008,Doctoral Consortium Abstracts,Social Interaction under Uncertainty in Multi Agent Systems,Noam Hazon,"Multi-agent systems deal with environments comprising several agents that interact with each other. The development of distributed, interconnected computer systems has invoked the rapid growth of this research area. Such settings, where one software agent interacts with another, require studying interactions such as coordination, cooperation and negotiation. In fact, many types of social interactions among humans relate to computerized agents as well. In my work I investigate computational aspects of two common social interactions, namely voting and collaborative search. I also propose to solve my suggested problems without many relaxing assumptions in order to come as close as possible to real-world settings. Hence, I concentrate on settings of imperfect information which I model using probabilities.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-315.pdf,Subjects: 7.1 Multi-Agent Systems; 15.5 Decision Theory
314,2008,Doctoral Consortium Abstracts,Tightly Coupled Cooperation Among Independent Agents,Daylond J Hooper,"Coordination is defined as �the harmonious functioning of parts for effective results� (Mish 1996). When applied to multiple robot systems, coordination is classified by one of two categories: collaboration or cooperation. Each component contributes to the harmonious functioning aspect of Coordination. Collaboration occurs when multiple robots engage in separate independent tasks to fulfill a higher goal. Collaboration is limited to situations where there is no requirement for synchronization on the tasks. An example of this is in distributed mapping: each robot�s progress on generating its portion of themap is unaffected by the progress of other robots. Cooperation, on the other hand, occurs when multiple robots engage in similar or identical tasks that are mutually dependent (coupled) in pursuit of a higher goal. These tasks require at least some degree of synchronization, and cooperative tasks fall on a spectrum that spans from loosely coupled to tightly coupled tasks. More tightly coupled tasks require a greater degree of synchronization. Cooperative box pushing is an example of a somewhat tightly coupled task, since the synchronization requirements are mostly limited to constraining the deviation from the intendended course. Cooperative lifting is a tightly coupled cooperative task because the robots must keep the item fairly level. This way, the robots avoid an uneven distribution of the weight and minimize the risk of damage to themselves and the item",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-316.pdf,Subjects: 7.1 Multi-Agent Systems; 15.3 Control
315,2008,Doctoral Consortium Abstracts,Autonomous Robot Skill Acquisition,George Konidaris,"My thesis applies and extends hierarchical reinforcement learning methods to the robot skill acquisition problem, with the aim of creating robots that are able to autonomously create new skills, refine them through practice, and apply them in new task contexts.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-317.pdf,Subjects: 12.1 Reinforcement Learning; 17. Robotics
316,2008,Doctoral Consortium Abstracts,"Generating Plans in Concurrent, Probabilistic, Over-Subscribed Domains",Li Li,"My thesis topic is plan generation in temporal, parallel, probabilistic domains with oversubscribed goals. I have defined a framework that includes two novel extensions. First, the plans can include parallel steps that serve the same goal and increase the probability of success in addition to parallel steps that serve different goals and decrease execution time. Second, already executing plan steps can be terminated if doing so saves resources to achieve more goals. My algorithm called CPOAO* (Concurrent, Probabilistic, Oversubscription AO*) can deal with these extensions. In this paper, I summarize the design and implementation of CPOAO* and its associated heuristics, and propose a plan of research.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-318.pdf,Subjects: 15. Problem Solving; 15.7 Search
317,2008,Doctoral Consortium Abstracts,Adaptive Abstraction of Constraint-Based Models for Self-Diagnosis and Planning,Paul Maier,"Model-based diagnosis and planning provide means to handle errors and unanticipated situations in today's increasingly complex embedded systems.  In my thesis I aim to address two problems that arise in this context: 1) a tighter integration of diagnosis and planning, which can be achieved using constraint optimization problems (COP) as common representation for both of them and 2) a more flexible belief state approximation which can be developed based on this representation using adaptive abstraction. Within this context, based on the existing COP algorithm Mini-Bucket Elimination I have implemented an algorithm which incorporates an adaptive abstraction method using domain abstraction.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-319.pdf,Subjects: 1.5 Diagnosis; 1.11 Planning
318,2008,Doctoral Consortium Abstracts,Distributed Robust Execution of Qualitative State Plan with Chance Constraints,"Masahiro Ono, Brian C. Williams","The research objective is to develop a distributed model-based Qualitative State Plan executive that is robust in a stochastic environment. As the first step towards this goal, a robust kinodynamic path planner called Bi-stage Robust Motion Planning algorithm is developed. The algorithm optimizes the risk allocation in the upper-stage while optimizing the nominal path in the lower-stage. The simulation result shows significant improvement in optimality and computation time compared to prior arts.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-320.pdf,Subjects: 3.4 Probabilistic Reasoning; 17. Robotics
319,2008,Doctoral Consortium Abstracts,Combining Global Relevance Information with Local Contextual Clues for Event-Oriented Information Extraction,Siddharth Patwardhan,"Existing Information Extraction (IE) systems tend to focus on a tight window of context surrounding the desired information to be extracted. This research addresses shortcomings of these systems by introducing a two-phase approach to IE that incorporates global relevance information with local contextual evidence, to effectively extract information from free text.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-321.pdf,Subjects: 13. Natural Language Processing; Please choose a second document classification
320,2008,Doctoral Consortium Abstracts,Computational Influence for Training and Entertainment,David L. Roberts,"My dissertation will advance the state of the art in virtual simulation technology for training and entertainment by applying computer science-based tools to the development of innovative simulation and training environments. In many cases, a technically-minded AI expert creates a technique to solve a class of problems and puts the power of that technology in the hands of a practitioner. In that spirit, I plan to develop AI technologies for computer-based gaming and simulation based on the ideas of persuasion from social psychology that when given to game designers will ease their authorial burden and increase their expressive power. Progress toward this goal will enable domain experts—rather than technical experts—to leverage the power of AI for creating interactive narratives and increase their potential to author complex and realistic content.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-322.pdf,Subjects: 1. Applications; 6.1 Life-Like Characters
321,2008,Doctoral Consortium Abstracts,Integrative Construction and Analysis of Condition-specific Biological Networks,"Sushmita Roy, Terran Lane, Margaret Werner-Washburne","We present a probabilistic graphical modeling approach for condition-specific biological networks—networks of genes and proteins that exist in living cells under different environmental conditions. We model a biological network using Markov random fields and describe an algorithm for learning the structure of Markov random fields. We describe methods to evaluate a structure learning algorithm's ability to capture different dependencies. Unlike existing approaches for identifying condition-specific behaviour of networks, where condition-specific subnetworks are identified after learning separate networks per condition, we propose to simultaneously learn specific and generic subnetworks across different conditions. The structural and functional aspects of the condition-specific networks learned from different conditions will provide a holistic view of the cellular mechanisms employed to respond, and survive in stressful and healthy conditions.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-323.pdf,Subjects: 12. Machine Learning and Discovery; 12.2 Scientific Discovery
322,2008,Doctoral Consortium Abstracts,Managing Quality of Service with Soft Constraints,Francesco Santini,"The term quality as it is commonly understood in the context of Quality of Service (QoS) is something' by which a user of the service (in a very large meaning) will judge how good the service is. In this research project we mainly focus our attention to three areas related with QoS: i) Networks, ii) Web Services and iii) Trust Management (TM). The aim of my PhD thesis is to provide expressive means (e.g. languages) in order to model and solve these frameworks with the help of Soft Constraints, benefiting from Artificial Intelligence background to tackle this kind of optimization problems. Soft constraints will represent the needs of the parties on the traded resources and the consistency value of the store represents a feedback on the current agreement. Using soft constraints gives to the service provider and the clients more flexibility in expressing their requests w.r.t. crisp constraints, and therefore there are more chances to reach a shared agreement. Moreover, the cost model is very adaptable to the specific problem, since it is parametric with the chosen semiring.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-324.pdf,Subjects: 15.2 Constraint Satisfaction; 3.5 Qualitative Reasoning
323,2008,Intelligent Systems Demonstrations,The Benefits of an Ontological Patient Model in Clinical Decision-Support,"Mark Austin, Matthew Kelly, Mike Brady","We have developed an application, MDTSuite, designed to support complex group decision making under difficult conditions including time pressure, incomplete information, changing group members and ever expanding guidelines. Taking the colorectal cancer MDT (Multi-Disciplinary-Team) meetings at the Radcliffe Infirmary in Oxford as our test case, we have been trialling the software live in the hospital providing decision support for clinicians discussing real patients. MDTSuite is an application integrating an ontological data model with an argumentation-based decision-support system, showing how the combination of leading technologies OWL, SPARQL and Jena can be used to achieve this.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-325.pdf,Subjects: 1.7 Expert Systems; 11.2 Ontologies
324,2008,Intelligent Systems Demonstrations,A Hybrid Approach to Domino Portrait Generation,"Hadrien Cambazard, John Horan, Eoin O’Mahony, Barry O’Sullivan","A domino portrait is an approximation of an image using a given number of sets of dominoes. This problem was first stated in 1981. Domino portraits have been generated most often using integer linear programming techniques that provide optimal solutions, but these can be slow and do not scale well. We demonstrate a new approach that overcomes these limitations and provides high quality portraits. Our software combines techniques from operations research, artificial intelligence, and computer vision. Starting from a randomly generated template of blank domino shapes, a subsequent optimal placement of dominoes can be achieved in constant time when the problem is viewed as a minimum cost flow. The domino portraits one obtains are good, but not as visually attractive as optimal ones. Combining techniques from computer vision and local search we can improve our portraits to be visually indistinguishable from those generated optimally.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-326.pdf,Subjects: 15.2 Constraint Satisfaction; 1.1 Art And Music
325,2008,Intelligent Systems Demonstrations,A Demonstration of the RADAR Personal Assistant,"Andrew Faulring, Brad Myers, Ken Mohnkern, Michael Freed","Email clients were not designed to serve as a task management tools, but a high volume of task-relevant information in email leads many people to use email clients for this purpose. Such usage aggravates a user’s experience of email overload and reduces productivity. Prior research systems have sought to address this problem by experimentally adding task management capabilities to email client software. RADAR (Reflective Agents with Distributed Adaptive Reasoning) takes a different approach in which a software agent acts like a trusted human assistant. Many RADAR components employ machine learning to improve their performance. Human participant studies showed a clear impact of learning on user performance metrics.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-327.pdf,Subjects: 7.2 Software Agents; 12. Machine Learning and Discovery
326,2008,Intelligent Systems Demonstrations,CogSketch,"Ken Forbus, Andrew Lovett, Kate Lockwood, Jon Wetzel, Camillia Matuk, Ben Jee, Jeffry Usher","CogSketch is an open-domain sketch understanding system. CogSketch takes a unique approach to sketch understanding that focuses less on low-level recognition and more on high-level reasoning with sketches. In addition to demonstrating the basic system, we will showcase applications to cognitive simulation and education.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-328.pdf,Subjects: 1. Applications; 3.2 Geometric Or Spatial Reasoning
327,2008,Intelligent Systems Demonstrations,Yoopick: A Combinatorial Sports Prediction Market,"Sharad Goel, David Pennock, Daniel Reeves, Cong Yu","We describe Yoopick, a combinatorial sports prediction market that implements a flexible betting language, and in turn facilitates fine-grained probabilistic estimation of outcomes.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-329.pdf,Subjects: 1. Applications; 6.3 User Interfaces
328,2008,Intelligent Systems Demonstrations,Prometheus Design Tool,"John Thangarajah, Lin Padgham, Michael Winikoff","The Prometheus Design Tool (PDT) supports the structured design of intelligent agent systems. It supports the Prometheus methodology, but can also be used more generally. This paper outlines the tool and some of its many features.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-330.pdf,Subjects: 7.1 Multi-Agent Systems; 1.4 Design
329,2008,Intelligent Systems Demonstrations,ARMOR Security for Los Angeles International Airport,"James Pita, Manish Jain, Fernando Ordénez, Christopher Portway, Milind Tambe, Craig Western, Praveen Paruchuri, Sarit Kraus","Security at major locations of economic or political importance is a key concern around the world, particularly given the threat of terrorism. Limited security resources prevent full security coverage at all times, which allows adversaries to observe and exploit patterns in selective patrolling or monitoring, e.g. they can plan an attack avoiding existing patrols. Hence, randomized patrolling or monitoring is important, but randomization must provide distinct weights to different actions based on their complex costs and benefits. To this end, this demonstration showcases a promising transition of the latest in multi-agent algorithms into a deployed application. In particular, it exhibits a software assistant agent called ARMOR (Assistant for Randomized Monitoring over Routes) that casts this patrolling/monitoring problem as a Bayesian Stackelberg game, allowing the agent to appropriately weigh the different actions in randomization, as well as uncertainty over adversary types. ARMOR combines two key features: (i) It uses the fastest known solver for Bayesian Stackelberg games called DOBSS, where the dominant mixed strategies enable randomization; (ii) Its mixed-initiative based interface allows users to occasionally adjust or override the automated schedule based on their local constraints. ARMOR has been successfully deployed since August 2007 at the Los Angeles International Airport (LAX) to randomize checkpoints on the roadways entering the airport and canine patrol routes within the airport terminals.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-331.pdf,Subjects: 1.12 Scheduling; 1.8 Game Playing
330,2008,Intelligent Systems Demonstrations,Human-Robot Collaboration for Remote Surveillance,"Evan A. Sultanik, Ilya Braude, Peter Thai, Robert N. Lass, Duc N. Nguyen, Joseph B. Kopena,  William C. Regli, Sean A. Lisse, Steven N. Furtwangler, and Alan J. Vayda",The demonstration presents an application of multiagent systems and wireless networking to remote robotbased surveillance,https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-332.pdf,Subjects: 1.12 Scheduling; 1.8 Game Playing
331,2008,Intelligent Systems Demonstrations,Knowledge-Based Spatial Reasoning for Scene Generation from Text Descriptions,Dan Tappan,"This system translates basic English descriptions of a wide range of objects in a simplistic zoo environment into plausible, three-dimensional, interactive visualizations of their positions, orientations, and dimensions. It combines a semantic network and contextually sensitive knowledge base as representations for explicit and implicit spatial knowledge, respectively. Its linguistic aspects address underspecification, vagueness, uncertainty, and context with respect to intrinsic, extrinsic, and deictic frames of spatial reference. The underlying, commonsense reasoning formalism is probability-based geometric fields that are solved through constraint satisfaction. The architecture serves as an extensible test-and-evaluation framework for a multitude of linguistic and artificial-intelligence investigations.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-333.pdf,Subjects: 13. Natural Language Processing; 3.2 Geometric Or Spatial Reasoning
332,2008,Intelligent Systems Demonstrations,IMT: A Mixed-Initiative Data Mapping and Search Toolkit,"Michael Zang, Adam Gray, Joe Kriege, Kalyan Moy Gupta, David W. Aha","Interoperability requires the resolution of syntactic and semantic variations among system data models. To address this problem, we developed the Intelligent Mapping Toolkit (IMT), which employs a distributed multi-agent architecture to enable the mixed-initiative mapping of metadata and instances. This architecture includes a novel federation of service-encapsulated matching agents that leverage case-based reasoning methods. We recently used the IMT matching service to develop several domain-specific search applications in addition to the IMT mapping application.",https://aaai.org/Library/AAAI/2008/../../../Papers/AAAI/2008/AAAI08-334.pdf,Subjects: 7.1 Multi-Agent Systems; 3.1 Case-Based Reasoning
