,conference_year,category,title,author,abstract,download_url,keywords
0,1997,Agent Architecture,If at First You Don’t Succeed...,"Kentaro Toyama, Gregory D. Hager","One quality that makes biological systems appear intelligent is their robustness to difficult circumstances. Robustness is crucial to intelligent behavior and important to AI research. We distinguish between ante-failtire and post-failure robustness for causal tasks. Ante-failure robust systems resist failure, whereas post-failure systems incorporate the ability to recover from failure once it happens. We point out the power of post-failure robustness in AI problems, closely examining one example in visual motion tracking. Finally, we raise theoretical issues and argue for greater effort towards building post-failure robust systems.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-001.pdf,
1,1997,Agent Architecture,Modeling Emotions and Other Motivations in Synthetic Agents,Juan D. Velásquez,"We present Cathexis, a distributed, computational model which offers an alternative approach to model the dynamic nature of different affective phenomena, such as emotions, moods and temperaments, and provides a flexible way of modeling their influence on the behavior of synthetic autonomous agents. The model has been implemented as part of an extensible, object-oriented framework which provides enough functionality for agent developers to design emotional agents that can be used in a variety of applications including entertainment (e.g. synthetic agents for interactive drama, video games, etc.), education (e.g. Intelligent Tutoring Systems), and human-computer interfaces.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-002.pdf,
2,1997,Agent Coordination,Coordinating Agents by Role Based Social Constraints and Conversation Plans,Mihai Barbuceanu,"We explore the view that coordinated behavior is explained by the social constraints that agents in organizations are subject to. In this framework, agents adopt those goals that are requested by their obligations, knowing that not fulfilling obligations induces a price to pay or a loss of utility. Based on this idea we build a coordination system where we represent the organization, the roles played by agents, the obligations imposed among roles, the goals and the plans that agents may adopt. Once a goal adopted, a special brand of plans, called conversation plans, are available to the agents for effectively carrying out coordinated action, Conversation plans explicitly represent interactions by message exchange and their actions are dynamically reordered using the theory of Markov Decision Processes to ensure the optimization of various criteria. The framework is applied to model supply chains of distributed enterprises.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-003.pdf,
3,1997,Agent Coordination,"Agent Architectures for Flexible, Practical Teamwork",Milind Tambe,"Teamwork in complex, dynamic, multi-agent domains mandates highly flexible coordination and communication. Simply fitting individual agents with precomputed coordination plans will not do, for their inflexibility can cause severe failures in teamwork, and their domain-specificity hinders reusability. Our central hypothesis is that the key to such flexibility and reusability is agent architectures with integrated teamwork capabilities. This fundamental shift in agent architectures is illustrated via an implemented candidate: STEAM. While STEAM is founded on the j&t intentions theory, practical operationalization has required it to integrate several key novel concepts: (i) team synchronization to establish joint intentions; (ii) constructs for monitoring joint intentions and repair; and (iii) decision-theoretic communication selectivity (to pragmatically extend the joint intentions theory). Applications in three different complex domains, with empirical results, are presented.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-004.pdf,
4,1997,Negotiation,Negotiation on Data Allocation in Multi-Agent Environments,"Rina Schwartz, Sarit Kraus","We propose a strategic negotiation model that takes into account the passage of time during the negotiation process itself in order to solve the problem of data allocation in environments with self-motivated servers which have no common interest and no central controller. The model considers situations characterized by complete, as well as incomplete, information. Using this negotiation mechanism, the servers have simple and stable negotiation strategies that result in efficient agreements without delays. We provide heuristics for finding the details of the strategies which depend on the specific settings of the environment, and demonstrate the quality of the heuristics, using simulations. We prove that our methods yield better results than the static allocation policy currently used for data allocation for servers in distributed systems.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-005.pdf,
5,1997,Negotiation,Benefits of Learning in Negotiation,"Dajun Zeng, Katia Sycara","Negotiation has been extensively discussed in game-theoretic, economic, and management science literatures for decades. Recent growing interest in electronic commerce has given increased importance to automated negotiation. Evidence both from theoretical analysis and from observations of human interactions suggests that if decision makers can somehow take into consideration what other agents are thinking and furthermore learn during their interactions how other agents behave, their payoff might increase. In this paper, we propose a sequential decision making model of negotiation, called Bazaar. Within the proposed negotiation framework, we model learning as a Bayesian belief update process. In this paper, we explore the hypothesis that learning is beneficial in sequential negotiation and present initial experimental results.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-006.pdf,
6,1997,Automated Reasoning/Diagnosis,Representing Actions and State Constraints in Model-Based Diagnosis,Sheila A. McIlraith,"In this paper we examine an important set of representation issues which have not been addressed by the model-based diagnosis community. In particular, we examine the problem of integrating a model-based diagnosis system description, SD, with a theory of action to parsimoniously represent the effect of actions on a system and the effects of system state on performing actions in the world. We employ the situation calculus, a first-order language, as our representation language. In the context of the situation calculus, SD presents an, often complex, set of state constraints. These state constraints implicitly define indirect effects of actions as well as indirectly imposing further preconditions on the performance of actions. As a consequence, SD presents further complications to addressing the frame, ramification and qualification problems. For the purposes of this paper, we examine a syntactically restricted SD, which commonly occurs in the axiomatization of model-based diagnosis domains. The contributions of this paper include: 1) a framework for integrating SD and a theory of action. 2) a procedure for compiling SD into a set of successor state axioms. These axioms capture the intended interpretation of SD, while providing a closed-form solution to the frame and ramification problems.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-007.pdf,
7,1997,Automated Reasoning/Diagnosis,Fast Context Switching in Real-Time Propositional Reasoning,"P. Pandurang Nayak, Brian C. Williams","The trend to increasingly capable and affordable control processors has generated an explosion of embedded real-time gadgets that serve almost every function imaginable. The daunting task of programming these gadgets is greatly alleviated with real-time deductive engines that perform all execution and monitoring functions from a single core model. Fast response times are achieved using an incremental propositional deductive database (an LTMS). Ideally the cost of an LTMS’s incremental update should be linear in the number of labels that change between successive contexts. Unfortunately an LTMS can expend a significant percentage of its time working on labels that remain constant between contexts. This is caused by the LTMS’s conservative approach: a context switch first removes all consequences of deleted clauses, whether or not those consequences hold in the new context. This paper presents a more aggressive incremental TMS, called the ITMS, that avoids processing a significant number of these consequences that are unchanged. Our empirical evaluation for spacecraft control shows that the overhead of processing unchanged consequences can be reduced by a factor of seven.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-008.pdf,
8,1997,Automated Reasoning & the User Interface,Visual Prompts and Graphical Design: A Framework for Exploring the Design Space of 2-D Charts and Graphs,Vibhu O. Mittal,"Graphical presentations can be very effective in communicating large datasets and patterns, trends and relationships in them. Charts and graphs used in reporting data usually tend to highlight certain aspects and suppress others. In fact, a recent study of several hundred annual reports found that more than 30% of charts in these reports were designed to facilitate inferences favorable to the companies while hindering others. Unfortunately, many of the techniques used to achieve these effects may not be obvious to the average user. One solution to this problem is to make design choices explicit to the user. This paper presents a data analysis interface that educates users by enabling them to explore the visualization space and modifying chart design parameters. This interface is based on an analysis of a corpus of charts and graphs and uses knowledge about a variety of techniques for emphasizing specific trends and/or values shown in 2-D charts and graphs.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-009.pdf,
9,1997,Automated Reasoning & the User Interface,Navigation and Planning in a Mixed-Initiative User Interface,Robert St. Amant,"Mixed-initiative planning is one approach to building an intelligent decision-making environment. A mixed-initiative system shares decision-making responsibility with the user such that it acts sometimes as a tool, to be directly applied to a specific task, and other times as an autonomous problem-solver. In the best case, the user can delegate the details of a task to the automated system without giving up the ability to guide and review the decision-making process. We have developed a simple mixed-initiative planner that incorporates a view of problem-solving as navigation. We have explored this notion in two different applications: exploratory statistical analysis and layout design for user interface dialogs. This paper discusses navigation issues in the context of these two systems, the poten- tial benefits of the approach, and some implications for user interface design.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-010.pdf,
10,1997,Belief and Decision,Possibilistic and Standard Probabilistic Semantics of Conditional Knowledge,"Salem Benferhat, Didier Dubois, Henri Prade","This paper offers a detailed analysis of the structure of this family of possibility distributions by exploiting two different orderings between them: Yager’s specificity ordering and a new refinement ordering. It is shown that from a representation point of view, it is sufficient to consider the subset of linear possibility distributions which corresponds to all the possible completions of the default knowledge in agreement with the constraints. There also exists a semantics for system P in terms of infinitesimal probabilities. Surprisingly, it is also shown that a standard probabilistic semantics can be equivalently given to System P, without referring to infinitesimals, by using a special family of probability measures, that two of the authors have called acceptance functions, and that has been also recently considered by Snow in that perspective.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-011.pdf,
11,1997,Belief and Decision,On the Axiomatization of Qualitative Decision Criteria,"Ronen I. Brafman, Moshe Tennenholtz","Qualitative decision tools have been used in AI and CS in various contexts, but their adequacy is still unclear. To examine this question, our work employs the axiomatic approach to characterize the properties of various decision rules. In the past, we presented a constructive representation theorem for the maximin decision criterion, and we characterized conditions under which an agent can be viewed as adopting a qualitative decision-making approach (consisting of beliefs, goals, and a qualitative decision criterion). In this paper we show that the maximin representation theorem applies to two additional decision criteria: minimax regret and competitive ratio, and with slight modifications, to a third one, maximax. In addition, we characterize conditions underwhich an agent with a given qualitative utility function can be ascribed beliefs when we assume it adopts maximin as its decision criterion.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-012.pdf,
12,1997,Classification,Symbolic Nearest Mean Classifiers,"Piew Datta, Dennis Kibler","The minimum-distance classifier summarizes each class with a prototype and then uses a nearest neighbor approach for classification. Three drawbacks of the original minimum-distance classifier are its inability to work with symbolic attributes, weigh attributes, and learn more than a single prototype for each class. The proposed solutions to these problems include defining the mean for symbolic attributes, providing a weighting metric, and learning several possible prototypes for each class. The learning algorithm developed to tackle these problems, SNMC, increases classification accuracy by 10% over the original minimum-distance classifier and has a higher average generalization accuracy than both C4.5 and PEBLS on 20 domains from the UCI data repository.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-013.pdf,
13,1997,Classification,Classification and Reductio-ad-Absurdum Optimality Proofs,Haim Schweitzer,"Proofs for the optimality of classification in real-world machine learning situations are constructed. The validity of each proof requires reasoning about the probability of certain subsets of feature vectors. It is shown that linear discriminants classify by making the least demanding assumptions on the values of these probabilities. This enables measuring the confidence of classification by linear discriminants. We demonstrate experimentally that when linear discriminants make decisions with high confidence, their performance on real-world data improves significantly, to the point where they beat the best known nonlinear techniques on large portions of the data.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-014.pdf,
14,1997,Diagnosis,The Effect of Observations on the Complexity of Model-Based Diagnosis,"Adnan Darwiche, Gregory Provan","This paper shows how to efficiently diagnose systems by making use of observations. In particular, we present two theorems concerning the effect of observations on the complexity of Model-Based Diagnosis. The first theorem shows how the presence of certain observations allows us to decompose a diagnostic reasoning task into independent reasoning tasks on subsystems. The second theorem shows how the absence of certain observations allows us to ignore parts of a system during diagnostic reasoning. Another main contribution of this paper is an application of these theorems to diagnosing discrete-event systems. In particular, we identify observability and modularity characteristics of discrete-event systems that make them amenable to the presented theorems and, hence, to any diagnostic approach that employs these theorems effectively. This also explains why a particular approach that we have presented elsewhere has proven effective for diagnosing these systems.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-015.pdf,
15,1997,Diagnosis,"Monitoring, Prediction, and Fault Isolation in Dynamic Physical Systems","Pieter J. Mosterman, Gautam Biswas","Diagnosis of dynamic physical systems is complex and requires close interaction of monitoring, fault generation and refinement, and prediction. We establish a methodology for model-based diagnosis of continuous systems in a qualitative reasoning framework. A temporal causal model capturing dynamic system behavior identifies faults from deviant measurements and predicts future system behavior expressed as signatures, i.e., qualitative magnitude changes and higher order time-derivative effects. A comparison of the transient characteristics of the observed variables with the predicted effects helps refine initial fault hypotheses. This shows for quick fault isolation, and circumvents difficulties that arise when interactions caused by feedback and dependent faults. This methodology has been successfully applied to the secondary cooling loop of fast breeder reactors.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-016.pdf,
16,1997,Modeling for Decision Processes,Model Minimization in Markov Decision Processes,"Thomas Dean, Robert Givan","We use the notion of stochastic bisimulation homogenity to analyze planning problems represented as Markov decision processes (MDPs). Informally, a partition of the state space for an MDP is said to be homogeneous if for each action, states in the same block have the same probability of being carried to each other block. We provide an algorithm for finding the coarsest homogeneous reflnement of any partition of the state space of an MDP. The resulting partition can be used to construct a reduced MDP which is minimal in a well defined sense and can be used to solve the original MDP. Our algorithm is an adaptation of known automata minimization algorithms, and is designed to operate naturally on factored or implicit representations in which the full state space is never explicitly enumerated. We show that simple variations on this algorithm are equivalent or closely similar to several different recently published algorithms for finding optimal solutions to (partially or fully observable) factored Markov decision processes, thereby providing alternative descriptions of the methods and results regarding those algorithms.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-017.pdf,
17,1997,Modeling for Decision Processes,Structured Solution Methods for Non-Markovian Decision Processes,"Fahiem Bacchus, Craig Boutilier, Adam Grove","Markov Decision Processes (MDPs), currently a popular method for modeling and solving decision theoretic planning problems, are limited by the Markovian assumption: rewards and dynamics depend on the current state only, and not on previous history. Non-Markovian decision processes (NMDPs) can also be defined, but then the more tractable solution techniques developed for MDP’s cannot be directly applied. In this paper, we show how an NMDP, in which temporal logic is used to specify history dependence, can be automatically converted into an equivalent MDP by adding appropriate temporal variables. The resulting MDP can be represented in a structured fashion and solved using structured policy construction methods. In many cases, this offers significant computational advantages over previous proposals for solving NMDPs.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-018.pdf,
18,1997,Qualitative Reasoning,Model Decomposition and Simulation: A Component Based Qualitative Simulation Algorithm,"Daniel J. Clancy, Benjamin Kuipers","Traditionally, qualitative simulation uses a global, state-based representation to describe the behavior of the modeled system. For larger, more complex systems this representation proves extremely inefficient since it provides a complete temporal ordering of all potential distinctions leading to a large, complex behavioral description that obscures relevant distinctions, or even fails to terminate. The model decomposition and simulation algorithm (DecSIM) uses a divide and conquer approach to qualitative simulation. Variables within the system are partitioned into components. Each component is viewed as a separate system and is simulated using a state-based representation limited to the variables within the component. Interactions between components are reasoned about separately. DecSIM provides a promising paradigm for qualitative simulation whose complexity is driven by the complexity of the problem specification rather than the inference mechanism used.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-019.pdf,
19,1997,Qualitative Reasoning,Static and Dynamic Abstraction Solves the Problem of Chatter in Qualitative Simulation,"Daniel J. Clancy, Benjamin Kuipers","One of the major factors hindering the use of qualitative simulation techniques to reason a,bout the behavior of complex dynamical systems is intractable branching due to a phenomenon called chatter. This paper presents two general abstraction techniques that solve the problem of chatter. Eliminating the problem of chatter significantly extends the range of models that can be tractably simulated using qualitative simulation. Chatter occurs when a variable’s direction of change is constrained only by continuity within a region of the state space. This results in intractable, potentially infinite branching within the behavioral description due to irrelevant distinctions in the direction of change. While a number of techniques have been proposed to eliminate chatter, none of them provide a general solution that can eliminate all instances of chatter. Chatter box abstraction and dynamic chatter abstraction provide two such solutions to this problem. Both solutions eliminate chatter by abstracting the chattering region of the state space into a single qualitative state with an abstract direction of change. The algorithms differ in the manner in which they identify the chattering region of the state space.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-020.pdf,
20,1997,Reasoning about Physical Systems,"The ""Inverse Hollywood Problem"": From Video to Scripts and Storyboards via Causal Analysis",Matthew Brand,"We address the problem of visually detecting causal events and fitting them together into a coherent story of the action witnessed by the camera. We show that this can be done by reasoning about the motions and collisions of surfaces, using high-level causal constraints derived from psychological studies of infant visual behavior. These constraints are naive forms of basic physical laws governing substantiality, contiguity, momentum, and acceleration. We describe two implementations. One system parses instructional videos, extracting plans of action and key frames suitable for storyboarding. Since learning will play a role in making such systems robust, we introduce a new framework for higher-order hidden Markov models and demonstrate its use in a second system that segments stereo video into actions in near real-time. Rather than attempt accurate low-level vision, both systems use high-level causal analysis to integrate fast but sloppy pixel-based representations over time. The output is suitable for summary, indexing, and automated editing.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-021.pdf,
21,1997,Reasoning about Physical Systems,Qualitative Rigid Body Mechanics,"Thomas F. Stahovich, Randall Davis, Howard Shrobe",We present a theory of qualitative rigid body mechanics and describe a program that uses this theory to compute qualitative dynamic simulations. The program works directly from a qualitative representation of geometry (qc-space). It employs a new qualitative representation for forces that reduces ambiguity in force sums and hence reduces branching.,https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-022.pdf,
22,1997,Spatial Uncertainty,Integrating a Spatial Reasoner with a Resolution Theorem-Prover,Thomas R. Ioerger,"Some spatial reasoning systems use images to solve problems, rather than making formal logical inferences. However, an open question is how to use these systems in contexts where some non-spatial information is also involved. We present a hybrid reasoning method in which we extend the capabilities of a spatial reasoner by integrating it with a resolution theorem-prover. We prove that the hybrid system is refutation-complete, in the sense that, if a domain theory is unsatisfiable, perhaps only because all of its models entail unrealizable images, then our algorithm will halt. We discuss how our approach differs from other hybrid reasoning algorithms in the way it manages the interaction between sub-systems.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-023.pdf,
23,1997,Spatial Uncertainty,"Noise, Non-Determinism and Spatial Uncertainty",Murray Shanahan,"This paper presents a logical account of sensor data assimilation in a mobile robot, based on abduction. Unlike previous work, the present formulation handles sensor noise as well as motor noise. In addition, it incorporates two significant technical advances. The use of determining fluents to deal with non-determinism obviates the need for a special form of abduction, and the use of uncertain object boundaries alleviates a problem with multiple explanations.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-024.pdf,
24,1997,Spatial Uncertainty,"Projective Relations for 3D Space: Computational Model, Application, and Psychological Evaluation","Constanze Vorwerg, Gudrun Socher, Thomas Fuhr, Gerhard Sagerer, Gert Rickheit","We propose a 3D computational model for projective relations which is used in an integrated image and speech understanding system. The image and speech understanding system is being developed within a joint research project focusing on both technical and cognitive aspects of human-computer interaction, Psychological experiments have been carried out to evaluate our computational model as an approximation of the meaning of projective prepositions used by humans in spoken instructions. These experiments investigate the acceptance of the model by subjects as well as the regularities regarding human usage of projective relations. Results of the computational model, the overall system, and the psychological experiments are presented.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-025.pdf,
25,1997,Techniques for Temporal Reasoning,A New Unification Method for Temporal Reasoning with Constraints,Eddie Schwalb,"In this work we consider using logic programs to perform temporal reasoning. We identify some difficulties of combining constraint propagation and generalized resolution when temporal information is represented using tokens. We show that standard top-down evaluation (i.e. resolution) is incomplete due to the inability to unify constraints and ground terms. We present some syntactic restrictions that enable temporal resolution. Under these restrictions, we propose a new unification method composed of constraint unification and token fusion algorithms. Incorporating them within a generalized resolution scheme render it, complete.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-026.pdf,
26,1997,Techniques for Temporal Reasoning,Connection Based Strategies for Deciding Propositional Temporal Logic,"Subash Shankar, James Slagle","Connection methods have proven their value for efficient automated theorem proving in classical logics. However, these methods have not been extended to temporal logics due to the lack of a subformula property in existing proof procedures. We show that a slightly looser generalized subformula property exists for temporal logics. We then exploit this generalized subformula property to develop a temporal notion of polarities and connections, upon which we base an efficient proof procedure for propositional temporal logic. The proof procedure is structured around semantic tableau augmented with connections, and we propose a number of connection-based strategies. The procedure achieves many of the benefits of connection methods. The method is also sufficiently general to be extensible to other temporal logics. Experimental results indicate substantial speedup resulting from this approach.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-027.pdf,
27,1997,Constraint Satisfaction Problems and Bayes Networks,Bayes Networks for Estimating the Number of Solutions to a CSP,"Amnon Meisels, Solomon Eyal Shimony, Gadi Solotorevsky","The problem of counting the number of solutions to a constraint satisfaction problem (CSP) is rephrased in terms of probability updating in Bayes networks. Approximating the probabilities in Bayes networks is a problem which has been studied for a while, and may well provide a good approximation to counting the number of solutions. We use a simple approximation based on independence, and show that it is correct for tree-structured CSPs. For other CSPs, it is a less optimistic approximation than those suggested in prior work, and experiments show that it is more accurate on the average. We present empirical evidence that our approximation is a useful search heuristic for finding a single solution to a CSP.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-028.pdf,
28,1997,Constraint Satisfaction Problems and Bayes Networks,A Practical Algorithm for Finding Optimal Triangulations,"Kirill Shoikhet, Dan Geiger",An algorithm called QUICKTREE is developed for finding a triangulation T of a given undirected graph G such that the size of T’s maximal clique is minimum and such that no other triangulation of G is a subgraph of T. We have tested QUICKTREE on graphs of up to 100 nodes for which the maximum clique in an optimal triangulation is of size 11. This is the first algorithm that can optimally triangulate graphs of such size in a reasonable time frame. This algorithm is useful for constraint satisfaction problems and for Bayesian inference through the clique tree inference algorithm.,https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-029.pdf,
29,1997,Constraint Satisfaction Problems: Symmetry,Interchangeability Supports Abstraction and Reformulation for Multi-Dimensional Constraint Satisfaction,"Eugene C. Freuder, Daniel Sabin","Interchangeability provides a principled approach to abstraction and reformulation of constraint satisfaction problems. Values are interchangeable if exchanging one for the other in any solution produces another solution. Abstracting problem by simplifying the constraints can increase interchangeability. Multi-dimensional constraint satisfaction problems can provide natural opportunities for this abstraction process. Multi-dimensional problems may involve vectors of values, or conjunctive constraints. Utilizing the interchangeability can permit more efficient solutions of the abstracted problem. These solutions can be expanded into smaller reformulations of the original problem. Solving abstracted and then reformulated problems can be considerably more efficient than solving the original problems. We provide data that demonstrates the potential of this abstraction/reformulation process for multi-dimensional problems, and illuminates how its utility can depend on natural problem parameters.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-030.pdf,
30,1997,Constraint Satisfaction Problems: Symmetry,Exploiting Symmetry in Lifted CSPs,"David Joslin, Amitabha Roy","When search problems have large-scale symmetric structure, detecting and exploiting that structure can greatly reduce the size of the search space. Previous work has shown how to find and exploit symmetries in propositional encodings of constraint satisfaction problems (CSPs). Here we consider problems that have more compact ""lifted"" (quantified) descriptions from which propositional encodings can be generated. We describe an algorithm for finding symmetries in lifted representations of CSPs, and show sufficient conditions under which these symmetries can be mapped to symmetries in the propositional encoding. Using two domains (pigeonhole problems, and a CSP encoding of planning problems), we demonstrate experimentally that the approach of finding symmetries in lifted problem representations is a significant improvement over previous approaches that find symmetries in propositional encodings.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-031.pdf,
31,1997,Constraint Satisfaction Techniques,Using CSP Look-Back Techniques to Solve Real-World SAT Instances,"Roberto J. Bayardo Jr., Robert C. Schrag","We report on the performance of an enhanced version of the ""Davis-Putnam"" (DP) proof procedure for propositional satisfiability (SAT) on large instances derived from realworld problems in planning, scheduling, and circuit diagnosis and synthesis. Our results show that incorporating CSP lookback techniques -- especially the relatively new technique of relevance-bounded learning -- renders easy many problems which otherwise are beyond DP’s reach. Frequently they make DP, a systematic algorithm, perform as well or better than stochastic SAT algorithms such as GSAT or WSAT. We recommend that such techniques be included as options in implementations of DP, just as they are in systematic algorithms for the more general constraint satisfaction problem.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-032.pdf,
32,1997,Constraint Satisfaction Techniques,Using Branch-and-Bound with Constraint Satisfaction in Optimization Problems,Stephen Beale,"This work integrates three related AI search techniques - constraint satisfaction, branch-and-bound and solution synthesis - and applies the result to constraint satisfaction problems for which optimal answers are required. This method has already been shown to work well in natural language semantic analysis (Beale, et al, 1996); here we extend the domain to optimizing graph coloring problems, which are abstractions of many common scheduling problems of interest. We demonstrate that the methods used here allow us to determine optimal answers to many types of problems without resorting to heuristic search, and, furthermore, can be combined with heuristic search methods for problems with excessive complexity.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-033.pdf,
33,1997,Constraint Satisfaction Techniques,Detecting Unsatisfiable CSPs by Coloring the Micro-Structure,"Daya Ram Gaur, W. Ken Jackson, William S. Havens","Constraint satisfaction research has focused on consistency checking using k-consistency and its variations such as arc-consistency, and path-consistency. We define a new form of consistency checking that is based on coloring the micro-structure graph of a constraint satisfaction problem (CSP). In our formulation, if the micro-structure graph of a CSP with n variables can be colored with n - 1 colors then the problem is unsatisfiable. This new notion of consistency-by-coloring is compared to arc-consistency. We provide examples that show that neither arc-consistency nor consistency-by-coloring is more powerful than the other in a theoretical sense. We also describe the results of preliminary computational experiments that compare consistency-by-coloring and arc-consistency.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-034.pdf,
34,1997,Efficient Reasoning,Problem Structure in the Presence of Perturbations,"Carla P. Gomes, Bart Selman","Recent progress on search and reasoning procedures has been driven by experimentation on computationally hard problem instances. Hard random problem distributions are an important source of such instances. Challenge problems from the area of finite algebra have also stimulated research on search and reasoning procedures. Nevertheless, the relation of such problems to practical applications is somewhat unclear. Realistic problem instances clearly have more structure than the random problem instances, but, on the other hand, they are not as regular as the structured mathematical problems. We propose a new benchmark domain that bridges the gap between the purely random instances and the highly structured problems, by introducing perturbations into a structured domain. We will show how to obtain interesting search problems in this manner, and how such problems can be used to study the robustness of search control mechanisms. Our experiments demonstrate that the performance of search strategies designed to mimic direct constructive methods degrade surprisingly quickly in the presence of even minor perturbations.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-035.pdf,
35,1997,Efficient Reasoning,Model-Theoretic Semantics and Tractable Algorithm for CNF-BCP,"Rahul Roy-Chowdhury, Mukesh Dalal","CNF-BCP is a well-known propositional reasoner that extends clausal Boolean Constraint Propagation (BCP) to non-clausal theories. Although BCP has efficient linear-time implementations, CNF-BCP requires clausal form transformation that sometimes leads to an exponential increase in the size of a theory. We present a new quadratic-time reasoner, RFP, that infers exactly the same literals as CNF-BCP. Although CNF-BCP has been specified only syntactically, we present a simple model-theoretic semantics for RFP. We also present a convergent term-rewriting system for RFP that is suitable for reasoning with knowledge bases that are built incrementally. Potential applications of RFP include logical truth-maintenance systems and general-purpose knowledge representation systems.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-036.pdf,
36,1997,Heuristics for Scheduling,Beyond Contention: Extending Texture-Based Scheduling Heuristics,"J. Christopher Beck, Andrew J. Davenport, Edward M. Sitarski, Mark S. Fox","In order to apply texture measurement based heuristic commitment techniques beyond the unary capacity resource constraints of job shop scheduling, we extend the contention texture measurement to a measure of the probability that a constraint will be broken. We define three methods for the estimation of this probability and show that they perform as well or better than existing heuristics on job shop scheduling problems. Empirical insight into the performance is provided and we sketch how we have extended probability-based heuristics to more complicated scheduling constraints.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-037.pdf,
37,1997,Heuristics for Scheduling,Texture-Based Heuristics for Scheduling Revisited,"J. Christopher Beck, Andrew J. Davenport, Edward M. Sitarski, Mark S. Fox",Recent scheduling work has challenged the need for sophisticated heuristics such as those based on texture measurements. This paper examines these claims in the light of advances in scheduling technology. We compare a number of current heuristic commitment techniques against a texture-based heuristic. Our results demonstrate that texture-based heuristics can outperform these widely-used heuristic commitment techniques.,https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-038.pdf,
38,1997,Information Retrieval,Query Optimization Using Local Completeness,Oliver M. Duschka,"We consider the problem of query plan optimization in information brokers. Information brokers are programs that facilitate access to collections of information sources by hiding source-specific peculiarities and presenting uniform query interfaces. It is unrealistic to assume that data stored by information sources is complete. Therefore, current implementations of information brokers query all possibly relevant information sources in order not to miss any answers. This approach is very costly. We show how a weaker form of completeness, local completeness, can be used to minimize the number of accesses to information sources.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-039.pdf,
39,1997,Information Retrieval,Template-Based Information Mining from HTML Documents,"Jane Yung-jen Hsu, Wen-tau Yih","Tools for mining information from data can create added value for the Iqternet. As the majority of electronic documents available over the network are in unstructured textual form, extracting useful information from a document usually involves information retrieval techniques or manual processing. This paper presents a novel approach to mining information from HTML documents using tree-structured templates. In addition to syntactic and semantic descriptions, each template is designed to capture the logical structure of a class of documents. Experiments have been conducted to extract FAQ information automatically frorn over one hundred HTML documents collected from the Web. Using two basic templates, the prototype FAQ Miner has accurately analyzed 65% of the collection of FAQ documents. With additional processing to handle ""near-pass""es, the success rate is approximately 75%. The preliminary results have demonstrated the utility of structural templates for mining information from semi-structured text-based documents.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-040.pdf,
40,1997,Local Search: Beyond SAT,Local Search Algorithms for Partial MAXSAT,"Byungki Cha, Kazuo Iwama, Yahiko Kambayashi, Shuichi Miyazaki","MAXSAT solutions, i.e., near-satisfying assignments for propositional formulas, are sometimes meaningless for real-world problems because such formulas include ""mandatory clauses"" that must be all satisfied for the solution to be reasonable. In this paper, we introduce Partial MAXSAT and investigate how to solve it using local search algorithms. An instance of Partial MAXSAT consists of two formulas fA and fB, and its solution must satisfy all clauses in fA and as many clauses in fB as possible. The basic idea of our algorithm is to give weight to fA-clauses (the mandatory clauses) and then apply local search. We face two problems; (i) what amount of weight is appropriate and (ii) how to deal with the common action of local search algorithms, giving weight to clauses for their own purpose, which will hide the initial weight as the algorithms proceed.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-041.pdf,
41,1997,Local Search: Beyond SAT,Solving Linear Pseudo-Boolean Constraint Problems with Local Search,Joachim P. Walser,"Stochastic local search is one of the most successful methods for model finding in propositional satisfiability. However, many combinatorial problems have no concise propositional encoding. In this paper, we show that domain-independent local search for satisfiability (Walksat) can be generalized to handle systems of linear pseudo-Boolean (O-1 integer) constraints, a representation that is widely used in operations research. We introduce the algorithm WSAT (Rb) and demonstrate its potential in two case studies. The first application is an optimization problem from radar surveillance. Experiments on problems of realistic size show that WSAT (Pb) is an efficient heuristic to find good approximate solutions. For most of the test problems, it found provably optimal solutions. In the second case study, we show that pseudo-Boolean local search can efficiently solve the progressive party problem, a problem that is hard for constraint programming with chronological backtracking, and whose O-1 encoding is beyond the size limitations of integer linear programming.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-042.pdf,
42,1997,Local Search Techniques,Variable-Selection Heuristics in Local Search for SAT,Alex S. Fukunaga,"One of the important components of a local search strategy for satisfiability testing is the variable selection heuristic, which determines the next variable to be flipped. In a greedy local search such as GSAT, the major decision in variable selection is the strategy for breaking ties between variables that offer the same improvement in the number of unsatisfied clauses. In this paper, we analyze a number of tie-breaking strategies for GSAT and evaluate the strategies empirically using randomly generated 3-SAT instances from a hard distribution of random instances. We find that the property of fairness, which was proposed in the literature as being the critical property of a successful variable strategy, is not a sufficient property, and show that randomness plays a significant role in the success of variable selection heuristics.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-043.pdf,
43,1997,Local Search Techniques,Tabu Search for SAT,"Bertrand Mazure, Lakhdar SaÏs, Éric Grégoire","In this paper, tabu search for SAT is investigated from an experimental point of view. To this end, TSAT, a basic tabu search algorithm for SAT, is introduced and compared with Selman et al. Random Walk Strategy GSAT procedure, in short RWS-GSAT. TSAT does not involve the additional stochastic process of RWS-GSAT. This should facilitate the understanding of why simple local search methods for SAT work. It is shown that the length of the tabu list plays a critical role in the performance of the algorithm. Moreover, surprising properties about the (experimental) optimal length of the tabu list are exhibited, raising interesting issues about the nature of hard random SAT problems.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-044.pdf,
44,1997,Problem Solving & Computational Resources,Models of Continual Computation,Eric Horvitz,"Automated problem solving is viewed typically as the expenditure of computation to solve one or more problems passed to a reasoning system. In response to each problem received, effort is applied to generate a solution and problem solving ends when the solution is rendered. We discuss the notion of continual computation that addresses a broader conception of problem by considering the ideal use of the idle time between problem instances. The time is used to develop solutions proactively to one or more expected challenges in the future. We consider analyses for traditional all-or-nothing algorithms as well as more flexible computational procedures. After exploring the allocation of idle time for several settings, we generalize the analysis to consider the case of shifting computation from a current problem to solve future challenges. Finally, we discuss a sample application of the use of continual computation in the setting of diagnostic reasoning.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-045.pdf,
45,1997,Problem Solving & Computational Resources,Complex Goal Criteria and Its Application in Design-to-Criteria Scheduling,"Thomas Wagner, Alan Garvey, Victor Lesser","Difficult real-time AI problems require a means for expressing multi-dimensional and dynamic goal criteria and a principled model for satisficing to best meet the criteria. In the context of the Design-to-Criteria task scheduling paradigm, we define a new general client specification metaphor for describing such complex goal criteria or utility attributes, and couple it with a principled evaluation model for using the criteria. The criteria specification and corresponding evaluation mechanism are used throughout the Design-to-Criteria scheduling process to focus scheduling activities on solutions and partial solutions that are most likely to meet the criteria, i.e., to result in the focused production of custom satisficing schedules. Examples of the power of the approach at reducing the complexity of the scheduling task and designing custom satisficing schedules, are shown.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-046.pdf,
46,1997,Scheduling,Effective Redundant Constraints for Online Scheduling,"Lise Getoor, Greger Ottosson, Markus Fromherz, Björn Carlson","The use of heuristics as a means to improve constraint solver performance has been researched widely. However, most work has been on problem-independent heuristics (e.g., variable and value ordering), and has focused on offline problems (e.g., one-shot constraint satisfaction). In this paper, we present an online scheduling problem for which we are developing a real-tune scheduling algorithm. While we can and do use generic heuristics in the scheduler, here we focus on the use of domain-specific redundant constraints to effectively approximate optimal offline solutions. We present a taxonomy of redundant domain constraints, and examine their impact on the effectiveness of the scheduler. We also describe several techniques for generating redundant constraints, which can be applied to a large class of job shop scheduling problems.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-047.pdf,
47,1997,Scheduling,Stochastic Procedures for Generating Feasible Schedules,"Angelo Oddi, Stephen F. Smith","In this paper, we investigate the use of stochastic variable and value ordering heuristics for solving job shop scheduling problems with non-relaxable deadlines and complex metric constraints. Previous research in constraint satisfaction scheduling has developed highly effective, deterministic heuristics for this class of problems based on simple measures of temporal sequencing flexibility. However, they are not infallible, and the possibility of search failure raises the issue of how to most productively enlarge the search. Backtracking is one alternative, but such systematicity generally implies high computational cost. We instead design an iterative sampling procedure, based on the intuition that it is more productive to deviate from heuristic advice in cases where the heuristic is less informed, and likewise better to follow the heuristic in cases where it is more knowledgeable. 'We specify stochastic counterparts to previously developed search heuristics, which are parameterized to calibrate degree of randomness to level of discriminatory power. Experimental results on job shop scheduling CSPs of increasing size demonstrate comparative advantage over chronological backtracking. Comparison is also made to another, recently proposed iterative sampling technique called heuristic-biased stochastic sampling (HBSS). Whereas HBSS assumes a statically specified heuristic bias that is utilized at every application of the heuristic, our approach defines bias dynamically according to how well the heuristic discriminates alternatives.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-048.pdf,
48,1997,Search (Cost),The Scaling of Search Cost,"Ian P. Gent, Ewan MacIntyre, Patrick Prosser, Toby Walsh","We show that a resealed constrainedness parameter provides the basis for accurate numerical models of search cost for both backtracking and local search algorithms. In the past, the scaling of performance has been restricted to critically constrained problems at the phase transition. Here, we show how to extend models of search cost to the full width of the phase transition. This enables the direct comparison of algorithms on both under-constrained and overconstrained problems. We illustrate the generality of the approach using three different problem domains (satisfiability, constraint satisfaction and travelling salesperson problems) with both backtracking algorithms like the Davis-Putnam procedure and local search algorithms like GSAT. As well as modelling data from experiments, we give accurate predictions for results beyond the range of the experiments.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-049.pdf,
49,1997,Search (Cost),Evidence for Invariants in Local Search,"David McAllester, Bart Selman, Henry Kautz","It is well known that the performance of a stochastic local search procedure depends upon the setting of its noise parameter, and that the optimal setting varies with the problem distribution. It is therefore desirable to develop general priniciples for tuning the procedures. We present two statistical measures of the local search process that allow one to quickly find the optimal noise settings. These properties are independent of the fine details of the local search strategies, and appear to be relatively independent of the structure of the problem domains. We applied these principles to the problem of evaluating new search heuristics, and discovered two promising new strategies.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-050.pdf,
50,1997,Structure of Constraint Satisfaction Problems,Summarizing CSP Hardness with Continuous Probability Distributions,"Daniel Frost, Irina Rish, Lluís Vila","We present empirical evidence that the distribution of effort required to solve CSPs randomly generated at the 50% satisfiable point, when using a backtracking algorithm, can be approximated by two standard families of continuous probability distribution functions. Solvable problems can be modelled by the Weibull distribution, and unsolvable problems by the lognormal distribution. These distributions fit equally well over a variety of backtracking based algorithms.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-051.pdf,
51,1997,Structure of Constraint Satisfaction Problems,Exploiting the Deep Structure of Constraint Satisfaction Problems with Quantum Computers,Tad Hogg,"The deep structure of constraint satisfaction problems explains the association of hard search instances with a phase transition in problem solubility. This structure is also the basis of a quantum search algorithm exhibiting the phase trausition. In this paper, this algorithm is modified to incorporate additional problem structure. This modification is an example of a general method for inchding heuristics in quantum search. The new algorithm is evaluated empirically for random 3SAT, illustrating how quantum searches can benefit from using problem structure, on average.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-052.pdf,
52,1997,Structure of Constraint Satisfaction Problems,Clustering at the Phase Transition,Andrew J. Parkes,"Many problem ensembles exhibit a phase transition that is associated with a large peak in the average cost of solving the problem instances. However, this peak is not necessarily due to a lack of solutions: indeed the average number of solutions is typically exponentially large. Here, we study this situation within the context of the satisfiability transition in Random SSAT. We find that a significant subclass of instances emerges as we cross the phase transition. These instances are characterized by having about 85-95% of their variables occurring in unary prime implicates (UPIs), with their remaining variables being subject to few constraints. In such instances the models are not randomly distributed but all lie in a cluster that is exponentially large, but still admits a simple description. Studying the effect of UPIs on the local search algorithm WSAT shows that these ""single-cluster"" instances are harder to solve, and we relate their appearance at the phase transition to the peak in search cost.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-053.pdf,
53,1997,Computational Systems for Education,Realtime Generation of Customized 3D Animated Explanations for Knowledge-Based Learning Environments,"William H. Bares, James C. Lester","Rich 3D animated explanations can have a powerful impact on students interacting with immersive knowledge-based learning environments. By generating 3D animated explanations in realtime, a learning environment can create engaging explanations that are tailored to individual students. This paper presents the immersive explanation planning framework for generating pedagogically-customized 3D animated explanations in realtime. In this framework, an explanation system selects 3D models and their relevant behaviors, creates camera shots that most clearly depict complex phenomena, constructs a temporal organization that synchronizes narrative utterances with visual elements, plans the movement of the virtual camera that ""films"" the explanation, and incorporates specialized visual effects to focus students’ attention on the most salient concepts. The framework has been implemented in RAPID, an explanation system that plans and renders customized 3D animated explanations of dynamic phenomena in realtime. Results of a focus group evaluation of RAPID are encouraging.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-054.pdf,
54,1997,Computational Systems for Education,The Sounds of Silence: Towards Automated Evaluation of Student Learning in a Reading Tutor that Listens,"Jack Mostow, Gregory Aist","We propose a paradigm for ecologically valid, authentic, unobtrusive, automatic, data-rich, fast, robust, and sensitive evaluation of computer-assisted student performance. We instantiate this paradigm in the context of a Reading Tutor that listens to children read aloud, and helps them. We introduce inter-word latency as a simple prosodic measure of assisted reading performance. Finally, to validate the measure and analyze performance improvement, we report initial experimental results from the first extended in-school deployment of the Reading Tutor.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-055.pdf,
55,1997,Experimental Methodology,Presenting and Analyzing the Results of AI Experiments: Data Averaging and Data Snooping,"C. Lee Giles, Steve Lawrence","Experimental results reported in the machine learning AI literature can be misleading. This paper investigates the common processes of data averaging (reporting results in terms of the mean and standard deviation of the results from multiple trials) and data snooping in the context of neural networks, one of the most popular AI machine learning models. Both of these processes can result in misleading results and inaccurate conclusions. We demonstrate how easily this can happen and propose techniques for avoiding these very important problems. For data averaging, common presentation assumes that the distribution of individual results is Gaussian. However, we investigate the distribution for common problems and find that it often does not approximate the Gaussian distribution, may not be symmetric, and may be multimodal. We show that assuming Gaussian distributions can significantly affect the interpretation of results, especially those of comparison studies. For a controlled task, we find that the distribution of performance is skewed towards better performance for smoother target functions and skewed towards worse performance for more complex target functions. We propose new guidelines for reporting performance which provide more information about the actual distribution (e.g. box-whiskers plots). For data snooping, we demonstrate that optimization of performance via experimentation with multiple parameters can lead to significance being assigned to results which are due to chance. We suggest that precise descriptions of experimental techniques can be very important to the evaluation of results, and that we need to be aware of potential data snooping biases when formulating these experimental techniques (e.g. selecting the test procedure). Additionally, it is important to only rely on appropriate statistical tests and to ensure that any assumptions made in the tests are valid (e.g. normality of the distribution).",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-056.pdf,
56,1997,Building and Modifying Knowledge Bases,Building Concept Representations from Reusable Components,"Peter Clark, Bruce Porter","Our goal is to build knowledge-based systems capable of answering a wide variety of questions, including questions that are unanticipated when the knowledge base is built. For systems to achieve this level of competence and generality, they require the ability to dynamically construct new concept representations, and to do so in response to the questions and tasks posed to them. Our approach to meeting this requirement is to build knowledge bases of generalized, representational components, and to develop methods for automatically composing components on demand. This work extends the normal inheritance approach used in frame-based systems, and imports ideas from several different areas of AI, in particular compositional modeling, terminological reasoning, and ontological engineering. The contribution of this work is a novel integration of these methods that improves the efficiency of building knowledge bases and the robustness of using them.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-057.pdf,
57,1997,Building and Modifying Knowledge Bases,A Script-Based Approach to Modifying Knowledge Bases,"Yolanda Gil, Marcelo Tallis","Our goal is to build knowledge acquisition tools that support users in modifying knowledge-based systems. These modifications may require several individual changes to various components of the knowledge base, which need to be carefully coordinated to prevent users from leaving the knowledge-based system in an unusable state. This paper describes an approach to building knowledge acquisition tools which capture knowledge about commonly occurring modification sequences and support users in completing the modifications they start. These sequences, which we call ICA Scripts, relate individual changes and the effects that they have on the knowledge base. We discuss our experience in designing and compiling a library of KA Scripts. We also describe the implementation of a tool that uses them and our preliminary evaluations that demonstrate their usability.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-058.pdf,
58,1997,Description Logics,Representing Sequences in Description Logics,"Haym Hirsh, Daniel Kudenko","Representing and manipulating sequences in description logics (DLs) has typically been achieved through the use of new sequence-specific operators or by relying on host-language functions. This paper shows that it is not necessary to add additional features to a DL to handle sequences, and instead describes an approach for dealing with sequences as first-class entities directly within a DL without the need for extensions or extra-linguistic constructs. The key idea is to represent sequences using suffix trees, then represent the resulting trees in a DL using traditional (tractable) concept and role operators. This approach supports the representation of a variety of information about a sequence, such as the locations and numbers of occurrences of all subsequences of the sequence. Moreover, subsequence testing and pattern matching reduce to subsumption checking in this representation, while computing the least common subsumer of two terms supports the application of inductive learning to sequences.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-059.pdf,
59,1997,Description Logics,P-classIC: A Tractable Probablistic Description Logic,"Daphne Koller, Alon Levy, Avi Pfeffer","Knowledge representation languages invariably reflect a trade-off between expressivity and tractability. Evidence suggests that the compromise chosen by description logics is a particularly successful one. However, description logic (as for all variants of first-order logic) is severely limited in its ability to express uncertainty. In this paper, we present P-classIC, a probabilistic version of the description logic classIC. In addition to terminological knowledge, the language utilizes Bayesian networks to express uncertainty about the basic properties of an individual, the number of fillers for its roles, and the properties of these fillers. We provide a semantics for P-classIC and an effective inference procedure for probabilistic subsumption: computing the probability that a random individual in class C is also in class D. The effectiveness of the algorithm relies on independence assumptions and on our ability to execute lifted inference: reasoning about similar individuals as a group rather than as separate ground terms. We show that the complexity of the inference algorithm is the best that can be hoped for in a language that combines description logic with Bayesian networks. In particular, if we restrict to Bayesian networks that support polynomial time inference, the complexity of our inference procedure is also polynomial time.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-060.pdf,
60,1997,Knowledge Representation for Automated Reasoning,A Reflective Proof System for Reasoning in Contexts,Pierre E. Bonzon,"We consider the problem of building an automated proof system for reasoning in contexts. Towards that goal, we first define a language of contextual implications, and give its operational semantics under the form of a natural deduction system using explicit context assertions. We show that this proof system has an equivalent straightforward logic program, which in turn can be reified, i.e. defined as an outer meta-level context, and thus applied to itself. More powerful reasoning models (e.g. those involving theory lifting) can be then implemented by applying the same logic program on extended meta-level contexts containing specialized axioms. As a theoretical application, we consider the task of concept learning. In order to achieve generality (i.e. abstracting solution classes from problem instances), we argue that concept learning goals should aim at the discovery of meta-level operators representing the sequence of inference steps leading to object-level moves or actions. We illustrate this idea with the definition of a learning model based on partial deduction with respect to theory lifting.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-061.pdf,
61,1997,Knowledge Representation for Automated Reasoning,Obvious Properties of Computer Programs,Robert Givan,"We explore the question of what properties of LISP programs can be made ""obvious"" to a computer system. We present a polynomial-time algorithm for inferring interesting properties of pure LISP programs. Building on previous work in knowledge representation for rapid inference, we present a language for representing properties of programs. We treat properties as generalized types, i.e., sets of program values. The property language is expressive enough to represent any RE set of LISP values as a property, and can naturally represent ,a wide variety of useful properties. We then use a general technique to construct a polynomial-time property inference relation and use type-inference style program analysis to integrate this relation into an algorithm for inferring properties of programs. This algorithm is intended to work in the context of a library of background information, most of which is typically derived from previous runs of the algorithm. Due to the expressive representation system, no algorithm can infer every valid property -- so instead of proving completeness we show our algorithm’s usefulness by giving examples of properties inferred. These examples include that insertion sort returns a sorted permutation of its input, and that a clique finding program correctly returns a clique.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-062.pdf,
62,1997,Knowledge Representation: Expert Systems,Applications of Rule-Base Coverage Measures to Expert System Evaluation,Valerie Barr,"Often a rule-based system is tested by checking its performance on a number of test cases with known solutions, modifying the system until it, gives the correct results for all or a sufficiently high proportion of the test cases. This method cannot guarantee that the rule-base has been adequately or completely covered during the testing process. We introduce an approach to testing of rule-based systems which uses coverage measures to guide and evaluate the testing process. In addition, the coverage measures can be used to assist rule-base pruning and identification of class dependencies, and serve as the foundation for a set of test data selection heuristics. We also introduce a complexity metric for rule-bases.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-063.pdf,
63,1997,Knowledge Representation: Expert Systems,Detecting Redundant Production Rules,"James G. Schmolze, Wayne Snyder","We present a general method for detecting redundant production rules based upon a term rewrite semantics. We present the semantic account, define rule execution over both ground memories and memory schemas, and define redundancy for production rules. From those definitions, an algorithm is developed that detects redundant rules, and which improves upon previously published methods.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-064.pdf,
64,1997,Knowledge Representation: Nonmonotonic Logic,A Comparison of Two Approaches to Splitting Default Theories,Grigoris Antoniou,"Default logic is computationally expensive. One of the most promising ways of easing this problem and developing powerful implementations is to split a default theory into smaller parts and compute extensions in a modular, ""local"" way. This paper compares two recent approaches, Turner’s splitting and Cholewinski’s stratification. It shows that the approaches are closely related - in fact the former can be viewed as a special case of the latter.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-065.pdf,
65,1997,Knowledge Representation: Nonmonotonic Logic,Reasoning with Minimal Belief and Negation as Failure: Algorithms and Complexity,Riccardo Rosati,"We study the computational properties of the propositional fragment of MBNF, the logic of minimal belief and negation as failure introduced by Lifschitz, which can be considered as a unifying framework for several nonmonotonic formalisms, including default logic, autoepistemic logic, circumscription, epistemic queries and logic programming. We characterize the complexity and provide algorithms for reasoning in propositional MBNF. In particular, we show that skeptical entailment in propositional MBNF is pp3-complete, hence, it is harder than reasoning in all the above mentioned propositional formalisms for nonmonotonic reasoning. We also prove the exact correspondence between negation as failure in MBNF and negative introspection in Moore’s autoepistemic logic.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-066.pdf,
66,1997,Knowledge Representation: Ontologies,Tools for Assembling Modular Ontologies in Ontolingua,"Richard Fikes, Adam Farquhar, James Rice","The Ontolingua ontology development environment provides a suite of ontology authoring tools and a library of modular, reusable ontologies. The environment is available as a World Wide Web service and has a substantial user community. The tools in Ontolingua are oriented toward the authoring of ontologies by assembling and extending ontologies obtained from a library. In this paper, we describe Ontolingua’s formalism for combining the axioms, definitions, and words (non-logical symbols) of multiple ontologies. We also describe Ontolingua’s facilities that enable renaming of words from multiple component ontologies and that provide unambiguous mapping between words and text strings during input and output. These features support cyclic inclusion graphs and enable users to extend ontologies in multiple ways such as adding simplifying assumptions and extending the domains of polymorphic operators.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-067.pdf,
67,1997,Knowledge Representation: Ontologies,Efficient Management of Very Large Ontologies,"Kilian Stoffel, Merwyn Taylor, Jim Hendler","This paper describes an environment for supporting very large ontologies. The system can be used on single PCs, workstations, a cluster of workstations, and high-end parallel supercomputers. The architecture of the system uses the secondary storage of a relational data base system, efficient memory management, and (optionally) parallelism. This allows us to answer complex queries in very large ontologies in a few seconds on a single processor machine and in fractions of a second on parallel super computers. The main contribution of our approach is the open architecture of the system on both the hardware and the software levels allowing us easily to translate existing ontologies for our system’s use, and to port the system to a wide range of platforms.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-068.pdf,
68,1997,Knowledge Representation: Reasoning about Action,Beyond Minimizing Change,Tom Costello,"We introduce a new methodology for comparing non-monotonic treatments of change. We consider the elaboration tolerance of a non-monotonic approach is defined as the elaborations, or changes, that can be made to the non-monotonic consequences, by conjoining on new information. The standard problem, the frame assumption, is capturing the tendence of properties to persist over time. We show that almost all approaches allow new effects to be added, and preconditions to be dropped. There are other ways of describing the world, and we investigate one in particular, assuming there are as few preconditions for an action as possible. This is equivalent to assuming that actions change properties as often as possible, if the ever change that property. We show that this assumption is in conflict with the usual frame assumption. We show that this methodology allows new effects to be added, and preconditions to be added. We show that this precondition assumption is naturally opposite to the frame assumption. We then show that this assumption can be naturally captured in a similar way to the frame problem, using circumscription.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-069.pdf,
69,1997,Knowledge Representation: Reasoning about Action,Adding Knowledge to the Action Description Language A,"Jorge Lobo, Gisela Mendez, Stuart R. Taylor","We introduce Ak an extension of the action description language A to handle actions which affect knowledge. We use sensing actions to increase an agent’s knowledge of the world and non-deterministic actions to remove knowledge. We include complex plans involving conditionals and loops in our query language for hypothetical reasoning. Finally, we present a translation of descriptions in Ak to epistemic logic programs.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-070.pdf,
70,1997,Knowledge Representation: Reasoning about Action,Causal Theories of Action and Change,"Norman McCain, Hudson Turner","For many commonsense reasoning tasks associated with action domains, only a relatively simple kind of causal knowledge (previously studied by Geffner and Lin) is required. We define a mathematically simple language for expressing knowledge of this kind and describe a general approach to formalizing action domains in it. The language can be used to express ramification and qualification constraints, explicit definitions, concurrency, nondeterminism, and dynamic domains in which things change by themselves.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-071.pdf,
71,1997,Knowledge Representation: Reasoning about Action,Qualified Ramifications,Michael Thielscher,"We consider the problem of ramifications, i.e., indirect effects of actions, having exceptions. It is argued that straightforward minimization of abnormality is insufficient in this context. Taking a recent causality-based solution to the plain Ramification Problem as starting point, we develop an action theory that is shown to successfully address this amalgamation of Ramification and Qualification Problem.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-072.pdf,
72,1997,Knowledge Representation: Theorem Proving,Ordered Semantic Hyper Linking,"David A. Plaisted, Yunshan Zhu","In this paper, we present a novel first order theorem proving strategy -- ordered semantic hyper linking. Ordered semantic hyper linking (OSHL) is an instance-based refutational theorem proving strategy. It is sound and complete. OSHL has an efficient propositional decision procedure. It solves first order problems by reducing them to propositional problems. It uses natural semantics of an input problem to guide its search. It also incorporates term rewriting to handle equality. The propositional efficiency, semantic guidance and equality support allow OSHL to solve problems that are difficult for many other strategies. The efficiency of OSHL is supported by experimental study as well as complexity analysis.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-073.pdf,
73,1997,Knowledge Representation: Theorem Proving,Extending the Regular Restriction of Resolution to Non-Linear Subdeductions,"Bruce Spencer, J. D. Horton","A binary resolution proof, represented as a binary tree, is irregular if some atom is resolved away and reappears on the same branch. We develop an algorithm, linear in the size of the tree, which detects whether reordering the resolutions in a given proof will generate an irregular proof. If so, the given proof is not minimal. A deduction system that keeps only minimal proofs retains completeness. We report on an initial implementation.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-074.pdf,
74,1997,Formal Analyses of Learning,Worst-Case Absolute Loss Bounds for Linear Learning Algorithms,Tom Bylander,"The absolute loss is the absolute difference between the desired and predicted outcome. I demonstrate worst-case upper bounds on the absolute loss for the perceptron algorithm and an exponentiated update algorithm related to the Weighted Majority algorithm. The bounds characterize the behavior of the algorithms over any sequence of trials, where each trial consists of an example and a desired outcome interval (any value in the interval is an acceptable outcome). The worstcase absolute loss of both algorithms is bounded by: the absolute loss of the best linear function in the comparison class, plus a constant dependent on the initial weight vector, plus a per-trial loss. The per-trial loss can be eliminated if the learning algorithm is allowed a tolerance from the desired outcome. For concept learning, the worst-case bounds lead to mistake bounds that are comparable to previous results.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-075.pdf,
75,1997,Formal Analyses of Learning,Version Spaces without Boundary Sets,"Haym Hirsh, Nina Mishra, Leonard Pitt","This paper shows that it is not necessary to maintain boundary sets to reason using version spaces. Rather, most of the operations typically performed on version spaces for a concept class can be tractably executed directly on the training data, as long as it is tractable to solve the consistency problem for that concept class - to determine whether there exists any concept in the concept class that correctly classifies the data. The equivalence of version-space learning to the consistency problem bridges a gap between empirical and theoretical approaches to machine learning, since the consistency problem is already known to be critical to learning in the PAC (Probably Approximately Correct) sense. By exhibiting this link to the consistency problem, we broaden the class of problems to which version spaces can be applied to include concept classes where boundary sets can have exponential or infinite size and cases where boundary sets are not even well defined.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-076.pdf,
76,1997,Formal Analyses of Learning,"Representation, Search and Genetic Algorithms","Darrell Whitley, Soraya B. Rana","Wolpert and Macready’s No Free Lunch theorem proves that no search algorithm is better than any other over all possible discrete functions. The meaning of the No Free Lunch theorem has, however, been the subject of intense debate. We prove that for local neighborhood search on problems of bounded complexity, where complexity is measured in terms of number of basins of attraction in the search space a Gray coded representation is better than Binary in the sense that on average it induces fewer minima in a Hamming distance 1 search neighborhood.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-077.pdf,
77,1997,Knowledge Discovery in Databases,Pattern Discovery in Distributed Databases,"Raj Bhatnagar, Sriram Srinivasan","Most algorithms for learning and pattern discovery in data assume that all the needed data is available on one computer at a single site. This assumption does not hold in situations where a number of independent databases reside on geographically distributed nodes of a computer network. These databases cannot be moved to a single site due to size, security, privacy and data-ownership concerns but all of them together constitute the dataset in which patterns must be discovered. Some pattern discovery algorithms can be adapted to such situations and some others become inefficient or inapplicable. In this paper we show how a decision-tree induction algorithm may be adapted for distributed data situations. We also discuss some general issues relating to the adaptability of other pattern discovery algorithms to distributed data situations.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-078.pdf,
78,1997,Knowledge Discovery in Databases,More Efficient Windowing,Johannes Fürnkranz,"Windowing has been proposed as a procedure for efficient memory use in the ID3 decision tree learning algorithm. However, previous work has shown that windowing may often lead to a decrease in performance. In this work, we try to argue that rule learning algorithms are more appropriate for windowing than decision tree algorithms, because the former typically learn and evaluate rules independently and are thus less susceptible to changes in class distributions. Most importantly, we present a new windowing algorithm that achieves additional gains in efficiency by saving promising rules and removing examples covered by these rules from the learning window. While the presented algorithm is only suitable for redundant, noise-free data sets, we will also briefly discuss the problem of noisy data for windowing algorithms.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-079.pdf,
79,1997,Learning In Linguistic Domains,Maximally Parsimonious Discrimination: A Generic Task from Linguistic Discovery,"Raúl Valdes-Pérez, Vladimir Pericliev","Data-driven model building is an important task of scientific discovery that is seeing real success in the development and application of discovery programs. Most efforts have targeted fields of natural science in which the hypothesis spaces are specialized and deal with domains having considerable formal structure. Less work has been directed toward qualitative areas of social science, in which model building also arises. This paper reports the first automation of a modelling task from linguistic anthropology: the analysis of natural-language kinship terminologies in terms of simpler semantic components. Our approach uses three generic simplicity criteria to comprehensively find all the simplest models that are consistent with kinship data. We have reproduced results from the linguistics literature, but have also found simpler models in some cases. The task has strong generic elements: extracts of the code are applied to other data sets to illustrate this potential.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-080.pdf,
80,1997,Learning In Linguistic Domains,"Sparse Representations for Fast, One-Shot Learning","Kenneth Yip, Gerald Jay Sussman",Humans rapidly and reliably learn many kinds of regularities and generalizations. We propose a novel model of fast learning that exploits the properties of sparse representations and the constraints imposed by a plausible hardware mechanism. To demonstrate our approach we describe a computational model of acquisition in the domain of morphophonology. We encapsulate phonological information as bidirectional boolean constraint relations operating on the classical linguistic representations of speech sounds in term of distinctive features. The performance model is described as a hardware mechanism that incrementally enforces the constraints. Phonological behavior arises from the action of this mechanism. Constraints are induced from a corpus of common English nouns and verbs. The induction algorithm compiles the corpus into increasingly sophisticated constraints. The algorithm yields one-shot learning from a few examples. Our model has been implemented as a computer program. The program exhibits phonological behavior similar to that of young children. As a bonus the constraints that are acquired can be interpreted as classical linguistic rules.,https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-081.pdf,
81,1997,Machine Learning (Probabilistic),Intelligent Methods for File System Optimization,"Leo Kuvayev, C. L. Giles, J. Philbin, H. Cejtin","The speed of I/O components is a major limitation of the speed of all other major components in today’s computer systems. Motivated by this, we investigated several algorithms for erfficient and intelligent organization of files on a hard disk. Total access time may be decreased if files with temporal locality also have spatial locality. Three intelligent methods based on file type, frequency, and transition probabilities information showed up to 60% savings of total I/O time over the naive placement of files. More computationally intensive hill climbing and genetic algorithms approaches did not outperform statistical methods. The experiments were run on a real and simulated hard drive in single and multiple user environments.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-082.pdf,
82,1997,Machine Learning (Probabilistic),Learning Bayesian Networks from Incomplete Data,Moninder Singh,"Much of the current research in learning Bayesian Networks fails to effectively deal with missing data. Most of the methods assume that the data is complete, or make the data complete using fairly ad-hoc methods; other methods do deal with missing data but learn only the conditional probabilities, assuming that the structure is known. We present a principled approach to learn both the Bayesian network structure as well as the conditional probabilities from incomplete data. The proposed algorithm is an iterative method that uses a combination of Expectation-Maximization (EM) and Imputation techniques. Results are presented on synthetic data sets which show that the performance of the new algorithm is much better than ad-hoc methods for handling missing data.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-083.pdf,
83,1997,Model Selection and Overfitting,Lessons in Neural Network Training: Overfitting May be Harder than Expected,"Steve Lawrence, C. Lee Giles, Ah Chung Tsoi","For many reasons, neural networks have become very popular AI machine learning models. Two of the most important aspects of machine learning models are how well the model generalizes to unseen data, and how well the model scales with problem complexity. Using a controlled task with known optimal training error, we investigate the convergence of the backpropagation (BP) algorithm. We find that the optimal solution is typically not found. Furthermore, we observe that networks larger than might be expected can result in lower training and generalization error. This result is supported by another real world example. We further investigate the training behavior by analyzing the weights in trained networks (excess degrees of freedom are seen to do little harm and to aid convergence), and contrasting the interpolation characteristics of multi-layer perceptron neural networks (MLPs) and polynomial models (overfitting behavior is very different - the MLP is often biased towards smoother solutions). Finally, we analyze relevant theory outlining the reasons for significant practical differences. These results bring into question common beliefs about neural network training regarding convergence and optimal network size, suggest alternate guidelines for practical use (lower fear of excess degrees of freedom), and help to direct future work (e.g. methods for creation of more parsimonious solutions, importance of the MLP/BP bias and possibly worse performance of ""improved"" training algorithms).",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-084.pdf,
84,1997,Model Selection and Overfitting,An Empirical Evaluation of Bagging and Boosting,"Richard Maclin, David Opitz","An ensemble consists of a set of independently trained classifiers (such as neural networks or decision trees) whose predictions are combined when classifying novel instances. Previous research has shown that an ensemble as a whole is often more accurate than any of the single classifiers in the ensemble. Bagging and Boosting are two relatively new but popular methods for producing ensembles. In this paper we evaluate these methods using both neural networks and decision trees as our classification algorithms. Our results clearly show two important facts. The first is that even though Bagging almost always produces a better classifier than any of its individual component classifiers and is relatively impervious to overfitting, it does not generalize any better than a baseline neural-network ensemble method. The second is that Boosting is a powerful technique that can usually produce better ensembles than Bagging; however, it is more susceptible to noise and can quickly overfit a data set.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-085.pdf,
85,1997,Model Selection and Overfitting,A New Metric-Based Approach to Model Selection,Dale Schuurmans,"We introduce a new approach to model selection that performs better than the standard complexity-penalization and hold-out error estimation techniques in many cases. The basic idea is to exploit the intrinsic metric structure of a hypothesis space, as determined by the natural distribution of unlabeled training patterns, and use this metric as a reference to detect whether the empirical error estimates derived from a small (labeled) training sample can be trusted in the region around an empirically optimal hypothesis. Using simple metric intuitions we develop new geometric strategies for detecting overfitting and performing robust yet responsive model selection in spaces of candidate functions. These new metric-based strategies dramatically outperform previous approaches in experimental studies of classical polynomial curve fitting. Moreover, the technique is simple, efficient, and can be applied to most function learning tasks. The only requirement is access to an auxiliary collection of unlabeled training data.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-086.pdf,
86,1997,Parallelism in Learning,Maximizing the Benefits of Parallel Search Using Machine Learning,"Diane J. Cook, R. Craig Varnell","Many of the artificial intelligence techniques developed to date rely on heuristic search through large spaces. Unfortunately, the size of these spaces and corresponding computational effort reduce the applicability of otherwise novel and effective algorithms. A number of parallel and distributed approaches to search have considerably improved the performance of certain aspects of the search process. In this paper we describe the EUREKA system, which combines the benefits of many different approaches to parallel heuristic search. EUREKA uses a machine learning system to decide upon the optimal parallel search strategy for a given problem space. When a new search task is input to the system, EUREKA gathers information about the search space and automatically selects the appropriate search strategy. EUREKA includes diverse approaches to task distribution, load balancing, and tree ordering, and has been tested on a MIMD parallel processor, a distributed network of workstations, and a single workstation using multi-threading. Results in the fifteen puzzle domain, robot arm path planning domain, and an artificial domain indicate that EUREKA outperforms any existing strategy used exclusively for all problem instances.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-087.pdf,
87,1997,Parallelism in Learning,Generating C4.5 Production Rules in Parallel,Richard Kufrin,"Induction systems that represent concepts in the form of production rules have proven to be useful in a variety of domains where both accuracy and comprehensibility of the resulting models are important. However, the computational requirements for inducing a set of rules from large, noisy training sets can be enormous, so that techniques for improving the performance of rule induction systems by exploiting parallelism are of considerable interest. Recent work to parallelize the C4.5 rule generator algorithm is described. After presenting an overview of the algorithm and the parallelization strategy employed, empirical results of the parallel implementation that demonstrate substantial speedup over serial execution are provided.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-088.pdf,
88,1997,Reactive Behavior,Detecting and Reacting to Unplanned-for World States,"Ella M. Atkins, Edmund H. Durfee, Kang G. Shin","The degree to which a planner succeeds and meets response deadlines depends on the correctness and completeness of its modelstwhich describe events and actions that change the world state. It is often unrealistic to expect perfect models, so a planner must detect and respond to states it had not planned to handle. In this paper, we characterize different classes of these ""unhandled"" states and describe planning algorithms to build tests for, and later respond to them. We have implemented these unhandled state detection and response algorithms in the Cooperative Intelligent Real-time Control Architecture (CIRCA), and present experiments from flight simulation that show how the new algorithm enables a fully-automated aircraft to react appropriately to certain classes of unhandled states, averting failure and giving the aircraft a new chance to achieve its goals.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-089.pdf,
89,1997,Reactive Behavior,Reinforcement Learning with Time,Daishi Harada,"This paper steps back from the standard infinite horizon formulation of reinforcement learning problems to consider the simpler case of finite horizon problems. Although finite horizon problems may be solved using infinite horizon learning algorithms by recasting the problem as an infinite horizon problem over a state space extended to include time, we show that such an application of infinite horizon learning algorithms does not make use of what is known about the environment structure, and is therefore inefficient. Preserving a notion of time within the environment allows us to consider extending the environment model to include, for example, random action duration. Such extentions allow us to model non-Markov environments which can be learned using reinforcement learning algorithms.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-090.pdf,
90,1997,Text Retrieval and Learning,Transferring and Retraining Learned Information Filters,"William W. Cohen, Daniel Kudenko","Any system that learns how to filter documents will suffer poor performance during an initial training phase. One way of addressing this problem is to exploit filters learned by other users in a collaborative fashion. We investigate ""direct transfer"" of learned filters in this setting-a limiting case for any collaborative learning system. We evaluate the stability of several different learning methods under direct transfer, and conclude that symbolic learning methods that use negatively correlated features of the data perform poorly in transfer, even when they perform well in more conventional evaluation settings. This effect is robust: it holds for several learning methods, when a diverse set of users is used in training the classifier, and even when the learned classifiers can be adapted to the new user’s distribution. Our experiments give rise to several concrete proposals for improving generalization performance in a collaborative setting, including a beneficial variation on a feature selection method that has been widely used in text categorization.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-091.pdf,
91,1997,Text Retrieval and Learning,Active Learning with Committees for Text Categorization,"Ray Liere, Prasad Tadepalli","In many real-world domains, supervised learning requires a large number of training examples. In this paper, we describe an active learning method that uses a committee of learners to reduce the number of training examples required for learning. Our approach is similar to the Query by Committee framework, where disagreement among the committee members on the predicted label for the input part of the example is used to signal the need for knowing the actual value of the label. Our experiments are conducted in the text categorization domain, which is characterized by a large number of features, many of which are irrelevant. We report here on experiments using a committee of Winnow-based learners and demonstrate that this approach can reduce the number of labeled training examples required over that used by a single Winnow learner by l-2 orders of magnitude.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-092.pdf,
92,1997,Language and Learning,Statistical Parsing with a Context-Free Grammar and Word Statistics,Eugene Charniak,"We describe a parsing system based upon a language model for English that is, in turn, based upon assigning probabilities to possible parses for a sentence. This model is used in a parsing system by finding the parse for the sentence with the highest probability. This system outperforms previous schemes. As this is the third in a series of parsers by different authors that are similar enough to invite detailed comparisons but different enough to give rise to different levels of performance, we also report on some experiments designed to identify what aspects of these systems best explain their relative performance.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-093.pdf,
93,1997,Language and Learning,A New Supervised Learning Algorithm for Word Sense Disambiguation,"Ted Pedersen, Rebecca Bruce","The Naive Mix is a new supervised learning algorithm that is based on a sequential method for selecting probabilistic models. The usual objective of model selection is to find a single model that adequately characterizes the data in a training sample. However, during model selection a sequence of models is generated that consists of the best-fitting model at each level of model complexity. The Naive Mix utilizes this sequence of models to define a probabilistic model which is then used as a probabilistic classifier to perform word-sense disambiguation. The models in this sequence are restricted to the class of decomposable log-linear models. This class of models offers a number of computational advantages. Experiments disambiguating twelve different words show that a Naive Mix formulated with a forward sequential search and Akaike’s Information Criteria rivals established supervised learning algorithms such as decision trees (C4.5), rule induction (CN2) and nearest-neighbor classification (PEBLS).",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-094.pdf,
94,1997,Natural Language,A Pragmatic Treatment of Quantification in Natural Language,"Walid S. Saba, Jean-Pierre Corriveau","Quantification in natural language is an important phenomena that seems to touch on some pragmatic and inferential aspects of language understanding. In this paper we focus on quantifier scope ambiguity and suggest a cognitively plausible model that resolves a number of problems that have traditionally been addressed in isolation. Our claim here is that the problem of quantifier scope ambiguity can not be adequately addressed at the syntactic and semantic levels, but is an inferencing problem that must be addressed at the pragmatic and discourse levels.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-095.pdf,
95,1997,Natural Language,Comparatives in Context,"Steffen Staab, Udo Hahn","We propose a model of semantic interpretation of comparatives which is based on a mechanism for semantic copying. Besides common phrasal and clausal forms of comparatives, our model also incorporates the analysis of referential and textual phenomena that interact with the interpretation of comparatives, viz. metonymies and omitted complements. In order to allow for efficient processing, guidance from syntactic, semantic, contextual and world knowledge sources is supplied.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-096.pdf,
96,1997,Natural Language Generation,Multi-Document Summarization by Graph Search and Matching,"Inderjeet Mani, Eric Bloedorn","We describe a new method for summarizing similarities and differences in a pair of related documents using a graph representation for text. Concepts denoted by words, phrases, and proper names in the document are represented positionally as nodes in the graph along with edges corresponding to semantic relations between items. Given a perspective in terms of which the pair of documents is to be summarized, the algorithm first uses a spreading activation technique to discover, in each document, nodes semantically related to the topic. The activated graphs of each document are then matched to yield a graph corresponding to similarities and differences between the pair, which is rendered in natural language. An evaluation of these techniques has been carried out.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-097.pdf,
97,1997,Natural Language Generation,From Local to Global Coherence: A Bottom-Up Approach to Text Planning,Daniel Marcu,"We present a new, data-driven approach to text planning, which can be used not only to map full knowledge pools into natural language texts, but also to generate texts that satisfy multiple, high-level communicative goals. The approach explains how global coherence can be achieved by exploiting the local coherence constraints of rhetorical relations. The local constraints were derived from a corpus analysis.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-098.pdf,
98,1997,Multi-Agent Systems,Interference as a Tool for Designing and Evaluating Multi-Robot Controllers,"Dani Goldberg, Maja J. Mataric","Designing and implementing cooperative group behaviors for robots is considered something of a black art involving an extensive amount of reprogramming and parameter adjustment. What seems to be lacking is a pragmatic, practical, general-purpose tool that would both guide the design and structure the evaluation of controllers for distributed real-world multi-robot tasks. In this paper, we propose the use of interference between robots as one such simple tool for designing and evaluating multi-robot controllers. We explore how key issues in multi-robot control can be addressed using interference, a directly measurable property of a multi-robot system. We discuss how behavior arbitration schemes, i.e., the choice of controllers, can be made and adjusted using interference. As an experimental example, we demonstrate three different implementations of a collection clean-up (foraging) task using four physical mobile robots, and present analyses of the experimental data gathered from trials of all three implementations.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-099.pdf,
99,1997,Multi-Agent Systems,Using Communication to Reduce Locality in Multi-Robot Learning,Maja J. Mataric,"This paper attempts to bridge the fields of machine learning, robotics, and distributed AI. It discusses the use of communication in reducing the undesirable effects of locality in fully distributed multi-agent systems with multiple agents/robots learning in parallel while interacting with each other. Two key problems, hidden state and credit assignment, are addressed by applying local undirected broadcast communication in a dual role: as sensing and as reinforcement. The methodology is demonstrated on two multi-robot learning experiments. The first describes learning a tightly-coupled coordination task with two robots, the second a loosely-coupled task with four robots learning social rules. Communication is used to share sensory data to overcome hidden state and reinforcement to overcome the credit assignment problem between the agents and to bridge the gap between local and global payoff.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-100.pdf,
100,1997,Navigation & Perception,Spatial Navigation with Uncertain Deviations,"Michel de Rougemont, Christoph Schlieder","We consider geometrical scenes with obstacles and landmarks that can’t necessarily be distinguished and generalize the notion of panoramas (Sch93; Her94), introduced in the qualitative Spatial Reasoning (QSR) approaches to robot navigation. We study various notions of motion strategies in the accessibility graph associated with the local panoramas under uncertain deviations, a natural model of uncertainty for motion planning and navigation. We show that randomized motion strategies can be better than deterministic ones with a finite memory and stress the usefulness of random decisions for qualitative spatial reasoning.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-101.pdf,
101,1997,Navigation & Perception,A Color Interest Operator for Landmark-Based Navigation,"Zachary Dodds, Gregory D. Hager","Landmark-based approaches to robot navigation require an ""interest operator"" to estimate the utility of a particular image region as an effective representative for a scene. This paper presents a color interest operator consisting of a weighted combination of heuristic scores. The operator selects those image regions (landmarks) likely to be found again, even under a different viewing geometry and/or diRerent illumination conditions. These salient regions yield a robust representation for recognition of a scene. Experiments showing the reproduceability of the regions selected by this operator demonstrate its use as a hedge against environment al uncertainties.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-102.pdf,
102,1997,Navigation & Perception,Combining Approximate Front End Signal Processing with Selective Reprocessing in Auditory Perception,"Frank Klassner, Victor Lesser, Hamid Nawab","When dealing with signals from complex environments, where multiple time-dependent signal signatures can interfere with each other in stochastically unpredictable ways, traditional perceptual systems tend to fall back on a strategy of always performing finely-detailed, costly analysis of the signal with a comprehensive front end set of signal processing algorithms (SPAS), whether or not the current scenario requires the extra detail. Approximate SPAS (ASPAs) - algorithms whose processing time can be limited in order to trade off precision in their outputs for reduced execution time - can play a role in producing adaptive, less-costly front ends, but their outputs tend to require context-dependent analysis for use as evidence in interpretation. This paper examines the IPUS (Integrated Processing and Understanding of Signals) architecture’s ability to serve as a support framework for applying ASPAs in interpretation problems. Specifically, our work shows that it is feasible to include an approximate version of the Short-Time Fourier Transform in an IPUS-based sound-understanding testbed.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-103.pdf,
103,1997,Case-Based Reasoning and Planning,Analogical Replay for Efficient Conditional Planning,"Jim Blythe, Manuela Veloso","Recently, several planners have been designed that can create conditionally branching plans to solve problems which involve uncertainty. These planners represent an important step in broadening the applicability of AI planning techniques, but they typically must search a larger space than non-branching planners, since they must produce valid plans for each branch considered. In the worst case this can produce an exponential increase in the complexity of planning. If conditional planners are to become usable in real-world domains, this complexity must be controlled by sharing planning effort among branches. Analogical plan reuse should play a fundamental role in this process. We have implemented a conditional probabilistic planner that uses analogical plan replay to derive the maximum benefit from previously solved branches of the plan. This approach provides valuable guidance for when and how to merge different branches of the plan and exploits the high similarity between the different branches in a conditional plan, which have the same goal and typically a very similar state. We present experimental data in which analogical plan replay significantly reduces the complexity of conditional planning. Analogical replay can be applied to a variety of conditional planners, complementing the plan sharing that they may perform naturally.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-104.pdf,
104,1997,Case-Based Reasoning and Planning,Case-Based Similarity Assessment: Estimating Adaptability from Experience,"David B. Leake, Andrew Kinley, David Wilson","Case-based problem-solving systems rely on similarity assessment to select stored cases whose solutions are easily adaptable to fit current problems. However, widely-used similarity assessment strategies, such as evaluation of semantic similarity, can be poor predictors of adaptability. As a result, systems may select cases that are difficult or impossible for them to adapt, even when easily adaptable cases are available in memory. This paper presents a new similarity assessment approach which couples similarity judgments directly to a case library containing the systemIs adaptation knowledge. It examines this approach in the context of a case-based planning system that learns both new plans and new adaptations. Empirical tests of alternative similarity assessment strategies show that this approach enables better case selection and increases the benefits accrued from learned adaptations.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-105.pdf,
105,1997,Flexible Hierarchical Planning,Dynamic Abstraction Planning,"Robert P. Goldman, David J. Musliner, Kurt D. Krebsbach, Mark S. Boddy","This paper describes Dynamic Abstraction Planning (DAP), an abstraction planning technique that improves the efficiency of state-enumeration planners for real-time embedded systems such as CIRCA. Abstraction is used to remove detail from the state representation, reducing both the size of the state space that must be explored to produce a plan and the size of the resulting plan. The intuition behind this approach is simple: in some situations, certain world features are important, while in other situations those same features are not important. By automatically selecting the appropriate level of abstraction at each step during the planning process, DAP can significantly reduce the size of the search space. Furthermore, the planning process can supply initial plans that preserve safety but might, on further refinement, do a better job of goal achievement. DAP can also terminate with an executable abstract plan, which may be much smaller than the corresponding plan expanded to precisely-defined states. Preliminary results show dramatic improvements in planning speed and scalability.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-106.pdf,
106,1997,Flexible Hierarchical Planning,Abductive Completion of Plan Sketches,Karen L. Myers,"Most work on AI planning has focused on the development of fully automated methods for generating plans that satisfy user-specified goals. However, users in many domains want the ability to influence the nature of the solutions that are generated. With the objective of fostering increased user participation in the planning process, this paper presents an HTN-based framework for the abductive completion of plan sketches. Within this framework, user-supplied outlines of partial plans (possibly spanning multiple abstraction levels) are interpreted and completed. The processing of plan sketches employs an initial abductive plan recognition phase to formulate candidate sets of intended user goals, followed by a plan refinement stage that generates sketch-compliant final plans for those goals. A prototype sketch-based planner based on this approach has been implemented and applied to a crisis action planning domain.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-107.pdf,
107,1997,Optimal Planning,A Linear Programming Heuristic for Optimal Planning,Tom Bylander,"I introduce a new search heuristic for propositional STRIPS planning that is based on transforming planning instances to linear programming instances. The linear programming heuristic is admissible for finding minimum length plans and can be used by partial-order planning algorithms. This heuristic appears to be the first non-trivial admissible heuristic for partial-order planning. An empirical study compares Lplan, a partial-order planner incorporating the heuristic, to Graphplan, Satplan, and UCPOP on the tower of Hanoi domain, random blocks-world instances, and random planning instances. Graphplan is far faster in the study than the other algorithms. Lplan is often slower because the heuristic is time-consuming, but Lplan shows promise because it often performs a small search.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-108.pdf,
108,1997,Optimal Planning,Finding Optimal Solutions to Rubik’s Cube Using Pattern Databases,Tom Bylander,"We have found the first optimal solutions to random instances of Rubik’s Cube. The median optimal solution length appears to be 18 moves. The algorithm used is iterative-deepening-A* (IDA*), with a lower-bound heuristic function based on large memory-based lookup tables, or ""pattern databases"" (Culberson and Schaeffer 1996). These tables store the exact number of moves required to solve various subgoals of the problem, in this case subsets of the individual movable cubies. We characterize the effectiveness of an admissible heuristic function by its expected value, and hypothesize that the overall performance of the program obeys a relation in which the product of the time and space used equals the size of the state space. Thus, the speed of the program increases linearly with the amount of memory available. As computer memories become larger and cheaper, we believe that this approach will become increasingly cost-effective.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-109.pdf,
109,1997,Plan Generation,Planning by Rewriting: Efficiently Generating High-Quality Plans,"José Luis Ambite, Craig A. Knoblock","Domain-independent planning is a hard combinatorial problem. Taking into account plan quality makes the task even more difficult. We introduce a new paradigm for efficient high-quality planning that exploits plan rewriting rules and efficient, local search techniques to transform an easy-to-generate, but possibly sub-optimal, initial plan into a low-cost plan. In addition to addressing the issues of efficiency and quality, this framework yields a new anytime planning algorithm. We have implemented this planner and applied it to several existing domains. The results show that this approach provides significant savings in planning effort while generating high-quality plans.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-110.pdf,
110,1997,Plan Generation,A Robust and Fast Action Selection Mechanism for Planning,"Blai Bonet, Gábor Loerincs, Héctor Geffner","The ability to plan and react in dynamic environments is central to intelligent behavior yet few algorithms have managed to combine fast planning with a robust execution. In this paper we develop one such algorithm by looking at planning as real time search. For that we develop a variation of Korf’s Learning Real Time A* algorithm together with a suitable heuristic function. The resulting algorithm interleaves lookahead with execution and never builds a plan. It is an action selection mechanism that decides at each time point what to do next. Yet it solves hard planning problems faster than any domain independent planning algorithm known to us, including the powerful SAT planner recently introduced by Kautz and Selman. It also works in the presence of perturbations and noise, and can be given a fixed time window to operate. We illustrate each of these features by running the algorithm on a number of benchmark problems.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-111.pdf,
111,1997,Plan Generation,Planning with Concurrent Interacting Actions,"Craig Boutilier, Ronen I. Brafman","In order to generate plans for agents with multiple actuators or agent teams, we must be able to represent and plan using concurrent actions with interacting effects. Historically, this has been considered a challenging task that could require a temporal planner. We show that, with simple modifications, the STRIPS action representation language can be used to represent concurrent interacting actions. Moreover, current algorithms for partial-order planning require only small modifications in order to handle this language and produce coordinated multiagent plans. These results open the way to partial order planners for cooperative multiagent systems.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-112.pdf,
112,1997,Planning Under Uncertainty,A Heuristic Variable Grid Solution Method for POMDPs,Ronen I. Brafman,"Partially observable Markov decision processes (POMDPs) are an appealing tool for modeling planning problems under uncertainty. They incorporate stochastic action and sensor descriptions and easily capture goal oriented and process oriented tasks. Unfortunately, POMDPs are very difficult to solve. Exact methods cannot handle problems with much more than 10 states, so approximate methods must be used. In this paper, we describe a simple variable-grid solution method which yields good results on relatively large problems with modest computational effort.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-113.pdf,
113,1997,Planning Under Uncertainty,Incremental Methods for Computing Bounds in Partially Observable Markov Decision Processes,Milos Hauskrecht,"Partially observable Markov decision processes (POMDPS) allow one to model complex dynamic decision or control problems that include both action outcome uncertainty and imperfect observability. The control problem is formulated as a dynamic optimization problem with a value function combining costs or rewards from multiple steps. In this paper we propose, analyse and test various incremental methods for computing bounds on the value function for control problems with infinite discounted horizon criteria. The methods described and tested include novel incremental versions of grid-based linear interpolation method and simple lower bound method with Sondik’s updates. Both of these can work with arbitrary points of the belief space and can be enhanced by various heuristic point selection strategies. Also introduced is a new method for computing an initial upper bound _ the fast informed bound method. This method is able to improve significantly on the standard and commonly used upper bound computed by the MDP-based method. The quality of resulting bounds are tested on a maze navigation problem with 20 states, 6 actions and 8 observations.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-114.pdf,
114,1997,Probability and Planning,Effective Bayesian Inference for Stochastic Programs,"Daphne Koller, David McAllester, Avi Pfeffer","In this paper, we propose a stochastic version of a general purpose functional programming language as a method of modeling stochastic processes. The language contains random choices, conditional statements, structured values, defined functions, and recursion. By imagining an experiment in which the program is ""run"" and the random choices made by sampling, we can interpret a program in this language as encoding a probability distribution over a (potentially infinite) set of objects. We provide an exact algorithm for computing conditional probabilities of the form Pr(P(z) 1 Q(z)) where x is chosen randomly from this distribution. This algorithm terminates precisely when sampling x and computing P(X) and Q(x) t erminates in all possible stochastic executions (under lazy evaluation semantics, in which only values needed to compute the output of the program are evaluated). We demonstrate the applicability of the language and the efficiency of the inference algorithm by encoding both Bayesian networks and stochastic context-free grammars in our language, and showing that our algorithm derives efficient inference algorithms for both. Our language easily supports interesting and useful extensions to these formalisms (e.g., recursive Bayesian networks), to which our inference algorithm will automatically apply.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-115.pdf,
115,1997,Probability and Planning,Probabilistic Propositional Planning: Representations and Complexity,Michael L. Littman,"Many representations for probabilistic propositional planning problems have been studied. This paper reviews several such representations and shows that, in spite of superficial differences between the representations, they are ""expressively equivalent ,"" meaning that planning problems specified in one representation can be converted to equivalent planning problems in any of the other representations with at most a polynomial factor increase in the size of the resulting representation and the number of steps needed to reach the goal with sufficient probability. The paper proves that the computational complexity of determining whether a successful plan exists for planning problems expressed in any of these representations is EXPTIME-complete and PSPACE-complete when plans are restricted to take a polynomial number of steps.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-116.pdf,
116,1997,Invited Talks,"The AAAI-97 Mobile Robot Competition: Martians, remotes, Hors d'oeuvres, and Cleaning Up the Mess Afterwards",Ronald C. Arkin,"This years competition, the sixth annual held at AAAI, continues to expand upon the legacy of those which preceded it. In this talk I first, review the event’shistory and goals. This year, however, marks a significant departure from the past. I survey the four different events that make up this year’s competition (Find life on Mars, Find the Remote Control, Home Vacuuming, and Hors d'oeuvres anyone?).",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-218.pdf,
117,1997,Invited Talks,The Emergence of Spacecraft Autonomy,Richard J. Doyle,"The challenge of space flight in NASA’s future is to enable more frequent and more intensive space exploration missions at lower cost. Nowhere is this challenge more acute than among the planetary exploration missions which JPL conducts for NASA. The launching of a new era of solar system exploration -- beyond reconnaissance -- is being designed for the first time around the concept of sustained intelligent presence on the space platforms themselves. Artificial intelligence, spacecraft engineering, mission design, software engineering and systems engineering all have a role to play in this vision, and all are being integrated in new work on spacecraft autonomy.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-117.pdf,
118,1997,Invited Talks,What Does Knowledge Representation Have to Say to Artificial Intelligence?,David W. Etherington,"In recent years, the subarea of Knowledge Representation and Reasoning (KR) has become more and more of a discipline unto itself, focusing on artificial problems while other areas of AI have tended to develop their own representations and algorithms. There are signs that this is changing, however. This talk will explore what the current state of KR has to offer to AI.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-118.pdf,
119,1997,Invited Talks,Machine Learning for Intelligent Systems,Pat Langley,"Recent research in machine learning has focused on supervised induction for simple classification and reinforcement learning for simple reactive behaviors. In the process, the field has become disconnected from AI’s original goal of creating complete intelligent agents. In this paper, I review recent work on machine learning for planning, language, vision, and other topics that runs counter to this trend and thus holds interest for the broader AI research community. I also suggest some steps to encourage further research along these lines.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-119.pdf,
120,1997,Invited Talks,James Bond and Michael Ovitz: The Secret Life of Agents,Katia P. Sycara,"As agents populate Cyberspace in their many guises and roles, they coordinate and interact in different ways, spanning self-interested, as well as collaborative interactions. Agent coordination should be supported by an agent’s internal architecture and agent societal frameworks. We take a micro-economic view of coordination. In this talk we report on our work on adaptive agent architecture and the primitive agent behaviors it supports, agent organizations, contracting protocols among agents and presence of middle agents.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-120.pdf,
121,1997,Invited Talks,Market-Oriented Programming (Abstract),Michael P. Wellman,"Market-oriented programming is the construction of computational economies, where agents interact through a price system. Markets can provide effective allocation of resources for a variety of distributed environments, and economic analysis a powerful design tool for interaction mechanisms. The spread of electronic commerce puts a premium on market-aware agents, and presents a case for market awareness on the part of agent developers and AI researchers as well.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-121.pdf,
122,1997,Mobile Robot Competition Abstracts,Hack and Kluge,"Pete Beim, Ian Horswill, Ivan Yen","Hack and Kluge are high performance, low cost vision-based robots developed at Northwestern University. Hack and Kluge have a number of interesting features: They use a novel architecture that supports problem solving, reasoning, and instruction following, without a cen-tralized world model; All inferences are grounded in perception and updated at 5-10Hz; Nearly all sensing is performed using real-time vision; All computation is performed on-board; They use very low cost hardware (equivalent systems could be built for under $10,000)",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-122.pdf,
123,1997,Mobile Robot Competition Abstracts,Learning in a Fuzzy Logic Robot Controller,"Douglas S. Blank, J. Oliver Ross","Although Zadeh defined the basic operations of fuzzy set theory over thirty years ago (Zadeh, 1965), fuzzy logic-based controllers have just recently become the technique of choice for many researchers in robotics. Fuzzy logic controllers allow for the integration of high-level, human-designed plans to operate along side immediate, reactive actions in a successful manner. The key to this line of research has been the development of the concept of behaviors.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-123.pdf,
124,1997,Mobile Robot Competition Abstracts,Autonomous Exploration: An Integrated Systems Approach,"Marc Bolduc, Eric Bourque, Gregory Dudek, Nicholas Roy, Robert Sim","Mobile robotic systems offer an ideal platform for testing and implementing many of the concepts developed in more abstract artificial intelligence. Robotic systems embody a complex interaction of computation, perception and actuation that depend upon such familiar tasks as recognition and reaction. In order for robots to perform real-world tasks such as navigation, localization and exploration, the subsystems of motion, sensing and computation must be merged into a single, realizable unit that uses the different techniques together. Our group is investigating problems in the domain of computational perception, in the context of mobile robotics. In particular, we are concerned with environment exploration, and map construction. We are using the AAAI 1997 Mobile Robot competition as an opportunity to test a number of implementations of systems in navigation, spatial reasoning and perception.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-124.pdf,
125,1997,Mobile Robot Competition Abstracts,ServerDroid: A MultiMedia Service Robot,Pete Bonasso,"In this abstract I describe the robot platform and the software processing running on the robot, and discuss the interleaving of sensing and action to convey the multimedia information. I close with a short summary of the kinds of applications in which this technology should be useful.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-125.pdf,
126,1997,Mobile Robot Competition Abstracts,A Situated Vacuuming Robot,"D. Bruemmer, R. Dickson, J. Dilatush, D. Lewis, H. Mateyak, M. Mirarchi, M. Morton, J. Tracy, A. Vorobiev, L. Meeden","We undertook this project as an opportunity to explore design ideals of the embodied approach. At our disposal was a Pioneer robot and its Saphira software (ActivMedia 1996). Similar to subsumption architecture (Brooks 1986), the Saphira software tackles the dilemma of how to implement layered control design within a system which is inherently centralized. Brooks saw each layer as a simple and almost independent computational entity and, likewise, Saphira allows us to create a hierarchy of behaviors that each have the capacity to function simultaneously and yet asynchronously. Just as Brooks proposed a means by which one level can subsume a lower level by inhibiting its output, so behaviors can each be assigned a priority.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-126.pdf,
127,1997,Mobile Robot Competition Abstracts,Teaming Up: Georgia Tech’s Multi-Robot Competition Teams,"Thomas R. Collins, Tucker R. Balch","In past AAAI competition entries (1992-94), Georgia Tech has fielded robots developed by experienced graduate students. This year, we will take a different approach, with two separate teams: a group of experienced graduate students will enter the Find Life on Mars event with research-quality equipment, and a less-experienced group will enter the Home Vacuum event with entry-level robots.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-127.pdf,
128,1997,Mobile Robot Competition Abstracts,The Dartmouth Mobile Robot: SK,"William Garner, Gregory Friedland, Artyom Lifshits, Daniela Rus, Keith Kotay, Jon Howell","The Dartmouth Mobile Robot Serial Killer (see Figures 1 and 2) is a minimalist, architectually-lean autonomous robot that can vacuum your room. The robot is controlled by a Motorola 6811 microcontroller and has 40kb usable memory. The robot has several sensors including sonar, motion detection, contact, and analog IR. The robot’s motion is based on a combination of off-line and on-line algorithms that run on-board.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-128.pdf,
129,1997,Mobile Robot Competition Abstracts,LOBOtomous: An Autonomous Platform for Indoor Environments,"Ales V. Hvezda, John J. Garcia, Paul R. Klarer, Raymond H. Byrne, Gregory L. Heileman, Chaouki T. Abdallah",The University of New Mexico’s entry in this year’s AAAI Mobile Robot competition is LOBOtomous. LOBOtomous was constructed from scratch by UNM students in a senior level design class. Hardware for the project was loaned by Sandia National Labs. LOBOtomous will be entered into the home vacuuming and the hors d'oeuvres event.,https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-129.pdf,
130,1997,Mobile Robot Competition Abstracts,"Finding Life on Mars, and Other Tasks for NCSU’s Mobile Robots","Jason A. Janét, Bruce R. Linnell, Sean M. Scoggins","The North Carolina State University (NCSU) team intends to participate in the 1997 Mobile Robot Competition and Exhibition. This year marks our fourth entry in this competition. While there are many events in which we intend to compete, our primary focus is on the one entitled ""Find Life on Mars"". We decided to concentrate most of our efforts on this event because it requires environment learning, intelligent navigation, localization of objects in the environment and deliberate interaction with (or avoidance of) these objects.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-130.pdf,
131,1997,Mobile Robot Competition Abstracts,Are You Being Served?,"David P. Miller, Cathryne Stein, Anne Wright, Randy Sargent","There has been a lot of talk about service robots over the past decade, and indeed some service robots are starting to make their way into the real world; delivering food in hospitals, turning book pages for people with physical diabilities, and the like. Unfortunately, while functional, these robots perform their jobs with all the panache of machines. When people want service robots they really want ""servant robots"" but without the social guilt that now often accompanies the hiring of actual human servants. To do servants correctly, it is necessary to have a hierarchy in the 'help'. Only the Dark Knight has been able to maintain style and social standing with a single servant.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-131.pdf,
132,1997,Mobile Robot Competition Abstracts,Intelligent Sensor Fusion for the 1997 AAAI Mobile Robot Competition,Robin R. Murphy,"The Colorado School of Mines (CSM) will field a team of undergraduates for two events in the 1997 AAAI Mobile Robot Competition: Life on Mars and HOTS D'oeuvres. The objectives of the team are (1) to gain experience with implementing behaviors under a hybrid deliberative/reactive style of architecture and (2) to transfer research being conducted at CSM in intelligent sensor fusion to new applications. The students are preparing the entries as part of the class projects for the MACS415: Introduction to AI Robotics and Computer Vision and MACS370: Field Session courses. The team is using two different robots, both running subsets of the Sensor Fusion Effects (SFX) architecture implemented in C++.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-132.pdf,
133,1997,Mobile Robot Competition Abstracts,Kansas State Robotics,"Todd Prater, Michael Novak, Brian Rectanus, Steven Gustafson, David A. Gustafson","The robotics team from Kansas State University consists of three undergraduates, one graduate student, and a faculty advisor from the Department of Computing and Information Sciences. The group intends to compete in the ""Find the Remote"" event at this year’s AAAI 97 Mobile Robotics Competition in Providence, Rhode Island. Kansas State University has participated in each of the last four competitions, placing two teams (second and third place) in last year’s ""Office Delivery"" event. This year’s team has two principal goals: to win the ""Find the Remote"" event and to provide a solid foundation on which to build future entries.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-133.pdf,
134,1997,Mobile Robot Competition Abstracts,A Cooperative Multi-Robot Approach to the Mapping and Exploration of Mars,"Paul Rybski, Sascha Stoeter, Chris Wyman, Maria Gini","In the AAAI ""Life on Mars"" competition this year, we intend to employ a multi-robot team which combines traditional methods of autonomous navigation with experimental group arbitration strategies to explore and map a simulated extra-terrestrial environment. By communicating with each other to optimize the search, the robots will be able to explore the environment faster than could a single robot. Group strategies will also be used to coordinate the robot’s actions to optimize the retrieval of objects in the environment .",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-134.pdf,
135,1997,Mobile Robot Competition Abstracts,Lobokhod: The University of New Mexico’s Robotic Mars Rover,"Dan Stormont, Jane Canulette, Timothy Eyring, Jose Juste, Salamon Quintana, Chaouki T. Abdallah, Ray Byrne, Greg Heileman","Lobokhod is one of the University of New Mexico’s entries in the Association for the Advancement of Artificial Intelligence (AAAI) Sixth Annual Mobile Robot Competition. Lobokhod will be competing in the ""Find Life on Mars"" event. Lobokhod is named in honor of the Lunokhod series of robotic rovers, which were the first robotic rovers to explore an astronomical body other that the Earth. Lunokhod 1 landed on the moon in November 1970, followed shortly by Lunokhod 2. Lobokhod joins a family of previous UNM mobile robot competition entries, including Lobotomous (which is being entered in the ""Home Vacuum"" and ""Hors d'oeuvres Anyone?"" events this year) and Lobot.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-135.pdf,
136,1997,Mobile Robot Competition Abstracts,Multiple Agents from the Bottom Up: The Interaction Lab’s Robot Competition Effort,"Barry Brian Werger, Miguel Schneider Fontan, Dani Goldberg, Greg Hornby, Maja Mataric, Sen Song","Our goal is to exploit the benefits of multi-agent systems so as to gain a super-linear increase in performance relative to that of a single robot. By this we mean that a team of n robots either performs a task more than n times ""better"" (depending on the task, faster, more thoroughly, more reliably) than a single robot could perform the task, or performs a task that a single robot simply cannot. We strive to build these systems from the bottom up using behavior-based principles of system organization such as subsumption and activation (Brooks 85). We are preparing entries for three events - Find Life on Mars, Vacuuming, and Hors-d'oeuvres serving - where the responsiveness and flexibility of this approach will enable our robots to organize themselves into efficient, effective, and entertaining teams.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-136.pdf,
137,1997,Mobile Robot Competition Abstracts,ARIEL: Autonomous Robot for Integrated Exploration and Localization,"Brian Yamauchi, Alan Schultz, William Adams, Kevin Graves, John Grefenstette, Dennis Perzanowski","In order for a robot to add its perceptions to a map, it needs to know its location, but in order for a robot to determine its location, it often needs a map. This is a central dilemma in robot exploration. Robots often use dead reckoning to estimate their position without a map, but wheels slip and internal linkages may be imprecise. These errors accumulate over time, and the robot’s position estimate becomes increasingly inaccurate. We have addressed this problem in ARIEL. ARIEL uses frontier-based exploration (Yamauchi 1997) to navigate to unexplored space and to map the territory that it perceives, and continuous localization (Schultz, Adams, and Grefenstette 1996) to maintain an accurate estimate of its position at all times. ARIEL has been implemented on a Nomad 200 mobile robot equipped with sonar, infrared, and laser range sensors. ARIEL runs on a SPARCstation 20 and communicates with the robot’s onboard Pentium processor via radio ethernet. This system has been used to explore real-world office environments. We will demonstrate ARIEL at the AAAI-97 Robot Exhibition. We are also interested in using genetic algorithms to automatically learn behaviors for controlling mobile robots, and we will be demonstrating some of those learned behaviors at the Exhibition.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-137.pdf,
138,1997,Doctorial Consortium Abstracts,Pragmatic Question Answering: Generic versus Specific Responses,Debra T. Burhans,"Asking questions is a fundamental human activity. Questions of the form What objects X have property Y?"" can be viewed as having two types of responses: specific (extensional) and generic (intensional). A specific response to the question ""Who got a raise this year?"" is a list of individuals who got a raise this year. A generic response to this question is a description of the ,criteria used in determining who got a raise, for example, ""all employees with greater than five years of service and good reviews"". The focus of this research is to determine the circumstances that dictate whether a generic or specific referent constitutes the most appropriate response to a question.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-138.pdf,
139,1997,Doctorial Consortium Abstracts,Adaptive Hybrid System Architecture for Forecasting,Juan M. Corchado,"The aim of the research is to combine Symbolic Artificial Intelligence (AI) (Case Base Reasoning systems) and Connectionist AJ (particularly Radial Basis Functions, Multi-layer Perceptron and Neuro-fuzzy Algorithms) to develop an improved joint approach to forecasting. New ways to combine Connectionist and Symbolic AI techniques to obtain stronger, more flexible and more adaptive forecasting systems are being investigated.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-139.pdf,
140,1997,Doctorial Consortium Abstracts,Iterative Refinement of Knowledge Bases with Consistency Guarantees,Stephen F. Correl,"Natural kinds, such as the concepts toy block or photosynthesis, are ubiquitous in human reasoning yet lack definitional (i.e., individually necessary and jointly sufficient) properties as membership conditions. The meaning of these concepts emerges through the inter-relatedness of facts about them rather than from mathematical definition. The goal of my research is to support construction of large, multi-functional knowledge bases of assertions about such natural kinds.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-140.pdf,
141,1997,Doctorial Consortium Abstracts,Probabilistic Learning in Bayesian and Stochastic Neural Networks,William H. Hsu,"The goal of this research is to integrate aspects of artificial neural networks (ANNs) with symbolic machine learning methods in a probabilistic reasoning framework. Improved understanding of the semantics of neural nets supports principled integration efforts between seminumerical (so-called ""subsymbolic"") and symbolic intelligent systems. My dissertation focuses on learning of spatiotemporal (ST) sequences. In recent work, I have investigated architectures for modeling of ST sequences, and dualities between Bayesian networks and ANNs that expose their probabilistic and information theoretic foundations. In addition, I am developing algorithms for automated construction of Bayesian networks (and hybrid models); metrics for comparison of Bayesian networks across architectures; and a quantitative theory of feature construction (in the spirit of the PAC formalism from computational learning theory) for this learning environment. (Haussler 1988) Such methods for pattern prediction will be useful for building advanced knowledge based systems, with diagnostic applications such as intelligent monitoring tools.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-141.pdf,
142,1997,Doctorial Consortium Abstracts,Unified Hardware and Software Models for Smart System Design,Ravi Kapadia,"""Smart"" electromechanical systems (e.g., washing machines, car anti-skid braking systems and reprographic machines, i.e., printers and photocopiers) are machines with intelligent, embedded computer control. Conventional embedded controllers performed a preprogrammed set of actions, but as machines have become more versatile, controllers are being designed to generate and evaluate different plans to perform specified tasks, search for optimal actions, and react to changing environments. Traditionally, hardware design in embedded systems has preceded software design resulting in sub-optimal designs. As the use of embedded software proliferates, integrated hardware and software design becomes critical.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-142.pdf,
143,1997,Doctorial Consortium Abstracts,Evaluating the Role of Background Knowledge in Enhancing Knowledge Discovery in Databases,Venkateswarlu Kolluri,"In the field of Knowledge Discovery in Databases (KDD), background knowledge is usually available in the form of taxonomies (is-a hierarchies) over the features and the corresponding feature-value hierarchies. Using the RL inductive rule learning system as a test bed, we are trying to evaluate the effectiveness of such background knowledge in enhancing the KDD process. The improvements in the learned concept definitions are evaluated based on the learnt rule set’s predictive power and simplicity.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-143.pdf,
144,1997,Doctorial Consortium Abstracts,Belief Network Inference in Dynamic Environments,Ole J. Mengshoel,"Belief networks (BNs) are an essential knowledge representation technique in AI (Pearl 1988). Substantial progress has been made over the last ten years in all areas of BN research. However, at AAAI-96, Horvitz called for more research related to handling time, synchronicity, and streams of events (Selman et el. 1996): ""We [...] need to develop better means of synchronizing an agent’s perceptions, inference, and actions with important events in the world."" In this abstract, I consider how to achieve efficient and synchronized inference by approximate BN inference and BN approximation. For approximate BN inference I investigate genetic algorithms (GAS). GAS are robust function optimizers that employ stochastic, instance-based (or population-based) search (Goldberg 1989). Since a BN represents a function, it is natural to consider using GAS to search in the space of instantiated BNs, and to combine GA search with existing algorithms for BN inference.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-144.pdf,
145,1997,Doctorial Consortium Abstracts,Knowledge Lean Word Sense Disambiguation,Ted Pedersen,"A central problem in any natural language processing application is determining the meaning of ambiguous words. Word-sense disambiguation (WSD) is often cast as a problem in supervised learning. These approaches assume the availability of text to train a learning algorithm where ambiguous words have been manually annotated with sense distinctions. If such text is available, supervised approaches are effective and we present several extensions to an existing method. However, since sense-tagged text is expensive to create and only exists for a small number of ambiguous words, unsupervised alternatives are presented that do not require such an expensive knowledge source.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-145.pdf,
146,1997,Doctorial Consortium Abstracts,Dynamic Organization of Search Results Using a Taxonomic Domain Model,Wanda Pratt,"Current information-retrieval tools return the results of a search as a flat list of documents. Some tools order the documents according to relevance criteria, such as date created or number of matching search terms, but few group them in a meaningful way. The returned list of search results is often so long that it is too time consuming for the user to browse and understand all of it. I propose that organizing search results into categories will help users to explore and understand the information space related to their query.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-146.pdf,
147,1997,Doctorial Consortium Abstracts,Applications of Machine Learning to Information Access,Mehran Sahami,"The recent explosion of on-line information has given rise to a number of query-based search engines (e.g., Alta Vista) and manually constructed topic hierarchies (e.g., Yuhoo!). But with the current rate of growth in the amount of available information, query results grow incomprehensibly large and manual classification in topic hierarchies creates an immense information bottleneck. Therefore, these tools are rapidly becoming inadequate for addressing users’ information needs. We address these problems with a system for topical information space navigation that combines the query-based and taxonomic systems. Our system is built within a unifying probabilistic framework, thereby harnessing the expressive power of this representation while also providing understandable semantics.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-147.pdf,
148,1997,Doctorial Consortium Abstracts,Computing Discourse Information with Statistical Methods,Kenneth B. Samuel,"This dissertation research involves implementing a computer system that, given a natural language dialogue, will automatically tag each utterance with a discourse label (a concise abstraction of the intentional function of the speaker) and a discourse pointer (a focusing mechanism that represents the dialogue context in which an utterance is to be understood). (Samuel 1996)",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-148.pdf,
149,1997,Doctorial Consortium Abstracts,An Information-Based Approach to Punctuation,Bilge Say,"Punctuation marks have a special importance in bringing out the meaning of a text. There has been recent computational work concentrating on punctuation marks in Natural Language Processing (NLP) mostly following Nunberg’s pioneering work (Nunberg 1990), in which he bridged the gap between descriptive linguistic treatments of actual usage of punctuation and prescriptive accounts, by putting down the features of a ""text grammar"" for the orthographic sentence. Several grammars for syntactic parsing incorporating punctuation were then shown by NLP researchers to reduce parse failures and ambiguities in parsing (Briscoe 1996). Nunberg’s approach to presenting punctuation (and other formatting devices) was partially incorporated into Natural Language Generation systems. However, little has been done on how punctuation marks bring semantic and discourse-based cues to the text and whether those cues can be exploited computationally. The aim of this thesis is to analyze, in an information-based framework, the semantic and discourse aspects of punctuation, drawing computational implications for NLP systems. This will not only enable NLP software writers to make use of the punctuation marks effectively but also may reveal interesting linguistic phenomena in conjunction with punctuation marks.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-149.pdf,
150,1997,Doctorial Consortium Abstracts,Layered Learning in Multiagent Systems,Peter Stone,"Multiagent Systems is the emerging subfield of Artificial Intelligence that aims to provide both principles for construction of complex systems involving multiple agents and mechanisms for coordination of independent agents’ behaviors. As of yet, there has been little work with lVIultiagent Systems that require real-time control in noisy environments. Because of the inherent complexity of this type of Multiagent System, Machine Learning is an interesting and promising area to merge with Multiagent Systems. Machine learning has the potential to provide robust mechanisms that leverage upon experience to equip agents with a large spectrum of behaviors, ranging from effective individual performance in a team, to collaborative achievement of independently and jointly set high-level goals in the presence of adversaries. Learning will also help agents adapt to unforeseen behaviors on the parts of other agents, through the use of on-line adaptive methods that may include explicit opponent modelling. My thesis will focus on learning in this particularly complex class of multiagent domains.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-150.pdf,
151,1997,Student Abstracts,Avoiding Failure via Pre-Planned Responses and Time-Bounded Planning,"Ella M. Atkins, Edmund H. Durfee, Kang G. Shin","Complex plans are required to safely operate an autonomous system in a dynamic environment. An ideal planner would build all reactions offline so it could deliberate as long as necessary to develop its response set. However, it may be impossible to build and store all plans offline, so online planning is required whenever previously unplanned-for situations arise. In a dynamic system, online planning must be terminated within time bounds imposed by the environment, with potentially adverse affects on plan quality. We propose that the primary goal of any system is to avoid failure (e.g., system destruction), and a secondary consideration is to achieve other goals. In this abstract, we propose a method to balance offline vs. online planning in terms of failure avoidance. We combine pre-planned responses with time-bounded online planning in CIRCA, the Cooperative Intelligent Real-time Control Architecture (Musliner, Durfee, and Shin 1993), shown in Figure 1. CIRCA combines a planner, scheduler, and real-time plan execution subsystem (RTS) to allow guaranteed performance for critical responses. We have augmented CIRCA to allow contingency plan storage via a Plan Dispatcher module and a small but quickly-accessed cache within the RTS.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-151.pdf,
152,1997,Student Abstracts,Dynamic Prioritization of Complex Agents in Distributed Constraint Satisfaction Problems,"Aaron A. Armstrong, Edmund H. Durfee","Cooperative distributed problem solving (CDPS) is often modeled as being done by a group of loosely-coupled computational agents involved in extensive local computations. A useful way of viewing this is as a distributed constraint satisfaction problem (DCSP), where there are constraints between the local solutions of the different agents. The agents want to exchange enough information to identify violations of constraints and to rectify them.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-152.pdf,
153,1997,Student Abstracts,An Efficient Heuristic Search in a Large Multi-Agent System,"Cheng-Gang Bian, Wen Cao, Gunnar Hartvigsen","We are investigating the cooperative behavior of intelligent agents in a large group. A cooperative intelligent agent is a user’s personal consultant that can take care of problems the user got, and solve them either by itself or via cooperation. We have proposed a twin-base (cooperator-base u task-base) agent modeling technique for individual agents to monitor activities of the others in order to achieve efficient cooperation in a small agent group. While the group grows in size and complexity, an activity-oriented hierarchical organization structure, club-community-society, has been studied. In this organization, each agent shows its activities to the outside world, and these activities are symbolic categories for the twin-base guided heuristic searches in peer locating processes.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-153.pdf,
154,1997,Student Abstracts,Summarizing Time-Varying Data,Sarah Boyd,"In generating textual summaries of data, the content determination problem is even more complicated when summarizing time-varying data, such as in weather or stockmarket report generation. As well as the maximum, minimum and mean, what is of interest is the behaviour of the variable over time; e.g. dramatic changes, trends and degree of variability in the data.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-154.pdf,
155,1997,Student Abstracts,Efficient Production Match Algorithm and Its Implication for Dynamic Constraint Satisfaction Problems,"Bonghan Cho, Paul Rosenbloom, Milind Tambe","Production systems have been a successful paradigm in Artificial Intelligence (AI) programming and have been extensively used in building AI systems including problem-solving systems, cognitive models, expert systems and real-time systems. Despite this extensive use, there remains a key performance bottleneck that limits the applicability of production systems - the combinatoric match process. Algorithms that handle the match combinatorics efficiently are increasingly needed as (1) knowledge bases grow in size and (2) real time performance becomes more important. There has in fact been much progress in production match since Rete (Forgy 1982) was developed, resulting in orders of magnitude of improvements in production system performance. However, despite the current match technology, programmers of production systems experience that they spend substantial amounts of time in rewriting productions just in order to improve production system efficiency. The goal of our research is to develop an efficient match algorithm for large data sets in working memory in real time environments. The match algorithm we have developed, called ERMA, attempts to eliminate match combinatorics. Due to the elimination of such combinatorics (though not fully eliminated yet), ERMA is able to scale well with large data sets in working memory.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-155.pdf,
156,1997,Student Abstracts,Applying Clustering to the Classification Problem,Piew Datta,"The minimum-distance classifier learns a single mean prototype for each class and uses a nearest neighbor approach for classification. A problem arises when classes cannot be accurately represented using a single prototype; multiple prototypes may be necessary. Our approach is to find groups of examples for each of the classes, generalize these groups into prototypes using a mean representation, and then classify using a nearest neighbor approach.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-156.pdf,
157,1997,Student Abstracts,Experiments in UNIX Command Prediction,"Brian D. Davison, Haym Hirsh","Most users demonstrate regularities in their work with a computer system. Even when a user’s activities are unique, those interactions often exhibit systematic patterns. Accordingly, there has been a range of work developing systems that recognize regularities in computer usage (Cypher 1993; Mitchell et al. 1994; Schlimmer and Hermens 1993). Our current effort is to consider different methods that would enable us to build similar pattern-recognition into the UNIX command shell (Hirsh and Davison 1997; Davison and Hirsh 1997), although the concept of command prediction is similarly applicable to other user interfaces.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-157.pdf,
158,1997,Student Abstracts,A Comparison of Model Averaging Methods in Foreign Exchange Prediction,Pedro Domingos,"Statistical learning theory predicts, and empirical results confirm, that averaging the predictions of several learned models will often result in higher accuracies than using only the single ""best"" model. However, the averaging methods typically used in practice (e.g., assigning uniform weights to all models) differ from the theoretical Bayesian optimum, which is to weight each model by its posterior probability. In this extended abstract, uniform and Bayesian weighting are compared on a practical task, some problems of the latter are identified, and a new heuristic weighting scheme is proposed, leading to improved performance.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-158.pdf,
159,1997,Student Abstracts,Learning Multiple Models without Sacrificing Comprehensibility,Pedro Domingos,"Learning multiple models and combining their results can often lead to significant accuracy improvements over the single ""best"" model. This area of research has recently received much attention (e.g., Chan, Stolfo, and Wolpert 1996). However, as Breiman (1996) notes, when the models being combined are ""human-readable"" (as is the case with, for example, decision trees and rule sets), the cost of this procedure is the loss of the comprehensibility afforded by the single model. Not only is the complexity of m models m times greater than that of one, but it is difficult and tedious for a human to predict the output of the model ensemble, and thus to understand its behavior. This can be a significant disadvantage, since comprehensibility is often of paramount importance to make the learner’s output acceptable to the users, to allow interactive refinement of the model produced, and to gain knowledge of the domain. This extended abstract describes and evaluates a method for retaining most of the accuracy improvements obtained by multiple model approaches, while still producing a single comprehensible model.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-159.pdf,
160,1997,Student Abstracts,Stratification for Variants of Default Logic,"Jörg Ernst, Grigoris Antoniou","Default logic (DL) (Reiter 1980) is one of the most prominent approaches to nonmonotonic reasoning. One of the main problems with its applicability is that it is computationally harder than classical logic (Gottlob 1992). (Cholewinski 1994,1995) introduced and studied stratification of default theories to increase the efficiency of default reasoning. The idea is to to split the knowledge into smaller parts, and to apply reasoning in a local way. This paper shows how stratification can work for some important variants of Default Logic. These variants are Justified Default Logic (JDL), Rational Default Logic (RDL), and Constrained Default Logic (CDL).",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-160.pdf,
161,1997,Student Abstracts,Speeding Safely: Multi-Criteria Optimization in Probabilistic Planning,"Michael S. Fulkerson, Michael L. Littman, Greg A. Keim","In deterministic planning, an optimal plan reaches the goal in the minimum number of steps. In this work, we find plans for probabilistic domains, in which there is a tradeoff between reaching the goal with high probability (safety) and reaching it quickly (cost).",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-161.pdf,
162,1997,Student Abstracts,Information Routing Using a Corpus Distribution,Jeffrey A. Goldman,"The research goal of information routing (IR) is to retrieve and rank a collection of text documents that coincide with a user profile (Harman 1995). Ideally, the profile can be derived automatically from a set of documents the user has identified as relevant to a particular topic of interest. The assumption for this work is a user has provided this small set of documents. It is then our goal to rank a previously unseen set .",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-162.pdf,
163,1997,Student Abstracts,Althea: Minimalist Representation for Robot Assembly Tasks,Jonathan B. Handler,"Althea is a hand-eye robot system that applies minimalist representation techniques to the task of building a wall from Duplo bricks. Duplos are large Lego bricks -- molded plastic blocks that interlock with one another. The system visually and then manually acquires Duplos, orients them in the robot’s gripper, and then joins them to the wall.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-163.pdf,
164,1997,Student Abstracts,Social Comparison for Failure Detection and Recovery in Multi-Agent Settings,"Gal A. Kaminka, Milind Tambe","Our application domain involves developing pilot agents for participation in synthetic environments that are highly dynamic and rich in detail. While it is easy for a human designer to detect and correct failures once they occur, it is generally hard for her to anticipate them in advance.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-164.pdf,
165,1997,Student Abstracts,Smart System Design Using Hybrid Models,Ravi Kapadia,"""Smart"" electromechanical systems are machines with intelligent, embedded computer control such as washing machines, car anti-skid braking systems and reprographic machines (e.g., printers, photocopiers, and fax machines). Conventional embedded controllers performed a pre-programmed set of actions, but as machines have become more versatile, controllers are being designed to generate and evaluate different plans to perform specified tasks, search for optimal solutions, and react to changing environments.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-165.pdf,
166,1997,Student Abstracts,Learning to Play Hearts,Leo Kuvayev,The success of neural networks and temporal difference methods in complex tasks such as in (Tesauro 1992) provides the opportunity to apply these methods in other game playing domains. I compared two learning architectures: supervised learning and temporal difference learning for the game of hearts.,https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-166.pdf,
167,1997,Student Abstracts,Predicting Resource Use with Case-Based Plan Recognition,"Jung-Jin Lee, Robert McCartney","When managing a computing system, it is better to predict problems before they occur, rather than just observing them when they occur. Our research develops self-interested agents designed for the prediction of resource usages, that is, assessing the likelihood of upcoming demands by users on the limited resources and detecting potential problems from the observations of human-computer interactions (Etzioni and Weld 1994). Furthermore, these agents will have behavior that changes over time based on their own experiences, which will improve their predictive ability and allow them to adapt to changing usage patterns.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-167.pdf,
168,1997,Student Abstracts,Active Learning with Committees,"Ray Liere, Prasad Tadepalli","In many real-world domains like text categorization, supervised learning requires a large number of training examples. In our research, we are using active learning with committees methods to reduce the number of training examples required for learning. Disagreement among the committee members on the predicted label for the input part of each example is used to determine the need for knowing the actual value of the label. Our experiments in text categorization using this approach demonstrate a 1-2 orders of magnitude reduction in the number of labeled training examples required.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-168.pdf,
169,1997,Student Abstracts,Development of Iterative Scheduler to Planner Feedback,"Charles B. McVey, Ella M. Atkins, Edmund H. Durfee, Kang G. Shin","The traditional scheduling problem can be reformulated in an agent-oriented paradigm. A manager agent proposes a set of tasks to schedule along with scheduling constraints among these tasks. A scheduler agent receives this data and attempts to build a schedule which satisfies all scheduling constraints. Ideally, if the scheduler solves the problem as the manager requests, a successful schedule will be returned. If the scheduler is unable to satisfy the manager’s request, it might return NULL, forcing the manager to blindly modify and resubmit its request. Our scheduler is designed to return feedback to the manager regarding why a successful schedule could not be produced from the original request. This additional knowledge can then be used by the manager to direct its modification of tasks and/or relaxation of constraints for a subsequent scheduling request. This process iterates until a successful schedule with well-utilized resources is obtained.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-169.pdf,
170,1997,Student Abstracts,A Stochastic Strategy for Multiagent Contracts and the Impact of Deliberation Overhead,"Sunju Park, Edmund H. Durfee","In multiagent systems consisting of self-interested agents, forming a contract often requires complex, strategic thinking (Rosenschein and Zlotkin 1994, Vidal and Durfee 1996). In this abstract, we describe a stochastic contracting strategy for a utility-maximizing agent and discuss the impact of deliberation overhead on its performance.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-170.pdf,
171,1997,Student Abstracts,Naive Mixes for Word Sense Disambiguation,Ted Pedersen,"The Naive Mix is a new supervised learning algorithm based on sequential model selection. The usual objective of model selection is to find a single probabilistic model that adequately characterizes, i.e. fits, the data in a training sample. The Naive Mix combines models discarded during the selection process with the best-fitting model to form an averaged probabilistic model. This is shown to improve classification accuracy when applied to the problem of determining the meaning of an ambiguous word in a sentence.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-171.pdf,
172,1997,Student Abstracts,On the Discovery of Patterns in Medical Data,"Jorge C. G. Ramirez, Lynn L. Peterson, Dolores M. Peterson, Gretchen K. Cormier","We have looked at the KDD field for techniques that might be useful in our domain. As a result of our investigation to date, we have concluded first that KDD is pervaded by human intervention and verification of hypotheses, as opposed to discovery. Second, data mining techniques require that data be in standard form, whether it be in the form of a training set or preprocessed to meet the techniques’ input requirements. Finally, our perspective of spanning the course of disease does not well fit with any of the traditional data mining techniques. In view of these conclusions, it seems that the temporal issue is the dominant factor in our problem domain and therefore, we must attempt to adapt or create new techniques to accomplish our goal.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-172.pdf,
173,1997,Student Abstracts,Learning Goal-Decomposition Rules Using Exercises,"Chandra Reddy, Prasad Tadepalli","Teaching problem-solving through exercises is a widely used pedagogic technique. A human teacher selects certain problems and orders them according to their level of difficulty to form a sequence of exercises. A student starts by solving simple problems first; then, attempts harder problems applying the knowledge gained from solving the earlier problems; and then still harder problems, and so on.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-173.pdf,
174,1997,Student Abstracts,Quantification and Commonsense Reasoning,"Walid S. Saba, Jean-Pierre Corriveau","Traditional approaches to the resolution of quantifier scope ambiguity are based on devising syntactic and semantic rules to eliminate a multitude of otherwise equally valid readings. This approach is neither cognitively nor computationally plausible. Instead we suggest a cognitively plausible model to quantifier scope using a ""quantificational restriction"" which we assume speakers of ordinary language compute in appropriately defined contexts.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-174.pdf,
175,1997,Student Abstracts,Real-Time Full-Text Clustering of Networked Documents,"Mehran Sahami, Salim Yusufali, Michelle Q. W. Baldonado","With the recent explosion of available on-line information, there is an enormous need for methods that allow users to easily access this information. We address this problem with a system, named SONIA (Service for Organizing Networked Information Autonomously), which enables topicad information space navigation by employing machine learning to create dynamic document categorizations based on the fulltext of articles that are germane to users’ queries.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-175.pdf,
176,1997,Student Abstracts,A Model of Invention,"Marin Simina, Ashwin Ram, Janet Kolodner, Michael Gorman","This poster investigates the enterprises of invention. We focus on invention goals, which address those enterprises of an inventor resulting in the creation of novel and useful devices. Invention goals provide one way to explain how creative and innovative ideas are generated, evaluated and further pursued by expert reasoners, such as inventors. Our distributed model of invention, ALEC, highlights the role of social and environmental interaction.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-176.pdf,
177,1997,Student Abstracts,Modifying Knowledge Bases Using Scripts,"Marcelo Tallis, Yolanda Gil","Most current Knowledge Acquisition (KA) approaches provide tools that are specifically tailored to a predefined library of problem-solving methods (Klinker et al. 1991; Puerta et al. 1992). These tools support users in populating knowledge bases (KBs) with domain-specific knowledge that the methods need. However, these tools do not support users in modifying the individual problem-solving methods beyond substituting one method for another one in the library. Hence, KA tools that support users in making wider range of changes to problem-solving methods are needed. We are currently developing EXPECT (Gil 1994), a tool that supports users in making a broad range of changes to knowledge-based systems (KBSs), including changes to problem-solving methods. EXPECT represents problem-solving methods explicitly, and its KA tool reasons about them to guide KA. Problem solving knowledge in EXPECT is structured in smallsize methods. A method is a procedure for achieving a problem-solving goal. This procedure may include subgoals which are invocations to other methods. Methods goals have parameters that are bound to the values of the parameters of the subgoals that call them.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-177.pdf,
178,1997,Student Abstracts,Noise Sensitivity Analysis for Shape from Focus Methods,Jenn-Kwei Tyan,"Shape from focus (SFF) methods provide a useful technique for passive autofocusing and three-dimensional (3D) shape recovery of objects. In these methods, focus measures are used to extract 3D information from a sequence of images taken with different camera parameters such as lens/object position or focal length. The accuracy of autofocusing and 3D shape measurement using the image focus analysis technique depends on the particular focus measure that is used.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-178.pdf,
179,1997,Student Abstracts,Analyzing Agents that Learn about Agents,"José M. Vidal, Edmund H. Durfee","Our research provides a framework for describing the multi-agent system and the different types of knowledge in an agent. We assume that the MAS is discrete, such that agents take an action at each time step and these are all effectively concurrent.",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-179.pdf,
180,1997,Student Abstracts,Matching Requests for Agent Services with Differentiated Vocabulary,"Peter Weinstein, William P. Birmingham","To enable decentralized development of large societies of agents, agents should be able to selectively team with others based on declarative descriptions of services, rather than a priori knowledge.' This capability is difficult to achieve because descriptions written by different developers may be terminologically heterogenous-including vocabulary from ontologies that are potentially inconsistent. For example, one agent might describe its service as (a formal equivalent of) ""query planning for high-school biology"", while another agent wants to ""find collections for advanced life sciences"". We want the latter agent to recognize that the former might satisfy its request. We have completed research on two aspects of this problem. Our Service Classifier Agent (SCA) supports selection of agent services in societies that are dynamic and evolving, but whose agents all use the same ontologies [Weinstein and Birmingham 97]. We have also developed an algorithm that identifies maximal similarity between concept definitions that are terminologically heterogenous [Weinstein 95].",https://aaai.org/Library/AAAI/1997/../../../Papers/AAAI/1997/AAAI97-180.pdf,
