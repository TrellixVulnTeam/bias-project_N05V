,conference_year,category,title,author,abstract,download_url,keywords
0,2006,Contents,AAAI Organization,AAAI officers and staff.,This page is copyrighted by AAAI. All rights reserved. Your use of this site constitutes acceptance of all of AAAI's terms and conditions and privacy policy.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-386.pdf,
1,2006,Contents,AAAI-06 and IAAI-06 Conference Program Committees,"List of conference reviewers, program committee, and organizers for AAAI-06 and IAAI-06.",This page is copyrighted by AAAI. All rights reserved. Your use of this site constitutes acceptance of all of AAAI's terms and conditions and privacy policy.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-387.pdf,
2,2006,Contents,AAAI-06 Awards,Best paper awards presented at AAAI-06.,This page is copyrighted by AAAI. All rights reserved. Your use of this site constitutes acceptance of all of AAAI's terms and conditions and privacy policy.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-388.pdf,
3,2006,Contents,Sponsoring Organizations,Corporate sponsors of AAAI and IAAI 2006.,This page is copyrighted by AAAI. All rights reserved. Your use of this site constitutes acceptance of all of AAAI's terms and conditions and privacy policy.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-389.pdf,
4,2006,Contents,AAAI-06 Preface,Yolanda Gil and Raymond J. Mooney,"Welcome to the Twenty-First National Conference on Artificial Intelligence, AAAI-06! 2006 is a special year for the AI research community because we celebrate the fiftieth anniversary of the Dartmouth project where the term “artificial intelligence” was first introduced by John McCarthy as the topic of investigation. AAAI-06 celebrates the growth and diversity of our field and includes a number of new features to encourage wide participation of researchers and practitioners in the field and related disciplines.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-390.pdf,
5,2006,Contents,IAAI-06 Preface,Bruce Porter and William Cheetham,"Welcome to the Eighteenth Annual Conference on Innovative Applications of Artificial Intelligence (IAAI-06). The purpose of this conference is to discuss, document, and—indeed— to celebrate the maturation of AI technologies into successful applications.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-391.pdf,
6,2006,Contents,Invited Talks,"Tim Berners-Lee, Bruce Buchanan, Pedro Domingos, Ken Koedinger, Karen Myers, Dan Roth, Neil Jacobstein, Sebastian Thrun",Abstracts of the invited talks presented at AAAI-06 and IAAI-06.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-392.pdf,
7,2006,Invited Talk,Unifying Logical and Statistical AI,"Pedro Domingos, Stanley Kok, Hoifung Poon, Matthew Richardson, Parag Singla","Intelligent agents must be able to handle the complexity and uncertainty of the real world. Logical AI has focused mainly on the former, and statistical AI on the latter. Markov logic combines the two by attaching weights to first-order formulas and viewing them as templates for features of Markov networks. Inference algorithms for Markov logic draw on ideas from satisfiability, Markov chain Monte Carlo and knowledge-based model construction. Learning algorithms a re based on the voted perceptron, pseudo-likelihood and inductive logic programming. Markov logic has been successfully applied to problems in entity resolution, link prediction, information extraction and others, and is the basis of the open-source Alchemy system.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-001.pdf,Subjects: 12. Machine Learning and Discovery; 3. Automated Reasoning
8,2006,Constraint Satisfaction and Satisfiability,The Impact of Balancing on Problem Hardness in a Highly Structured Domain,"Carlos Ansotegui, Ramon Bejar, Cesar Fernandez, Carla Gomes, Carles Mateu","Random problem distributions have played a key role in the study and design of algorithms for constraint satisfaction and Boolean satisfiability, as well as in our understanding of problem hardness, beyond standard worst-case complexity. We consider random problem distributions from a highly structured problem domain that generalizes the Quasigroup Completion problem (QCP) and Quasigroup with Holes (QWH), a widely used domain that captures the structure underlying a range of real-world applications. Our problem domain is also a generalization of the well-known Sudoku puzzle: we consider Sudoku instances of arbitrary order, with the additional generalization that the block regions can have rectangular shape, in addition to the standard square shape. We evaluate the computational hardness of Generalized Sudoku instances, for different parameter settings. Our experimental hardness results show that we can generate instances that are considerably harder than QCP/QWH instances of the same size. More interestingly, we show the impact of different balancing strategies on problem hardness. We also provide insights into backbone variables in Generalized Sudoku instances and how they correlate to problem hardness.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-002.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
9,2006,Constraint Satisfaction and Satisfiability,Abstract Branching for Quantified Formulas,Marco Benedetti,"We introduce a novel search-based decision procedure for Quantified Boolean Formulas (QBFs), called Abstract Branching. As opposed to standard search-based procedures, it escapes the burdensome need for branching on both children of every universal node in the search tree. This is achieved by branching on existential variables only, while admissible universal assignments are inferred. Running examples and experimental results are reported.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-003.pdf,Subjects: 15.7 Search; 15.2 Constraint Satisfaction
10,2006,Constraint Satisfaction and Satisfiability,Exploiting Tree Decomposition and Soft Local Consistency in Weighted CSP,"Simon de Givry, Thomas Schiex, Gerard Verfaillie","Several recent approaches for processing graphical models (constraint and Bayesian networks) simultaneously exploit graph decomposition and local consistency enforcing. Graph decomposition exploits the problem structure and offers space and time complexity bounds while hard information propagation provides practical improvements of space and time behavior inside these theoretical bounds. Concurrently, the extension of local consistency to weighted constraint networks has led to important improvements in branch and bound based solvers. Indeed, soft local consistencies give incrementally computed strong lower bounds providing inexpensive yet powerful pruning and better informed heuristics. In this paper, we consider combinations of tree decomposition based approaches and soft local consistency enforcing for solving weighted constraint problems. The intricacy of weighted information processing leads to different approaches, with different theoretical properties. It appears that the most promising combination sacrifices a bit of theory for improved practical efficiency.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-004.pdf,Subjects: 15. Problem Solving; 15.2 Constraint Satisfaction
11,2006,Constraint Satisfaction and Satisfiability,Extending Dynamic Backtracking to Solve Weighted Conditional CSPs,Robert T. Effinger Brian C. Williams,"Many planning and design problems can be characterized as optimal search over a constrained network of conditional choices with preferences. To draw upon the advanced methods of constraint satisfaction to solve these types of problems, many dynamic and flexible CSP variants have been proposed. One such variant is the Weighted Conditional CSP (WCCSP). So far, however, little work has been done to extend the full suite of CSP search algorithms to solve these CSP variants. In this paper, we extend Dynamic Backtracking and similar backjumping-based CSP search algorithms to solve WCCSPs by utilizing activity constraints and soft constraints in order to quickly prune infeasible and suboptimal regions of the search space. We provide experimental results on randomly generated WCCSP instances to prove these claims.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-005.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
12,2006,Constraint Satisfaction and Satisfiability,DNNF-based Belief State Estimation,"Paul H Elliott, Brian Williams","As embedded systems grow increasingly complex, there is a pressing need for diagnosing and monitoring capabilities that estimate the system state robustly. This paper is based on approaches that address the problem of robustness by reasoning over declarative models of the physical plant, represented as a variant of factored Hidden Markov Models, called Probabilistic Concurrent Constraint Automata. Prior work on Mode Estimation of PCCAs is based on a Best-First Trajectory Enumeration (BFTE) algorithm. Two algorithms have since made improvements to the BFTE algorithm: 1) the Best-First Belief State Update (BFBSU) algorithm has improved the accuracy of BFTE and 2) the MEXEC algorithm has introduced a polynomial-time bounded algorithm using a smooth deterministic decomposable negation normal form (sd-DNNF) representation. This paper introduces a new DNNF-based Belief State Estimation (DBSE) algorithm that merges the polynomial time bound of the MEXEC algorithm with the accuracy of the BFBSU algorithm. This paper also presents an encoding of a PCCA as a CNF with probabilistic data, suitable for compilation into an sd-DNNF-based representation. The sd-DNNF representation supports computing k belief states from k previous belief states in the DBSE algorithm.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-006.pdf,Subjects: 1.5 Diagnosis; 15.2 Constraint Satisfaction
13,2006,Constraint Satisfaction and Satisfiability,On the Use of Partially Ordered Decision Graphs for Knowledge Compilation and Quantified Boolean,"Helene Fargier, Pierre Marquis","Decomposable Negation Normal Form formulae DNNFs form an interesting propositional fragment, both for efficiency and succinctness reasons. A famous subclass of the DNNF fragment is the OBDD fragment which offers many polytime queries and transformations, including quantifier eliminations (under some ordering restrictions). Nevertheless, the decomposable AND nodes at work in OBDDs enable only sequential decisions: clusters of variables are never assigned ""in parallel"" like in full DNNFs. This is an serious drawback since succinctness for the full t DNNF fragment relies on such a ""parallelization property"". This is why we suggest to go a step further, from (sequentially) ordered decision diagrams to (partially) ordered, decomposable decision graphs, in which any decomposable AND node is allowed, and not only assignment ones. We show that, like the OBDD fragment, such a new class offers many tractable queries and transformations, including quantifier eliminations under some ordering restrictions. Furthermore, we show that this class is strictly more succinct than OBDD.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-007.pdf,Subjects: 11. Knowledge Representation; 9.2 Computational Complexity
14,2006,Constraint Satisfaction and Satisfiability,Length-Lex Ordering for Set CSPs,"Pascal Van Hentenryck, Carmen Gervet","Combinatorial design problems arise in many application areas, including networking, sport scheduling, and coding. They are naturally modelled in terms of set variables and set contraints (membership, inclusion, disjointness, and cardinality) and typically exhibit many symmetries. Traditionally, the domain of for set variables is specified by two sets (R,P) and denotes all sets containing R and included in P. While this representation is appropriate for many constraints, it has inherent difficulties in handling cardinality and lexicographic constraints so important in configuration design. This paper takes a dual view of set variables. It proposes a representation that encodes directly cardinality and lexicographic information, by totally ordering a set domain with a length-lex ordering. With this representation, the solver can achieve bound-consistency of all unary constraints in time O(k) where k is the greatest set size. In analogy with finite-domain solvers, non-unary constraints can be viewed as inference rules generating new unary constraints, allowing them to interact in reducing the domains. The resulting set-solver achieves a pruning (at least) comparable to the hybrid domain of Sadler and Gervet at a fraction of the computational cost.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-008.pdf,Subjects: 15. Problem Solving; 15.2 Constraint Satisfaction
15,2006,Constraint Satisfaction and Satisfiability,Model Counting: A New Strategy for Obtaining Good Bounds,"Carla P. Gomes, Ashish Sabharwal, Bart Selman","Model counting is the classical problem of computing the number of solutions of a given propositional formula. It vastly generalizes the NP-complete problem of propositional satisfiability, and hence is both highly useful and extremely expensive to solve in practice. We present a new approach to model counting that is based on adding a carefully chosen number of so-called streamlining constraints to the input formula in order to cut down the size of its solution space in a controlled manner. Each of the additional constraints is a randomly chosen XOR or parity constraint on the problem variables, represented either directly or in the standard CNF form. Inspired by a related yet quite different theoretical study of the properties of XOR constraints, we provide a formal proof that with high probability, the number of XOR constraints added in order to bring the formula to the boundary of being unsatisfiable determines with high precision its model count. Experimentally, we demonstrate that this approach can be used to obtain good bounds on the model counts for formulas that are far beyond the reach of exact counting methods. In fact, we obtain the first non-trivial solution counts for very hard, highly structured combinatorial problem instances. Note that unlike other counting techniques, such as Markov Chain Monte Carlo methods, we are able to provide high-confidence guarantees on the quality of the counts obtained.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-009.pdf,Subjects: 15.2 Constraint Satisfaction; 3. Automated Reasoning
16,2006,Constraint Satisfaction and Satisfiability,A BDD-Based Polytime Algorithm for Cost-Bounded Interactive Configuration,"Tarik Hadzic, Henrik Reif Andersen","Interactive configurators are decision support systems assisting users in selecting values for parameters that respect given constraints. The underlying knowledge can be conveniently formulated as a Constraint Satisfaction Problem where the constraints are propositional formulas. The problem of interactive configuration was originally inspired by the product configuration problem with the emergence of the mass-customization paradigm in product manufacturing, but has also been applied to other tasks requiring user interaction, such as specifying services or setting up complex equipment. The user-friendly requirements of complete, backtrack-free and real-time interaction makes the problem computationally challenging. Therefore, it is beneficial to compile the configuration constraints into a tractable representation such as Binary Decision Diagrams (BDD) to support efficient user interaction. The compilation deals with the NP-hardness such that the online interaction is in polynomial time in the size of the BDD.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-010.pdf,Subjects: 15.2 Constraint Satisfaction; 1.7 Expert Systems
17,2006,Constraint Satisfaction and Satisfiability,New inference Rules for efficient Max-SAT Solving,"Heras Viaga Federico, Javier Larrosa",In this paper we augment a Max-SAT solver with three new inference rules. The three of them are special cases of Max-SAT resolution with which better lower bounds and more value pruning is achieved. Our experimental results on several domains show that the resulting algorithm can be orders of magnitude faster than state-of-the-art Max-SAT solvers and the best Weighted CSP solver.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-011.pdf,Subjects: 15. Problem Solving
18,2006,Constraint Satisfaction and Satisfiability,Simple Randomized Algorithms for Tractable Row and Tree Convex Constraints,T. K. Satish Kumar,"We identify tractable classes of constraints based on the following simple property of a constraint: ""At every infeasible point, there exist two directions such that with respect to any other feasible point, moving along at least one of these two directions decreases a certain distance metric to it"". We show that connected row convex (CRC) constraints, arc-consistent consecutive tree convex (ACCTC) constraints, etc fit this characterization, and are therefore amenable to extremely simple polynomial-time randomized algorithms—the complexities of which are shown to be much less than that of the corresponding deterministic algorithms (when they exist) and/or the lower bounds for establishing path-consistency. On a related note, we also provide a simple polynomial-time deterministic algorithm for finding tree embeddings of variable domains (if they exist) for establishing tree convexity in path-consistent networks.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-012.pdf,Subjects: 15.2 Constraint Satisfaction; 9.2 Computational Complexity
19,2006,Constraint Satisfaction and Satisfiability,Weighted Constraint Satisfaction with Set Variables,"J.H.M. Lee, C.F.K. Siu","Set variables are ubiquitous in modeling (soft) constraint problems, but efforts on practical consistency algorithms for Weighted Constraint Satisfaction Problems (WCSPs) have only been on integer variables. We adapt the classical notion of set bounds consistency for WCSPs, and propose efficient representation schemes for set variables and common unary, binary, and ternary set constraints, as well as cardinality constraints. Instead of reasoning consistency on an entire set variable directly, we propose local consistency check at the set element level, and demonstrate that this apparent ""micro""-management of consistency does imply set bounds consistency at the variable level. In addition, we prove that our framework captures classical CSPs with set variables, and degenerates to the classical case when the weights in the problem contain only 0 and ⊤. Last but not least, we verify the feasibility and efficiency of our proposal with a prototype implementation, the efficiency of which is competitive against ILOG Solver on classical problems and orders of magnitude better than WCSP models using 0-1 variables to simulate set variables on soft problems.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-013.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
20,2006,Constraint Satisfaction and Satisfiability,Detecting Disjoint Inconsistent Subformulas for Computing Lower Bounds for Max-SAT,"Chu-Min Li, Felip Manya, Jordi Planes","Many lower bound computation methods for branch and bound Max-SAT solvers can be explained as procedures that search for disjoint inconsistent subformulas in the Max-SAT instance under consideration. The difference among them is the technique used to detect inconsistencies. In this paper, we define five new lower bound computation methods: two of them are based on detecting inconsistencies via a unit propagation procedure that propagates unit clauses using an original ordering; the other three add an additional level of forward look-ahead based on detecting failed literals. Finally, we provide empirical evidence that the new lower bounds are of better quality than the existing lower bounds, as well as that a solver with our new lower bounds greatly outperforms some of the best performing state-of-the-art Max-SAT solvers on Max-2SAT, Max-3SAT, and Max-Cut instances.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-014.pdf,Subjects: 15. Problem Solving; 15.2 Constraint Satisfaction
21,2006,Constraint Satisfaction and Satisfiability,Fast SAT-based Answer Set Solver,"Zhijun Lin, Yuanlin Zhang, Hector Hernandez","Recent research shows that SAT (propositional satisfiability) techniques can be employed to build efficient systems to compute answer sets for logic programs. ASSAT and CMODELS are two well-known such systems. They find an answer set from the full models for the completion of the input program, which is (iteratively) augmented with loop formulas. Making use of the fact that, for non-tight programs, during the model generation, a partial assignment may be extensible to a full model but may not grow into any answer set, we propose to add answer set extensibility checking on partial assignments. Furthermore, given a partial assignment, we identify a class of loop formulas that are ""active"" on the assignment. These “active” formulas can be used to prune the search space. We also provide an efficient method to generate these formulas. These ideas can be implemented with a moderate modification on SAT solvers. We have developed a new answer set solver SAG on top of the SAT solver MCHAFF. Empirical studies on well-known benchmarks show that in most cases it is faster than the state-of-the-art answer set solvers, often by an order of magnitude. In the few cases when it is not the winner, it is close to the top performer, which shows its robustness.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-015.pdf,Subjects: 3. Automated Reasoning; 3.3 Nonmonotonic Reasoning
22,2006,Constraint Satisfaction and Satisfiability,Local-search Techniques for Boolean Combinations of Pseudo-Boolean Constraints,"Lengning Liu, Miroslaw Truszczynski","Some search problems are most directly specified by boolean combinations of pseudo-boolean constraints. We study a logic PL(PB) whose formulas are of this form, and design local-search methods to compute models of PL(PB)-theories. In our approach we view a PL(PB)-theory T as a data structure — a concise representation of a certain propositional CNF theory cl(T) logically equivalent to T. We show that parameters needed by local-search algorithms for CNF theories, such as WalkSAT, can be estimated on the basis of T, without the need to compute cl(T) explicitly. Since cl(T) is often much larger than T, running search based on T promises performance gains. Our experimental results confirm this expectation.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-016.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
23,2006,Constraint Satisfaction and Satisfiability,Efficient Haplotype Inference with Boolean Satisfiability,"Ines Lynce, Joao Marques-Silva","One of the main topics of research in genomics is determining the relevance of mutations, described in haplotype data, as causes of some genetic diseases. However, due to technological limitations, genotype data rather than haplotype data is usually obtained. The haplotype inference by pure parsimony (HIPP)problem consists in inferring haplotypes from genotypes s.t.~the number of required haplotypes is minimum. Previous approaches to the HIPP problem have focused on integer programming models and branch-and-bound algorithms. In contrast, this paper proposes the utilization of Boolean Satisfiability (SAT). The proposed solution entails a SAT model, a number of key pruning techniques, and an iterative algorithm that enumerates the possible solution values for the target optimization problem. Experimental results, obtained on a wide range of instances, demonstrate that the SAT-based approach can be several orders of magnitude faster than existing solutions. Besides being more efficient, the SAT-based approach is also the only capable of computing the solution for a large number of instances.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-017.pdf,Subjects: 15. Problem Solving; 1. Applications
24,2006,Constraint Satisfaction and Satisfiability,Temporal Preference Optimization as Weighted Constraint Satisfaction,"Michael D. Moffitt, Martha E. Pollack","We present a new efficient algorithm for obtaining utilitarian optimal solutions to Disjunctive Temporal Problems with Preferences (DTPPs). The previous state-of-the-art system achieves temporal preference optimization using a SAT formulation, with its creators attributing its performance to advances in SAT solving techniques. We depart from the SAT encoding and instead introduce the Valued DTP (VDTP). In contrast to the traditional semiring-based formalism that annotates legal tuples of a constraint with preferences, our framework instead assigns elementary costs to the constraints themselves. After proving that the VDTP can express the same set of utilitarian optimal solutions as the DTPP with piecewise-constant preference functions, we develop a method for achieving weighted constraint satisfaction within a meta-CSP search space that has traditionally been used to solve DTPs without preferences. This allows us to directly incorporate several powerful techniques developed in previous decision-based DTP literature. Finally, we present empirical results demonstrating that an implementation of our approach consistently outperforms the SAT-based solver by orders of magnitude.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-018.pdf,Subjects: 3.6 Temporal Reasoning; 15.2 Constraint Satisfaction
25,2006,Constraint Satisfaction and Satisfiability,An Efficient Way of Breaking Value Symmetries,Jean-Francois Puget,"Several methods for breaking value symmetries have been proposed recently in the constraint programming community. They can be used in conjunction with variable symmetry breaking methods. However, this combination does not break all symmetries in general. We present a combination of lex constraints and element constraints that can be used to break all combinations of variable and value symmetries. It is the first time to our knowledge that it is possible to break all combinations of value and variable symmetries by adding constraints. This method is quite efficient when the number of symmetries is not too large, as shown by experiments using graceful graph problems. We also present a new global constraint that deals with the case where there are too many value symmetries. Experiments show that this is highly effective.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-019.pdf,Subjects: 15.2 Constraint Satisfaction
26,2006,Constraint Satisfaction and Satisfiability,A Quadratic Propagator for the Inter-Distance Constraint,"Claude-Guy Quimper, Alejandro Lopez-Ortiz, Gilles Pesant","We present a new propagator achieving bound consistency for the Inter-Distance constraint. This constraint ensures that, among a set of variables X1, ..., Xn, the difference between two variables is at least p. This restriction models, in particular, scheduling problems in which tasks require p contiguous units of a resource to be completed. Until now, the best known propagator for bound consistency had time complexity O(n3). In this work we propose a quadratic propagator for the same level of consistency. We then show that this theoretical gain gives savings of an order of magnitude in our benchmark of scheduling problems.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-020.pdf,Subjects: 15.2 Constraint Satisfaction; 1.12 Scheduling
27,2006,Constraint Satisfaction and Satisfiability,Answer Sets for Logic Programs with Arbitrary Abstract Constraint Atoms,"Cao Son Tran, Enrico Pontelli, Phan Huy Tu","We present two equivalent approaches for defining answer sets for logic programs with arbitrary abstract constraint atoms (c-atoms). The first approach uses an immediate consequence operator for answer set checking, whose definition relies on the notion of conditional satisfaction of c-atoms w.r.t. a pair of interpretations. The second approach generalizes the notion of well-supported models of normal logic programs to programs with c-atoms. We prove that the newly defined semantics coincides with previously introduced semantics for logic programs with monotone c-atoms and extends the original answer set semantics for normal logic programs. We discuss different possibilities for treating negation-as-failure c-atoms and characterize situations in which they yield the same answer sets. We study some properties of answer sets of programs with c-atoms and relate our definition to several semantics for logic programs with aggregates.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-021.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
28,2006,Constraint Satisfaction and Satisfiability,An Asymptotically Optimal Algorithm for the Max k-Armed Bandit Problem,Matthew J. Streeter and Stephen F. Smith,We present an asymptotically optimal algorithm for the max variant of the k-armed bandit problem.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-022.pdf,
29,2006,Constraint Satisfaction and Satisfiability,Solving QBF with Combined Conjunctive and Disjunctive Normal Form,Lintao Zhang,"Similar to most state-of-the-art Boolean Satisfiability (SAT) solvers, all contemporary Quantified Boolean Formula (QBF) solvers require inputs to be in the Conjunctive Normal Form (CNF). Most of them also store the QBF in CNF internally for reasoning. In order to use these solvers, arbitrary Boolean formulas have to be transformed into equi-satisfiable formulas in Conjunctive Normal Form by introducing additional variables. In this paper, we point out an inherent limitation of this approach, namely the asymmetric treatment of satisfactions and conflicts. This deficiency leads to artificial increase of search space for QBF solving. To overcome the limitation, we propose to transform a Boolean formula into a combination of an equi-satisfiable CNF formula and an equi-tautological DNF formula for QBF solving. QBF solvers based on this approach treat satisfactions and conflicts symmetrically, thus avoiding the exploration of unnecessary search space. A QBF solver called IQTest is implemented based on this idea. Experimental results show that it significantly outperforms existing QBF solvers.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-023.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
30,2006,Human Computer Interaction and Cognitive Modeling,Classifying Learner Engagement through Integration of Multiple Data Sources,"Carole R Beal, Lei Qu, Hyokyeong Lee","Intelligent tutoring systems (ITS) can provide effective instruction, but learners do not always use such systems effectively. In the present study, high school students' action sequences with a mathematics ITS were machine-classified into five finite-state machines indicating guessing strategies, appropriate help use, and independent problem solving; over 90% of problem events were categorized. Students were grouped via cluster analyses based on self reports of motivation. Motivation grouping predicted ITS strategic approach better than prior math achievement (as rated by classroom teachers). Learners who reported being disengaged in math were most likely to exhibit appropriate help use while working with the ITS, relative to average and high motivation learners. The results indicate that learners can readily report their motivation state and that these data predict how learners interact with the ITS.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-024.pdf,Subjects: 1.3 Computer-Aided Education; 4. Cognitive Modeling
31,2006,Human Computer Interaction and Cognitive Modeling,Evaluating Critiquing-based Recommender Agents,"Li Chen, Pearl Pu","We describe a user study evaluating two critiquing-based recommender agents based on three criteria: decision accuracy, decision effort, and user confidence. Results show that user-motivated critiques were more frequently applied and the example critiquing system employing only this type of critiques achieved the best results. In particular, the example critiquing agent significantly improves users' decision accuracy with less cognitive effort consumed than the dynamic critiquing recommender with system-proposed critiques. Additionally, the former is more likely to inspire users' confidence of their choice and promote their intention to purchase and return to the agent for future use.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-025.pdf,Subjects: 6. Computer-Human Interaction; 6.3 User Interfaces
32,2006,Human Computer Interaction and Cognitive Modeling,A Dynamic Mixture Model to Detect Student Motivation and Proficiency,"Jeff Johns, Beverly Woolf","Unmotivated students do not reap the full rewards of using a computer-based intelligent tutoring system. Detection of improper behavior is thus an important component of an online student model. To meet this challenge, we present a dynamic mixture model based on Item Response Theory. This model, which simultaneously estimates a student's proficiency and changing motivation level, was tested with data of high school students using a geometry tutoring system. By accounting for student motivation, the dynamic mixture model can more accurately estimate proficiency and the probability of a correct response. The model's generality is an added benefit, making it applicable to many intelligent tutoring systems as well as other domains.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-026.pdf,Subjects: 6. Computer-Human Interaction
33,2006,Human Computer Interaction and Cognitive Modeling,Modeling Human Decision Making in Cliff-Edge Environments,"Ron Katz, Sarit Kraus","In this paper we propose a model for human learning and decision making in environments of repeated Cliff-Edge (CE) interactions. In CE environments, which include common daily interactions, such as sealed-bid auctions and the Ultimatum Game (UG), the probability of success decreases monotonically as the expected reward increases. Thus, CE environments are characterized by an underlying conflict between the strive to maximize profits and the fear of causing the entire deal to fall through. We focus on the behavior of people who repeatedly compete in one-shot CE interactions, with a different opponent in each interaction. Our model, which is based upon the Deviated Virtual Reinforcement Learning (DVRL) algorithm, integrates the Learning Direction Theory with the Reinforcement Learning algorithm. We also examined several other models, using an innovative methodology in which the decision dynamics of the models were compared with the empirical decision patterns of individuals during their interactions. An analysis of human behavior in auctions and in the UG reveals that our model fits the decision patterns of far more subjects than any other model.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-027.pdf,Subjects: 4. Cognitive Modeling; 12.1 Reinforcement Learning
34,2006,Human Computer Interaction and Cognitive Modeling,Using Anticipation to Create Believable Behaviour,"Carlos Martinho, Ana Paiva","Although anticipation is an important part of creating believable behaviour, it has had but a secondary role in the field of life-like characters. In this paper, we show how a simple anticipatory mechanism can be used to control the behaviour of a synthetic character implemented as a software agent, without disrupting the user's suspension of disbelief. We describe the emotivector, an anticipatory mechanism coupled with a sensor, that: (1) uses the history of the sensor to anticipate the next sensor state; (2) interprets the mismatch between the prediction and the sensed value, by computing its attention grabbing potential and associating a basic qualitative sensation with the signal; (3) sends its interpretation along with the signal. When a signal from the sensor reaches the processing module of the agent, it carries recommendations such as: 'you should seriously take this signal into consideration, as it is much better than we had expected' or 'just forget about this one, it is as bad as we predicted'. We delineate several strategies to manage several emotivectors at once and show how one of these strategies (meta-anticipation) transparently introduces the concept of uncertainty. Finally, we describe an experiment in which an emotivector-controlled synthetic character interacts with the user in the context of a word-puzzle game and present the evaluation supporting the adequacy of our approach.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-028.pdf,Subjects: 6.1 Life-Like Characters; 7.2 Software Agents
35,2006,Human Computer Interaction and Cognitive Modeling,Extracting Knowledge about Users' Activities from Raw Workstation Contents,"Tom M. Mitchell, Sophie H. Wang, Yifen Huang, Adam Cheyer","A long-standing goal of AI is the development of intelligent workstation-based personal agents to assist users in their daily lives. A key impediment to this goal is the unrealistic cost of developing and maintaining a detailed knowledge base describing the user’s different activities, and which people, meetings, emails, etc. are affiliated with each such activity. This paper presents a clustering approach to automatically acquiring such a knowledge base by analyzing the raw contents of the workstation, including emails, contact person names, and online calendar meetings. Our approach analyzes the distribution of email words, the social network of email senders and recipients, and the results of Google Desktop Search queried with text from online calendar entries and person contact names. For each cluster it constructs, the program outputs a frame-based representation of the corresponding user activity. This paper describes our approach and experimentally assesses its performance over the workstations of three different users.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-029.pdf,Subjects: 12. Machine Learning and Discovery; 7.2 Software Agents
36,2006,Human Computer Interaction and Cognitive Modeling,Probabilistic Goal Recognition in Interactive Narrative Environments,"Bradford Mott, Sunyoung Lee, James Lester","Recent years have witnessed a growing interest in interactive narrative-centered virtual environments for education, training, and entertainment. Narrative environments dynamically craft engaging story-based experiences for users, who are themselves active participants in unfolding stories. A key challenge posed by interactive narrative is recognizing users' goals so that narrative planners can dynamically orchestrate plot elements and character actions to create rich, customized stories. In this paper we present an inductive approach to predicting users' goals by learning probabilistic goal recognition models. This approach has been evaluated in a narrative environment for the domain of microbiology in which the user plays the role of a medical detective solving a science mystery. An empirical evaluation of goal recognition based on n-gram models and Bayesian networks suggests that the models offer significant predictive power.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-030.pdf,Subjects: 6. Computer-Human Interaction
37,2006,Human Computer Interaction and Cognitive Modeling,Salience in Orientation-Filter Response Measured as Suspicious Coincidence in Natural Images,"Subramonia Sarma, Yoonsuck Choe","Visual cortex neurons have receptive fields resembling oriented bandpass filters, and their response distributions on natural images are non-Gaussian. Inspired by this, we previously showed that comparing the response distribution to normal distribution with the same variance gives a good thresholding criterion for detecting salient levels of edginess in images. However, (1) the results were based on comparison with human data, thus, an objective, quantitative performance measure was not taken. Furthermore, (2) why a normal distribution would serve as a good baseline was not investigated in full. In this paper, we first conduct a quantitative analysis of the normal-distribution baseline, using artificial images that closely mimic the statistics of natural images. Since in these artificial images, we can control and obtain the exact saliency information, the performance of the thresholding algorithm can be measured objectively. We then interpret the issue of the normal distribution being an effective baseline for thresholding, under the general concept of suspicious coincidence proposed by Barlow. It turns out that salience defined our way can be understood as a deviation from the unsuspicious baseline. Our results show that the response distribution on white-noise images (where there is no structure, thus zero salience and nothing suspicious) has a near-Gaussian distribution. We then show that the response threshold directly calculated from the response distribution to white-noise images closely matches that of humans, providing further support for the analysis. In sum, our results and analysis show an intimate relationship among subjective perceptual measure of salience, objective measures of salience using normal distributions as a baseline, and the theory of suspicious coincidence.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-031.pdf,Subjects: 19. Vision; 19.1 Perception
38,2006,Human Computer Interaction and Cognitive Modeling,From Pigeons to Humans: Grounding Relational Learning in Concrete Examples,"Marc T. Tomlinson, Bradley C. Love","We present a cognitive model that bridges work in analogy and category learning. The model, Building Relations through Instance Driven Gradient Error Shifting (BRIDGES), extends ALCOVE, an exemplar-based connectionist model of human category learning (Kruschke, 1992). Unlike ALCOVE which is limited to featural or spatial representations, BRIDGES can appreciate analogical relationships between stimuli and stored predicate representations of exemplars. Like ALCOVE, BRIDGES learns to shift attention over the course of learning to reduce error and, in the process, alters its notion of similarity. A shift toward relational sources of similarity allows BRIDGES to display what appears to be an understanding of abstract domains, when in fact performance is driven by similarity-based structural alignment (i.e., analogy) to stored exemplars. Supportive simulations of animal, infant, and adult learning are provided. We end by considering possible extensions of BRIDGES suitable for computationally demanding applications.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-032.pdf,Subjects: 4. Cognitive Modeling; 11. Knowledge Representation
39,2006,Human Computer Interaction and Cognitive Modeling,Evaluating Preference-based Search Tools: A Tale of Two Approaches,"Paolo Viappiani, Boi Faltings, and Pearl Pu","People frequently use the world-wide web to find their most preferred item among a large range of options. We call this task preference-based search. The most common tool for preference-based search on the WWW today obtains users’ preferences by asking them to fill in a form. It then returns a list of items that most closely match these preferences. Recently, several researchers have proposed tools for preference-based search that elicit preferences from the critiques a user actively makes on examples shown to them. We carried out a user study in order to compare the performance of traditional preference-based search tools using form-filling with two different versions of an example-critiquing tool. The results show that example critiquing achieves almost three times the decision accuracy, while requiring only slightly higher interaction effort.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-033.pdf,
40,2006,Knowledge Representation and Logic,Model-Checking Memory Requirements of Resource-Bounded Reasoners,"Alex Albore, Natasha Alechina, Piergiorgio Bertoli, Chiara Ghidini, Brian Logan, Luciano Serafini","Memory bounds may limit the ability of a reasoner to make inferences and therefore affect the reasoner's usefulness. In this paper, we propose a framework to automatically verify the reasoning capabilities of propositional memory-bounded reasoners which have a sequential architecture. Our framework explicitly accounts for the use of memory both to store facts and to support backtracking in the course of deductions. We describe an implementation of our framework in which proof existence is recast as a strong planning problem, and present results of experiments using the MBP planner which indicate that memory bounds may not be trivial to infer even for simple problems, and that memory bounds and length of derivations are closely interrelated.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-034.pdf,Subjects: 3. Automated Reasoning; 9. Foundational Issues
41,2006,Knowledge Representation and Logic,Explaining Qualitative Decision Under Uncertainty by Argumentation,"Leila Amgoud, Henri Prade","Decision making under uncertainty is usually based on the comparative evaluation of different alternatives by means of a decision criterion. In a qualitative setting, pessimistic and optimistic criteria have been proposed. In that setting, the whole decision process is compacted into a criterion formula on the basis of which alternatives are compared. It is thus impossible for an end user to understand why an alternative is good, or better than another. Besides, argumentation is a powerful tool for explaining inferences, decisions, etc. This paper articulates optimistic and pessimistic decision criteria in terms of an argumentation process that consists of constructing arguments in favor/against decisions, evaluating the strengths of those arguments, and comparing pairs of alternatives on the basis of their supporting/attacking arguments.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-035.pdf,Subjects: 15.5 Decision Theory; 3.5 Qualitative Reasoning
42,2006,Knowledge Representation and Logic,Compilation of Query-Rewriting Problems into Tractable Fragments of Propositional Logic,"Yolife Arvelo, Blai Bonet, Maria Esther Vidal","We consider the problem of rewriting a query efficiently using materialized views. In the context of information integration, this problem has received significant attention in the scope of emerging infrastructures such as WWW, Semantic Web, Grid, and P2P which require efficient algorithms. The problem is in general intractable, and the current algorithms do not scale well when the number of views or the size of the query grow. We show however that this problem can be encoded as a propositional theory in CNF such that its models are in correspondence with the rewritings of the query. The theory is then compiled into a normal form, that is called d-DNNF and supports several operations like model counting and enumeration in polynomial time (in the size of the compiled theory), for computing the rewritings. Although this method is also intractable in the general case, it is not necessarily so in all cases. We have developed, along these lines and from off the shelf propositional engines, novel algorithms for finding maximally-contained rewritings of the query given the set of accessible resources (views). The algorithms scale much better than the current state-of-the-art algorithm, the MiniCon algorithm, over a large number of benchmarks and show in some cases improvements in performance of a couple orders of magnitude.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-036.pdf,Subjects: 8. Enabling Technologies; 3.5 Qualitative Reasoning
43,2006,Knowledge Representation and Logic,"Goal Specification, Non-determinism and Quantifying over Policies","Chitta Baral, Jicheng Zhao","One important aspect in directing cognitive robots or agents is to formally specify what is expected of them. This is often referred to as goal specification. Temporal logics such as LTL, and CTL* have been used to specify goals of cognitive robots and agents when their actions have deterministic consequences. It has been suggested that in domains where actions have non-deterministic effects, temporal logics may not be able to express many intuitive and useful goals. In this paper we first show that this is indeed true with respect to existing temporal logics such as LTL, CTL*, and pi-CTL*. We then propose the language, P-CTL*, which includes the quantifiers, exist a policy and for all policies. We show that this language allows for the specification of richer goals, including many intuitive and useful goals mentioned in the literature which cannot be expressed in existing temporal languages. We generalize our approach of showing the limitations of pi-CTL* to develop a framework to compare expressiveness of goal languages.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-037.pdf,Subjects: 11. Knowledge Representation; 7.2 Software Agents
44,2006,Knowledge Representation and Logic,Forgetting and Conflict Resolving in Disjunctive Logic Programming,"Thomas Eiter, Kewen Wang","We establish a declarative theory of forgetting for disjunctive logic programs. The suitability of this theory is justified by a number of desirable properties. In particular, one of our results shows that our notion of forgetting is completely captured by the classical forgetting. A transformation-based algorithm is also developed for computing the result of forgetting. We also provide an analysis of computational complexity. As an application of our approach, a fairly general framework for resolving conflicts in inconsistent knowledge bases represented by disjunctive logic programs is defined. The basic idea of our framework is to weaken the preferences of each agent by forgetting certain knowledge that causes inconsistency. In particular, we show how to use the notion of forgetting to provide an elegant solution for preference elicitation in disjunctive logic programming.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-038.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
45,2006,Knowledge Representation and Logic,Elementary Sets of Logic Programs,"Martin Gebser, Joohyung Lee, Yuliya Lierler","By introducing the concepts of a loop and a loop formula, Lin and Zhao showed that the answer sets of a nondisjunctive logic program are exactly the models of its Clark's completion that satisfy the loop formulas of all loops. Recently, Gebser and Schaub showed that the Lin-Zhao theorem remains correct even if we restrict loop formulas to a special class of loops called ""elementary loops."" In this paper, we simplify and generalize the notion of an elementary loop, and clarify its role. We propose the notion of an elementary set, which is almost equivalent to the notion of an elementary loop for nondisjunctive programs, but is simpler, and, unlike elementary loops, can be extended to disjunctive programs without producing unintuitive results. We show that the maximal unfounded elementary sets for the ""relevant"" part of a program are exactly the minimal sets among the nonempty unfounded sets. We also present a graph-theoretic characterization of elementary sets for nondisjunctive programs, which is simpler than the one proposed in Gebser and Schaub (2005). Unlike the case of nondisjunctive programs, we show that the problem of deciding an elementary set is coNP-complete for disjunctive programs.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-039.pdf,Subjects: 3.3 Nonmonotonic Reasoning
46,2006,Knowledge Representation and Logic,Bounded Treewidth as a Key to Tractability of Knowledge Representation and Reasoning,"Georg Gottlob, Reinhard Pichler, Fang Wei","Several forms of reasoning in AI -- like abduction, closed world reasoning, circumscription, and disjunctive logic programming -- are well known to be intractable. In fact, many of the relevant problems are on the second or third level of the polynomial hierarchy. In this paper, we show how the powerful notion of treewidth can be fruitfully applied to this area. In particular, we show that all these problems become tractable (actually, even solvable in linear time), if the treewidth of the involved formulae (or of the disjunctive logic programs, resp.) is bounded by some constant. Experiments with a prototype implementation prove the feasibility of this new approach, in principle, and also give us hints for necessary improvements. In many areas of computer science, bounded treewidth has been shown to be a realistic and practically relevant restriction. We thus argue that bounded treewidth is a key factor in the development of efficient algorithms also in knowledge representation and reasoning -- despite the high worst case complexity of the problems of interest.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-040.pdf,Subjects: 9. Foundational Issues
47,2006,Knowledge Representation and Logic,Belief Change in the Context of Fallible Actions and Observations,"Aaron Hunter, James P. Delgrande","We consider the iterated belief change that occurs following an alternating sequence of actions and observations. At each instant, an agent has some beliefs about the action that occurs as well as beliefs about the resulting state of the world. We represent such problems by a sequence of ranking functions, so an agent assigns a quantitative plausibility value to every action and every state at each point in time. The resulting formalism is able to represent fallible knowledge, erroneous perception, exogenous actions, and failed actions. We illustrate that our framework is a generalization of several existing approaches to belief change, and it appropriately captures the non-elementary interaction between belief update and belief revision.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-041.pdf,Subjects: 15.1 Belief Revision; 5. Common Sense Reasoning
48,2006,Knowledge Representation and Logic,Towards an Axiom System for Default Logic,"Gerhard Lakemeyer, Hector J. Levesque","Recently, Lakemeyer and Levesque proposed a logic of only-knowing which precisely captures three forms of nonmonotonic reasoning: Moore's Autoepistemic Logic, Konolige's variant based on moderately grounded expansions, and Reiter's default logic. Defaults have a uniform representation under all three interpretations in the new logic. Moreover, the logic itself is monotonic, that is, nonmonotonic reasoning is cast in terms of validity in the classical sense. While Lakemeyer and Levesque gave a model-theoretic account of their logic, a proof-theoretic characterization remained open. This paper fills that gap for the propositional subset: a sound and complete axiom system in the new logic for all three varieties of default reasoning. We also present formal derivations for some examples of default reasoning. Finally we present evidence that it is unlikely that a complete axiom system exists in the first-order case, even when restricted to the simplest forms of default reasoning.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-042.pdf,Subjects: 3.3 Nonmonotonic Reasoning; 9.3 Mathematical Foundations
49,2006,Knowledge Representation and Logic,Finding Maximally Satisfiable Terminologies for the Description Logic ALC,"Thomas Meyer, Kevin Lee, Richard Booth, Jeff Pan.","For ontologies represented as Description Logic Tboxes, optimised DL reasoners are able to detect logical errors, but there is comparatively limited support for resolving such problems. One possible remedy is to weaken the available information to the extent that the errors disappear, but to limit the weakening process as much as possible. The most obvious way to do so is to remove just enough Tbox sentences to eliminate the errors. In this paper we propose a tableau-like procedure for finding maximally concept-satisfiable terminologies represented in the description logic ALC. We discuss some optimisation techniques, and report on preliminary, but encouraging, experimental results.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-043.pdf,Subjects: 11.1 Description Logics; 11. Knowledge Representation
50,2006,Knowledge Representation and Logic,Characterizing Data Complexity for Conjunctive Query Answering in Expressive Description Logics,"Magdalena Ortiz, Diego Calvanese, and Thomas Eiter","Description Logics (DLs) are the formal foundations of the standard web ontology languages OWL-DL and OWL-Lite. In the Semantic Web and other domains, ontologies are increasingly seen also as a mechanism to access and query data repositories. This novel context poses an original combination of challenges that has not been addressed before: (i) sufficient expressive power of the DL to capture common data modeling constructs; (ii) well established and flexible query mechanisms such as Conjunctive Queries (CQs); (iii) optimization of inference techniques with respect to data size, which typically dominates the size of ontologies. This calls for investigating data complexity of query answering in expressive DLs. While the complexity of DLs has been studied extensively, data complexity has been characterized only for answering atomic queries, and was still open for answering CQs in expressive DLs. We tackle this issue and prove a tight CONP upper bound for the problem in SHIQ, as long as no transitive roles occur in the query. We thus establish that for a whole range of DLs from AL to SHIQ, answering CQs with no transitive roles has CONP-complete data complexity. We obtain our result by a novel tableaux-based algorithm for checking query entailment, inspired by the one in [19], but which manages the technical challenges of simultaneous inverse roles and number restrictions (which leads to a DL lacking the finite model property).",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-044.pdf,
51,2006,Knowledge Representation and Logic,Merging Stratified Knowledge Bases under Constraints,"Gulin Qi, Weiru Liu, David A. Bell","In this paper, we propose a family of operators for merging stratified knowledge bases under integrity constraints. The operators are defined in a model-theoretic way. Our merging operators can be used to merge stratified knowledge bases where no numerical information is available. Furthermore, the original knowledge bases to be merged can be individually inconsistent. Both logical properties and computational complexity issues of the operators are studied.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-045.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
52,2006,Knowledge Representation and Logic,Reconciling Situation Calculus and Fluent Calculus,Stephan Schiffel and Michael Thielscher,"The Situation Calculus and the Fluent Calculus are successful action formalisms that share many concepts. But until now there is no formal relation between the two calculi that would allow to formally analyze the relationship between the two approaches as well as between the programming languages based on them, Golog and FLUX. Furthermore, such a formal relation would allow to combine Golog and FLUXand to analyze which of the underlying computation principles is better suited for different classes of programs. We develop a formal translation between domain axiomatizations of the Situation Calculus and the Fluent Calculus and present a Fluent Calculus semantics for Golog programs. For domains with deterministic actions our approach allows an automatic translation of Golog domain descriptions and execution of Golog programs with FLUX.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-046.pdf,
53,2006,Knowledge Representation and Logic,Classification Spanning Private Databases,"Ke Wang, Yabo Xu, Rong She, Philip S. Yu","In this paper, we study the classification problem involving information spanning multiple private databases. The privacy challenges lie in the facts that data cannot be collected in one place and the classifier itself may disclose private information. We present a novel solution that builds the same decision tree classifier as if data are collected in a central place, but preserves the privacy of participating sites.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-047.pdf,Subjects: 15.6 Decision Trees
54,2006,Knowledge Representation and Logic,On the Complexity of Linking Deductive and Abstract Argument Systems,"Michael Wooldridge, Paul E. Dunne, Simon Parsons","We investigate the computational complexity of a number of questions relating to deductive argument systems, in particular the complexity of linking deductive and more abstract argument systems. We start by presenting a simple model of deductive arguments based on propositional logic, and define logical equivalence and defeat over individual arguments. We then extend logical equivalence to sets of arguments, and show that the problem of checking equivalence of argument sets is co-NP-complete. We also show that the problem of checking that an argument set contains no two logically equivalent arguments is NP-complete, while the problem of checking that a set of arguments is maximal (i.e., that no argument could be added without such an argument being logically equivalent to one that is already present) is co-NP-complete. We then show that checking whether a digraph over an argument set is sound with respect to the defeat relation is co-NP-complete, while the problem of showing that such a digraph is complete is NP-complete, and the problem of showing both soundness and completeness is D^p-complete.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-048.pdf,Subjects: 11. Knowledge Representation; 9.2 Computational Complexity
55,2006,Knowledge Representation and Logic,A Unified Knowledge Based Approach for Sense Disambiguation and Semantic Role Labeling,"Peter Z. Yeh, Bruce Porter, Ken Barker","In this paper, we present a unified knowledge based approach for sense disambiguation and semantic role labeling. Our approach performs both tasks through a single algorithm that matches candidate semantic interpretations to background knowledge to select the best matching candidate. We evaluate our approach on a corpus of sentences collected from various domains and show how our approach performs well on both sense disambiguation and semantic role labeling.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-049.pdf,Subjects: 13. Natural Language Processing; 10. Knowledge Acquisition
56,2006,Machine Learning,Clustering by Exceptions,Fabrizio Angiulli,"A density-based clustering algorithm, called OUTCLUST, is presented. The algorithm exploits a notion of local density in order to find homogeneous groups of objects as opposite to objects mostly deviating from the overall population. The proposed algorithm tries to simultaneously consider several features of real data sets, namely finding clusters of different shapes and densities in high dimensional data in presence of noise. It is shown that the method is able to identify very meaningful clusters, and experimental comparison with partitioning, hierarchial, and density-based clustering algorithms, is presented, pointing out that the algorithm achieves good clustering quality.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-050.pdf,Subjects: 12. Machine Learning and Discovery
57,2006,Machine Learning,On the Difficulty of Modular Reinforcement Learning for Real-World Partial Programming,"Sooraj Bhat, Charles L. Isbell Jr., Michael Mateas","In recent years there has been a great deal of interest in ""modular reinforcement learning"" (MRL). Typically, problems are decomposed into concurrent subgoals, allowing increased scalability and state abstraction. An arbitrator combines the subagents' preferences to select an action. In this work, we contrast treating an MRL agent as a set of subagents with the same goal with treating an MRL agent as a set of subagents who may have different, possibly conflicting goals. We argue that the latter is a more realistic description of real-world problems, especially when building partial programs. We address a range of algorithms for single-goal MRL, and leveraging social choice theory, we present an impossibility result for applications of such algorithms to multi-goal MRL. We suggest an alternative formulation of arbitration as scheduling that avoids the assumptions of comparability of preference that are implicit in single-goal MRL. A notable feature of this formulation is the explicit codification of the tradeoffs between the subproblems. Finally, we introduce A2BL, a language that encapsulates many of these ideas.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-051.pdf,Subjects: 12.1 Reinforcement Learning
58,2006,Machine Learning,On Combining Multiple Classifiers Using an Evidential Approach,"Yaxin Bi, Sally McClean, Terry Anderson","Combining multiple classifiers via combining schemes or meta-learners has led to substantial improvements in many classification problems. One of the challenging tasks is to choose appropriate combining schemes and classifiers involved in an ensemble of classifiers. In this paper we propose a novel evidential approach to combining decisions given by multiple classifiers. We develop a novel evidence structure ñ a focal triplet, examine its theoretical properties and establish computational formulations for representing classifier outputs as pieces of evidence to be combined. The evaluations on the effectiveness of the established formalism have been carried out over the data sets of 20-newsgroup and Reuters-21578, demonstrating the advantage of this novel approach in combining classifiers.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-052.pdf,Subjects: 12. Machine Learning and Discovery; 3.4 Probabilistic Reasoning
59,2006,Machine Learning,Tensor Embedding Methods,"Guang Dai, Dit-Yan Yeung","Over the past few years, some embedding methods have been proposed for feature extraction and dimensionality reduction in various machine learning and pattern classification tasks. Among the methods proposed are Neighborhood Preserving Embedding (NPE), Locality Preserving Projection (LPP) and Local Discriminant Embedding (LDE) which have been used in such applications as face recognition and image/video retrieval. However, although the data in these applications are more naturally represented as higher-order tensors, the embedding methods can only work with vectorized data representations which may not capture well some useful information in the original data. Moreover, high-dimensional vectorized representations also suffer from the curse of dimensionality and the high computational demand. In this paper, we propose some novel tensor embedding methods which, unlike previous methods, take data directly in the form of tensors of arbitrary order as input. These methods allow the relationships between dimensions of a tensor representation to be efficiently characterized. Moreover, they also allow the intrinsic local geometric and topological properties of the manifold embedded in a tensor space to be naturally estimated. Furthermore, they do not suffer from the curse of dimensionality and the high computational demand. We demonstrate the effectiveness of the proposed tensor embedding methods on a face recognition application and compare them with some previous methods. Extensive experiments show that our methods are not only more effective but also more efficient.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-053.pdf,Subjects: 12. Machine Learning and Discovery
60,2006,Machine Learning,Identifying and Generating Easy Sets of Constraints For Clustering,"Ian N Dvidson, S.S. Ravi","Clustering under constraints is a recent innovation in the artificial intelligence community that has yielded significant practical benefit. However, recent work has shown that for some negative forms of constraints the associated subproblem of just finding a feasible clustering is NP-complete. These worst case results for the entire problem class say nothing of where and how prevalent easy problem instances are. In this work, we show that there are large pockets within these problem classes where clustering under constraints is easy and that using easy sets of constraints yields better empirical results. We then illustrate several sufficient conditions from graph theory to identify a priori where these easy problem instances are and present algorithms to create large and easy to satisfy constraint sets.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-054.pdf,Subjects: 12. Machine Learning and Discovery
61,2006,Machine Learning,"Nonnegative Matrix Factorization and Probabilistic Latent Semantic Indexing: Equivalence, Chi-square Statistic, and a Hybrid Method","Chris Ding, Tao Li, Wei Peng","Non-negative Matrix Factorization (NMF) and Probabilistic Latent Semantic Indexing (PLSI) have been successfully applied to document clustering recently. In this paper, we show that PLSI and NMF optimize the same objective function, although PLSI and NMF are different algorithms as verified by experiments. This provides a theoretical basis for a new hybrid method that runs PLSI and NMF alternatively, each jumping out of local minima of the other method successively, thus achieving better final solution. Extensive experiments on 5 real-life datasets show relations between NMF and PLSI, and indicate the hybrid method lead to significant improvements over NMF-only or PLSI-only methods. We also show that at first order approximation, NMF is identical to Chi-square Statistic.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-055.pdf,Subjects: 12. Machine Learning and Discovery
62,2006,Machine Learning,Anytime Induction of Decision Trees: an Iterative Improvement Approach,"Saher Esmeir, Shaul Markovitch","Most existing decision tree inducers are very fast due to their greedy approach. In many real-life applications, however, we are willing to allocate more time to get better decision trees. Our recently introduced LSID3 contract anytime algorithm allows computation speed to be traded for better tree quality. As a contract algorithm, LSID3 must be allocated its resources a priori, which is not always possible. In this work, we present IIDT, a general framework for interruptible induction of decision trees that need not be allocated resources a priori. The core of our proposed framework is an iterative improvement algorithm that repeatedly selects a subtree whose reconstruction is expected to yield the highest marginal utility. The algorithm then rebuilds the subtree with a higher allocation of resources. IIDT can also be configured to receive training examples as they become available, and is thus appropriate for incremental learning tasks. Empirical evaluation with several hard concepts shows that IIDT exhibits good anytime behavior and significantly outperforms greedy inducers when more time is available. A comparison of IIDT to several modern decision tree learners showed it to be superior.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-056.pdf,Subjects: 12. Machine Learning and Discovery; 15.6 Decision Trees
63,2006,Machine Learning,Incremental Least-Squares Temporal Difference Learning,"Alborz Geramifard, Michael Bowling, Richard S. Sutton","Approximate policy evaluation with linear function approximation is a commonly arising problem in reinforcement learning, usually solved using temporal difference (TD) algorithms. In this paper we introduce a new variant of linear TD learning, called incremental least-squares TD learning, or iLSTD. This method is more data efficient than conventional TD algorithms such as TD(0) and is more computationally efficient than non-incremental least-squares TD methods such as LSTD. In particular, we show that the per-time-step complexities of iLSTD and TD(0) are O(n), where n is the number of features, whereas that of LSTD is O(n^2). This difference can be decisive in modern applications of reinforcement learning where the use of a large number features has proven to be an effective solution strategy. We present empirical comparisons, using the test problem introduced by Boyan (1999), in which iLSTD converges faster than TD(0) and almost as fast as LSTD.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-057.pdf,Subjects: 12.1 Reinforcement Learning
64,2006,Machine Learning,Active Learning with Near Misses,"Nela Gurevich, Shaul Markovitch, Ehud Rivlin","Assume that we are trying to build a visual recognizer for a particular class of objects - chairs, for example - using existing induction methods. Assume the assistance of a human teacher who can label an image of an object as a positive or a negative example. As positive examples, we can obviously use images of real chairs. It is not clear, however, what types of objects we should use as negative examples. This is an example of a common problem where the concept we are trying to learn represents a small fraction of a large universe of instances. In this work we suggest learning with the help of near misses - negative examples that differ from the learned concept in only a small number of significant points, and we propose a framework for automatic generation of such examples. We show that generating near misses in the feature space is problematic in some domains, and propose a methodology for generating examples directly in the instance space using modification operators - functions over the instance space that produce new instances by slightly modifying existing ones. The generated instances are evaluated by mapping them into the feature space and measuring their utility using known active learning techniques. We apply the proposed framework to the task of learning visual concepts from range images.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-058.pdf,Subjects: 12. Machine Learning and Discovery; 19. Vision
65,2006,Machine Learning,Representing Systems with Hidden State,"Christopher Hundt, Prakash Panangaden, Joelle Pineau, Doina Precup","We discuss the problem of finding a good state representation in stochastic systems with observations. We develop a duality theory that generalizes existing work in predictive state representations as well as automata theory. We discuss how this theoretical framework can be used to build learning algorithms, approximate planning algorithms as well as to deal with continuous observations.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-059.pdf,Subjects: 12.1 Reinforcement Learning; 11. Knowledge Representation
66,2006,Machine Learning,Improving Approximate Value Iteration using Memories and Predictive State Representations,"Michael R. James, Ton Wessling, Nikos Vlassis","Planning in partially-observable dynamical systems is a challenging problem, and recent developments in point-based techniques such as Perseus significantly improve performance as compared to exact techniques. In this paper, we show how to apply these techniques to new models for non-Markovian dynamical systems called Predictive State Representations (PSRs) and Memory-PSRs (mPSRs). PSRs and mPSRs are models of non-Markovian decision processes that differ from latent-variable models (e.g. HMMs, POMDPs) by representing state using only observable quantities. Further, mPSRs explicitly represent certain structural properties of the dynamical system that are also relevant to planning. We show how planning techniques can be adapted to leverage this structure to improve performance both in terms of execution time as well as quality of the resulting policy.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-060.pdf,Subjects: 12.1 Reinforcement Learning
67,2006,Machine Learning,Learning Systems of Concepts with an Infinite Relational Model,"Charles Kemp, Joshua Tenenbaum, Thomas Griffiths, Takeshi Yamada, Naonori Ueda","Relationships between concepts account for a large proportion of semantic knowledge. We present a nonparametric Bayesian model that discovers systems of related concepts. Given data involving several sets of entities, our model discovers the kinds of entities in each set and the relations between kinds that are possible or likely. We apply our approach to four problems: clustering objects and features, learning ontologies, discovering kinship systems, and discovering structure in political data.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-061.pdf,Subjects: 12. Machine Learning and Discovery
68,2006,Machine Learning,kFOIL: Learning Simple Relational Kernels,"Niels Landwehr, Andrea Passerini, Luc De Raedt, Paolo Frasconi","A novel and simple combination of inductive logic programming with kernel methods is presented. The kFOIL algorithm integrates the well-known inductive logic programming system FOIL with kernel methods. The feature space is constructed by leveraging FOIL search for a set of relevant clauses. The search is driven by the performance obtained by a support vector machine based on the resulting kernel. In this way, kFOIL implements a dynamic propositionalization approach. Both classification and regression tasks can be naturally handled. Experiments in applying kFOIL to well-known benchmarks in chemoinformatics show the promise of the approach.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-062.pdf,Subjects: 12. Machine Learning and Discovery
69,2006,Machine Learning,Quantifying the Impact of Learning Algorithm Parameter Tuning,"Niklas Lavesson, Paul Davidsson","The impact of learning algorithm optimization by means of parameter tuning is studied. To do this, two quality attributes, sensitivity and classification performance, are investigated, and two metrics for quantifying each of these attributes are suggested. Using these metrics, a systematic comparison has been performed between four induction algorithms on eight data sets. The results indicate that parameter tuning is often more important than the choice of algorithm and there does not seem to be a trade-off between the two quality attributes. Moreover, the study provides quantitative support to the assertion that some algorithms are more robust than others with respect to parameter configuration. Finally, it is briefly described how the quality attributes and their metrics could be used for algorithm selection in a systematic way.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-063.pdf,Subjects: 12. Machine Learning and Discovery
70,2006,Machine Learning,Efficient L1 Regularized Logistic Regression,"Su-In Lee, Honglak Lee, Pieter Abbeel, Andrew Y. Ng","L1 regularized logistic regression is now a workhorse of machine learning: it is widely used for many classification problems, particularly ones with many features. L1 regularized logistic regression requires solving a convex optimization problem. However, standard algorithms for solving convex optimization problems do not scale well enough to handle the large datasets encountered in many practical settings. In this paper, we propose an efficient algorithm for L1 regularized logistic regression. Our algorithm iteratively approximates the objective function by a quadratic approximation at the current point. In each iteration, it uses the efficient LARS (Least Angle Regression) algorithm to solve the resulting quadratic optimization problem with the L1 constraints. Our theoretical results show that our algorithm is guaranteed to converge to the global optimum. Our experiments show that our algorithm significantly outperforms standard algorithms for solving convex optimization problems. Moreover, our algorithm outperforms four previously published algorithms that were specifically designed to solve the L1 regularized logistic regression problem.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-064.pdf,Subjects: 12. Machine Learning and Discovery
71,2006,Machine Learning,Minimum Description Length Principle: Generators are Preferable to Closed Patterns,"Jinyan Li, Haiquan Li, Limsoon Wong, Jian Pei, Guozhu Dong","The generators and the unique closed pattern of an equivalence class of itemsets share a common set of transactions. The generators are the minimal ones among the equivalent itemsets, while the closed pattern is the maximum one. As a generator is usually smaller than the closed pattern in cardinality, by the Minimum Description Length Principle, the generator is preferable to the closed pattern in inductive inference and classification. To efficiently discover frequent generators from a large dataset, we develop a depth-first algorithm called Gr-growth. The idea is novel in contrast to traditional breadth-first bottom-up generator-mining algorithms. Our extensive performance study shows that Gr-growth is significantly faster (an order or even two orders of magnitudes when the support thresholds are low) than the existing generator mining algorithms. It can be also faster than the state-of-the-art frequent closed itemset mining algorithms such as FPclose and CLOSET+.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-065.pdf,Subjects: 12. Machine Learning and Discovery; 15.7 Search
72,2006,Machine Learning,Value-Function-Based Transfer for Reinforcement Learning Using Structure Mapping,"Yaxin Liu, Peter Stone","Transfer learning concerns applying knowledge learned in one task (the source) to improve learning another related task (the target). In this paper, we use structure mapping, a psychological and computational theory about analogy making, to find mappings between the source and target tasks and thus construct the transfer functional automatically. Our structure mapping algorithm is a specialized and optimized version of the structure mapping engine and uses heuristic search to find the best maximal mapping. The algorithm takes as input the source and target task specifications represented as qualitative dynamic Bayes networks, which do not need probability information. We apply this method to the Keepaway task from RoboCup simulated soccer and compare the result from automated transfer to that from handcoded transfer.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-066.pdf,Subjects: 12.1 Reinforcement Learning; 15.7 Search
73,2006,Machine Learning,Semisupervised Multi-label Learning by Constrained Nonnegative Matrix Factorization,"Yi Liu, Rong Jin, Liu Yang","We present a novel framework for multi-label learning that explicitly addresses the challenge arising from the large number of classes and a small size of training data. The key assumption behind this work is that two examples tend to have large overlap in their assigned class memberships if they share high similarity in their input patterns. We capitalize this assumption by first computing two sets of similarities, one based on the input patterns of examples, and the other based on the class memberships of the examples. We then search for the optimal assignment of class memberships to the unlabeled data that minimizes the difference between these two sets of similarities. The optimization problem is formulated as a constrained Non-negative Matrix Factorization (NMF) problem, and an algorithm is presented to efficiently find the solution. Compared to the existing approaches for multi-label learning, the proposed approach is advantageous in that it is able to explore both the unlabeled data and the correlation among different classes simultaneously. Experiments with text categorization show that our approach performs significantly better than several state-of-the-art classification techniques when the number of classes is large and the size of training data is small.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-067.pdf,Subjects: 12. Machine Learning and Discovery
74,2006,Machine Learning,A Simple and Effective Method for Incorporating Advice into Kernel Methods,"Richard Maclin, Jude Shavlik, Trevor Walker, Lisa Torrey","We propose a simple mechanism for incorporating advice (prior knowledge), in the form of simple rules, into support-vector methods for both classification and regression. Our approach is based on introducing inequality constraints associated with datapoints that match the advice. These constrained datapoints can be standard examples in the training set, but can also be unlabeled data in a semi-supervised, advice-taking approach. Our new approach is simpler to implement and more efficiently solved than the knowledge-based support vector classification methods of Fung, Mangasarian and Shavlik (2002; 2003) and the knowledge-based support vector regression method of Mangasarian, Shavlik, and Wild (2004), while performing approximately as well as these more complex approaches. Experiments using our new approach on a synthetic task and a reinforcementlearning problem within the RoboCup soccer simulator show that our advice-taking method can significantly outperform a method without advice and perform similarly to prior advice-taking, support-vector machines.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-068.pdf,Subjects: 12. Machine Learning and Discovery; 12.1 Reinforcement Learning
75,2006,Machine Learning,Multi-Conditional Learning: Generative/Discriminative Training for Clustering and Classification,"Andrew McCallum, Chris Pal, Greg Druck, Xuerui Wang","This paper presents multi-conditional learning (MCL), a training criterion based on a product of multiple conditional likelihoods. When combining the traditional conditional probability of ""label given input"" with a generative probability of ""input given label"" the later acts as a surprisingly effective regularizer. When applied to models with latent variables, MCL combines the structure-discovery capabilities of generative topic models, such as latent Dirichlet allocation and the exponential family harmonium, with the accuracy and robustness of discriminative classifiers, such as logistic regression and conditional random fields. We present results on several standard text data sets showing significant reductions in classification error due to MCL regularization, and substantial gains in precision and recall due to the latent structure discovered under MCL.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-069.pdf,Subjects: 12. Machine Learning and Discovery; 13. Natural Language Processing
76,2006,Machine Learning,Learning Blocking Schemes for Record Linkage,Matthew Michelson and Craig A. Knoblock,"Record linkage is the process of matching records across data sets that refer to the same entity. One issue within record linkage is determining which record pairs to consider, since a detailed comparison between all of the records is impractical. Blocking addresses this issue by generating candidate matches as a preprocessing step for record linkage. For example, in a person matching problem, blocking might return all people with the same last name as candidate matches. Two main problems in blocking are the selection of attributes for generating the candidate matches and deciding which methods to use to compare the selected attributes. These attribute and method choices constitute a blocking scheme. Previous approaches to record linkage address the blocking issue in a largely ad-hoc fashion. This paper presents a machine learning approach to automatically learn effective blocking schemes. We validate our approach with experiments that show our learned blocking schemes outperform the ad-hoc blocking schemes of non-experts and perform comparably to those manually built by a domain expert.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-070.pdf,
77,2006,Machine Learning,Strategy Variations in Analogical Problem Solving,"Tom Y. Ouyang, Kenneth D. Forbus","While it is commonly agreed that analogy is useful in human problem solving, exactly how analogy can and should be used remains an intriguing problem. VanLehn (1998) for instance argues that there are differences in how novices and experts use analogy, but the VanLehn and Jones (1993) Cascade model does not implement these differences. This paper analyzes several variations in strategies for using analogy to explore possible sources of novice/expert differences. We describe a series of ablation experiments on an expert model to examine the effects of strategy variations in using analogy in problem solving. We provide evidence that failing to use qualitative reasoning when encoding problems, being careless in validating analogical inferences, and not using multiple retrievals can degrade the efficiency of problem-solving.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-071.pdf,Subjects: 3.5 Qualitative Reasoning; 3.1 Case-Based Reasoning
78,2006,Machine Learning,Gradient Boosting for Sequence Alignment,"Charles Parker, Alan Fern, Prasad Tadepalli","Sequence alignment is a common subtask in many applications such as genetic matching and music information retrieval. Crucial to the performance of any sequence alignment algorithm is an accurate model of the reward of transforming one sequence into another. Using this model, we can find the optimal alignment of two sequences or perform query-based selection from a database of target sequences with a dynamic programming approach. In this paper, we describe a new algorithm to learn the reward models from positive and negative examples of matching sequences. We develop a gradient boosting approach that reduces sequence learning to a series of standard function approximation problems that can be solved by any function approximator. A key advantage of this approach is that it is able to induce complex features using function approximation rather than relying on the user to predefine such features. Our experiments on synthetic data and a fairly complex real-world music retrieval domain demonstrate that our approach can achieve better accuracy and faster learning compared to a state-of-the-art structured SVM approach.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-072.pdf,Subjects: 1.1 Art And Music; 12. Machine Learning and Discovery
79,2006,Machine Learning,Sound and Efficient Inference with Probabilistic and Deterministic Dependencies,"Hoifung Poon, Pedro Domingos","Reasoning with both probabilistic and deterministic dependencies is important for many real-world problems, and in particular for the emerging field of statistical relational learning. However, probabilistic inference methods like MCMC or belief propagation tend to give poor results when deterministic or near-deterministic dependencies are present, and logical ones like satisfiability testing are inapplicable to probabilistic ones. In this paper we propose MC-SAT, an inference algorithm that combines ideas from MCMC and satisfiability. MC-SAT is based on Markov logic, which defines Markov networks using weighted clauses in first-order logic. From the point of view of MCMC, MC-SAT is a slice sampler with an auxiliary variable per clause, and with a satisfiability-based method for sampling the original variables given the auxiliary ones. From the point of view of satisfiability, MC-SAT wraps a procedure around the SampleSAT uniform sampler that enables it to sample from highly non-uniform distributions over satisfying assignments. Experiments on entity resolution and collective classification problems show that MC-SAT greatly outperforms Gibbs sampling and simulated tempering over a broad range of problem sizes and degrees of determinism.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-073.pdf,Subjects: 3.4 Probabilistic Reasoning
80,2006,Machine Learning,Boosting Expert Ensembles for Rapid Concept Recall,"Achim Rettinger, Martin Zinkevich, Michael Bowling","Many learning tasks in adversarial domains tend to be highly dependent on the opponent. Predefined strategies optimized for play against a specific opponent are not likely to succeed when employed against another opponent. Learning a strategy for each new opponent from scratch, though, is inefficient as one is likely to encounter the same or similar opponents again. We call this particular variant of inductive transfer a concept recall problem. We present an extension to AdaBoost called ExpBoost that is especially designed for such a sequential learning tasks. It automatically balances between an ensemble of experts each trained on one known opponent and learning the concept of the new opponent. We present and compare results of ExpBoost and other algorithms on both synthetic data and in a simulated robot soccer task. ExpBoost can rapidly adjust to new concepts and achieve performance comparable to a classifier trained exclusively on a particular opponent with far more data.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-074.pdf,Subjects: 12. Machine Learning and Discovery
81,2006,Machine Learning,Identification and Evaluation of Weak Community Structures in Networks,"Jianhua Ruan, Weixiong Zhang","Identifying intrinsic structures in large networks is a fundamental problem in many fields, such as engineering, social science and biology. In this paper, we are concerned with communities, which are densely connected sub-graphs in a network, and address two critical issues for finding community structures from large experimental data. First, most existing network clustering methods assume sparse networks and networks with strong community structures. In contrast, we consider sparse and dense networks with weak community structures. We introduce a set of simple operations that capture local neighborhood information of a node to identify weak communities. Second, we consider the issue of automatically determining the most appropriate number of communities, a crucial problem for all clustering methods. This requires to properly evaluate the quality of community structures. Built atop a function for network cluster evaluation by Newman and Girvan, we extend their work to weighted graphs. We have evaluated our methods on many networks of known structures, and applied them to analyze a collaboration network and a genetic network. The results showed that our methods can find superb community structures and correct numbers of communities. Comparing to the existing approaches, our methods performed significantly better on networks with weak community structures and equally well on networks with strong community structures.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-075.pdf,Subjects: 12. Machine Learning and Discovery; 1.6 Engineering And Science
82,2006,Machine Learning,Thresholding for Making Classifiers Cost-sensitive,"Victor S. Sheng, Charles X. Ling","In this paper we propose a very simple, yet general and effective method to make any cost-insensitive classifiers (that can produce probability estimates) cost-sensitive. The method, called Thresholding, selects a proper threshold from training instances according to the misclassification cost. Similar to other cost-sensitive meta-learning methods, Thresholding can convert any existing (and future) cost-insensitive learning algorithms and techniques into cost-sensitive ones. However, by comparing with the existing cost sensitive meta-learning methods and the direct use of the theoretical threshold, Thresholding almost always produces the lowest misclassification cost. Experiments also show that Thresholding has the least sensitivity on the misclassification cost ratio. Thus, it is recommended to use when the difference on misclassification costs is large.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-076.pdf,Subjects: 12. Machine Learning and Discovery; 1.6 Engineering And Science
83,2006,Machine Learning,Cost-Sensitive Test Strategies,"Victor S. Sheng, Charles X. Ling, Ailing Ni, Shichao Zhang","In medical diagnosis doctors must often determine what medical tests (e.g., X-ray, blood tests) should be ordered for a patient to minimize the total cost of medical tests and misdiagnosis. In this paper, we design cost-sensitive machine learning algorithms to model this learning and diagnosis process. Medical tests are like attributes in machine learning whose values may be obtained at cost (attribute cost), and misdiagnoses are like misclassifications which may also incur a cost (misclassification cost). We first propose an improved decision tree learning algorithm that minimizes the sum of attribute costs and misclassification costs. Then we design several novel ""test strategies"" that may request to obtain values of unknown attributes at cost (similar to doctors' ordering of medical tests at cost) in order to minimize the total cost for test examples (new patients). We empirically evaluate and compare these test strategies, and show that they are effective and that they outperform previous methods. A case study on heart disease is given.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-077.pdf,Subjects: 12. Machine Learning and Discovery; 1.5 Diagnosis
84,2006,Machine Learning,Memory-Efficient Inference in Relational Domains,"Parag Singla, Pedro Domingos","Propositionalization of a first-order theory followed by satisfiability testing has proved to be a remarkably efficient approach to inference in relational domains such as planning and verification. More recently, weighted satisfiability solvers have been used successfully for MPE inference in statistical relational learners. However, fully instantiating a finite first-order theory requires memory on the order of the number of constants raised to the arity of the clauses, which significantly limits the size of domains it can be applied to. In this paper we propose LazySAT, a variation of the WalkSAT solver that avoids this blowup by taking advantage of the extreme sparseness that is typical of relational domains (i.e., only a small fraction of ground atoms are true, and most clauses are trivially satisfied). Experiments on entity resolution and planning problems show that LazySAT reduces memory usage by orders of magnitude compared to WalkSAT, while taking comparable time to run and producing the same solutions.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-078.pdf,Subjects: 3. Automated Reasoning; 3.4 Probabilistic Reasoning
85,2006,Machine Learning,Using Homomorphisms to Transfer Options across Continuous Reinforcement Learning Domains,"Vishal Soni, Satinder Singh Baveja","We examine the problem of Transfer in Reinforcement Learning and present a method to utilize knowledge acquired in one Markov Decision Process (MDP) to bootstrap learning in a more complex but related MDP. We build on work in model minimization in Reinforcement Learning to define relationships between state-action pairs of the two MDPs. Our main contribution in this work is to provide a way to compactly represent such mappings using relationships between state variables in the two domains. We use these functions to transfer a learned policy in the first domain into an option in the new domain, and apply intra-option learning methods to bootstrap learning in the new domain. We first evaluate our approach in the well known Blocksworld domain. We then demonstrate that our approach to transfer is viable in a complex domain with a continuous state space by evaluating it in the Robosoccer Keepaway domain.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-079.pdf,Subjects: 12.1 Reinforcement Learning
86,2006,Machine Learning,A Fast Decision Tree Learning Algorithm,"Jiang Su, Harry Zhang","There is growing interest in scaling up the widely-used decision-tree learning algorithms to very large data sets. Although numerous diverse techniques have been proposed, a fast tree-growing algorithm without substantial decrease in accuracy and substantial increase in space complexity is essential. In this paper, we present a novel, fast decision-tree learning algorithm that is based on a conditional independence assumption. The new algorithm has a time complexity of O(mn), where m is the size of the training data and n is the number of attributes. This is a significant asymptotic improvement over the time complexity O(mn^2) of the standard decision-tree learning algorithm C4.5, with an additional space increase of only O(n). Experiments show that our algorithm performs competitively with C4.5 in accuracy on a large number of UCI benchmark data sets, and performs even better and significantly faster than C4.5 on a large number of text classification data sets. The time complexity of our algorithm is as low as naive Bayes'. Indeed, it is as fast as naive Bayes but outperforms naive Bayes in accuracy according to our experiments. Our algorithm is a core tree-growing algorithm that can be combined with other scaling-up techniques to achieve further speedup.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-080.pdf,Subjects: 12. Machine Learning and Discovery; 15.6 Decision Trees
87,2006,Machine Learning,Cross-Domain Knowledge Transfer Using Structured Representations,"Samarth Swarup, Sylvian R. Ray","Previous work in knowledge transfer in machine learning has been restricted to tasks in a single domain. However, evidence from psychology and neuroscience suggests that humans are capable of transferring knowledge across domains. We present here a novel learning method, based on neuroevolution, for transferring knowledge across domains. We use many-layered, sparsely-connected neural networks in order to learn a structural representation of tasks. Then we mine frequent sub-graphs in order to discover sub-networks that are useful for multiple tasks. These sub-networks are then used as primitives for speeding up the learning of subsequent related tasks, which may be in different domains.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-081.pdf,Subjects: 12. Machine Learning and Discovery
88,2006,Machine Learning,Conflict Resolution and a Framework for Collaborative Interactive Evolution,"Sean R. Szumlanski, Annie S. Wu, Charles E. Hughes","Interactive evolutionary computation (IEC) has proven useful in a variety of applications by combining the subjective evaluation of a user with the massive parallel search power of the genetic algorithm (GA). Here, we articulate a framework for an extension of IEC into collaborative interactive evolution, in which multiple users guide the evolutionary process. In doing so, we introduce the ability for users to combine their efforts for the purpose of evolving effective solutions to problems. This necessarily gives rise to the possibility of conflict between users. We draw on the salient features of the GA to resolve these conflicts and lay the foundation for this new paradigm to be used as a tool for conflict resolution in complex group-wise human-computer interaction tasks.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-082.pdf,Subjects: 1.9 Genetic Algorithms; 6. Computer-Human Interaction
89,2006,Machine Learning,Sample-Efficient Function Approximation for Reinforcement Learning,"Shimon Whiteson, Peter Stone","Reinforcement learning problems are commonly tackled with temporal difference methods, which attempt to estimate the agent's optimal value function. In most real-world problems, learning this value function requires a function approximator, which maps state-action pairs to values via a concise, parameterized function. In practice, the success of function approximators depends on the ability of the human designer to select an appropriate representation for the value function. A recently developed approach called evolutionary function approximation uses evolutionary computation to automate the search for effective representations. While this approach can substantially improve the performance of TD methods, it requires many sample episodes to do so. We present an enhancement to evolutionary function approximation that makes it much more sample-efficient by exploiting the off-policy nature of certain TD methods. Empirical results in a server job scheduling domain demonstrate that the enhanced method can learn better policies than evolution or TD methods alone and can do so in many fewer episodes than standard evolutionary function approximation.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-083.pdf,Subjects: 12.1 Reinforcement Learning; 1.9 Genetic Algorithms
90,2006,Machine Learning,Mixtures of Predictive Linear Gaussian Models for Nonlinear Stochastic Dynamical Systems,"David Wingate, Satinder Baveja","The Predictive Linear Gaussian model (or PLG) improves upon traditional linear dynamical system models by using a predictive representation of state, which makes consistent parameter estimation possible without any loss of modeling power and while using fewer parameters. This work extends the PLG to model nonlinear dynamical systems through the use of a kernelized, nonlinear mixture technique. The resulting generative model has been named the ""MPLG,"" for ""Mixture of PLGs."" We also develop a novel technique to perform inference in the model, which consists of a hybrid of sigma-point approximations and analytical statistics. We show that the technique leads to fast and accurate approximations, and that it is general enough to be applied in other contexts. We empirically explore the MPLG and demonstrate its viability on several real-world and synthetic tasks.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-084.pdf,Subjects: 12.1 Reinforcement Learning
91,2006,Machine Learning,Decision Tree Methods for Finding Reusable MDP Homomorphisms,"Alicia P Wolfe, Andrew G. Barto","State abstraction is a useful tool for agents interacting with complex environments. Good state abstractions are compact, reuseable, and easy to learn from sample data. This paper combines and extends two existing classes of state abstraction methods to achieve these criteria. The first class of methods search for MDP homomorphisms, which produce models of reward and transition probabilities in an abstract state space. The second class of methods, like the UTree algorithm, learn compact models of the value function quickly from sample data. Models based on MDP homomorphisms can easily be extended such that they are usable across tasks with similar reward functions. However, value based methods like UTree cannot be extended in this fashion. We present results showing a new, combined algorithm that fulfills all three criteria: the resulting models are compact, can be learned quickly from sample data, and can be used across a class of reward functions.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-085.pdf,Subjects: 12.1 Reinforcement Learning
92,2006,Machine Learning,Robust Support Vector Machine Training via Convex Outlier Ablation,"Linli Xu, Koby Crammer, Dale Schuurmans","One of the well known risks of large margin training methods, such as boosting and support vector machines (SVMs), is their sensitivity to outliers. These risks are normally mitigated by using a soft margin criterion, such as hinge loss, to reduce outlier sensitivity. In this paper, we present a more direct approach that explicitly incorporates outlier suppression in the training process. In particular, we show how outlier detection can be encoded in the large margin training principle of support vector machines. By expressing a convex relaxation of the joint training problem as a semidefinite program, one can use this approach to robustly train a support vector machine while suppressing outliers. We demonstrate that our approach can yield superior results to the standard soft margin approach in the presence of outliers.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-086.pdf,Subjects: 12. Machine Learning and Discovery
93,2006,Machine Learning,An Efficient Algorithm for Local Distance Metric Learning,"Liu Yang, Rong Jin, Rahul Sukthankar, Yi Liu","Learning application-specific distance metrics from labeled data is critical for both statistical classification and information retrieval. Most of the earlier work in this area has focused on finding metrics that simultaneously optimize compactness and separability in a global sense. Specifically, such distance metrics attempt to keep all of the data points in each class close together while ensuring that data points from different classes are separated. However, particularly when classes exhibit multimodal data distributions, these goals conflict and thus cannot be simultaneously satisfied. This paper proposes a Local Distance Metric (LDM) that aims to optimize local compactness and local separability. We present an efficient algorithm that employs eigenvector analysis and bound optimization to learn the LDMfrom training data in a probabilistic framework. We demonstrate that LDM achieves significant improvements in both classification and retrieval accuracy compared to global distance learning and kernel-based KNN.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-087.pdf,Subjects: 12. Machine Learning and Discovery; 12. Machine Learning and Discovery
94,2006,Machine Learning,Hard Constrained Semi-Markov Decision Processes,"Wai-Leong Yeow, Chen-Khong Tham, and Wai-Choong Wong","In multiple criteriaMarkov Decision Processes (MDP) where multiple costs are incurred at every decision point, current methods solve them by minimising the expected primary cost criterion while constraining the expectations of other cost criteria to some critical values. However, systems are often faced with hard constraints where the cost criteria should never exceed some critical values at any time, rather than constraints based on the expected cost criteria. For example, a resource-limited sensor network no longer functions once its energy is depleted. Based on the semi-MDP (sMDP) model, we study the hard constrained (HC) problem in continuous time, state and action spaces with respect to both finite and infinite horizons, and various cost criteria. We show that the HCsMDP problem is NP-hard and that there exists an equivalent discrete-time MDP to every HCsMDP. Hence, classical methods such as reinforcement learning can solve HCsMDPs.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-088.pdf,
95,2006,Machine Learning,A New Approach to Estimating the Expected First Hitting Time of Evolutionary Algorithms,"Yang Yu, Zhi-Hua Zhou","The {\it expected first hitting time} is an important issue in theoretical analyses of evolutionary algorithms since it implies the average computational time complexity. In this paper, by exploiting the relationship between the convergence rate and the expected first hitting time, a new approach to estimating the expected first hitting time is proposed. This approach is then applied to four evolutionary algorithms which involve operators of mutation, mutation with population, mutation with recombination, and time-variant mutation, respectively. The results show that the proposed approach is helpful for analyzing a broad range of evolutionary algorithms.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-089.pdf,Subjects: 1.9 Genetic Algorithms
96,2006,Machine Learning,A Direct Evolutionary Feature Extraction Algorithm for Classifying High Dimensional Data,"Qijun Zhao, David Zhang, Hongtao Lu","Among various feature extraction algorithms, those based on genetic algorithms are promising owing to their potential parallelizability and possible applications in large scale and high dimensional data classification. However, existing genetic algorithm based feature extraction algorithms are either limited in searching optimal projection basis vectors or costly in both time and space complexities and thus not directly applicable to high dimensional data. In this paper, a direct evolutionary feature extraction algorithm is proposed for classifying high-dimensional data. It constructs projection basis vectors using the linear combination of the basis of the search space and the technique of orthogonal complement. It also constrains the search space when seeking for the optimal projection basis vectors. It evaluates individuals according to the classification performance on a subset of the training samples and the generalization ability of the projection basis vectors represented by the individuals. We compared the proposed algorithm with some representative feature extraction algorithms in face recognition, including the evolutionary pursuit algorithm, Eigenfaces, and Fisherfaces. The results on the widely-used Yale and ORL face databases show that the proposed algorithm has an excellent performance in classification while reducing the space complexity by an order of magnitude.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-090.pdf,Subjects: 1.9 Genetic Algorithms; 12. Machine Learning and Discovery
97,2006,Machine Learning,On Multi-Class Cost-Sensitive Learning,"Zhi-Hua Zhou, Xu-Ying Liu","A popular approach to cost-sensitive learning is to rescale the classes according to their misclassification costs. Although this approach is effective in dealing with binary-class problems, recent studies show that it is often not so helpful when being applied to multi-class problems directly. This paper analyzes that why the traditional rescaling approach is often helpless on multi-class problems, which reveals that before applying rescaling, the {\it consistency} of the costs must be examined. Based on the analysis, a new approach is presented, which should be the choice if the user wants to use rescaling for multi-class cost-sensitive learning. Moreover, this paper shows that the proposed approach is helpful when unequal misclassification costs and class imbalance occur simultaneously, and can also be used to tackle pure class-imbalance learning. Thus, the proposed approach provides a unified framework for using rescaling to address multi-class cost-sensitive learning as well as multi-class class-imbalance learning.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-091.pdf,Subjects: 12. Machine Learning and Discovery
98,2006,Machine Learning,Unbiased Estimators for Evaluating Agent Performance,"Martin Zinkevich, Michael Bowling, Nolan Bard, Morgan Kan, Darse Billings","Evaluating the performance of an agent or group of agents can be, by itself, a very challenging problem. The stochastic nature of the environment plus the stochastic nature of agents' decisions can result in estimates with intractably large variances. This paper examines the problem of finding low variance estimates of agent performance. In particular, we assume that some agent-environment dynamics are known, such as the random outcome of drawing a card or rolling a die. Other dynamics are unknown, such as the reasoning of a human or other black-box agent. Using the known dynamics, we describe the complete set of all unbiased estimators, that is, for any possible unknown dynamics the estimate's expectation is always the agent's expected utility. Then, given a belief about the unknown dynamics, we identify the unbiased estimator with minimum variance. If the belief is correct our estimate is optimal, and if the belief is wrong it is at least unbiased. Finally, we apply our unbiased estimator to the game of poker, demonstrating dramatically reduced variance and faster evaluation.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-0925.pdf,Subjects: 1.8 Game Playing
99,2006,Multiagent Systems,Keeping in Touch: Maintaining Biconnected Structure by Homogeneous Robots,"Mazda Ahmadi, Mazda Ahmadi, Peter Stone","For many distributed autonomous robotic systems, it is important to maintain communication connectivity among the robots. That is, each robot must be able to communicate with each other robot, perhaps through a series of other robots. Ideally, this property should be robust to the removal of any single robot from the system. In (Ahmadi, Stone 2006) we define a property of a team's communication graph that ensures this property, called biconnectivity. In that paper, a distributed algorithm to check if a team of robots is biconnected and its correctness proof are also presented. In this paper we provide distributed algorithms to add and remove robots to/from a multi-robot team while maintaining the biconnected property. These two algorithms are implemented and tested in the Player/Stage simulator.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-093.pdf,Subjects: 7.1 Multi-Agent Systems; 17. Robotics
100,2006,Multiagent Systems,Quantifying Incentive Compatibility of Ranking Systems,"Alon Altman, Moshe Tennenholtz","Reasoning about agent preferences on a set of alternatives, and the aggregation of such preferences into some social ranking is a fundamental issue in reasoning about multi-agent systems. When the set of agents and the set of alternatives coincide, we get the ranking systems setting. A famous type of ranking systems are page ranking systems in the context of search engines. Such ranking systems do not exist in empty space, and therefore agents' incentives should be carefully considered. In this paper we define three measures for quantifying the incentive compatibility of ranking systems. We apply these measures to several known ranking systems, such as PageRank, and prove tight bounds on the level of incentive compatibility under two basic properties: strong monotonicity and non-imposition. We also introduce two novel non-imposing ranking systems, one general, and the other for the case of systems with three participants. A full axiomatization is provided for the latter.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-094.pdf,Subjects: 7.1 Multi-Agent Systems; 9.3 Mathematical Foundations
101,2006,Multiagent Systems,Impersonation-Based Mechanisms,"Moshe Babioff, Ron Lavi, Elan Pavlov","In this paper we present a general scheme to create mechanisms that approximate the social welfare in the presence of selfish (but rational) behavior of agents. The usual approach is to design truthful mechanisms in which an agent can only lose by impersonating as another agent. In contrast, our approach is to allow an agent to impersonate several different agents. We design the mechanisms such that only a limited set of impersonations are reasonable to rational agents. Our mechanisms make sure that for any choice of such impersonations by the agents, an approximation to the social welfare is achieved. We demonstrate our results on the well studied domain of Combinatorial Auctions. Our mechanisms are algorithmic implementations, a notion recently suggested in (Babaioff, Lavi, and Pavlov, 2006).",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-095.pdf,Subjects: 7.1 Multi-Agent Systems
102,2006,Multiagent Systems,Algorithms for Rationalizability and CURB sets,"Michael Benisch, George B. Davis, Tuomas Sandholm","Significant work has been done on computational aspects of solving games under various solution concepts, such as Nash equilibrium, subgame perfect Nash equilibrium, correlated equilibrium, and (iterated) dominance. However, the fundamental concepts of rationalizability and CURB (Closed Under Rational Behavior sets have not, to our knowledge, been studied from a computational perspective. First, for rationalizability we describe an LP-based polynomial algorithm that finds all strategies that are rationalizable against a mixture over a given set of opponent strategies. Then, we describe a series of increasingly sophisticated polynomial algorithms for finding all minimal CURB sets, one minimal CURB set, and the smallest minimal CURB set. Finally, we give theoretical results regarding the relationships between CURB sets and Nash equilibria, showing that finding a Nash equilibrium can be exponential only in the size of the smallest CURB set. We show that this can lead to an arbitrarily large reduction in the complexity of finding a Nash equilibrium. On the downside, we also show that the smallest CURB set can be arbitrarily larger than the supports of the enclosed Nash equilibrium.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-096.pdf,Subjects: 7.1 Multi-Agent Systems
103,2006,Multiagent Systems,On Strictly Competitive Multi-Player Games,"Felix Brandt, Felix Fischer, Yoav Shoham","We embark on an initial study of a new class of strategic (normal-form) games, so-called ranking games, in which the payoff to each agent solely depends on his position in a ranking of the agents induced by their actions. This definition is motivated by the observation that in many strategic situations such as parlor games, competitive economic scenarios, and some social choice settings, players are merely interested in performing optimal relative to their opponents rather than in absolute measures. A simple but important subclass of ranking games are single-winner games where in any outcome one agent wins and all others lose. We investigate the computational complexity of a variety of common game-theoretic solution concepts in ranking games and deliver hardness results for iterated weak dominance and mixed Nash equilibria when there are more than two players and pure Nash equilibria when the number of players is unbounded. This dashes hope that multi-player ranking games can be solved efficiently, despite the structural restrictions of these games.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-097.pdf,Subjects: 1.8 Game Playing; 9.2 Computational Complexity
104,2006,Multiagent Systems,Computing Slater Rankings Using Similarities Among Candidates,Vincent Conitzer,"Voting (or rank aggregation) is a general method for aggregating the preferences of multiple agents. One important voting rule is the Slater rule. It selects a ranking of the alternatives (or candidates) to minimize the number of pairs of candidates such that the ranking disagrees with the pairwise majority vote on these two candidates. The use of the Slater rule has been hindered by a lack of techniques to compute Slater rankings. In this paper, we show how we can decompose the Slater problem into smaller subproblems if there is a set of similar candidates. We show that this technique suffices to compute a Slater ranking in linear time if the pairwise majority graph is hierarchically structured. For the general case, we also give an efficient algorithm for finding a set of similar candidates. We provide experimental results that show that this technique significantly (sometimes drastically) speeds up search algorithms. Finally, we also use the technique of similar sets to show that computing an optimal Slater ranking is NP-hard, even in the absence of pairwise ties.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-098.pdf,Subjects: 7.1 Multi-Agent Systems; 9.2 Computational Complexity
105,2006,Multiagent Systems,Improved Bounds for Computing Kemeny Rankings,"Vincent Conitzer, Andrew Davenport, Jayant Kalagnanam","Voting (or rank aggregation) is a general method for aggregating the preferences of multiple agents. One voting rule of particular interest is the Kemeny rule, which minimizes the number of cases where the final ranking disagrees with a vote on the order of two alternatives. Unfortunately, Kemeny rankings are NP-hard to compute. Recent work on computing Kemeny rankings has focused on producing good bounds to use in search-based methods. In this paper, we extend on this work by providing various improved bounding techniques. Some of these are based on cycles in the pairwise majority graph, others are based on linear programs. We completely characterize the relative strength of all of these bounds and provide some experimental results.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-099.pdf,Subjects: 7.1 Multi-Agent Systems; 15.7 Search
106,2006,Multiagent Systems,Nonexistence of Voting Rules That Are Usually Hard to Manipulate,"Vincent Conitzer, Tuomas Sandholm","Aggregating the preferences of self-interested agents is a key problem for multiagent systems, and one general method for doing so is to vote over the alternatives (candidates). Unfortunately, the Gibbard-Satterthwaite theorem shows that when there are three or more candidates, all reasonable voting rules are manipulable (in the sense that there exist situations in which a voter would benefit from reporting its preferences insincerely). To circumvent this impossibility result, recent research has investigated whether it is possible to make finding a beneficial manipulation computationally hard. This approach has had some limited success, exhibiting rules under which the problem of finding a beneficial manipulation is {\sf NP}-hard, {\sf \#P}-hard, or even {\sf PSPACE}-hard. Thus, under these rules, it is unlikely that a computationally efficient algorithm can be constructed that {\em always} finds a beneficial manipulation (when it exists). However, this still does not preclude the existence of an efficient algorithm that {\em often} finds a successful manipulation (when it exists). There have been attempts to design a rule under which finding a beneficial manipulation is {\em usually} hard, but they have failed. To explain this failure, in this paper, we show that it is in fact impossible to design such a rule, if the rule is also required to satisfy another property: a large fraction of the manipulable instances are both weakly monotone, and allow the manipulators to make either of exactly two candidates win. We argue why one should expect voting rules to have this property, and show experimentally that common voting rules clearly satisfy it. We also discuss approaches for potentially circumventing this impossibility result.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-100.pdf,Subjects: 7.1 Multi-Agent Systems; 9.2 Computational Complexity
107,2006,Multiagent Systems,Overlapping Coalition Formation for Efficient Data Fusion in Multi-Sensor Networks,"Dung V. Dang, Rajdeep K. Dash, Alex Rogers, Nicholas R. Jennings","This paper develops new algorithms for coalition formation within multi-sensor networks tasked with performing wide-area surveillance. Specifically, we cast this application as an instance of coalition formation, with overlapping coalitions. We show that within this application area sub-additive coalition valuations are typical, and we thus use this structural property of the problem to derive two novel algorithms (an approximate greedy one that operates in polynomial time and has a calculated bound to the optimum, and an optimal branch-and-bound one) to find the optimal coalition structure in this instance. We empirically evaluate the performance of these algorithms within a generic model of a multi-sensor network performing wide area surveillance. These results show that the polynomial algorithm typically generated solutions much closer to the optimal than the theoretical bound, and prove the effectiveness of our pruning procedure.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-101.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
108,2006,Multiagent Systems,The Complexity of Bribery in Elections,"Piotr Faliszewski, Edith Hemaspaandra, Lane A. Hemaspaandra","We study the complexity of influencing elections through bribery: How computationally complex is it for an external actor to determine whether by a certain amount of bribing voters a specified candidate can be made the election's winner? We study this problem for election systems as varied as scoring protocols and Dodgson voting, and in a variety of settings regarding homogeneous-vs.-nonhomogeneous electorate bribability, bounded-size-vs.-arbitrary-sized candidate sets, weighted-vs.-unweighted voters, and succinct-vs.-nonsuccinct input specification. We obtain both polynomial-time bribery algorithms and proofs of the intractability of bribery, and indeed our results show that the complexity of bribery is extremely sensitive to the setting. For example, we find settings in which bribery is NP-complete but manipulation (by voters) is in P, and we find settings in which bribing weighted voters is NP-complete but bribing voters with individual bribe thresholds is in P. For the broad class of elections (including plurality, Borda, k-approval, and veto) known as scoring protocols, we prove a dichotomy result for bribery of weighted voters: We find a simple-to-evaluate condition that classifies every case as either NP-complete or in P.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-102.pdf,Subjects: 7.1 Multi-Agent Systems; 9.2 Computational Complexity
109,2006,Multiagent Systems,Analysis of Privacy Loss in Distributed Constraint Optimization,"Rachel Greenstadt, Jonathan P. Pearce, Milind Tambe","Distributed Constraint Optimization (DCOP) is rapidly emerging as a prominent technique for multiagent coordination. However, despite agent privacy being a key motivation for applying DCOPs in many applications, rigorous quantitative evaluations of privacy loss in DCOP algorithms have been lacking. Recently, Maheswaran et al. introduced a framework for quantitative evaluations of privacy in DCOP algorithms, showing that some DCOP algorithms lose more privacy than purely centralized approaches and questioning the motivation for applying DCOPs. This paper addresses the question of whether state-of-the art DCOP algorithms suffer from a similar shortcoming by investigating several of the most efficient DCOP algorithms, including both DPOP and ADOPT. Furthermore, while previous work investigated the impact on efficiency of distributed contraint reasoning design decisions (e.g. constraint-graph topology, asynchrony, message-contents), this paper examines the privacy aspect of such decisions, providing an improved understanding of privacy-efficiency tradeoffs.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-103.pdf,Subjects: 15.2 Constraint Satisfaction; 7.1 Multi-Agent Systems
110,2006,Multiagent Systems,From Centralized to Distributed Selective Overhearing,"Gery Gutnik, Gal A. Kaminka","Overhearing is an approach for monitoring open, distributed, multi-agent systems by listening to the routine communications taking place within them. Previous investigations of overhearing assumed that all inter-agent communications are accessible to a single overhearing agent. However, as multiagent systems grow both in size and distribution two problems arise. First, in large-scale settings, an overhearing agent cannot monitor all agents and their conversations, and must therefore be selective in carefully choosing its targets. Second, a single overhearer would encounter difficulties overhearing agents acting in a geographically-distributed environment. This paper tackles these challenges by addressing distributed teams of overhearing agents involved in selective overhearing. Building on prior work on centralized selective overhearing, we consider the consequences of transitioning from overhearing teams working in a centrally-coordinated manner to distributed overhearing teams. In doing so, we distinguish the various factors influencing the level of distribution within these teams and determine their importance in terms of effective selective overhearing.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-104.pdf,Subjects: 7.1 Multi-Agent Systems
111,2006,Multiagent Systems,A New Approach to Distributed Task Assignment using Lagrangian Decomposition and Distributed Constraint Satisfaction,Katsutoshi Hirayama,"We present a new formulation of distributed task assignment, called Generalized Mutual Assignment Problem (GMAP), which is derived from an NP-hard combinatorial optimization problem that has been studied for many years in the operations research community. To solve the GMAP, we introduce a novel distributed solution protocol using Lagrangian decomposition and distributed constraint satisfaction, where the agents solve their individual optimization problems and coordinate their locally optimized solutions through a distributed constraint satisfaction technique. Next, to produce quick agreement between the agents on a feasible solution with reasonably good quality, we provide a parameter that controls the range of ""noise"" mixed with an increment/decrement in a Lagrange multiplier. Our experimental results indicate that the parameter may allow us to control tradeoffs between the quality of a solution and the cost of finding it.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-105.pdf,Subjects: 7. Distributed AI; 7.1 Multi-Agent Systems
112,2006,Multiagent Systems,Distributed Interactive Learning in Multi-Agent Systems,"Jian Huang, Adrian R. Pearce","Both explanation-based and inductive learning techniques have proven successful in a variety of distributed domains. However, learning in multi-agent systems does not necessarily involve the participation of other agents directly in the inductive process itself. Instead, many systems frequently employ multiple instances of induction separately, or single-agent learning. In this paper we present a new framework, named the Multi-Agent Inductive Learning System (MAILS), that tightly integrates processes of induction between agents. The MAILS framework combines inverse entailment with an epistemic approach to reasoning about knowledge in a multi-agent setting, facilitating a systematic approach to the sharing of knowledge and invention of predicates when required. The benefits of the new approach are demonstrated for inducing declarative program fragments in a multi-agent distributed programming system.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-106.pdf,Subjects: 7. Distributed AI; 7.1 Multi-Agent Systems
113,2006,Multiagent Systems,Regret-based Incremental Partial Revelation Mechanisms,"Nathanael Hyafil, Craig Boutilier","Classic direct mechanisms suffer from the drawback of requiring full type (or utility function) revelation from participating agents. In complex settings with multi-attribute utility, assessing utility functions can be very difficult, a problem addressed by recent work on preference elicitation. In this work we propose a framework for incremental, partial revelation mechanisms and study the use of minimax regret as an optimization criterion for allocation determination with type uncertainty. We examine the incentive properties of incremental mechanisms when minimax regret is used to determine allocations with no additional elicitation of payment information, and when additional payment information is obtained. We argue that elicitation effort can be focused simultaneously on reducing allocation and payment uncertainty.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-107.pdf,Subjects: 7.1 Multi-Agent Systems; 15.5 Decision Theory
114,2006,Multiagent Systems,A Polynomial-Time Algorithm for Action-Graph Games,"Albert X. Jiang, Kevin Leyton-Brown",Action-Graph Games (AGGs) are a fully expressive game representation which can compactly express strict and context-specific independence and anonymity structure in players' utility functions. We present an efficient algorithm for computing expected payoffs under mixed strategy profiles. This algorithm runs in time polynomial in the size of the AGG representation (which is itself polynomial in the number of players when the in-degree of the action graph is bounded). We also present an extension to the AGG representation which allows us to compactly represent a wider variety of structured utility functions.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-108.pdf,Subjects: 7.1 Multi-Agent Systems
115,2006,Multiagent Systems,Multiparty Proactive Communication: A Perspective for Evolving Shared Mental Models,"Kaivan Kamali, Xiaocong Fan, John Yen","Helping behavior in effective teams is enabled by some overlapping ""shared mental models"" that are developed and maintained by members of the team. In this paper, we take the perspective that multiparty ""proactive"" communication is critical for establishing and maintaining such a shared mental model among teammates, which is the basis for agents to offer proactive help and to achieve coherent teamwork. We first provide formal semantics for multiparty proactive performatives within a team setting. We then examine how such performatives result in updates to mental model of teammates, and how such updates can trigger helpful behaviors from other teammates.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-109.pdf,Subjects: 7. Distributed AI; 7.1 Multi-Agent Systems
116,2006,Multiagent Systems,Strong Mediated Equilibrium,"Moshe Tennenholtz, Dov Monderer","Providing agents with strategies that will be robust against deviations by coalitions is central to the design of multi-agent agents. However, such strategies, captured by the notion of strong equilibrium, rarely exist. This paper suggests the use of mediators in order to enrich the set of situations where we can obtain stability against deviations by coalitions. A mediator is a reliable entity, which can ask the agents for the right to play on their behalf, and is guaranteed to behave in a pre-specified way based on messages received from the agents. However, a mediator can not enforce behavior; that is, agents can play in the game directly without the mediator's help. We prove some general results about mediators, and concentrate on the notion of strong mediated equilibrium; we show that desired behaviors, which are stable against deviations by coalitions, can be obtained using mediators in a rich class of settings.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-110.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
117,2006,Multiagent Systems,A Compact Representation Scheme for Coalitional Games in Open Anonymous Environments,"Naoki Ohta, Atsushi Iwasaki, Makoto Yokoo, Kohki Maruono, Vincent Conitzer, Tuomas Sandholm","Coalition formation is an important capability of automated negotiation among self-interested agents. In order for coalitions to be stable, a key question that must be answered is how the gains from cooperation are to be distributed. Recent research has revealed that traditional solution concepts, such as the Shapley value, core, least core, and nucleolus, are vulnerable to various manipulations in open anonymous environments such as the Internet. These manipulations include submitting false names, collusion, and hiding some skills. To address this, a solution concept called the anonymity-proof core, which is robust against such manipulations, was developed. However, the representation size of the outcome function in the anonymity-proof core (and similar concepts) requires space exponential in the number of agents/skills. This paper proposes a compact representation of the outcome function, given that the characteristic function is represented using a recently introduced compact language that explicitly specifies only coalitions that introduce synergy. This compact representation scheme can successfully express the outcome function in the anonymity-proof core. Furthermore, this paper develops a new solution concept, the anonymity-proof nucleolus, that is also expressible in this compact representation. We show that the anonymity-proof nucleolus always exists, is unique, and is in the anonymity-proof core (if the latter is nonempty), and assigns the same value to symmetric skills.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-111.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
118,2006,Multiagent Systems,ODPOP: An Algorithm For Open/Distributed Constraint Optimization,"Adrian Petcu, Boi Faltings","We propose ODPOP, a new distributed algorithm for open multiagent combinatorial optimization that feature unbounded domains. The ODPOP algorithm explores the same search space as the dynamic programming algorithm DPOP or ADOPT, but does so in an incremental, best-first fashion suitable for open problems. ODPOP has several advantages over DPOP. First, it uses messages whose size only grows linearly with the treewidth of the problem. Second, by letting agents explore values in a best-first order, it avoids incurring always the worst case complexity as DPOP, and on average it saves a significant amount of computation and information exchange. To show the merits of our approach, we report on experiments with practically sized distributed meeting scheduling problems in a multiagent system.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-112.pdf,Subjects: 15.2 Constraint Satisfaction; 7. Distributed AI
119,2006,Multiagent Systems,Behaviosites: Manipulation of Multiagent System Behavior,"Amit Shabtay, Zinovi Rabinovich, Jeffrey S. Rosenschein","In this paper we present the Behaviosite Paradigm, a new approach to coordination and control of distributed agents in a multiagent system, inspired by biological parasites with behavior manipulation properties. Behaviosites are code modules that ""infect"" a system, attaching themselves to agents and altering the sensory activity and actions of those agents. These behavioral changes can be used to achieve altered, potentially improved, performance of the overall system; thus, Behaviosites provide a mechanism for distributed control over a distributed system. Behaviosites need to be designed so that they are intimately familiar with the internal workings of the environment and of the agents operating within it. To demonstrate our approach, we use behaviosites to control the behavior of a swarm of simple agents. With a relatively low infection rate, a few behaviosites can engender desired behavior over the swarm as a whole: keeping it in one place, leading it through checkpoints, or moving the swarm from one stable equilibrium to another. We contrast behaviosites as a distributed swarm control mechanism with alternatives, such as the use of group leaders, herders, or social norms.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-113.pdf,Subjects: 7.1 Multi-Agent Systems; 2. Architectures
120,2006,Multiagent Systems,Simultaneous Team Assignment and Behavior Recognition from Spatio-temporal Agent Traces,"Gita Sukthankar, Katia Sycara","This paper addresses the problem of activity recognition for physically-embodied agent teams. We define team activity recognition as the process of identifying team behaviors from traces of agent positions over time; for many physical domains, military or athletic, coordinated team behaviors create distinctive spatio-temporal patterns that can be used to identify low-level action sequences. This paper focuses on the novel problem of recovering agent-to-team assignments for complex team tasks where team composition, the mapping of agents into teams, changes over time. Without a priori knowledge of current team assignments, the behavior recognition problem is challenging since behaviors are characterized by the aggregate motion of the entire team and cannot generally be determined by observing the movements of a single agent in isolation. To handle this problem, we introduce a new algorithm, Simultaneous Team Assignment and Behavior Recognition(STABR), that generates behavior annotations from spatio-temporal agent traces. STABR completely annotates agent traces with 1) the correct sequence of low-level actions performed by each agent and 2) an assignment of agents to teams over time. Our algorithm employs a randomized search strategy, RANSAC, to efficiently identify candidate team assignments at selected timesteps; these hypotheses are evaluated using dynamic programming to derive a parsimonious explanation for the entire observed spatio-temporal sequence. The proposed approach is able to perform accurate team behavior recognition without an exhaustive search over the combinatorial space of potential team assignments. Experiments on simulated military maneuvers demonstrate that STABR outperforms spatial clustering, both in assignment and recognition accuracy.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-114.pdf,Subjects: 7.1 Multi-Agent Systems; 3.2 Geometric Or Spatial Reasoning
121,2006,Multiagent Systems,Contract Enactment in Virtual Organizations: A Commitment-Based Approach,"Yathiraj B. Udupi, Munindar P. Singh","A virtual organization (VO) is a dynamic collection of entities (individuals, enterprises, and information resources) collaborating on some computational activity. VOs are an emerging means to model, enact, and manage large-scale computations. VOs consist of autonomous, heterogeneous members, often dynamic exhibiting complex behaviors. Thus, VOs are best modeled via multiagent systems. An agent can be an individual such as a person, business partner, or a resource. An agent may also be a VO. A VO is an agent that comprises other agents. Contracts provide a natural arms-length abstraction for modeling interaction among autonomous and heterogeneous agents. The interplay of contracts and VOs is the subject of this paper. The core of this paper is an approach to formalize VOs and contracts based on commitments. Our main contributions are (1) a formalization of VOs, (2) a discussion of certain key properties of VOs, and (3) an identification of a variety of VO structures and an analysis of how they support contract enactment. We evaluate our approach with an analysis of several scenarios involving the handling of exceptions and conflicts in contracts.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-115.pdf,Subjects: 7. Distributed AI; 7.1 Multi-Agent Systems
122,2006,Multiagent Systems,A Computational Model of Logic-Based Negotiation,"Dongmo Zhang, Zhang,Yan","This paper presents a computational model of negotiation based on Nebel's syntax-based belief revision. The model guarantees a unique bargaining solution for each bargaining game without using lotteries. Its game-theoretic properties are discussed against the existence and uniqueness of Nash equilibrium and subgame perfect equilibrium. We also study essential computational properties in relation to our negotiation model. In particular, we show that the deal membership checking is DP-complete and the corresponding agreement inference problem is P2P-hard.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-116.pdf,Subjects: 11. Knowledge Representation; 15.1 Belief Revision
123,2006,Multiagent Systems,"Mechanisms for Partial Information Elicitation: The Truth, but Not the Whole Truth","Aviv Zohar, Jeffrey S. Rosenschein","We examine a setting in which a buyer wishes to purchase probabilistic information from some agent. The seller must invest effort in order to gain access to the information, and must therefore be compensated appropriately. However, the information being sold is hard to verify and the seller may be tempted to lie in order to collect a higher payment. While it is generally easy to design information elicitation mechanisms that motivate the seller to be truthful, we show that if the seller has additional relevant information it does not want to reveal, the buyer must resort to elicitation mechanisms that work only some of the time. The optimal design of such mechanisms is shown to be computationally hard. We show two different algorithms to solve the mechanism design problem, each appropriate (from a complexity point of view) in different scenarios.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-117.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
124,2006,Multiagent Systems,Robust Mechanisms for Information Elicitation,"Aviv Zohar, Jeffrey S. Rosenschein","We study information elicitation mechanisms in which a principal agent attempts to elicit the private information of other agents using a carefully selected payment scheme based on proper scoring rules. Scoring rules, like many other mechanisms set in a probabilistic environment, assume that all participating agents share some common belief about the underlying probability of events. In real-life situations however, the underlying distributions are not known precisely, and small differences in beliefs of agents about these distributions may alter their behavior under the prescribed mechanism. We propose designing elicitation mechanisms that will be robust to small changes in belief. We show how to algorithmically design such mechanisms in polynomial time using tools of stochastic programming and convex programming, and discuss implementation issues for multiagent scenarios.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-118.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
125,2006,Natural Language Processing,Societal Grounding is Essential to Meaningful Language Use,"David J. DeVault, Iris Oved, Matthew Stone","Language engineers often point to tight connections between their systems' linguistic representations and accumulated sensor data as a sign that their systems really mean what they say. While we believe such connections are an important piece in the puzzle of meaning, we argue that perceptual grounding alone does not suffice to explain the specific, stable meanings human speakers attribute to each other. Instead, human attributions of meaning depend on a process of societal grounding by which individual language speakers coordinate their perceptual experience and linguistic usage with other members of their linguistic communities. For system builders, this suggests that implementing a strategy of societal grounding would justify the attribution of bona fide linguistic meaning to a system even if it had little perceptual experience and only modest perceptual accuracy. We illustrate the importance and role of societal grounding using an implemented dialogue system that collaboratively identifies visual objects with human users.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-119.pdf,Subjects: 9.4 Philosophical Foundations; 13. Natural Language Processing
126,2006,Natural Language Processing,"Negation, Contrast and Contradiction in Text Processing","Sanda Harabagiu, Andrew Hickl, Finley Lacatusu","This paper describes a framework for recognizing contradictions between multiple text sources by relying on three forms of linguistic information: (a) negation; (b) antonymy; and (c) semantic and pragmatic information associated with the discourse relations. Two views of contradictions are considered, in which a novel method of recognizing contrast and of finding antonymies are described. Contradictions are used for informing fusion operators in question answering. Our experiments show promising results for the detection of contradictions.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-120.pdf,Subjects: 13. Natural Language Processing
127,2006,Natural Language Processing,Proposing a New Term Weighting Scheme for Text Categorization,"Man Lan, Chew-Lim Tan, Hwee-Boon Low","In text categorization, term weighting methods assign appropriate weights to the terms to improve the classification performance. In this study, we propose an effective term weighting scheme, i.e. tf.rf, and investigate several widely-used unsupervised and supervised term weighting methods on two popular data collections in combination with SVM and kNN algorithms. From our controlled experimental results, not all supervised term weighting methods have a consistent superiority over unsupervised term weighting methods. Specifically, the three supervised methods based on the information theory, i.e. tf.chi2, tf.ig and tf.or, perform rather poorly in all experiments. On the other hand, our proposed tf.rf achieves the best performance consistently and outperforms other methods substantially and significantly. The popularly-used tf.idf method has not shown a uniformly good performance with respect to different data corpora.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-121.pdf,Subjects: 11. Knowledge Representation; 12. Machine Learning and Discovery
128,2006,Natural Language Processing,Script and Language Identification in Degraded and Distorted Document Images,"Shijian Lu, Chew Lim Tan","This paper reports a statistical identification technique that differentiates scripts and languages in degraded and distorted document images. We identify scripts and languages through document vectorization, which transforms each document image into an electronic document vector that characterizes the shape and frequency of the contained character and word images. We first identify scripts based on the density and distribution of vertical runs between character strokes and a vertical scan line. Latin-based languages are then differentiated using a set of word shape codes constructed using horizontal word runs and character extremum points. Experimental results show that our method is tolerant to noise, document degradation, and slight document skew and attains an average identification rate over 95%.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-122.pdf,Subjects: 19. Vision; 19.1 Perception
129,2006,Natural Language Processing,Corpus-based and Knowledge-based Measures of Text Semantic Similarity,"Rada Mihalcea, Courtney Corley, Carlo Strapparava","This paper presents a method for measuring the semantic similarity of texts, using corpus-based and knowledge-based measures of similarity. Previous work on this problem has focused mainly on either large documents (e.g. text classification, information retrieval) or individual words (e.g. synonymy tests). Given that a large fraction of the information available today, on the Web and elsewhere, consists of short text snippets (e.g. abstracts of scientific documents, imagine captions, product descriptions), in this paper we focus on measuring the semantic similarity of short texts. Through experiments performed on a paraphrase data set, we show that the semantic similarity method outperforms methods based on simple lexical matching, resulting in up to 13% error rate reduction with respect to the traditional vector-based similarity metric.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-123.pdf,Subjects: 13. Natural Language Processing
130,2006,Natural Language Processing,Learning Noun-Modifier Semantic Relations with Corpus-based and WordNet-based Features,"Vivi Nastase, Jelber Sayyad Shirabad, Marina Sokolova, Stan Szpakowicz","We study the performance of two representations of word meaning in learning noun-modifier semantic relations. One representation is based on lexical resources, in particular WordNet, the other - on a corpus. We experimented with decision trees, instance-based learning and Support Vector Machines. All these methods work well in this learning task. We report high precision, recall and F-score, and small variation in performance across several 10-fold cross-validation runs. The corpus-based method has the advantage of working with data without word-sense annotations and performs well over the baseline. The WordNet-based method, requiring word-sense annotated data, has higher precision.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-124.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
131,2006,Reasoning about Plans and Actions,Planning with First-Order Temporally Extended Goals Using Heuristic Search,"Jorge A. Baier, Sheila A. McIlraith","Temporally extended goals (TEGs) refer to properties that must hold over intermediate and/or final states of a plan. The problem of planning with TEGs is of renewed interest because it is at the core of planning with temporal preferences. Currently, the fastest domain-independent classical planners employ some kind of heuristic search. However, existing planners for TEGs are not heuristic and are only able to prune the search space by progressing the TEG. In this paper we propose a method for planning with TEGs using heuristic search. We represent TEGs using a rich and compelling subset of a first-order linear temporal logic. We translate a planning problem with TEGs to a classical planning problem. With this translation in hand, we exploit heuristic search to determine a plan. Our translation relies on the construction of a parameterized nondeterministic finite automaton for the TEG. We have proven the correctness of our algorithm and analyzed the complexity of the resulting representation. The translator is fully implemented and available. Our approach consistently outperforms TLPlan on standard benchmark domains, often by orders of magnitude.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-125.pdf,Subjects: 1.11 Planning; 11. Knowledge Representation
132,2006,Reasoning about Plans and Actions,Fast Hierarchical Goal Schema Recognition,"Nate Blaylock, James Allen","We present our work on using statistical, corpus-based machine learning techniques to simultaneously recognize an agent's current goal schemas at various levels of a hierarchical plan. Our recognizer is based on a novel type of graphical model, a Cascading Hidden Markov Model, which allows the algorithm to do exact inference and make predictions at each level of the hierarchy in time quadratic to the number of possible goal schemas. We also report results of our recognizer's performance on a plan corpus.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-126.pdf,Subjects: 8. Enabling Technologies; 1.11 Planning
133,2006,Reasoning about Plans and Actions,"Robust Execution of Contingent, Temporally Flexible Plans","Stephen Block, Andreas Wehowsky, Brian Williams","Many applications of autonomous agents require groups to work in tight coordination. To be dependable, these groups must plan, carry out and adapt their activities in a way that is robust to failure and uncertainty. Previous work has produced contingent plan execution systems that provide robustness during their plan extraction phase, by choosing between functionally redundant methods, and during their execution phase, by dispatching temporally flexible plans. Previous contingent execution systems use a centralized architecture in which a single agent conducts planning for the entire group. This can result in a communication bottleneck at the time when plan activities are passed to the other agents for execution, and state information is returned. This paper introduces the plan extraction component of a robust, distributed executive for contingent plans. Contingent plans are encoded as Temporal Plan Networks (TPNs), which use a non-deterministic choice operator to compose temporally flexible plan fragments into a nested hierarchy of contingencies. To execute a TPN, the TPN is first distributed over multiple agents, by creating a hierarchical ad-hoc network and by mapping the TPN onto this hierarchy. Second, candidate plans are extracted from the TPN using a distributed, parallel algorithm that exploits the structure of the TPN. Third, the temporal consistency of each candidate plan is tested using a distributed Bellman-Ford algorithm. Each stage of plan extraction distributes communication to adjacent agents in the TPN, and in so doing eliminates communication bottlenecks. In addition, the distributed algorithm reduces the computational load on each agent. The algorithm is empirically validated on a range of randomly generated contingent plans.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-127.pdf,Subjects: 1.11 Planning; 7.1 Multi-Agent Systems
134,2006,Reasoning about Plans and Actions,"Factored Planning: How, When, and When Not","Ronen I. Brafman, Carmel Domshlak","Automated domain factoring, and planning methods that utilize them, have long been of interest to planning researchers. Recent work in this area yielded new theoretical insight and algorithms, but left many questions open: How to decompose a domain into factors? How to work with these factors? And whether and when decomposition-based methods are useful? This paper provides theoretical analysis that answers many of these questions: it proposes a novel approach to factored planning; proves its theoretical superiority over previous methods; provides insight into how to factor domains; and uses its novel complexity results to analyze when factored planning is likely to perform well, and when not. It also establishes the key role played by the domain's causal graph in the complexity analysis of planning algorithms.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-128.pdf,Subjects: 1.11 Planning; 9.2 Computational Complexity
135,2006,Reasoning about Plans and Actions,Adaptive Sampling Based Large-Scale Stochastic Resource Control,"Balazs Csanad Csaji, Laszlo Monostori","We consider closed-loop solutions to stochastic optimization problems of resource allocation type. They concern with the dynamic allocation of reusable resources over time to non-preemtive interconnected tasks with stochastic durations. The aim is to minimize the expected value of a regular performance measure. First, we formulate the problem as a stochastic shortest path problem and argue that our formulation has favorable properties, e.g., it has finite horizon, it is acyclic, thus, all policies are proper, and moreover, the space of control policies can be safely restricted. Then, we propose an iterative solution. Essentially, we apply a reinforcement learning based adaptive sampler to compute a suboptimal control policy. We suggest several approaches to enhance this solution and make it applicable to largescale problems. The main improvements are: (1) the value function is maintained by feature-based support vector regression; (2) the initial exploration is guided by rollout algorithms; (3) the state space is partitioned by clustering the tasks while keeping the precedence constraints satisfied; (4) the action space is decomposed and, consequently, the number of available actions in a state is decreased; and, finally, (5) we argue that the sampling can be effectively distributed among several processors. The effectiveness of the approach is demonstrated by experimental results on both artificial (benchmark) and real-world (industry related) data.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-129.pdf,Subjects: 1.12 Scheduling; 12.1 Reinforcement Learning
136,2006,Reasoning about Plans and Actions,Cost-Optimal External Planning,Stefan Edelkamp and Shahid Jabbar,"This paper considers strategies for external memory based optimal planning. An external breadth-first search exploration algorithm is devised that is guaranteed to find the costoptimal solution. We contribute a procedure for finding the upper bound on the locality of the search in planning graphs that dictates the number of layers that have to be kept to avoid re-openings. We also discuss an external variant of Enforced Hill Climbing. Using relaxed-plan heuristic without helpful-action pruning we have been able to perform large explorations on metric planning problems, providing better plan lengths than have been reported earlier. A novel approach to plan reconstruction in external setting with linear I/O complexity is proposed. We provide external exploration results on some recently proposed planning domains.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-130.pdf,
137,2006,Reasoning about Plans and Actions,A Two-Step Hierarchical Algorithm for Model-Based Diagnosis,"Alexander Feldman, Arjan van Gemund","For many large systems the computational complexity of complete model-based diagnosis is prohibitive. In this paper we investigate the speedup of the diagnosis process by exploiting the hierarchy/locality as is typically present in wellengineered systems. The approach comprises a compile-time and a run-time step. In the first step, a hierarchical CNF representation of the system is compiled to hierarchical DNF of adjustable hierarchical depth. In the second step, the diagnoses are computed from the hierarchical DNF and the actual observations. Our hierarchical algorithm, while sound and complete, allows large models to be diagnosed, where compiletime investment directly translates to run-time speedup. The benefits of our approach are illustrated by using weak-fault models of real-world systems, including the ISCAS-85 combinatorial circuits. Even for these non-optimally partitioned problems the speedup compared to traditional approaches ranges in the hundreds.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-131.pdf,Subjects: 3. Automated Reasoning; 1.5 Diagnosis
138,2006,Reasoning about Plans and Actions,Exploration of the Robustness of Plans,"Maria Fox, Richard Howey, Derek Long","This paper considers the problem of stochastic robustness testing for plans. As many authors have observed, unforeseen execution-time variations, both in the effects of actions and in the times at which they occur, can result in a plan failing to execute correctly even when it is valid with respect to a domain model. In this paper we contrast the validation of a plan with respect to a domain model, confirming soundness, with the validation with respect to an execution model, which we call robustness. We describe a Monte Carlo probing strategy that takes a hypothesis testing approach to confirming the robustness of a plan. An important contribution of the work is that we draw links between the robustness of plans and the notion of the ""fuzzy"" robustness of traces through timed hybrid automata, introduced by Gupta et al. We show that robustness depends on the metric used to define the set of plans that are probed, and that the most appropriate metric depends on the capabilities of the executive and the way in which it will interpret and execute the plan.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-132.pdf,Subjects: 1.11 Planning
139,2006,Reasoning about Plans and Actions,A Causal Analysis Method for Concurrent Hybrid Automata,"Michael Hofbaur, Franz Wotawa",Modern artifacts are typically composed of many system components and exhibit a complex pattern of continuous/discrete behaviors. A concurrent hybrid automaton is a powerful modeling concept to capture such a system's behavior in terms a concurrent composition of hybrid automata for the individual system components. Because of the potentially large number of modes of the concurrent automaton model it is non-trivial to validate the composition such that every possible operational mode leads to a causally valid dynamic model for the overall system. This paper presents a novel model analysis method that validates the automata composition without the necessity to analyze a prohibitively large number of modes. We achieve this by formulating the exhaustive causal analysis of hybrid automata as a diagnosis problem. This provides causal specifications of the component automata and enables us to efficiently calculate the causal relationships for their concurrent composition and thus validate a concurrent automaton model.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-133.pdf,Subjects: 9.1 Causality; 1.5 Diagnosis
140,2006,Reasoning about Plans and Actions,Tractable Classes of Metric Temporal Problems with Domain Rules,T. K. Satish Kumar,"In this paper, we will deal with some important kinds of metric temporal reasoning problems that arise in many real-life situations. In particular, events X_0, X_1 ... X_N are modeled as time points, and a constraint between the execution times of two events X_i and X_j is either simple temporal (of the form X_i - X_j in [a,b]), or has a connected feasible region that can be expressed using a finite set of domain rules each in turn of the form X_i in [a,b] -> X_j in [c,d] (and conversely X_j in [e,f] -> X_i in [g,h]). We argue that such rules are useful in capturing important kinds of non-monotonic relationships between the execution times of events when they are governed by potentially complex (external) factors. Our polynomial-time (deterministic and randomized) algorithms for solving such problems therefore enable us to efficiently deal with very expressive representations of time.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-134.pdf,Subjects: 3.6 Temporal Reasoning; 1.12 Scheduling
141,2006,Reasoning about Plans and Actions,A Modular Action Description Language,"Vladimir Lifschitz, Wanwan Ren","""Toy worlds"" involving actions, such as the blocks world and the Missionaries and Cannibals puzzle, are often used by researchers in the areas of commonsense reasoning and planning to illustrate and test their ideas. We would like to create a database of general-purpose knowledge about actions that encodes common features of many action domains of this kind, in the same way as abstract algebra and topology represent common features of specific number systems. This paper is a report on the first stage of this project—the design of an action description language in which this database will be written. The new language is an extension of the action language C+. Its main distinctive feature is the possibility of referring to other action descriptions in the definition of a new action domain.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-135.pdf,Subjects: 5. Common Sense Reasoning; 11. Knowledge Representation
142,2006,Reasoning about Plans and Actions,PPCP: Efficient Probabilistic Planning with Clear Preferences in Partially-Known Environments,"Maxim Likhachev, Anthony Stentz","For most real-world problems the agent operates in only partially-known environments. Probabilistic planners can reason over the missing information and produce plans that take into account the uncertainty about the environment. Unfortunately though, they can rarely scale up to the problems that are of interest in real-world. In this paper, however, we show that for a certain subset of problems we can develop a very efficient probabilistic planner. The proposed planner, called PPCP, is applicable to the problems for which it is clear what values of the missing information would result in the best plan. In other words, there exists a clear preference for the actual values of the missing information. For example, in the problem of robot navigation in partially-known environments it is always preferred to find out that an initially unknown location is traversable rather than not. The planner we propose exploits this property by using a series of deterministic A*-like searches to construct and refine a policy in anytime fashion. On the theoretical side, we show that once converged, the policy is guaranteed to be optimal under certain conditions. On the experimental side, we show the power of PPCP on the problem of robot navigation in partially-known terrains. The planner can scale up to very large environments with thousands of initially unknown locations. We believe that this is several orders of magnitude more unknowns than what the current probabilistic planners developed for the same problem can handle. Also, despite the fact that the problem we experimented on in general does not satisfy the conditions for the solution optimality, PPCP still produces the solutions that are nearly always optimal.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-136.pdf,Subjects: 1.11 Planning; 15.5 Decision Theory
143,2006,Reasoning about Plans and Actions,Reasoning about Discrete Event Sources,Shieu-Hong Lin,"We investigate the modelling of workflows, plans, and other event-generating processes as discrete event sources and reason about the possibility of having event sequences ending in undesirable states. In previous research, the problem is shown to be NP-Complete even if the number of events to occur is fixed in advance. In this paper, we consider possible events sequences of indefinite length and show that many interesting cases of such reasoning task are solvable in polynomial time.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-137.pdf,Subjects: 3.6 Temporal Reasoning; 1.11 Planning
144,2006,Reasoning about Plans and Actions,Optimal Scheduling of Contract Algorithms for Anytime Problems,"Alejandro Lopez-Ortiz, Spyros Angelopoulos, Angele M. Hamel","A contract algorithm is an algorithm which is given, as part of the input, a specified amount of allowable computation time. The algorithm must then compute a solution within the alloted time. An interruptible algorithm, in contrast, can be interrupted at an arbitrary point in time and must produce a solution. It is known that contract algorithms can simulate interruptible algorithms using iterative deepening techniques. This simulation is done at a penalty in the performance of the solution, as measured by the so-called acceleration ratio. In this paper we give matching (i.e. optimal) upper and lower bounds for the acceleration ratio under this simulation. This resolves an open conjecture of Bernstein et al. [IJCAI 2003]who gave an ingenious optimal schedule under the restricted setting of round robin and length-increasing processor schedules, but whose optimality in the general unrestricted case remained open.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-138.pdf,Subjects: 1.12 Scheduling
145,2006,Reasoning about Plans and Actions,Probabilistic Temporal Planning with Uncertain Durations,"Mausam Mausam, Daniel S. Weld","Few temporal planners handle both concurrency and uncertain durations, but these features commonly co-occur in real-world domains. In this paper, we discuss the challenges caused by concurrent, durative actions whose durations are uncertain. We present five implemented algorithms, including ΔDURprun, a planner guaranteed to find the optimal policy. An empirical comparison reveals that ΔDURexp, our fastest planner, obtains orders of magnitude speed-up compared to ΔDURprun — with little loss in solution quality. Importantly, our algorithms can handle probabilistic effects in addition to stochastic durations, and they are effective even when duration distributions are multi-modal.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-139.pdf,Subjects: 1.11 Planning
146,2006,Reasoning about Plans and Actions,Reasoning about Partially Observed Actions,"Megan Nance, Adam Vogel, Eyal Amir","Partially observed actions are observations of action executions in which we are uncertain about the identity of objects, agents, or locations involved in the actions (e.g., we know that action move(?o,?x,?y) occurred, but do not know ?o,?y). Observed-Action Reasoning is the problem of reasoning about the world state after a sequence of partial observations of actions and states. In this paper we formalize Observed-Action Reasoning, prove intractability results for current techniques, and find tractable algorithms for STRIPS and other actions. Our new algorithms update a representation of all possible world states (the belief state) in logic using new logical constants for unknown objects. A straightforward application of this idea is incorrect, and we identify and add two key amendments. We also present successful experimental results for our algorithm in Blocks-world domains of varying sizes and in Kriegspiel (partially observable chess). These results are promising for relating sensors with symbols, partial-knowledge games, multi-agent decision making, and AI planning.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-140.pdf,Subjects: 5. Common Sense Reasoning
147,2006,Reasoning about Plans and Actions,Approximate Compilation for Embedded Model-based Reasoning,"Barry O'Sullivan, Gregory M. Provan","The use of embedded technology has become widespread. Many complex engineered systems comprise embedded features to perform self-diagnosis or self-reconfiguration. These features require fast response times in order to be useful in domains where embedded systems are typically deployed. Researchers often advocate the use of compilation-based approaches to store the set of environments (resp. solutions) to a diagnosis (resp. reconfiguration) problem, in some compact representation. However, the size of a compiled representation may be exponential in the treewidth of the problem. In this paper we propose a novel method for compiling the most preferred environments in order to reduce the large space requirements of our compiled representation. We show that approximate compilation is an effective means of generating the highest-valued environments, while obtaining a representation whose size can be tailored to any embedded application. The method also provides a graceful way to tradeoff space requirements with the completeness of our coverage of the environment space.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-141.pdf,Subjects: 1.5 Diagnosis; 15.2 Constraint Satisfaction
148,2006,Reasoning about Plans and Actions,Compiling Uncertainty Away: Solving Conformant Planning Problems Using a Classical Planner (Sometimes),"Palacios Hector, Hector Geffner","Even under polynomial restrictions on plan length, conformant planning remains a very hard computational problem as plan verification itself can take exponential time. This heavy price cannot be avoided in general although in many cases conformant plans are verifiable efficiently by means of simple forms of disjunctive inference. This raises the question of whether it is possible to identify and use such forms of inference for developing an efficient but incomplete planner capable of solving non-trivial problems quickly. In this work, we show that this is possible by mapping conformant into classical problems that are then solved by an off-the-shelf classical planner. The formulation is sound as the classical plans obtained are all conformant, but it is incomplete as the inverse relation does not always hold. The translation accommodates `reasoning by cases' by means of an `split-protect-and-merge' strategy; namely, atoms L/Xi that represent conditional beliefs `if Xi then L' are introduced in the classical encoding, that are combined by suitable actions to yield the literal L when the disjunction X1 or ... or Xn holds and certain invariants in the plan are verified. Empirical results over a wide variety of problems illustrate the power of the approach.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-142.pdf,Subjects: 1.11 Planning
149,2006,Reasoning about Plans and Actions,Sensor-Based Understanding of Daily Life via Large-Scale Use of Common Sense,"William Pentney, Ana-Maria Popescu, Shiaokai Wang, Henry Kautz, Matthai Philipose","The use of large quantities of common sense has long been thought to be critical to the automated understanding of the world. To this end, various groups have collected repositories of common sense in machine-readable form. However, efforts to apply these large bodies of knowledge to enable correspondingly large-scale sensor-based understanding of the world have been few. Challenges have included semantic gaps between facts in the repositories and phenomena detected by sensors, fragility of reasoning in the face of noise, incompleteness of repositories, and slowness of reasoning with these large repositories. We show how to address these problems with a combination of novel sensors, probabilistic representation, web-scale information retrieval and approximate reasoning. In particular, we show how to use the 50,000-fact hand-entered OpenMind Indoor Common Sense database to interpret sensor traces of day-to-day activities with 88% accuracy (which is easy) and 32/53% precision/recall (which is not).",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-143.pdf,Subjects: 3.4 Probabilistic Reasoning; 11. Knowledge Representation
150,2006,Reasoning about Plans and Actions,Learning Partially Observable Action Schemas,"Dafna Shahaf, Eyal Amir","We present an algorithm that derives actions' effects and preconditions in partially observable, relational domains. Our algorithm has two unique features: an expressive relational language, and an exact tractable computation. An action schema language that we present permits learning of preconditions and effects that include implicit objects and unstated relationships between objects. For example, we can learn that replacing a blown fuse turns on all the lights whose switch is set to on. The algorithm maintains and outputs a relational logical representation of all possible action-schema models after a sequence of executed actions and partial observations. Importantly, our algorithm takes polynomial time in the number of time steps and predicates. Time dependence on other domain parameters varies with the action-schema language. Our experiments show that the relational structure speeds up both learning and generalization, and outperforms propositional learning methods. It also allows establishing apriori unknown connections between objects (e.g. light bulbs and their switches), and permits learning conditional effects in realistic and complex situations. Our algorithm takes advantage of a DAG structure that can be updated efficiently and preserves compactness of representation.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-144.pdf,Subjects: 3. Automated Reasoning; 11. Knowledge Representation
151,2006,Reasoning about Plans and Actions,Learning Partially Observable Action Models: Efficient Algorithms,"Dafna Shahaf, Allen Chang, Eyal Amir","We present tractable, exact algorithms for learning actions' effects and preconditions in partially observable domains. Our algorithms maintain a propositional logical representation of the set of possible action models after each observation and action execution. The algorithms perform exact learning of preconditions and effects in any deterministic action domain. This includes STRIPS actions and actions with conditional effects. In contrast, previous algorithms rely on approximations to achieve tractability, and do not supply approximation guarantees. Our algorithms take time and space that are polynomial in the number of domain features, and can maintain a representation that stays compact indefinitely. Our experimental results show that we can learn efficiently and practically in domains that contain over 1000's of features (more than 2^1000 states).",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-145.pdf,Subjects: 3. Automated Reasoning; 1.11 Planning
152,2006,Reasoning about Plans and Actions,Contingent Planning with Goal Preferences,"Paolo Traverso, Dmitry Shaparau, Marco Pistore","The importance of the problems of contingent planning with actions that have non-deterministic effects and of planning with goal preferences has been widely recognized, and several works address these two problems separately. However, combining conditional planning with goal preferences adds some new difficulties to the problem. Indeed, even the notion of optimal plan is far from trivial, since plans in nondeterministic domains can result in several different behaviors satisfying conditions with different preferences. Planning for optimal conditional plans must therefore take into account the different behaviors, and conditionally search for the highest preference that can be achieved. In this paper, we address this problem. We formalize the notion of optimal conditional plan, and we describe a correct and complete planning algorithm that is guaranteed to find optimal solutions. We implement the algorithm using BDD-based techniques, and show the practical potentialities of our approach through a preliminary experimental evaluation.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-146.pdf,Subjects: 3. Automated Reasoning; 1.11 Planning
153,2006,Robotics and Computer Vision,Motion-Based Autonomous Grounding: Inferring External World Properties from Encoded Internal Sensory States Alone,"Yoonsuck Choe, Noah H. Smith","How can we build artificial agents that can autonomously explore and understand their environments? An immediate requirement for such an agent is to learn how its own sensory state corresponds to the external world properties: It needs to learn the semantics of its internal state (i.e., grounding). In principle, we as programmers can provide the agents with the required semantics, but this will compromise the autonomy of the agent. To overcome this problem, we may fall back on natural agents and see how they acquire meaning of their own sensory states, their neural firing patterns. We can learn a lot about what certain neural spikes mean by carefully controlling the input stimulus while observing how the neurons fire. However, neurons embedded in the brain do not have direct access to the outside stimuli, so such a stimulus-to-spike association may not be learnable at all. How then can the brain solve this problem? (We know it does.) We propose that motor interaction with the environment is necessary to overcome this conundrum. Further, we provide a simple yet powerful criterion, sensory invariance, for learning the meaning of sensory states. The basic idea is that a particular form of action sequence that maintains invariance of a sensory state will express the key property of the environmental stimulus that gave rise to the sensory state. Our experiments with a sensorimotor agent trained on natural images show that sensory invariance can indeed serve as a powerful objective for semantic grounding.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-147.pdf,Subjects: 4. Cognitive Modeling; 19.1 Perception
154,2006,Robotics and Computer Vision,Efficient Triangulation-Based Pathfinding,"Douglas Demyen, Michael Buro","In this paper we present a method for abstracting an environment represented using constrained Delaunay triangulations in a way that significantly reduces pathfinding search effort, as well as better representing the basic structure of the environment. The techniques shown here are ideal for objects of varying sizes and environments that are not axis-aligned or that contain many dead-ends, long corridors, or jagged walls that complicate other search techniques. In fact, the abstraction simplifies pathfinding to deciding to which side of each obstacle to go. This technique is suited to real-time computation both because of its speed and because it lends itself to an anytime algorithm, allowing it to work when varying amounts of resources are assigned to pathfinding. We test search algorithms running on both the base triangulation (Triangulation A* -- TA*) and our abstraction (Triangulation Reduction A* -- TRA*) against A* and PRA* on grid-based maps from the commercial games Baldur's Gate and WarCraft III. We find that in these cases almost all paths are found much faster using TA*, and more so using TRA*.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-148.pdf,Subjects: 15.7 Search; 17. Robotics
155,2006,Robotics and Computer Vision,"Exploiting Spatial and Temporal Flexibility for Plan Execution of Hybrid, Under-actuated Systems","Andreas G. Hofmann, Brian C. Williams","Robotic devices, such as rovers and autonomous spacecraft, have been successfully controlled by plan execution systems that use plans with temporal flexibility to dynamically adapt to temporal disturbances. To date these execution systems apply to discrete systems that abstract away the detailed dynamic constraints of the controlled device. To control dynamic, under-actuated devices, such as agile bipedal walking machines, we extend this execution paradigm to incorporate detailed dynamic constraints. Building upon prior work on dispatchable plan execution, we introduce a novel approach to flexible plan execution of hybrid under-actuated systems that achieves robustness by exploiting spatial as well as temporal plan flexibility. To accomplish this, we first transform the high-dimensional system into a set of low dimensional, weakly coupled systems. Second, to coordinate these systems such that they achieve the plan in real-time, we compile a plan into a concurrent timed flow tube description. This description represents all feasible control trajectories and their temporal coordination constraints, such that each trajectory satisfies all plan and dynamic constraints. Finally, the problem of runtime plan dispatching is reduced to maintaining state trajectories in their associated flow tubes, while satisfying the coordination constraints. This is accomplished through an efficient local search algorithm that adjusts a small number of control parameters in real-time. The first step has been published previously; this paper focuses on the last two steps. The approach is validated on the execution of a set of bipedal walking plans, using a high fidelity simulation of a biped.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-149.pdf,Subjects: 3.5 Qualitative Reasoning; 3.6 Temporal Reasoning
156,2006,Robotics and Computer Vision,Object Boundary Detection in Images using a Semantic Ontology,"Anthony Hoogs, Roderic Collins","We present a novel method for detecting the boundaries between objects in images that uses a large, hierarchical, semantic ontology -- WordNet. The semantic object hierarchy in WordNet grounds this ill-posed segmentation problem, so that true boundaries are defined as edges between instances of different classes, and all other edges are clutter. To avoid fully classifying each pixel, which is very difficult in generic images, we evaluate the semantic similarity of the two regions bounding each edge in an initial oversegmentation. Semantic similarity is computed using WordNet enhanced with appearance information, and is largely orthogonal to visual similarity. Hence two regions with very similar visual attributes, but from different categories, can have a large semantic distance and therefore evidence of a strong boundary between them, and vice versa. The ontology is trained with images from the UC Berkeley image segmentation benchmark, extended with manual labeling of the semantic content of each image segment. Results on boundary detection against the benchmark images show that semantic similarity computed through WordNet can significantly improve boundary detection compared to generic segmentation.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-150.pdf,Subjects: 19. Vision; 12. Machine Learning and Discovery
157,2006,Robotics and Computer Vision,Bayesian Calibration for Monte Carlo Localization,"Armita Kaboli, Michael Bowling, Petr Musilek","Localization is a fundamental challenge for autonomous robotics. Although accurate and efficient techniques now exist for solving this problem, they require explicit probabilistic models of the robot's motion and sensors. These models are usually obtained from time-consuming and error-prone measurement or tedious manual tuning. In this paper we examine automatic calibration of sensor and motion models from a Bayesian perspective. We introduce an efficient MCMC procedure for sampling from the posterior distribution of the model parameters. We also present a novel extension of particle filters to make use of our posterior parameter samples. Finally, we demonstrate our approach both in simulation and on a physical robot. Our results demonstrate effective inference of model parameters as well as a paradoxical result that using posterior parameter samples can produce more accurate position estimates than the true parameters.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-151.pdf,Subjects: 17. Robotics
158,2006,Robotics and Computer Vision,Diagnosis of Multi-Robot Coordination Failures Using Distributed CSP Algorithms,"Meir Kalech, Gal A. Kaminka , Amnon Meisels","With increasing deployment of multi-agent and distributed systems, there is an increasing need for coordination failure diagnosis systems. While successfully addressing key challenges, model-based diagnosis had difficulty in being applied to diagnosing coordination failures. However, it is possible to diagnose such failures using a model of the coordination between agents, by defining coordination primitives (concurrence and mutual exclusion). Earlier work showed that a centralized model-based diagnoser can diagnose coordination failures, however, it is not always applicable due to communication and computational overhead, and the problem it has a single point of failure. In this paper we propose a distributed approach to diagnose the coordination between the agents by exchanging information between the agents. We exploit a constraint-satisfaction model, and adapt algorithms from the distributed CSP area, to use as the basis for the diagnosis algorithms. We evaluate these algorithms in extensive experiments with simulated and real mobile robots and show a tradeoff between the effectiveness of the algorithms in terms of communication and computation and the correctness of the diagnosis that the algorithms produce.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-152.pdf,Subjects: 1.5 Diagnosis; 17. Robotics
159,2006,Robotics and Computer Vision,Probabilistic Self-Localization for Sensor Networks,"Dimitri Marinakis, Gregory Dudek","This paper describes a technique for the probabilistic self-localization of a sensor network based on noisy inter-sensor range data. Our method is based on a number of parallel instances of Markov Chain Monte Carlo (MCMC). By combining estimates drawn from these parallel chains, we build up a representation of the underlying probability distribution function (PDF) for the network pose. Our approach includes sensor data incrementally in order to avoid local minima and is shown to produce meaningful results efficiently. We return a distribution over sensor locations rather than a single maximum likelihood estimate. This can then be used for subsequent exploration and validation.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-153.pdf,Subjects: 17. Robotics
160,2006,Robotics and Computer Vision,Winning the DARPA Grand Challenge with an AI Robot,"Michael Montemerlo, Sebastian Thrun, Hendrik Dahlkamp, David Stavens, Sven Strohband","This paper describes the software architecture of Stanley, an autonomous land vehicle developed for high-speed desert driving without human intervention. The vehicle recently won the DARPA Grand Challenge, a major robotics competition. The article describes the software architecture of the robot, which relied pervasively on state-of-the-art AI technologies, such as machine learning and probabilistic reasoning.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-154.pdf,Subjects: 17. Robotics
161,2006,Robotics and Computer Vision,A Manifold Regularization Approach to Calibration Reduction for Sensor-Network Based Tracking,"Jeffrey Junfeng Pan, Qiang Yang, Hong Chang, and Dit-Yan Yeung","The ability to accurately detect the location of a mobile node in a sensor network is important for many artificial intelligence (AI) tasks that range from robotics to context-aware computing. Many previous approaches to the location-estimation problem assume the availability of calibrated data. However, to obtain such data requires great effort. In this paper, we present a manifold regularization approach known as LeMan to calibration-effort reduction for tracking a mobile node in a wireless sensor network. We compute a subspace mapping function between the signal space and the physical space by using a small amount of labeled data and a large amount of unlabeled data. This mapping function can be used online to determine the location of mobile nodes in a sensor network based on the signals received. We use Crossbow MICA2 to setup the network and USB camera array to obtain the ground truth. Experimental results show that we can achieve a higher accuracy with much less calibration effort as compared to several previous systems.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-155.pdf,
162,2006,Robotics and Computer Vision,Running the Table: An AI for Computer Billiards,Michael Smith,"Billiards is a game of both strategy and physical skill. To succeed, a player must be able to select strong shots, and then execute them accurately and consistently. Several robotic billiards players have recently been developed. These systems address the task of executing shots on a physical table, but so far have incorporated little strategic reasoning. They require AI to select the ""best"" shot taking into account the accuracy of the robotics, the noise inherent in the domain, the continuous nature of the search space, the difficulty of the shot, and the goal of maximizing the chances of winning. This paper develops and compares several approaches to establishing a strong AI for billiards. The resulting program, PickPocket, won the first international computer billiards competition.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-156.pdf,Subjects: 1.8 Game Playing; 15.7 Search
163,2006,Robotics and Computer Vision,Reinforcement Learning with Human Teachers: Evidence of Feedback and Guidance with Implications for Learning Performance,"Andrea L. Thomaz, Cynthia Breazeal","As robots become a mass consumer product, they will need to learn new skills by interacting with typical human users. Past approaches have adapted reinforcement learning (RL) to accept a human reward signal; however, we question the implicit assumption that people shall only want to give the learner feedback on its past actions. We present findings from a human user study showing that people use the reward signal not only to provide feedback about past actions, but also to provide future directed rewards to guide subsequent actions. Given this, we made specific modifications to the simulated RL robot to incorporate guidance. We then analyze and evaluate its learning performance in a second user study, and we report significant improvements on several measures. This work demonstrates the importance of understanding the human-teacher/robot-learner system as a whole in order to design algorithms that support how people want to teach while simultaneously improving the robot's learning performance.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-157.pdf,Subjects: 12.1 Reinforcement Learning; 6. Computer-Human Interaction
164,2006,Search and Game Playing,A Competitive Texas Hold’em Poker Player via Automated Abstraction and Real-time Equilibrium Computation,"Andrew Gilpin, Tuomas Sandholm","We present a game theory-based heads-up Texas Hold'em poker player, GS1. To overcome the computational obstacles stemming from Texas Hold'em's gigantic game tree, the player employs our automated abstraction techniques to reduce the complexity of the strategy computations. Texas Hold'em consists of four betting rounds. Our player solves a large linear program (offline) to compute strategies for the abstracted first and second rounds. After the second betting round, our player updates the probability of each possible hand based on the observed betting actions in the first two rounds as well as the revealed cards. Using these updated probabilities, our player computes in real-time an equilibrium approximation for the last two abstracted rounds. We demonstrate that our player, which incorporates very little poker-specific knowledge, is competitive with leading poker-playing programs which incorporate extensive domain knowledge, as well as with advanced human players.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-158.pdf,Subjects: 7.1 Multi-Agent Systems; 1.8 Game Playing
165,2006,Search and Game Playing,Estimating Search Tree Size,"Philip Kilby, John Slaney, Sylvie Thiebaux, Toby Walsh",We propose two new online methods for estimating the size of a backtracking search tree. The first method is based on a weighted sample of the branches visited by chronological backtracking. The second is a recursive method based on assuming that the unexplored part of the search tree will be similar to the part we have so far explored. We compare these methods against an old method due to Knuth based on random probing. We show that these methods can reliably estimate the size of search trees explored by both optimization and decision procedures. We also demonstrate that these methods for estimating search tree size can be used to select the algorithm likely to perform best on a particular problem instance.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-159.pdf,Subjects: 15.7 Search; 15.2 Constraint Satisfaction
166,2006,Search and Game Playing,Properties of Forward Pruning in Game-Tree Search,"Yew Jin Lim, Wee Sun Lee","Forward pruning, or selectively searching a subset of moves, is now commonly used in game-playing programs to reduce the number of nodes searched with manageable risk. Forward pruning techniques should consider how pruning errors in a game-tree search propagate to the root to minimize the risk of making errors. In this paper, we explore forward pruning using theoretical analyses and Monte Carlo simulations and report on two findings. Firstly, we find that pruning errors propagate differently depending on the player to move, and show that pruning errors on the opponent's moves are potentially more serious than pruning errors on the player's own moves. This suggests that pruning on the player's own move can be performed more aggressively compared to pruning on the opponent's move. Secondly, we examine the ability of the minimax search to filter away pruning errors and give bounds on the rate of error propagation to the root. We find that if the rate of pruning error is kept constant, the growth of errors with the depth of the tree dominates the filtering effect, therefore suggesting that pruning should be done more aggressively near the root and less aggressively near the leaves.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-160.pdf,Subjects: 15.7 Search; 1.8 Game Playing
167,2006,Search and Game Playing,RankCut — A Domain Independent Forward Pruning Method for Games,"Yew Jin Lim, Wee Sun Lee","Forward pruning, also known as selective search, is now employed in many strong game-playing programs. In this paper, we introduce RankCut - a domain independent forward pruning technique which makes use of move ordering, and prunes once no better move is likely to be available. Since game-playing programs already perform move ordering to improve the performance of αβ search, this information is available at no extra cost. As RankCut uses additional information untapped by current forward pruning techniques, RankCut is a complementary forward pruning method that can be used with existing methods, and is able to achieve improvements even when conventional pruning techniques are simultaneously employed. We implemented RankCut in a modern open-source chess program, Crafty. RankCut reduces the game-tree size by approximately 10%-40% for search depths 8-12 while retaining tactical reliability, when implemented alongside Crafty's existing forward pruning techniques.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-161.pdf,Subjects: 1.8 Game Playing; 15.7 Search
168,2006,Search and Game Playing,DD* Lite: Efficient Incremental Search with State Dominance,"G. Ayorkor Mills-Tettey, Anthony Stentz, M. Bernardine Dias","This paper presents DD* Lite, an efficient incremental search algorithm for problems that can capitalize on state dominance. Dominance relationships between nodes are used to prune graphs in search algorithms. Thus, exploiting state dominance relationships can considerably speed up search problems in large state spaces, such as mobile robot path planning considering uncertainty, time, or energy constraints. Incremental search techniques are useful when changes can occur in the search graph, such as when re-planning paths for mobile robots in partially known environments. While algorithms such as D* and D* Lite are very efficient incremental search algorithms, they cannot be applied as formulated to search problems in which state dominance is used to prune the graph. DD* Lite extends D* Lite to seamlessly support reasoning about state dominance. It maintains the algorithmic simplicity and incremental search capability of D* Lite, while resulting in orders of magnitude increase in search efficiency in large state spaces with dominance. We illustrate the efficiency of DD* Lite with simulation results from applying the algorithm to a path planning problem with time and energy constraints. We also prove that DD* Lite is sound, complete, optimal, and efficient.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-162.pdf,Subjects: 15.7 Search; 1.11 Planning
169,2006,Search and Game Playing,Sequential and Parallel Algorithms for Frontier A* with Delayed Duplicate Detection,"Robert Niewiadomski, Jose Nelson Amaral, Robert C. Holte","We present sequential and parallel algorithms for Frontier A* (FA*) algorithm augmented with a form of Delayed Duplicate Detection (DDD). The sequential algorithm, FA*-DDD, overcomes the leak-back problem associated with the combination of FA* and DDD. The parallel algorithm, PFA*-DDD, is a parallel version of FA*-DDD that features a novel workload distribution strategy based on intervals. We outline an implementation of PFA*-DDD designed to run on a cluster of workstations. The implementation computes intervals at runtime that are tailored to fit the workload at hand. Because the implementation distributes the workload in a manner that is both automated and adaptive, it does not require the user to specify a workload mapping function, and, more importantly, it is applicable to arbitrary problems that may be irregular. We present the results of an experimental evaluation of the implementation where it is used to solve instances of the multiple sequence alignment problem on a cluster of workstations running on top of a commodity network. Results demonstrate that the implementation offers improved capability in addition to improved performance.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-163.pdf,Subjects: 15.7 Search
170,2006,Search and Game Playing,Overconfidence or Paranoia? Search in Imperfect-Information Games,"Austin Parker, Dana Nau, VS Subrahmanian","We derive a recursive formula for expected utility values in imperfect-information game trees, and an imperfect-information game tree search algorithm based on it. The formula and algorithm are general enough to incorporate a wide variety of opponent models. We analyze two opponent models. The ""paranoid"" model is an information-set analog of the minimax rule used in perfect-information games. The ""overconfident"" model assumes the opponent moves randomly. Our experimental tests in the game of kriegspiel chess (an imperfect-information variant of chess) produced surprising results: (1) against each other, and against one of the kriegspiel algorithms presented at IJCAI-05, the overconfident model usually outperformed the paranoid model; (2) the performance of both models depended greatly on how well the model corresponded to the opponent's behavior. These results suggest that the usual assumption of perfect-information game tree search—that the opponent will choose the best possible move—isn't as useful in imperfect-information games.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-164.pdf,Subjects: 1.8 Game Playing
171,2006,Search and Game Playing,Disco—Novo—GoGo: Integrating Local Search and Complete Search with Restarts,Meinolf Sellmann and Carlos Ansótegui,"A hybrid algorithm is devised to boost the performance of complete search on under-constrained problems. We suggest to use random variable selection in combination with restarts, augmented by a coarse-grained local search algorithm that learns favorable value heuristics over the course of several restarts. Numerical results show that this method can speed-up complete search by orders of magnitude.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-165.pdf,
172,2006,Search and Game Playing,Prob-Maxn : Playing N-Player Games with Opponent Models,"Nathan R. Sturtevant, Martin Zinkevich, Michael Bowling","Much of the work on opponent modeling for game tree search has been unsuccessful. In two-player, zero-sum games, the gains from opponent modeling are often outweighed by the cost of modeling. Opponent modeling solutions simply cannot search as deep as the highly optimized minimax search with alpha-beta pruning. Recent work has begun to look at the need for opponent modeling in n-player or general-sum games. We introduce a probabilistic approach to opponent modeling in n-player games called probmaxn, which can robustly adapt to unknown opponents. We implement probmaxn in the game of Spades, showing that probmaxn is highly effective in practice, beating out the maxn and softmaxn algorithms when faced with unknown opponents.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-166.pdf,Subjects: 1.8 Game Playing; 15.7 Search
173,2006,Search and Game Playing,An Efficient Algorithm for Scatter Chart Labeling,"Sebastian Theophil, Arno Schödl","This paper presents an efficient algorithm for a new variation of the point feature labeling problem. The goal is to position the largest number of point labels such that they do not intersect each other or their points. First we present an algorithm using a greedy algorithm with limited lookahead. We then present an algorithm that iteratively regroups labels, calling the first algorithm on each group, thereby identifying a close to optimal labeling order. The presented algorithm is being used in a commercial product to label charts, and our evaluation shows that it produces results far superior to those of other labeling algorithms.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-167.pdf,Subjects: 15.7 Search; 15.2 Constraint Satisfaction
174,2006,Search and Game Playing,Monte Carlo Go Has a Way to Go,"Haruhiro Yoshimoto, Kazuki Yoshizoe, Tomoyuki Kaneko, Akihiro Kishimoto, Kenjiro Taura","Monte Carlo Go is a promising method to improve the performance of computer Go programs. This approach determines the next move to play based on many Monte Carlo samples. This paper examines the relative advantages of additional samples and enhancements for Monte Carlo Go. By parallelizing Monte Carlo Go, we could increase sample sizes by two orders of magnitude. Experimental results obtained in 9 x 9 Go show strong evidence that there are trade-offs among these advantages and performance, indicating a way for Monte Carlo Go to go.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-168.pdf,Subjects: 15.7 Search
175,2006,Search and Game Playing,Dual Search in Permutation State Spaces,"Uzi Zahavi, Ariel Felner, Robert Holte, and Jonathan Schaeffer","Geometrical symmetries are commonly exploited to improve the efficiency of search algorithms. We introduce a new logical symmetry in permutation state spaces which we call duality. We show that each state has a dual state. Both states share important attributes and these properties can be used to improve search efficiency. We also present a new search algorithm, dual search, which switches between the original state and the dual state when it seems likely that the switch will improve the chances of a cutoff. The decision of when to switch is very important and several policies for doing this are investigated. Experimental results show significant improvements for a number of applications.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-169.pdf,
176,2006,Search and Game Playing,Domain-Independent Structured Duplicate Detection,"Rong Zhou, Eric A. Hansen","The scalability of graph-search algorithms can be greatly extended by using external memory, such as disk, to store generated nodes. We consider structured duplicate detection, an approach to external-memory graph search that limits the number of slow disk I/O operations needed to access search nodes stored on disk by using an abstract representation of the graph to localize memory references. For graphs with sufficient locality, structured duplicate detection outperforms other approaches to external-memory graph search. We develop an automatic method for creating an abstract representation that reveals the local structure of a graph. We then integrate this approach into a domain-independent STRIPS planner and show that it dramatically improves scalability for a wide range of planning problems. The success of this approach strongly suggests that similar local structure can be found in many other graph-search problems.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-170.pdf,Subjects: 15.7 Search; 1.11 Planning
177,2006,Uncertainty in AI,An Iterative Algorithm for Solving Constrained Decentralized Markov Decision Processes,"Aurelie Beynier, Abdel-Illah Mouaddib","Despite the significant progress to extend Markov Decision Processes (MDP) to cooperative multi-agent systems, developing approaches that can deal with realistic problems remains a serious challenge. Existing approaches that solve Decentralized Markov Decision Processes (DEC-MDPs) suffer from the fact that they can only solve relatively small problems without complex constraints on task execution. OC-DEC-MDP has been introduced to deal with large DEC-MDPs under resource and temporal constraints. However, the proposed algorithm to solve this class of DEC-MDPs has some limits: it suffers from overestimation of opportunity cost and restricts policy improvement to one sweep (or iteration). In this paper, we propose to overcome these limits by first introducing the notion of Expected Opportunity Cost to better assess the influence of a local decision of an agent on the others. We then describe an iterative version of the algorithm to incrementally improve the policies of agents leading to higher quality solutions in some settings. Experimental results are shown to support our claims.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-171.pdf,Subjects: 7.1 Multi-Agent Systems; 15.5 Decision Theory
178,2006,Uncertainty in AI,An Anytime Scheme for Bounding Posterior Beliefs,"Bozhena Bidyuk, Rina Dechter","This paper presents an any-time scheme for computing lower and upper bounds on posterior marginals in Bayesian networks. The scheme draws from two previously proposed methods, bounded conditioning and bound propagation. Following the principles of cutset conditioning, our method enumerates a subset of cutset tuples and applies exact reasoning in the network instances conditioned on those tuples. The probability mass of the remaining tuples is bounded using a variant of bound propagation. We show that our new scheme improves on the earlier schemes.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-172.pdf,Subjects: 3. Automated Reasoning; 3.4 Probabilistic Reasoning
179,2006,Uncertainty in AI,Preferences over Sets,"Ronen I. Brafman, Carmel Domshlak, Solomon E. Shimony, Yael Silver","Research on preference elicitation and reasoning typically focuses on preferences over single objects of interest. However, in a number of applications the ""outcomes"" of interest are sets of such atomic objects. For instance, when creating the program for a film festival, editing a newspaper, or putting together a team, we need to select a set of films (resp. articles, members) that is optimal with respect to quality, diversity, cohesiveness, etc. This paper describes an intuitive approach for specifying preferences over sets of objects. An algorithm for computing an optimal subset, given a set of candidate objects and a preference specification, is developed and evaluated.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-173.pdf,Subjects: 3. Automated Reasoning; 15.2 Constraint Satisfaction
180,2006,Uncertainty in AI,An Edge Deletion Semantics for Belief Propagation and its Practical Impact on Approximation Quality,"Arthur Choi, Adnan Darwiche","We show in this paper that the influential algorithm of iterative belief propagation can be understood in terms of exact inference on a polytree, which results from deleting enough edges from the original network. We show that deleting edges implies adding new parameters into a network, and that the iterations of belief propagation are searching for values of these new parameters which satisfy intuitive conditions that we characterize. The new semantics lead to the following question: Can one improve the quality of approximations computed by belief propagation by recovering some of the deleted edges, while keeping the network easy enough for exact inference? We show in this paper that the answer is yes, leading to another question: How do we choose which edges to recover? To answer, we propose a specific method based on mutual information which is motivated by the edge deletion semantics. Empirically, we provide experimental results showing that the quality of approximations can be improved without incurring much additional computational cost. We also show that recovering certain edges with low mutual information may not be worthwhile as they increase the computational complexity, without necessarily improving the quality of approximations.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-174.pdf,Subjects: 3.4 Probabilistic Reasoning
181,2006,Uncertainty in AI,When Gossip is Good: Distributed Probabilistic Inference for Detection of Slow Network Intrusions,"Denver Dash, Branislav Kveton, John Mark Agosta, Eve Schooler, Jaideep Chandrashekar, Abraham Bachrach, Alex Newman","Intrusion attempts due to self-propagating code are becoming an increasingly urgent problem, in part due to the homogeneous makeup of the internet. Recent advances in anomalybased intrusion detection systems (IDSs) have made use of the quickly spreading nature of these attacks to identify them with high sensitivity and at low false positive (FP) rates. However, slowly propagating attacks are much more difficult to detect because they are cloaked under the veil of normal network traffic, yet can be just as dangerous due to their exponential spread pattern. We extend the idea of using collaborative IDSs to corroborate the likelihood of attack by imbuing end hosts with probabilistic graphical models and using random messaging to gossip state among peer detectors. We show that such a system is able to boost a weak anomaly detector D to detect an order-of-magnitude slower worm, at false positive rates less than a few per week, than would be possible using D alone at the end-host or on a network aggregation point. We show that this general architecture is scalable in the sense that a fixed absolute false positive rate can be achieved as the network size grows, spreads communication bandwidth uniformly throughout the network, and makes use of the increased computation power of a distributed system. We argue that using probabilistic models provides more robust detections than previous collaborative counting schemes and allows the system to account for heterogeneous detectors in a principled fashion.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-175.pdf,Subjects: 3.4 Probabilistic Reasoning; 1. Applications
182,2006,Uncertainty in AI,MPE and Partial Inversion in Lifted Probabilistic Variable Elimination,"Rodrigo de Salvo Braz, Eyal Amir, Dan Roth","It is often convenient to represent probabilistic models in a first-order fashion, using logical atoms such as $partners(X,Y)$ as random variables parameterized by logical variables. de Salvo Braz, Amir and Roth, following(Poole, give a lifted variable elimination algorithm (FOVE) for computing marginal probabilities from first-order probabilistic models (belief assessment, or BA). FOVE is lifted because it works directly at the first-order level, eliminating all the instantiations of a set of atoms in a single step, in some cases independently of the number of these instantiations. Previous work could treat only restricted potential functions. There, atoms' instantiations cannot constrain each other: predicates can appear at most once, or logical variables must not interact across atoms. In this paper, we present two contributions. The first one is a significantly more general lifted variable elimination algorithm, FOVE-P, that covers many cases where atoms share logical variables. The second contribution is to use FOVE-P for solving the Most Probable Explanation (MPE) problem, which consists of calculating the most probable assignment of the random variables in a model. The transition from BA to MPE is straightforward in propositional models, but the lifted first-order case is harder. We introduce the notion of lifted assignments, a distribution of values to a set of random variables rather than to each individual one. Lifted assignments are cheaper to compute while being as useful as regular assignments over that group. Both contributions advance the theoretical understanding of lifted probabilistic inference.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-176.pdf,Subjects: 3.4 Probabilistic Reasoning
183,2006,Uncertainty in AI,On the Difficulty of Achieving Equilibrium in Interactive POMDPs,"Prashant Doshi, Piotr Gmytrasiewicz","We analyze the asymptotic behavior of agents engaged in an infinite horizon partially observable stochastic game as formalized by the interactive POMDP framework. We show that when agents' initial beliefs satisfy a truth compatibility condition, their behavior converges to a subjective epsilon-equilibrium in a finite time, and subjective equilibrium in the limit. This result is a generalization of a similar result in repeated games, to partially observable stochastic games. However, it turns out that the equilibrating process is difficult to demonstrate computationally because of the difficulty in coming up with initial beliefs that are both natural and satisfy the truth compatibility condition. Our results, therefore, shed some negative light on using equilibria as a solution concept for decision making in partially observable stochastic games.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-177.pdf,Subjects: 7.1 Multi-Agent Systems; 9.3 Mathematical Foundations
184,2006,Uncertainty in AI,CUI Networks: A Graphical Representation for Conditional Utility Independence,"Yagil Engel, Michael P. Wellman","We introduce CUI networks, a compact graphical representation of utility functions over multiple attributes. CUI networks model multiattribute utility functions using the well studied and widely applicable utility independence concept. We show how conditional utility independence leads to an effective functional decomposition that can be exhibited graphically, and how local, compact data at the graph nodes can be used to calculate joint utility. We discuss aspects of elicitation and network construction, and contrast our new representation with previous graphical preference modeling.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-178.pdf,Subjects: 15.5 Decision Theory
185,2006,Uncertainty in AI,Solving MAP Exactly by Searching on Compiled Arithmetic Circuits,"Jinbo Huang, Mark Chavira, and Adnan Darwiche","The MAP (maximum a posteriori hypothesis) problem in Bayesian networks is to find the most likely states of a set of variables given partial evidence on the complement of that set. Standard structure-based inference methods for finding exact solutions to MAP, such as variable elimination and jointree algorithms, have complexities that are exponential in the constrained treewidth of the network. A more recent algorithm, proposed by Park and Darwiche, is exponential only in the treewidth and has been shown to handle networks whose constrained treewidth is quite high. In this paper we present a new algorithm for exact MAP that is not necessarily limited in scalability even by the treewidth. This is achieved by leveraging recent advances in compilation of Bayesian networks into arithmetic circuits, which can circumvent treewidth-imposed limits by exploiting the local structure present in the network. Specifically, we implement a branch-and-bound search where the bounds are computed using linear-time operations on the compiled arithmetic circuit. On networks with local structure, we observe orders-of-magnitude improvements over the algorithm of Park and Darwiche. In particular, we are able to efficiently solve many problems where the latter algorithm runs out of memory because of high treewidth.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-179.pdf,
186,2006,Uncertainty in AI,Identifiability in Causal Bayesian Networks: A Sound and Complete Algorithm,"Yimin Huang, Marco Valtorta","This paper addresses the problem of identifying causal effects from nonexperimental data in a causal Bayesian network, i.e., a directed acyclic graph that represents causal relationships. The identifiability question asks whether it is possible to compute the probability of some set of (effect) variables given intervention on another set of (intervention) variables, in the presence of non-observable (i.e., hidden or latent) variables. It is well known that the answer to the question depends on the structure of the causal Bayesian network, the set of observable variables, the set of effect variables, and the set of intervention variables. Our work is based on the work of Tian, Pearl, Huang, and Valtorta (Tian and Pearl 2002a; 2002b; 2003; Huang and Valtorta 2006a) and extends it. We show that the identify algorithm that Tian and Pearl define and prove sound for semi-Markovian models can be transfered to general causal graphs and is not only sound, but also complete. This result effectively solves the identifiability question for causal Bayesian networks that Pearl posed in 1995 (Pearl 1995), by providing a sound and complete algorithm for identifiability.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-180.pdf,
187,2006,Uncertainty in AI,A Bayesian Network for Outbreak Detection and Prediction,"Xia Jiang, Garrick Wallstrom","Health care officials are increasingly concerned with knowing early whether an outbreak of a particular disease is unfolding. We often have daily counts of some variable that are indicative of the number of individuals in a given community becoming sick each day with a particular disease. By monitoring these daily counts we can possibly detect an outbreak in an early stage. A number of classical time-series methods have been applied to outbreak detection based on monitoring daily counts of some variables. These classical methods only give us an alert as to whether there may be an outbreak. They do not predict properties of the outbreak such as its size, duration, and how far we are into the outbreak. Knowing the probable values of these variables can help guide us to a cost-effective decision that maximizes expected utility. Bayesian networks have become one of the most prominent architectures for reasoning under uncertainty in artificial intelligence. We present an intelligent system, implemented using a Bayesian network, which not only detects an outbreak, but predicts its size and duration, and estimates how far we are into the outbreak. We show results of investigating the performance of the system using simulated outbreaks based on real outbreak data. These results indicate that the system shows promise of being able to predict properties of an outbreak.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-181.pdf,Subjects: 1.7 Expert Systems; 3.4 Probabilistic Reasoning
188,2006,Uncertainty in AI,Learning Basis Functions in Hybrid Domains,"Branislav Kveton, Milos Hauskrecht","Markov decision processes (MDPs) with discrete and continuous state and action components can be solved efficiently by hybrid approximate linear programming (HALP). The main idea of the approach is to approximate the optimal value function by a set of basis functions and optimize their weights by linear programming. The quality of this approximation naturally depends on its basis functions. However, basis functions leading to good approximations are rarely known in advance. In this paper, we propose a new approach that discovers these functions automatically. The method relies on a class of parametric basis function models, which are optimized using the dual formulation of a relaxed HALP. We demonstrate the performance of our method on two hybrid optimization problems and compare it to manually selected basis functions.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-182.pdf,Subjects: 15.5 Decision Theory; 12.1 Reinforcement Learning
189,2006,Uncertainty in AI,Incremental Least Squares Policy Iteration for POMDPs,"Hui Li, Xuejun Liao, Lawrence Carin","We present a new algorithm, called incremental least squares policy iteration (ILSPI), for finding the infinite-horizon stationary policy for partially observable Markov decision processes (POMDPs). The ILSPI algorithm computes a basis representation of the infinite-horizon value function by minimizing the square of Bellman residual and performs policy improvement in reachable belief states. A number of optimal basis functions are determined by the algorithm to minimize the Bellman residual incrementally, via efficient computations. We show that, by using optimally determined basis functions, the policy can be improved successively on a set of most probable belief points sampled from the reachable belief set. As the ILSPI is based on belief sample points, it represents a point-based policy iteration method. The results on four benchmark problems show that the ILSPI compares competitively to its value-iteration counterparts in terms of both performance and computational efficiency.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-183.pdf,Subjects: 1.11 Planning; 12.1 Reinforcement Learning
190,2006,Uncertainty in AI,Performing Incremental Bayesian Inference by Dynamic Model Counting,"Wei Li, Peter van Beek, and Pascal Poupart","The ability to update the structure of a Bayesian network when new data becomes available is crucial for building adaptive systems. Recent work by Sang, Beame, and Kautz (AAAI 2005) demonstrates that the well-known Davis-Putnam procedure combined with a dynamic decomposition and caching technique is an effective method for exact inference in Bayesian networks with high density and width. In this paper, we define dynamic model counting and extend the dynamic decomposition and caching technique to multiple runs on a series of problems with similar structure. This allows us to perform Bayesian inference incrementally as the structure of the network changes. Experimental results show that our approach yields significant improvements over the previous model counting approaches on multiple challenging Bayesian network instances.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-184.pdf,
191,2006,Uncertainty in AI,Efficient Active Fusion for Decision-making via VOI Approximation,"Wenhui Liao, Qiang Ji","Active fusion is a process that purposively selects the most informative information from multiple sources as well as combines these information for achieving a reliable result efficiently. This paper presents a general mathematical framework based on Influence Diagrams (IDs) for active fusion and timely decision making. Within this framework, an approximation algorithm is proposed to efficiently compute non-myopic value-of-information (VOI) for multiple sensory actions. Meanwhile a sensor selection algorithm is proposed to choose optimal sensory action sets efficiently. Both the experiments with synthetic data and real data from a real-world application demonstrate that the proposed framework together with the algorithms are well suited to applications where the decision must be made efficiently and timely from dynamically available information of diverse and disparate sources.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-185.pdf,Subjects: 15.5 Decision Theory; 1.12 Scheduling
192,2006,Uncertainty in AI,Functional Value Iteration for Decision-Theoretic Planning with General Utility Functions,"Yaxin Liu, Sven Koenig","We study how to find plans that maximize the expected total utility for a given MDP, a planning objective that is important for decision making in high-stakes domains. The optimal actions can now depend on the total reward that has been accumulated so far in addition to the current state. We extend our previous work on functional value iteration from one-switch utility functions to all utility functions that can be approximated with piecewise linear utility functions (with and without exponential tails) by using functional value iteration to find a plan that maximizes the expected total utility for the approximate utility function. Functional value iteration does not maintain a value for every state but a value function that maps the total reward that has been accumulated so far into a value. We describe how functional value iteration represents these value functions in finite form, how it performs dynamic programming by manipulating these representations and what kinds of approximation guarantees it is able to make. We also apply it to a probabilistic blocksworld problem, a standard test domain for decision-theoretic planners.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-186.pdf,Subjects: 1.11 Planning; 15.5 Decision Theory
193,2006,Uncertainty in AI,Learning Representation and Control In Continuous Markov Decision Processes,"Sridhar Mahadevan, Mauro Maggioni, Kimberly Ferguson, Sarah Osentoski","This paper presents a novel framework for simultaneously learning representation and control in continuous Markov decision processes. Our approach builds on the framework of proto-value functions, in which the underlying representation or basis functions are automatically derived from a spectral analysis of the state space manifold. The proto-value functions correspond to the eigenfunctions of the graph Laplacian. We describe an approach to extend the eigenfunctions to novel states using the Nystrom extension. A least-squares policy iteration method is used to learn the control policy, where the underlying subspace for approximating the value function is spanned by the learned proto-value functions. A detailed set of experiments is presented using classic benchmark tasks, including the inverted pendulum and the mountain car, measuring the sensitivity to various parameters, and including comparisons with a handcoded parametric radial basis function approximator.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-187.pdf,Subjects: 12.1 Reinforcement Learning; 12. Machine Learning and Discovery
194,2006,Uncertainty in AI,Memory Intensive Branch-and-Bound Search for Graphical Models,"Radu Marinescu, Rina Dechter","AND/OR search spaces have recently been introduced as a unifying paradigm for advanced algorithmic schemes for graphical models. The main virtue of this representation is its sensitivity to the structure of the model, which can translate into exponential time savings for search algorithms. AND/OR Branch-and-Bound (AOBB) is a new algorithm that explores the AND/OR search tree for solving optimization tasks in graphical models. In this paper we extend the algorithm to explore an AND/OR search graph by equipping it with a context-based adaptive caching scheme similar to good and no-good recording. The efficiency of the new graph search algorithm is demonstrated empirically on various benchmarks, including the very challenging ones that arise in genetic linkage analysis.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-188.pdf,Subjects: 15. Problem Solving; 15.7 Search
195,2006,Uncertainty in AI,"Bayesian Reputation Modeling in E-Marketplaces Sensitive to Subjectivity, Deception and Change","Kevin Regan, Pascal Poupart, and Robin Cohen","We present a model for buying agents in e-marketplaces to interpret evaluations of sellers provided by other buying agents, known as advisors. The interpretation of seller evaluations is complicated by the inherent subjectivity of each advisor, the possibility that advisors may deliberately provide misleading evaluations to deceive competitors and the dynamic nature of seller and advisor behaviours that may naturally change seller evaluations over time. Using a Bayesian approach, we demonstrate how to cope with subjectivity, deception and change in a principled way. More specifically, by modeling seller properties and advisor evaluation functions as dynamic random variables, buyers can progressively learn a probabilistic model that naturally and “correctly” calibrates the interpretation of seller evaluations without having to resort to heuristics to explicitely detect and filter/discount unreliable seller evaluations. Our model, called BLADE, is shown empirically to achieve lower mean error in the estimation of seller properties when compared to other models for reasoning about advisor ratings of sellers in electronic maketplaces.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-189.pdf,
196,2006,Uncertainty in AI,Targeting Specific Distributions of Trajectories in MDPs,"David L. Roberts, Mark J. Nelson, Charles L. Isbell, Jr., Michael Mateas, Michael L. Littman","We define TTD-MDPs, a novel class of Markov decision processes where the traditional goal of an agent is changed from finding an optimal trajectory through a state space to realizing a specified distribution of trajectories through the space. After motivating this formulation, we show how to convert a traditional MDP into a TTD-MDP. We derive an algorithm for finding non-deterministic policies by constructing a trajectory tree that allows us to compute locally-consistent policies. We specify the necessary conditions for solving the problem exactly and present a heuristic algorithm for constructing policies when an exact answer is impossible or impractical. We present empirical results for our algorithm in two domains: a synthetic grid world and stories in an interactive drama or game.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-190.pdf,Subjects: 12. Machine Learning and Discovery
197,2006,Uncertainty in AI,Identification of Joint Interventional Distributions in Recursive Semi-Markovian Causal Models,"Ilya Shpitser, Judea Pearl","This paper is concerned with estimating the effects of actions from causal assumptions, represented concisely as a directed graph, and statistical knowledge, given as a probability distribution. We provide a necessary and sufficient graphical condition for the cases when the causal effect of an arbitrary set of variables on another arbitrary set can be determined uniquely from the available information, as well as an algorithm which computes the effect whenever this condition holds. Furthermore, we use our results to prove completeness of do-calculus [Pearl, 1995], and a version of an identification algorithm in [Tian, 2002] for the same identification problem. Finally, we derive a complete characterization of semi-Markovian models in which all causal effects are identifiable.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-191.pdf,Subjects: 9.1 Causality; 3.4 Probabilistic Reasoning
198,2006,Uncertainty in AI,Focused Real-Time Dynamic Programming for MDPs: Squeezing More Out of a Heuristic,"Trey Smith, Reid Simmons","Real-time dynamic programming (RTDP) is a heuristic search algorithm for solving MDPs. We present a modified algorithm called Focused RTDP with several improvements. While RTDP maintains only an upper bound on the long-term reward function, FRTDP maintains two-sided bounds and bases the output policy on the lower bound. FRTDP guides search with a new rule for outcome selection, focusing on parts of the search graph that contribute most to uncertainty about the values of good policies. FRTDP has modified trial termination criteria that should allow it to solve some problems (within ε) that RTDP cannot. Experiments show that for all the problems we studied, FRTDP significantly outperforms RTDP and LRTDP, and converges with up to six times fewer backups than the state-of-the-art HDP algorithm.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-192.pdf,Subjects: 12.1 Reinforcement Learning; 15.7 Search
199,2006,Uncertainty in AI,Point-based Dynamic Programming for DEC-POMDPs,"Daniel Szer, Francois Charpillet","We introduce point-based dynamic programming (DP) for decentralized partially observable Markov decision processes (DEC-POMDPs), a new discrete DP algorithm for planning strategies for cooperative multi-agent systems. Our approach makes a connection between optimal DP algorithms for partially observable stochastic games, and point-based approximations for single-agent POMDPs. We show for the first time how relevant multi-agent belief states can be computed. Building on this insight, we then show how the linear programming part in current multi-agent DP algorithms can be avoided, and how multi-agent DP can thus be applied to solve larger problems. We derive both an optimal and an approximated version of our algorithm, and we show its efficiency on test examples from the literature.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-193.pdf,Subjects: 7.1 Multi-Agent Systems; 15.4 Reactive Control
200,2006,Uncertainty in AI,A Characterization of Interventional Distributions in Semi-Markovian Causal Models,"Jin Tian, Changsung Kang, Judea Pearl","We offer a complete characterization of the set of distributions that could be induced by local interventions on variables governed by a causal Bayesian network of unknown structure, in which some of the variables remain unmeasured. We show that such distributions are constrained by a simply formulated set of inequalities, from which bounds can be derived on causal effects that are not directly measured in randomized experiments.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-194.pdf,Subjects: 9.1 Causality; 3.4 Probabilistic Reasoning
201,2006,Uncertainty in AI,"Compact, Convex Upper Bound Iteration for Approximate POMDP Planning","Tao Wang, Pascal Poupart, Michael Bowling, Dale Schuurmans","Partially observable Markov decision processes (POMDPs) are an intuitive and general way to model sequential decision making problems under uncertainty. Unfortunately, even approximate planning in POMDPs is known to be hard, and developing heuristic planners that can deliver reasonable results in practice has proved to be a significant challenge. In this paper, we present a new approach to approximate value-iteration for POMDP planning that is based on quadratic rather than piecewise linear function approximators. Specifically, we approximate the optimal value function by a convex upper bound composed of a fixed number of quadratics, and optimize it at each stage by semidefinite programming. We demonstrate that our approach can achieve competitive approximation quality to current techniques while still maintaining a bounded size representation of the function approximator. Moreover, an upper bound on the optimal value function can be preserved if required. Overall, the technique requires computation time and space that is only linear in the number of iterations (horizon time).",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-195.pdf,Subjects: 12.1 Reinforcement Learning; 1.11 Planning
202,2006,Special Track on Artificial Intelligence and the Web,A Platform to Evaluate the Technology for Service Discovery in the Semantic Web,"Cecile Aberg, Johan Aberg, Patrick Lambrix, Nahid Shahmehri","Since the description of the Semantic Web paradigm in 2001, technology has been proposed to allow its deployment and use. However, there is not yet any large and widely deployed set of semantically annotated Web resources available. As a result, it is not possible to evaluate the use of the technology in a real environment, and several assumptions about how the Semantic Web should work are emerging. In order to further investigate these assumptions and the related technology, we propose a simulation and evaluation platform. The platform provides tools to create Semantic Web simulations using different technologies for different purposes, and to evaluate their performance. In this paper we introduce the model of the platform and describe the current implementation. The implementation facilitates the integration of technology for an essential operation on the Semantic Web, namely Semantic Web service discovery. We illustrate the use of the platform in a case study by implementing a Semantic Web where the Jade multi-agent platform provides the framework to describe the agents, and a number of existing Semantic Web technologies are embedded in agent behavior.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-196.pdf,Subjects: 1.4 Design; 7.1 Multi-Agent Systems
203,2006,Special Track on Artificial Intelligence and the Web,Using Semantics to Identify Web Objects,"Nathanael Chambers, James Allen, Lucian Galescu, Hyuckchul Jung, William Taysom","Many common web tasks can be automated by algorithms that are able to identify web objects relevant to the user's needs. This paper presents a novel approach to web object identification that finds relationships between the user's actions and linguistic information associated with web objects. From a single training example involving demonstration and a natural language description, we create a parameterized object description. The approach performs as well as a popular web wrapper on a routine task, but it has the additional capability of performing in dynamic environments and the attractive property of being reusable in other domains without additional training.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-197.pdf,Subjects: 1.10 Information Retrieval; 13. Natural Language Processing
204,2006,Special Track on Artificial Intelligence and the Web,Comparative Experiments on Sentiment Classification for Online Product Reviews,"Hang Cui, Vibhu Mittal, Mayur Datar","Evaluating text fragments for positive and negative subjective expressions and their strength can be important in applications such as single- or multi- document summarization, document ranking, data mining, etc. This paper looks at a simplified version of the problem: classifying online product reviews into positive and negative classes. We discuss a series of experiments with different machine learning algorithms in order to experimentally evaluate various trade-offs, using approximately 100K product reviews from the web.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-198.pdf,Subjects: 12. Machine Learning and Discovery; 13. Natural Language Processing
205,2006,Special Track on Artificial Intelligence and the Web,On the Update of Description Logic Ontologies at the Instance Level,"Giuseppe De Giacomo, Maurizio Lenzerini, Antonella Poggi, Riccardo Rosati","We study the notion of update of an ontology expressed as a Description Logic knowledge base. Such a knowledge base is constituted by two components, called TBox and ABox. The former expresses general knowledge about the concepts and their relationships, whereas the latter describes the state of affairs regarding the instances of concepts. We investigate the case where the update affects only the instance level of the ontology, i.e., the ABox. Building on classical approaches on knowledge base update, our first contribution is to provide a general semantics for instance level update in Description Logics. We then focus on DL-Lite, a specific Description Logic where the basic reasoning tasks are computationally tractable. We show that DL-Lite is closed with respect to instance level update, in the sense that the result of an update is always expressible as a new DL-Lite ABox. Finally we provide an algorithm that computes the result of an update in DL-Lite, and we show that it runs in polynomial time with respect to the size of both the original knowledge base and the update formula.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-199.pdf,Subjects: 11.1 Description Logics; 11.2 Ontologies
206,2006,Special Track on Artificial Intelligence and the Web,Inexact Matching of Ontology Graphs Using Expectation-Maximization,"Prashant Doshi, Christopher Thomas","We present a new method for mapping ontology schemas that address similar domains. The problem of ontology mapping is crucial since we are witnessing a decentralized development and publication of ontological data. We formulate the problem of inferring a match between two ontologies as a maximum likelihood problem, and solve it using the technique of expectation-maximization (EM). Specifically, we adopt directed graphs as our model for ontologies and use a generalized version of EM to arrive at a mapping between the nodes of the graphs. We exploit the structural and lexical similarity between the graphs, and improve on previous approaches by generating a many-one correspondence between the concept nodes. We provide preliminary experimental results in support of our method and outline its limitations.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-200.pdf,Subjects: 11.2 Ontologies
207,2006,Special Track on Artificial Intelligence and the Web,Mining and Re-ranking for Answering Biographical Queries on the Web,"Donghui Feng, Deepak Ravichandran, Eduard Hovy","The rapid growth of the Web has made itself a huge and valuable knowledge base. Among them, biographical information is of great interest to society. However, there has not been an efficient and complete approach to automated biography creation by querying the web. This paper describes an automatic web-based question answering system for biographical queries. Ad-hoc improvements on pattern learning approaches are proposed for mining biographical knowledge. Using bootstrapping, our approach learns surface text patterns from the web, and applies the learned patterns to extract relevant information. To reduce human labeling cost, we propose a new IDF-inspired re-ranking approach and compare it with pattern’s precision-based re-ranking approach. A comparative study of the two re-ranking models is conducted. The tested system produces promising results for answering biographical queries.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-201.pdf,Subjects: 13. Natural Language Processing; 10. Knowledge Acquisition
208,2006,Special Track on Artificial Intelligence and the Web,Towards Modeling Threaded Discussions using Induced Ontology Knowledge,"Donghui Feng, Jihie Kim, Erin Shaw, Eduard Hovy","Online discussion boards are a popular form of web-based computer-mediated communication, especially in the areas of distributed education and customer support. Automatic analysis for discussion understanding would enable better information assessment and assistance. This paper describes an extensive study of the relationship between individual messages and full discussion threads. We present a new approach to classifying discussions using a Rocchio-style classifier with little cost for data labeling. In place of a labeled data set, we employ a coarse domain ontology that is automatically induced from a canonical text in a novel way and use it to build discussion topic profiles. We describe a new classify-by-dominance strategy for classifying discussion threads and demonstrate that in the presence of noise it can perform better than the standard classify-as-a-whole approach with an error rate reduction of 16.8%. This analysis of human conversation via online discussions provides a basis for the development of future information extraction and question answering techniques.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-202.pdf,Subjects: 13. Natural Language Processing; 1.10 Information Retrieval
209,2006,Special Track on Artificial Intelligence and the Web,"Inconsistencies, Negations and Changes in Ontologies","Giorgos Flouris, Zhisheng Huang, Jeff Z. Pan, Dimitris Plexousakis, Holger Wachek","Ontology management and maintenance are considered cornerstone issues in current Semantic Web applications in which semantic integration and ontological reasoning play a fundamental role. The ability to deal with inconsistency and to accommodate change is of utmost importance in realworld applications of ontological reasoning and management, wherein the need for expressing negated assertions also arises naturally. For this purpose, precise, formal definitions of the the different types of inconsistency and negation in ontologies are required. Unfortunately, ontology languages based on Description Logics (DLs) do not provide enough expressive power to represent axiom negations. Furthermore, there is no single, well-accepted notion of inconsistency and negation in the Semantic Web community, due to the lack of a common and solid foundational framework. In this paper, we propose a general framework accounting for inconsistency, negation and change in ontologies. Different levels of negation and inconsistency in DL-based ontologies are distinguished. We demonstrate how this framework can provide a foundation for reasoning with and management of dynamic ontologies..",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-203.pdf,Subjects: 12. Machine Learning and Discovery
210,2006,Special Track on Artificial Intelligence and the Web,Overcoming the Brittleness Bottleneck using Wikipedia: Enhancing Text Categorization with Encyclopedic Knowledge,"Evgeniy Gabrilovich, Shaul Markovitch","When humans approach the task of text categorization, they interpret the specific wording of the document in the much larger context of their background knowledge and experience. On the other hand, state-of-the-art information retrieval systems are quite brittle - they traditionally represent documents as bags of words, and are restricted to learning from individual word occurrences in the (necessarily limited) training set. For instance, given the sentence ""Wal-Mart supply chain goes real time"", how can a text categorization system know that Wal-Mart manages its stock with RFID technology? And having read that ""Ciprofloxacin belongs to the quinolones group"", how on earth can a machine know that the drug mentioned is an antibiotic produced by Bayer? In this paper we present algorithms that can do just that. We propose to enrich document representation through automatic use of a vast compendium of human knowledge - an encyclopedia. We apply machine learning techniques to Wikipedia, the largest encyclopedia to date, which surpasses in scope many conventional encyclopedias and provides a cornucopia of world knowledge. Each Wikipedia article represents a concept, and documents to be categorized are represented in the rich feature space of words and relevant Wikipedia concepts. Empirical results confirm that this knowledge-intensive representation brings text categorization to a qualitatively new level of performance across a diverse collection of datasets.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-204.pdf,Subjects: 1.10 Information Retrieval; 12. Machine Learning and Discovery
211,2006,Special Track on Artificial Intelligence and the Web,Mixed Collaborative and Content-Based Filtering with User-Contributed Semantic Features,"Matthew Garden, Gregory Dudek","We describe a recommender system which uses a unique combination of content-based and collaborative methods to suggest items of interest to users, and also to learn and exploit item semantics. Recommender systems typically use techniques from collaborative filtering, in which proximity measures between users are formulated to generate recommendations, or content-based filtering, in which users are compared directly to items. Our approach uses similarity measures between users, but also directly measures the attributes of items that make them appealing to specific users. This can be used to directly make recommendations to users, but equally importantly it allows these recommendations to be justified. We introduce a method for predicting the preference of a user for a movie by estimating the user's attitude toward features with which other users have described that movie. We show that this method allows for accurate recommendations for a sub-population of users, but not for the entire user population. We describe a hybrid approach in which a user-specific recommendation mechanism is learned and experimentally evaluated. It appears that such a recommender system can achieve significant improvements in accuracy over alternative methods, while also retaining other advantages.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-205.pdf,Subjects: 1.10 Information Retrieval; 12. Machine Learning and Discovery
212,2006,Special Track on Artificial Intelligence and the Web,Table Extraction Using Spatial Reasoning on the CSS2 Visual Box Model,"Wolfgang Gatterbauer, Paul Bohunsky","Tables on web pages contain a huge amount of semantically explicit information, which makes them a worthwhile target for automatic information extraction and knowledge acquisition from the Web. However, the task of table extraction from web pages is difficult, because of HTML's design purpose to convey visual instead of semantic information. In this paper, we propose a robust technique for table extraction from arbitrary web pages. This technique relies upon the positional information of visualized DOM element nodes in a browser and, hereby, separates the intricacies of code implementation from the actual intended visual appearance. The novel aspect of the proposed web table extraction technique is the effective use of spatial reasoning on the CSS2 visual box model, which shows a high level of robustness even without any form of learning (F-measure ≈ 90%). We describe the ideas behind our approach, the tabular pattern recognition algorithm operating on a double topographical grid structure and allowing for effective and robust extraction, and general observations on web tables that should be borne in mind by any automatic web table extraction mechanism.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-206.pdf,Subjects: 1. Applications; 3.2 Geometric Or Spatial Reasoning
213,2006,Special Track on Artificial Intelligence and the Web,Deciding Semantic Matching of Stateless Services,"Duncan Hull, Evgeny Zolin, Andrey Bovykin, Ian Horrocks, Ulrike Sattler, Robert Stevens","We present a novel approach to describe and reason about stateless information processing services. It can be seen as an extension of standard descriptions which makes explicit the relationship between inputs and outputs and takes into account OWL ontologies to fix the meaning of the terms used in a service description. This allows us to define a notion of matching between services which yields high precision and recall for service location. We explain why matching is decidable, and provide biomedical example services to illustrate the utility of our approach.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-207.pdf,Subjects: 11.1 Description Logics; 11.2 Ontologies
214,2006,Special Track on Artificial Intelligence and the Web,OntoSearch: A Full-Text Search Engine for the Semantic Web,"Xing Jiang, An-Hwee Tan","OntoSearch, a full-text search engine that exploits ontological knowledge for document retrieval, is presented in this paper. Different from other ontology based search engines, OntoSearch does not require a user to specify the associated concepts of his/her queries. Domain ontology in OntoSearch is in the form of a semantic network. Given a keyword based query, OntoSearch infers the related concepts through a spreading activation process in the domain ontology. To provide personalized information access, we further develop algorithms to learn and exploit user ontology model based on a customized view of the domain ontology. The proposed system has been applied to the domain of searching scientific publications in the ACM Digital Library. The experimental results support the efficacy of the OntoSearch system by using domain ontology and user ontology for enhanced search performance.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-208.pdf,Subjects: 15.7 Search
215,2006,Special Track on Artificial Intelligence and the Web,Mining Comparative Sentences and Relations,"Nitin Jindal, Bing Liu","This paper studies a text mining problem, comparative sentence mining (CSM). A comparative sentence expresses an ordering relation between two sets of entities with respect to some common features. For example, the comparative sentence “Canon’s optics are better than those of Sony and Nikon” expresses the comparative relation: (better, [optics], [Canon], [Sony, Nikon]). Given a set of evaluative texts on the Web, e.g., reviews, forum postings, and news articles, the task of comparative sentence mining is (1) to identify comparative sentences from the texts and (2) to extract comparative relations from the identified comparative sentences. This problem has many applications. For example, a product manufacturer wants to know customer opinions of its products in comparison with those of its competitors. In this paper, we propose two novel techniques based on two new types of sequential rules to perform the tasks. Experimental evaluation has been conducted using different types of evaluative texts from the Web. Results show that our techniques are very promising.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-209.pdf,Subjects: 13. Natural Language Processing; 1.10 Information Retrieval
216,2006,Special Track on Artificial Intelligence and the Web,Using Semantic Web Technologies for Policy Management on the Web,"Lalana Kagal, Tim Berners-Lee, Dan Connolly, Daniel Weitzner","With policy management becoming popular as a means of providing flexible Web security, the number of policy languages being proposed for the Web is constantly increasing. We recognize the importance of policies for securing the Web and believe that the future will only bring more policy languages. We do not, however, believe that users should be forced to conform the description of their policy relationships to a single standard policy language. Instead there should be a way of encompassing different policy languages and supporting heterogeneous policy systems. As a step in this direction, we propose Rein, a policy framework grounded in Semantic Web technologies, which leverages the distributed nature and linkability of the Web to provide Web-based policy management. Rein provides ontologies for describing policy domains in a decentralized manner and provides an engine for reasoning over these descriptions, both of which can be used to develop domain and policy language specific security systems. We describe the Rein policy framework and discuss how a Rein policy management systems can be developed for access control in an online photo sharing application.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-210.pdf,Subjects: 11.2 Ontologies; 1. Applications
217,2006,Special Track on Artificial Intelligence and the Web,Social Network-based Trust in Prioritized Default Logic,"Yarden Katz, Jennifer Golbeck","A drawback of traditional default logic is that there is no general mechanism for preferring one default rule over another. To remedy this problem, numerous default logics augmented with priority relations have been introduced. In this paper, we show how trust values, derived from web-based social networks, can be used to prioritize defaults. We provide a coupling between the method for computing trust values in social networks and the prioritized Reiter defaults of Baader and Hollunder (1995), where specificity of terminological concepts is used to prioritize defaults. We compare our approach with specificity-based prioritization, and discuss how the two can be combined. Finally, we show how our approach can be applied to other variants of prioritized default logic.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-211.pdf,Subjects: 11. Knowledge Representation; 3.3 Nonmonotonic Reasoning
218,2006,Special Track on Artificial Intelligence and the Web,Detecting Spam Blogs: A Machine Learning Approach,"Pranam Kolari, Akshay Java, Tim Finin, Tim Oates, Anupam Joshi","Weblogs or blogs are an important new way to publish information, engage in discussions, and form communities on the Internet. The has unfortunately been infected by several varieties of spam-like content. Blog search engines, for example, are inundated by posts from splogs -- false blogs with machine generated or hijacked content whose sole purpose is to host ads or raise the PageRank of target sites. We discuss how SVM models based on local and link-based features can be used to detect splogs. We present an evaluation of learned models and their utility to blog search engines; systems that employ techniques differing from those of conventional web search engines.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-212.pdf,Subjects: 12. Machine Learning and Discovery; 1.10 Information Retrieval
219,2006,Special Track on Artificial Intelligence and the Web,Novel Relationship Discovery Using Opinions Mined from the Web,"Lun-Wei Ku, Hsiu-Wei Ho, Hsin-Hsi Chen","This paper proposes relationship discovery models using opinions mined from the Web instead of only conventional collocations. Web opinion mining extracts subjective information from the Web for specific targets, summarizes the polarity and the degree of the information, and tracks the development over time. Targets which gain similar opinionated tendencies within a period of time may be correlated. This paper detects event bursts from the tracking plots of opinions, and decides the strength of the relationship using the coverage of the plots. Companies are selected as the experimental targets. A total of 1,282,050 economics-related documents are collected from 93 Web sources between August 2003 and May 2005 for experiments. Models that discover relations are then proposed and compared on the basis of their performance. There are three types of models, collocation-based, opinion-based, and integration models, and respectively, four, two and two variants of each type. For evaluation, company pairs which demonstrate similar oscillation of stock prices are considered correlated and are selected as the gold standard. The results show that collocation-based models and opinion-based models are complementary, and the integration models perform the best. The top 25, 50 and 100 answers discovered by the best integration model achieve precision rates of 1, 0.92 and 0.79, respectively.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-213.pdf,Subjects: 13. Natural Language Processing
220,2006,Special Track on Artificial Intelligence and the Web,Automatically Labeling the Inputs and Outputs of Web Services,"Kristina Lerman, Anon Plangprasopchok, Craig A. Knoblock","Information integration systems combine data from multiple heterogeneous Web services to answer complex user queries, provided a user has semantically modeled the service first. To model a service, the user has to specify semantic types of the input and output data it uses and its functionality. As large number of new services come online, it is impractical to require the user to come up with a semantic model of the service or rely on the service providers to conform to a standard. Instead, we would like to automatically learn the semantic model of a new service. This paper addresses one part of the problem: namely, automatically recognizing semantic types of the data used by Web services. We describe a metadata-based classification method for recognizing input data types using only the terms extracted from a Web Service Definition file. We then verify the classifier's predictions by invoking the service with some sample data of that type. Once we discover correct classification, we invoke the service to produce output data samples. We then use content-based classifiers to recognize semantic types of the output data. We provide performance results of both classification methods and validate our approach on several live Web services.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-214.pdf,Subjects: 12. Machine Learning and Discovery
221,2006,Special Track on Artificial Intelligence and the Web,Predicting Task-Specific Webpages for Revisiting,"Arwen Twinkle Lettkeman, Simone Stumpf, Jed Irvine, Jonathan Herlocker","With the increased use of the web has come a corresponding increase in information overload that users face when trying to locate specific webpages, especially as a majority of vis-its to webpages are revisits. While automatically created browsing history lists offer a potential low-cost solution to re-locating webpages, even short browsing sessions gener-ate a glut of webpages that do not relate to the user's infor-mation need or have no revisit value. We address how we can better support web users who want to return to informa-tion on a webpage that they have previously visited by building more useful history lists. The paper reports on a combination technique that semi-automatically segments the webpage browsing history list into tasks, applies heuristics to remove webpages that carry no intrinsic revisit value, and uses a learning model, sensitive to individual users and tasks, that predicts which webpages are likely to be revisited again. We present results from an empirical evaluation that report the likely revisit need of users and that show that adequate overall prediction accuracy can be achieved. This approach can be used to increase utility of history lists by removing information overload to users when revisiting webpages.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-215.pdf,Subjects: 6.3 User Interfaces; 12. Machine Learning and Discovery
222,2006,Special Track on Artificial Intelligence and the Web,Bookmark Hierarchies and Collaborative Recommendation,"Ben Markines, Lubomira Stoilova, Filippo Menczer","GiveALink.org is a social bookmarking site where users may donate and view their personal bookmark files online securely. The bookmarks are analyzed to build a new generation of intelligent information retrieval techniques to recommend, search, and personalize the Web. GiveALink does not use tags, content, or links in the submitted Web pages. Instead we present a semantic similarity measure for URLs that takes advantage both of the hierarchical structure in the bookmark files of individual users, and of collaborative filtering across users. In addition, we build a recommendation and search engine from ranking algorithms based on popularity and novelty measures extracted from the similarity-induced network. Search results can be personalized using the bookmarks submitted by a user. We evaluate a subset of the proposed ranking measures by conducting a study with human subjects.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-216.pdf,Subjects: 1.10 Information Retrieval; 12. Machine Learning and Discovery
223,2006,Special Track on Artificial Intelligence and the Web,Spinning Multiple Social Networks for Semantic Web,"Yutaka Matsuo, Masahiro Hamasaki, Hideaki Takeda, Junichiro Mori, Danushka Bollegara, Yoshiyuki Nakamura, Takuichi Nishimura, Koiti Hasida, Mitsuru Ishizuka","Social networks are important for the Semantic Web. Several means can be used to obtain social networks: using social networking services, aggregating Friend of a Friend (FOAF) documents, mining text information on the Web or in e-mail messages, and observing face-to-face communication using sensors. Integrating multiple social networks is a key issue for further utilization of social networks in the Semantic Web. This paper describes our attempt to extract, analyze and integrate multiple social networks from the same community: user-registered knows networks, web-mined collaborator networks, and face-to-face meets networks. We operated a social network-based community support system called Polyphonet at the 17th, 18th and 19th Annual Conferences of the Japan Society of Artificial Intelligence (JSAI2003, JSAI2004, and JSAI2005) and at The International Conference on Ubiquitous Computing (UbiComp 2005). Multiple social networks were obtained and analyzed. We discuss the integration of multiple networks based on the analyses.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-217.pdf,Subjects: 1.10 Information Retrieval; 10. Knowledge Acquisition
224,2006,Special Track on Artificial Intelligence and the Web,Model-Based Collaborative Filtering as a Defense Against Profile Injection Attacks,"Mobasher Bamshad, Robin Burke, JJ Sandvig","The open nature of collaborative recommender systems allows attackers who inject biased profile data to have a significant impact on the recommendations produced. Standard memory-based collaborative filtering algorithms, such as k-nearest neighbor, have been shown to be quite vulnerable to such attacks. In this paper, we examine the robustness of model-based recommendation algorithms in the face of profile injection attacks. In particular, we consider two recommendation algorithms, one based on k-means clustering and the other based on Probabilistic Latent Semantic Analysis (PLSA). These algorithms aggregate similar users into user segments that are compared to the profile of an active user to generate recommendations. Traditionally, model-based algorithms have been used to alleviate the scalability problems associated with memory-based recommender systems. We show, empirically, that these algorithms also offer significant improvements in stability and robustness over the standard k-nearest neighbor approach when attacked. Furthermore, our results show that, particularly, the PLSA-based approach can achieve comparable recommendation accuracy.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-218.pdf,Subjects: 12. Machine Learning and Discovery
225,2006,Special Track on Artificial Intelligence and the Web,An Investigation into the Feasibility of the Semantic Web,"Zhengxiang Pan, Abir Qasem, Jeff Heflin","We investigate the challenges that must be addressed for the Semantic Web to become a feasible enterprise. Specifically we focus on the query answering capability of the Semantic Web. We put forward that two key challenges we face are heterogeneity and scalability. We propose a flexible and decentralized framework for addressing the heterogeneity problem and demonstrate that sufficient reasoning is possible over a large dataset by taking advantage of database technologies and making some tradeoff decisions. As a proof of concept, we collect a significant portion of the available Semantic Web data; use our framework to resolve some heterogeneity and reason over the data as one big knowledge base. In addition to demonstrating the feasibility of a ""real"" Semantic Web, our experiments have provided us with some interesting insights into how it is evolving and the type of queries that can be answered.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-219.pdf,Subjects: 11. Knowledge Representation; 11.2 Ontologies
226,2006,Special Track on Artificial Intelligence and the Web,Organizing and Searching the World Wide Web of Facts — Step One: the One-Million Fact Extraction Challenge,"Marius Pasca, Dekang Lin, Jeffrey Bigham, Andrei Lifchits, Alpa Jain","Due to the inherent difficulty of processing noisy text, the potential of the Web as a decentralized repository of human knowledge remains largely untapped during Web search. The access to billions of binary relations among named entities would enable new search paradigms and alternative methods for presenting the search results. A first concrete step towards building large searchable repositories of factual knowledge is to derive such knowledge automatically at large scale from textual documents. Generalized contextual extraction patterns allow for fast iterative progression towards extracting one million facts of a given type (e.g., Person-BornIn-Year) from 100 million Web documents of arbitrary quality. The extraction starts from as few as 10 seed facts, requires no additional input knowledge or annotated text, and emphasizes scale and coverage by avoiding the use of syntactic parsers, named entity recognizers, gazetteers, and similar text processing tools and resources.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-220.pdf,Subjects: 13. Natural Language Processing; 10. Knowledge Acquisition
227,2006,Special Track on Artificial Intelligence and the Web,Minimally Invasive Randomization for Collecting Unbiased Preferences from Clickthrough Logs,"Filip Radlinski, Thorsten Joachims","Clickthrough data is a particularly inexpensive and plentiful resource to obtain implicit relevance feedback for improving and personalizing search engines. However, it is well known that the probability of a user clicking on a result is strongly biased toward documents presented higher in the result set irrespective of relevance. We introduce a simple method to modify the presentation of search results that provably gives relevance judgments that are unaffected by presentation bias under reasonable assumptions. We validate this property of the training data in interactive real world experiments. Finally, we show that using these unbiased relevance judgments learning methods can be guaranteed to converge to an ideal ranking given sufficient data.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-221.pdf,Subjects: 1.10 Information Retrieval
228,2006,Special Track on Artificial Intelligence and the Web,Inferring User’s Preferences using Ontologies,"Vincent Schickel, Boi Faltings","We consider recommender systems that filter information and only show the most preferred items. Good recommendations can be provided only when an accurate model of the user’s preferences is available. We propose a novel technique for filling in missing elements of a user’s preference model using the knowledge captured in an ontology. Furthermore, we show through experiments on the MovieLens data set that our model achieves a high prediction accuracy and personalization level when little about the user’s preferences is known.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-222.pdf,Subjects: 1. Applications; 11.2 Ontologies
229,2006,Special Track on Artificial Intelligence and the Web,WikiRelate! Computing Semantic Relatedness Using Wikipedia,Michael Strube Simone Paolo Ponzetto,"Wikipedia provides a knowledge base for computing word relatedness in a more structured fashion than a search engine and with more coverage than WordNet. In this work we present experiments on using Wikipedia for computing semantic relatedness and compare it to WordNet on various benchmarking datasets. Existing relatedness measures perform better using Wikipedia than a baseline given by Google counts, and we show that Wikipedia outperforms WordNet when applied to the largest available dataset designed for that purpose. The best results on this dataset are obtained by integrating Google, WordNet and Wikipedia based measures. We also show that including Wikipedia improves the performance of an NLP application processing naturally occurring texts.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-223.pdf,Subjects: 11.2 Ontologies; 13. Natural Language Processing
230,2006,Special Track on Artificial Intelligence and the Web,Trust Representation and Aggregation in a Distributed Agent System,"Yonghong Wang, Munindar P. Singh","This paper considers a distributed system of software agents who cooperate in helping their users to find services, provided by different agents. The agents need to ensure that the service providers they select are trustworthy. Because the agents are autonomous and there is no central trusted authority, the agents help each other determine the trustworthiness of the service providers they are interested in. This help is rendered via a series of referrals to other agents, culminating in zero or more trustworthy service providers being identified. A trust network is a multiagent system where each agent potentially rates the trustworthiness of another agent. This paper develops a formal treatment of trust networks. At the base is a recently proposed representation of trust via a probability certainty distribution. The main contribution of this paper is the definition of two operators, concatenation and aggregation, using which trust ratings can be combined in a trust network. This paper motivates and establishes some important properties regarding these operators, thereby ensuring that trust can be combined correctly. Further, it shows that effects of malicious agents, who give incorrect information, are limited.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-224.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
231,2006,Special Track on Artificial Intelligence and the Web,Improve Web Search Using Image Snippets,"Xiao-Bing Xue, Zhi-Hua Zhou, Zhongfei (Mark) Zhang","The Web has become the largest information repository over the world. Therefore, effectively and efficiently searching the Web becomes a key challenge. Previous research on Web search mainly attempts to exploit the text in the Web pages and the link information between the pages. This paper shows that the Web search performance can be enhanced if image information is considered. In detail, a new Web search framework is proposed, where image snippets are extracted for the Web pages, which are then provided along with text snippets to the user such that it is much easier and more accurate for the user to identify the Web pages he or she expects and to reformulate the initial query. Experimental evaluations demonstrate the promise of the proposed framework.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-225.pdf,Subjects: 1.10 Information Retrieval; 6.3 User Interfaces
232,2006,Special Track on Integrated Intelligent Capabilities,QUICR-learning for Multi-Agent Coordination,"Adrian Agogino, Kagan, Tumer","Coordinating multiple agents that need to perform a sequence of actions to maximize a system level reward requires solving two distinct credit assignment problems. First, credit must be assigned for an action taken at time step t that results in a reward at time step t' > t. Second, credit must be assigned for the contribution of agent i to the overall system performance. The first credit assignment problem is typically addressed with temporal difference methods such as Q-learning. The second credit assignment problem is typically addressed by creating custom reward functions. To address both credit assignment problems simultaneously, we propose the ""Q Updates with Immediate Counterfactual Rewards-learning"" (QUICR-learning) designed to improve both the convergence properties and performance of Q-learning in large multi-agent problems. QUICR-learning is based on previous work on single-time-step counterfactual rewards described by the collectives framework. Results on a traffic congestion problem shows that QUICR-learning is significantly better than a Q-learner using collectives-based (single-time-step counterfactual) rewards. In addition QUICR-learning provides significant gains over conventional and local Q-learning. Additional results on a multi-agent grid-world problem show that the improvements due to QUICR-learning are not domain specific and can provide up to a ten fold increase in performance over existing methods.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-226.pdf,Subjects: 7.1 Multi-Agent Systems; 12.1 Reinforcement Learning
233,2006,Special Track on Integrated Intelligent Capabilities,Perspective Taking: An Organizing Principle for Learning in Human-Robot Interaction,"Matt Berlin, Jesse Gray, Andrea L. Thomaz, Cynthia Breazeal","The ability to interpret demonstrations from the perspective of the teacher plays a critical role in human learning. Robotic systems that aim to learn effectively from human teachers must similarly be able to engage in perspective taking. We present an integrated architecture wherein the robot's cognitive functionality is organized around the ability to understand the environment from the perspective of a social partner as well as its own. The performance of this architecture on a set of learning tasks is evaluated against human data derived from a novel study examining the importance of perspective taking in human learning. Perspective taking, both in humans and in our architecture, focuses the agent's attention on the subset of the problem space that is important to the teacher. This constrained attention allows the agent to overcome ambiguity and incompleteness that can often be present in human demonstrations and thus learn what the teacher intends to teach.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-227.pdf,Subjects: 17. Robotics; 4. Cognitive Modeling
234,2006,Special Track on Integrated Intelligent Capabilities,Self-Supervised Acquisition of Vowels in American English,Michael Coen,"This paper presents a self-supervised framework for perceptual learning based upon correlations in different sensory modalities. We demonstrate this with a system that has learned the vowel structure of American English ñ i.e., the number of vowels and their phonetic descriptions ñ by simultaneously watching and listening to someone speak. It is highly non-parametric, knowing neither the number of vowels nor their input distributions in advance, and it has no prior linguistic knowledge. This work is the first example of unsupervised phonetic acquisition of which we are aware, outside of that done by human infants. This system is based on the cross-modal clustering framework introduced by [4], which has been significantly enhanced here. This paper presents our results and focuses on the mathematical framework that enables this type of intersensory self-supervised learning.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-228.pdf,Subjects: 12. Machine Learning and Discovery; 19.1 Perception
235,2006,Special Track on Integrated Intelligent Capabilities,Automatic Heuristic Construction in a Complete General Game Player,"Gregory Kuhlmann, Kurt Dresner, Peter Stone","Computer game players are typically designed to play a single game: today's best chess-playing programs cannot play checkers, or even tic-tac-toe. General Game Playing is the problem of designing an agent capable of playing many different previously unseen games. The first AAAI General Game Playing Competition was held at AAAI 2005 in order to promote research in this area. In this article, we survey some of the issues involved in creating a general game playing system and introduce our entry to that event. The main feature of our approach is a novel method for automatically constructing effective search heuristics based on the formal game description. Our agent is fully implemented and tested in a range of different games.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-229.pdf,Subjects: 1.8 Game Playing
236,2006,Special Track on Integrated Intelligent Capabilities,Know Thine Enemy: A Champion RoboCup Coach Agent,"Gregory Kuhlmann, William B. Knox, Peter Stone","In a team-based multiagent system, the ability to construct a model of an opponent team's joint behavior can be useful for determining an agent's expected distribution over future world states, and thus can inform its planning of future actions. This paper presents an approach to team opponent modeling in the context of the RoboCup simulation coach competition. Specifically, it introduces an autonomous coach agent capable of analyzing past games of the current opponent, advising its own team how to play against this opponent, and identifying patterns or weaknesses on the part of the opponent. Our approach is fully implemented and tested within the RoboCup soccer server, and was the champion of the RoboCup 2005 simulation coach competition.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-230.pdf,Subjects: 7.1 Multi-Agent Systems
237,2006,Special Track on Integrated Intelligent Capabilities,A Unified Cognitive Architecture for Physical Agents,"Pat Langley, Dongkyu Choi","In this paper we describe Icarus, a cognitive architecture for physical agents that integrates ideas from a number of traditions, but that has been especially influenced by results from cognitive psychology. We review Icarus' commitments to memories and representations, then present its basic processes for performance and learning. We illustrate the architecture's behavior on a task from in-city driving that requires interaction among its various components. In addition, we discuss Icarus' consistency with qualitative findings about the nature of human cognition. In closing, we consider the framework's relation to other cognitive architectures that have been proposed in the literature.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-231.pdf,Subjects: 2. Architectures; 4. Cognitive Modeling
238,2006,Special Track on Integrated Intelligent Capabilities,"Walk the Talk: Connecting Language, Knowledge, and Action in Route Instructions","Matt MacMahon, Brian Stankiewicz, Benjamin Kuipers","Following verbal route instructions requires knowledge of language, space, action and perception. We present Marco, an agent that follows free-form, natural language route instructions by representing and executing a sequence of compound action specifications that model which actions to take under which conditions. Marco infers implicit actions from knowledge of both linguistic conditional phrases and from spatial action and local configurations. Thus, Marco performs explicit actions, implicit actions necessary to achieve the stated conditions, and exploratory actions to learn about the world. We gathered a corpus of 786 route instructions from six people in three large-scale virtual indoor environments. Thirty-six other people followed these instructions and rated them for quality. These human participants finished at the intended destination on 69% of the trials. Marco followed the same instructions in the same environments, with a success rate of 61%. We measured the efficacy of action inference with Marco variants lacking action inference: executing only explicit actions, Marco succeeded on just 28% of the trials. For this task, inferring implicit actions is essential to follow poor instructions, but is also crucial for many highly-rated route instructions.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-232.pdf,Subjects: 13. Natural Language Processing; 4. Cognitive Modeling
239,2006,Special Track on Integrated Intelligent Capabilities,Intuitive Linguistic Joint Object Reference in Human-Robot Interaction: Human Spatial Reference Systems and Function-based Categorisation for Symbol Grounding,Reinhard Moratz,"The visionary goal of an easy to use service robot implies intuitive styles of interaction between humans and robots. Such natural interaction can only be achieved if means are found to bridge the gap between the forms of object perception and spatial knowledge maintained by such robots, and the forms of language, used by humans, to communicate such knowledge. Part of bridging this gap consists of allowing user and robot to establish joint reference on objects in the environment - without forcing the user to use unnatural means for object reference. We present an approach to establishing joint object reference which makes use of natural object classification and a computational model of basic intrinsic and relative reference systems. Our object recognition approach assigns natural categories (e.g. 'desk', 'chair', 'table') to new objects based on their functional design. With basic objects within the environment classified, we can then make use of a computational reference model, to process natural projective relations (e.g. 'the briefcase to the left of the chair'), allowing users to refer to objects which cannot be classified reliably by the recognition system alone.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-233.pdf,Subjects: 6. Computer-Human Interaction; 17. Robotics
240,2006,Special Track on Integrated Intelligent Capabilities,TacTex-05: A Champion Supply Chain Management Agent,"David Pardoe, Peter Stone","Supply chains are ubiquitous in the manufacturing of many complex products. Traditionally, supply chains have been created through the interactions of human representatives of the companies involved, but advances in autonomous agent technologies have sparked an interest in automating the process. The Trading Agent Competition Supply Chain Management (TAC SCM) scenario provides a unique testbed for studying supply chain management agents. This paper introduces TacTex-05 (the champion agent from the 2005 competition), describes its constituent intelligent components, and examines the success of the complete agent through analysis of competition results and controlled experiments.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-234.pdf,Subjects: 7.2 Software Agents
241,2006,Special Track on Integrated Intelligent Capabilities,Deeper Natural Language Processing for Evaluating Student Answers in Intelligent Tutoring Systems,"Vasile Rus, Arthur C. Graesser","This paper addresses the problem of evaluating students' answers in intelligent tutoring environments with mixed-initiative dialogue by modelling it as a textual entailment problem. The problem of meaning representation and inference is a pervasive challenge in any integrated intelligent system handling communication. For intelligent tutorial dialogue systems, we show that entailment cases can be detected at various dialog turns during a tutoring session. We report the performance of a lexico-syntactic approach on a set of entailment cases that were collected from a previous study we conducted with AutoTutor.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-235.pdf,Subjects: 13. Natural Language Processing; 11. Knowledge Representation
242,2006,Special Track on Integrated Intelligent Capabilities,"Integrating Joint Intention Theory, Belief Reasoning, and Communicative Action for Generating Team-Oriented Dialogue","Rajah Annamalai Subramanian, Sanjeev Kumar, Philip Cohen","The goal of this research is to develop an architecture that can guide an agent during collaborative teamwork. The architecture should generate communication and dialogue during the performance of collaborative multi-agent tasks as a byproduct of the agent’s rationally pursuing its intentions. This paper describes how a joint intention interpreter that is integrated with a reasoner over beliefs and communicative acts can form the core of a dialogue engine. As an interpreter of joint actions, the architecture enables agent programmers to describe a domain declaratively, specifying an agent’s individual and joint intentions, plans and actions at a high level. The interpreter attempts to fulfill the agent’s individual and joint intentions, subject to its beliefs and mutual beliefs. As a consequence, the system engages in dialogue through the planning and execution of communicative acts necessary to attain the collaborative task at hand. The dialogue engine is general enough to be applicable to both agent-agent and agent-human teams. The system has been implemented in a combination of Java and Prolog, and can be shown to obey the predictions of joint intention.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-236.pdf,Subjects: 7.1 Multi-Agent Systems
243,2006,Senior Member Papers,Multimodal Cognitive Architecture: Making Perception More Central to Intelligent Behavior,B. Chandrasekaran,"I propose that the notion of cognitive state be broadened from the current predicate-symbolic, Language-of-Thought framework to a multi-modal one, where perception and kinesthetic modalities participate in thinking. In contrast to the roles assigned to perception and motor activities as modules external to central cognition in the currently dominant theories in AI and Cognitive Science, in the proposed approach, central cognition incorporates parts of the perceptual machinery. I motivate and describe the proposal schematically, and describe the implementation of a bi-modal version in which a diagrammatic representation component is added to the cognitive state. The proposal explains our rich multimodal internal experience, and can be a key step in the realization of embodied agents. The proposed multimodal cognitive state can significantly enhance the agent’s problem solving.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-237.pdf,Subjects: 9. Foundational Issues; 2. Architectures
244,2006,Senior Member Papers,Integrated AI in Space: The Autonomous Sciencecraft on Earth Observing One,Steve Chien,"The Earth Observing One spacecraft has been under the control of AI software for several years ñ experimentally since 2003 and since November 2004 as the primary operations system. This software includes: model-based planning and scheduling, procedural execution, and event detection software learned by support vector machine (SVM) techniques. This software has enabled a 100x increase in the mission science return per data downlinked and a >$1M/year reduction in operations costs. In this paper we discuss the AI software used, the impact of the software, and lessons learned with implications for future AI research.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-238.pdf,Subjects: 7.2 Software Agents; 1.12 Scheduling
245,2006,Senior Member Papers,Machine Reading,"Oren Etzioni, Michele Banko, Michael J. Cafarella","The time is ripe for the AI community to set its sights on Machine Reading—the automatic, unsupervised understanding of text. In this paper, we place the notion of Machine Reading in context, describe progress towards this goal by the KnowItAll research group at the University of Washington, and highlight several central research questions.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-239.pdf,Subjects: 13. Natural Language Processing
246,2006,Senior Member Papers,Constraints: The Ties That Bind,Eugene C. Freuder,Constraints can serve as a unifying force in artificial intelligence.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-240.pdf,Subjects: 15.2 Constraint Satisfaction; 9. Foundational Issues
247,2006,Senior Member Papers,Deconstructing Planning as Satisfiability,Henry A Kautz,"The idea of encoding planning as satisfiability was proposed in 1992 as a method for generating interesting SAT problems, but did not appear to be a practical approach to planning. This changed in 1996, when Satplan was shown to be competitive with current planning technology, leading to a mini-explosion of interest in the approach. Within a few years, however, heuristic search planning appeared to be vastly superior to planning as satisfiability, and many researchers wrote off the earlier success of the approach as a fluke. It was therefore rather surprising when Satplan won first place for optimal STRIPS planning in the 2004 ICAPS planning competition. This talk will attempt to deconstruct the reasons for Satplan's successes and failures, and discuss ways the approach might be extended to handle open domains, metric constraints, and domain symmetries.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-241.pdf,Subjects: 1.11 Planning; 15.2 Constraint Satisfaction
248,2006,Senior Member Papers,Towards Chemical Universal Turing Machines,Stephen H. Muggleton,"Present developments in the natural sciences are providing enormous and challenging opportunities for various AI technologies to have an unprecedented impact in the broader scientific world. If taken up, such applications would not only stretch present AI technology to the limit, but if successful could also have a radical impact on the way natural science is conducted. We review our experience with the Robot Scientist and other Machine Learning applications as examples of such AI-inspired developments. We also consider potential future extensions of such work based on the use of Uncertainty Logics. As a generalisation of the robot scientist we introduce the notion of a Chemical Universal Turing machine. Such a machine would not only be capable of complex cell simulations, but could also be the basis for programmable chemical and biological experimentation robots.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-242.pdf,Subjects: 12.2 Scientific Discovery; 12. Machine Learning and Discovery
249,2006,Senior Member Papers,From the Programmer’s Apprentice to Human-Robot Interaction: Thirty Years of Research on Human-Computer Collaboration,"Charles Rich, Candace L. Sidner","We summarize the continuous thread of research we have conducted over the past thirty years on human-computer collaboration. This research reflects many of the themes and issues in operation in the greater field of AI over this period, such as knowledge representation and reasoning, planning and intent recognition, learning, and the interplay of human theory and computer engineering.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-243.pdf,Subjects: 6. Computer-Human Interaction; 13. Natural Language Processing
250,2006,Senior Member Papers,Turing’s Dream and the Knowledge Challenge,Lenhart Schubert,"There is a set of clear-cut challenges, all centering around knowledge, that have received insufficient attention in AI, and whose solution could bring the realization of Turing's dream -- the dream of a machine we can talk with just like a person, and which is therefore (at least) our intellectual equal. These challenges have to do with the representation of linguistically expressible knowledge, the role of knowledge in language understanding, the use of knowledge for several sorts of commonsense reasoning, and knowledge accumulation. Concerning the last topic, I briefly present preliminary results of some of our recent efforts to extract ""shallow"" general knowledge about the world from large text corpora.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-244.pdf,Subjects: 11. Knowledge Representation; 13. Natural Language Processing
251,2006,Senior Member Papers,Does the Turing Test Demonstrate Intelligence or Not?,Stuart M. Shieber,"The Turing Test has served as a defining inspiration throughout the early history of artificial intelligence research. Its centrality arises in part because verbal behavior indistinguishable from that of humans seems like an incontrovertible criterion for intelligence, a ""philosophical conversation stopper"" as Dennett says. On the other hand, from the moment Turing's seminal Mind article was published, the conversation hasn't stopped; the appropriateness of the Test has been continually questioned, and current philosophical wisdom holds that the Turing Test is hopelessly flawed as a sufficient condition for attributing intelligence. In this short article, I summarize for an artificial intelligence audience an argument that I have presented at length for a philosophical audience that attempts to reconcile these two mutually contradictory but well-founded attitudes towards the Turing Test that have been under constant debate since 1950.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-245.pdf,Subjects: 9.4 Philosophical Foundations
252,2006,Senior Member Papers,Virtual Humans,William R. Swartout,"Virtual humans are computer-generated characters that can take the part of humans in a variety of limited contexts. These can include acting as role-players in simulations and training systems, where they play a variety of parts, such as acting as friendly or hostile forces, or locals in the environment. Other uses for virtual humans include acting as museum guides, marketing assistants or characters in entertainment systems. Because virtual humans are intended to mimic a broad range of human behaviors, they must integrate a diverse set of AI technologies, including speech recognition, natural language understanding and generation, dialogue management, non-verbal communication, perception, automated reasoning, and emotion modeling. In this talk I will give an overview of virtual human research, focusing on the opportunities this area provides and the lessons learned and their larger implications for the field of artificial intelligence. I will conclude with some thoughts on future directions for virtual human research.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-246.pdf,Subjects: 6.1 Life-Like Characters; 6.4 Virtual Reality
253,2006,Senior Member Papers,Knowledge Infusion,Leslie Valiant,The question of how machines can be endowed with the ability to acquire and robustly manipulate commonsense knowledge is a fundamental scientific problem. Here we formulate an approach to this problem that we call knowledge infusion. We argue that robust logic offers an appropriate semantics for this endeavor because it supports provably efficient algorithms for a basic set of necessary learning and reasoning tasks. We observe that multiple concepts can be learned simultaneously from a common data set in a data efficient manner. We also point out that the preparation of appropriate teaching materials for training systems constructed according to these principles raises new challenges.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-247.pdf,Subjects: 5. Common Sense Reasoning; 12. Machine Learning and Discovery
254,2006,Senior Member Papers,Methods for Empirical Game-Theoretic Analysis (Extended Abstract),Michael P. Wellman,An emerging empirical methodology bridges the gap between game theory and simulation for practical strategic reasoning.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-248.pdf,Subjects: 7.1 Multi-Agent Systems
255,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Building Semantic Mappings from Databases to Ontologies,"Yuan An, John Mylopoulos, Alex Borgida","A recent special issue of AI Magazine was dedicated to the topic of semantic integration — the problem of sharing data across disparate sources. At the core of the solution lies the discovery the ""semantics"" of different data sources. Ideally, the semantics of data are captured by a formal ontology of the domain together with a semantic mapping connecting the schema describing the data to the ontology. However, establishing the semantic mapping from a database schema to a formal ontology in terms of formal logic expressions is inherently difficult to automate, so the task was left to humans. In this paper, we report on our study of a semi-automatic tool, called MAPONTO, that assists users to discover plausible semantic relationships between a database schema (relational or XML) and an ontology, expressing them as logical formulas/rules.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-249.pdf,Subjects: 11.2 Ontologies; 1.10 Information Retrieval
256,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Maintaining Cooperation in Noisy Environments,"Tsz-Chiu Au, Dana Nau","To prevent or alleviate conflicts in multi-agent environments, it is important to distinguish between situations where another agent has misbehaved intentionally and situations where the misbehavior was accidental. One situation where this problem arises is the Noisy Iterated Prisoner's Dilemma, a version of the Iterated Prisoner's Dilemma (IPD) in which there is a nonzero probability that a ""cooperate"" action will accidentally be changed into a ""defect"" action and vice versa. Tit-For-Tat and other strategies that do quite well in the ordinary (non-noisy) IPD can do quite badly in the Noisy IPD. This paper presents a technique called symbolic noise detection, for detecting whether anomalies in player's behavior are deliberate or accidental. This idea to use player's deterministic behavior to tell whether an action has been affected by noise. We also present DBS, an algorithm that uses symbolic noise detection in the Noisy IPD. DBS constructs a model of the other agent's deterministic behavior, and watches for any deviation from this model. If the other agent's next action is inconsistent with this model, the inconsistency can be due either to noise or to a genuine change in their behavior; and DBS can often distinguish between two cases by waiting to see whether this inconsistency persists in next few moves. This technique is effective because many IPD players often have clear deterministic patterns of behavior. We entered several different implementations of DBS in the 2005 Iterated Prisoner's Dilemma competition, in Category 2 (noisy environments). Out of the 165 contestants in this category, most of DBS implementations ranked among top ten. The best one ranked third, and it was beaten only by two ""master-and-slaves strategy"" programs that each had a large number of ""slave"" programs feeding points to them.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-250.pdf,Subjects: 7.1 Multi-Agent Systems; 1.8 Game Playing
257,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Acquiring Constraint Networks using a SAT-based Version Space Algorithm,"Christian Bessiere, Remi Coletta, Frederic Koriche, Barry O’Sullivan","Constraint programming is a commonly used technology for solving complex combinatorial problems. However, users of this technology need significant expertise in order to model their problems appropriately. We propose a basis for addressing this problem: a new SAT-based version space algorithm for acquiring constraint networks from examples of solutions and non-solutions of a target problem. An important advantage of the algorithm is the ease with which domain-specific knowledge can be exploited.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-251.pdf,Subjects: 15.2 Constraint Satisfaction; 12. Machine Learning and Discovery
258,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Subjective Mapping,"Michael Bowling, Dana Wilkinson, Ali Ghodsi","Extracting a map from a stream of experience is a key problem in robotics and artificial intelligence in general. We propose a technique, called subjective mapping, that seeks to learn a fully specified predictive model, or map, without the need for expert provided models of the robot's motion and sensor apparatus. We briefly overview the recent advancements presented elsewhere (ICML, IJCAI, and ISRR) that make this possible, examine its significance in relationship to other developments in the field, and outline open issues that remain to be addressed.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-252.pdf,Subjects: 12. Machine Learning and Discovery; 17. Robotics
259,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Preference Elicitation and Generalized Additive Utility,"Darius Braziunas, Craig Boutilier","Any automated decision support software must tailor its actions or recommendations to the preferences of different users. Thus it requires some representation of user preferences as well as a means of eliciting or otherwise learning the preferences of the specific user on whose behalf it is acting. While additive preference models offer a compact representation of multiattribute utility functions, and ease of elicitation, they are often overly restrictive. The more flexible generalized additive independence (GAI) model maintains much of the intuitive nature of additive models, but comes at the cost of much more complex elicitation. In this article, we summarize the key contributions of our earlier paper (UAI 2005): (a) the first elaboration of the semantic foundations of GAI models that allows one to engage in preference elicitation using local queries over small subsets of attributes rather than global queries over full outcomes; and (b) specific procedures for Bayesian preference elicitation of the parameters of a GAI model using such local queries.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-253.pdf,Subjects: 15.5 Decision Theory; 3.4 Probabilistic Reasoning
260,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Progress in Textual Case-Based Reasoning: Predicting the Outcome of Legal Cases from Text,"Stefanie Bruninghaus, Kevin D. Ashley",This paper reports on a project that explored reasoning with textual cases in the context of legal reasoning. The work is anchored in both Case-Based Reasoning (CBR) and AI and Law. It introduces the SMILE+IBP framework that generates a case-based analysis and prediction of the outcome of a legal case given a brief textual summary of the case facts. The focal research question in this work was to find a good text representation for text classification. An evaluation showed that replacing case-specific names by roles and adding NLP lead to higher performance for assigning CBR indices. The NLP-based representation produced the best results for reasoning with the automatically indexed cases.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-254.pdf,Subjects: 3.1 Case-Based Reasoning
261,2006,New Scientific and Technical Advances in Research (Nectar) Papers,B-ROC Curves for the Assessment of Classifiers over Imbalanced Data Sets,"Alvaro A. Cardenas, John S. Baras","The class imbalance problem appears to be ubiquitous to a large portion of the machine learning and data mining communities. One of the key questions in this setting is how to evaluate the learning algorithms in the case of class imbalances. In this paper we introduce the Bayesian Receiver Operating Characteristic (B-ROC) curves, as a set of tradeoff curves that combine in an intuitive way, the variables that are more relevant to the evaluation of classifiers over imbalanced data sets.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-255.pdf,Subjects: 12. Machine Learning and Discovery; 1.5 Diagnosis
262,2006,New Scientific and Technical Advances in Research (Nectar) Papers,"Handling Self-Interest in Groups, with Minimal Cost",Ruggiero Cavallo,"In group decision-making problems that involve self-interested agents with private information, reaching socially optimal outcomes requires aligning the goals of individuals with the welfare of the entire group. The well-known VCG mechanism achieves this by requiring specific payments from agents to a central coordinator. However, when the goal of coordination is to allow the group to jointly realize the greatest possible welfare, these payments amount to an unwanted cost of implementation, or waste. While it has often been stated that the payments VCG prescribes are necessary in order to implement the socially optimal outcome in dominant strategies without running a deficit, this is in fact not generally true. Cavallo (2006) specified the mechanism that requires the minimal payments among all mechanisms that are socially optimal, never run a deficit, and are ex post individual rational with an anonymity property. The mechanism achieves significant savings over VCG in a broad range of practically relevant domains, including allocation problems, by using information about the structure of valuations in the domain. This paper gives a high-level overview of that result, and discusses some potential applications to AI.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-256.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
263,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Constraint Symmetry and Solution Symmetry,"David Cohen, Peter Jeavons, Christopher Jefferson, Karen E. Petrie, Barbara M. Smith","Symmetry in constraint satisfaction problems (CSPs) has been considered in two fundamentally different ways: as an operation preserving the solutions of a CSP instance, or as an operation preserving the constraints. To reﬂect these two views, we deﬁne solution symmetry and constraint symmetry. We discuss how these concepts are related and show that some CSP instances have many more solution symmetries than constraint symmetries.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-257.pdf,Subjects: 15.2 Constraint Satisfaction; 9.3 Mathematical Foundations
264,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Traffic Intersections of the Future,"Kurt Dresner, Peter Stone","Few concepts embody the goals of artificial intelligence as well as fully autonomous robots. Countless films and stories have been made that focus on a future filled with autonomous agents that complete menial tasks or run errands that humans do not want or are too busy to carry out. One such task is driving automobiles. In this paper, we summarize the work we have done towards a future of fully-autonomous vehicles, specifically coordinating such vehicles safely and efficiently at intersections. We then discuss the implications this work has for other areas of AI, including planning, multiagent learning, and computer vision.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-258.pdf,Subjects: 7.1 Multi-Agent Systems
265,2006,New Scientific and Technical Advances in Research (Nectar) Papers,When a Decision Tree Learner Has Plenty of Time,"Saher Esmeir, Shaul Markovitch","The majority of the existing algorithms for learning decision trees are greedy-a tree is induced top-down, making locally optimal decisions at each node. In most cases, however, the constructed tree is not globally optimal. Furthermore, the greedy algorithms require a fixed amount of time and are not able to generate a better tree if additional time is available. To overcome this problem, we present a lookahead-based algorithm for anytime induction of decision trees which allows trading computational speed for tree quality. The algorithm uses a novel strategy for evaluating candidate splits; a stochastic version of ID3 is repeatedly invoked to estimate the size of the tree in which each split results, and the split that minimizes the expected size is preferred. Experimental results indicate that for several hard concepts, our proposed approach exhibits good anytime behavior and yields significantly better decision trees when more time is available.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-259.pdf,Subjects: 12. Machine Learning and Discovery; 15.6 Decision Trees
266,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Overview of AutoFeed: An Unsupervised Learning System for Generating Webfeeds,"Bora Gazen, Steven Minton","The AutoFeed system automatically extracts data from semi-structured web sites. Previously, researchers have developed two types of supervised learning approaches for extracting web data: methods that create precise, site-specific extraction rules and methods that learn less-precise site-independent extraction rules. In either case, significant training is required. AutoFeed follows a third, more ambitious approach, in which unsupervised learning is used to analyze sites and discover their structure. Our method relies on a set of heterogeneous ""experts"", each of which is capable of identifying certain types of generic structure. Each expert represents its discoveries as ""hints"". Based on these hints, our system clusters the pages and identifies semi-structured data that can be extracted. To identify a good clustering, we use a probabilistic model of the hint-generation process. This paper summarizes our formulation of the fully-automatic web-extraction problem, our clustering approach, and our results on a set of experiments.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-260.pdf,Subjects: 12. Machine Learning and Discovery
267,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Embedding Heterogeneous Data using Statistical Models,"Amir Globerson, Gal Chechik, Fernando Pereira, Naftali Tishby","Embedding algorithms are a method for revealing low dimensional structure in complex data. Most embedding algorithms are designed to handle objects of a single type for which pairwise distances are specified. Here we describe a method for embedding objects of different types (such as authors and terms) into a single common Euclidean space based on their co-occurrence statistics. The joint distributions of the heterogenous objects are modeled as exponentials of squared Euclidean distances in a low-dimensional embedding space. This construction links the problem to convex optimization over positive semidefinite matrices. We quantify the performance of our method on two text datasets, and show that it consistently and significantly outperforms standard methods of statistical correspondence modeling, such as multidimensional scaling and correspondence analysis.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-261.pdf,Subjects: 12. Machine Learning and Discovery
268,2006,New Scientific and Technical Advances in Research (Nectar) Papers,TempoExpress: An Expressivity-Preserving Musical Tempo Transformation System,"Maarten Grachten, Josep Lluis Arcos, Ramon Lopez de Mantaras","The research described in this paper focuses on global tempo transformations of monophonic audio recordings of saxophone jazz performances. More concretely, we have investigated the problem of how a performance played at a particular tempo can be automatically rendered at another tempo while preserving its expressivity. To do so we have developed a case-based reasoning system called TempoExpress. The results we have obtained have been extensively compared against a standard technique called uniform time stretching (UTS), and show that our approach is superior to UTS.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-262.pdf,Subjects: 1.1 Art And Music; 3.1 Case-Based Reasoning
269,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Towards a Validated Model of “Emotional Intelligence”,"Jonathan Gratch, Stacy Marsella, Wenji Mao",This article summarizes recent progress in developing a validated computational account of the cognitive antece-dents and consequences of emotion. We describe the poten-tial of this work to impact a variety of AI problem domains.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-263.pdf,Subjects: 4. Cognitive Modeling; 6.1 Life-Like Characters
270,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Large Scale Knowledge Base Systems: An Empirical Evaluation Perspective,"Yuanbo Guo, Abir Qasem, Jeff Heflin","In this paper, we discuss how our work on evaluating Semantic Web knowledge base systems (KBSs) contributes to address some broader AI problems. First, we show how our approach provides a benchmarking solution to the Semantic Web, a new application area of AI. Second, we discuss how the approach is also beneficial in a more traditional AI context. We focus on issues such as scalability, performance tradeoffs, and the comparison of different classes of systems.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-264.pdf,Subjects: 11. Knowledge Representation
271,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Opinion Extraction and Summarization on the Web,"Minqing Hu, Bing Liu","The Web has become an excellent source for gathering consumer opinions. There are now numerous Web sources containing such opinions, e.g., product reviews, forums, discussion groups, and blogs. Techniques are now being developed to exploit these sources to help organizations and individuals to gain such important information easily and quickly. In this paper, we first discuss several aspects of the problem in the AI context, and then present some results of our existing work published in KDD-04 and WWW-05.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-265.pdf,Subjects: 1. Applications; 13. Natural Language Processing
272,2006,New Scientific and Technical Advances in Research (Nectar) Papers,The Power of Sequential Single-Item Auctions for Agent Coordination,"Sven Koenig, C. Tovey, M. Lagoudakis, V. Markakis, D. Kempe, P. Keskinocak, A. Kleywegt, A. Meyerson, S. Jain","Teams of robots are more fault tolerant than single robots, and auctions appear to be promising means for coordinating them. In a recent paper at ""Robotics: Science and Systems 2005,"" we analyzed a coordination system based on sequential single-item auctions. We showed that the coordination system is simple to implement and computation and communication efficient, and that the resulting sum of all travel distances in known terrain is guaranteed to be only a constant factor away from optimum. In this paper, we put these results in perspective by comparing our coordination system against those based on either parallel single-item auctions or combinatorial auctions, demonstrating that it combines the advantages of both.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-266.pdf,Subjects: 7.1 Multi-Agent Systems; 9.3 Mathematical Foundations
273,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Lessons on Applying Automated Recommender Systems to Information-Seeking Tasks,"Joseph A. Konstan, Sean M. McNee, Cai-Nicolas Ziegler, Roberto Torres, Nishikant Kapoor, John T. Riedl","Automated recommender systems predict user preferences by applying machine learning techniques to data on products, users, and past user preferences for products. Such systems have become increasingly popular in entertainment and e-commerce domains, but have thus far had little success in information-seeking domains such as identifying published research of interest. We report on several recent publications that show how recommenders can be extended to more effectively address information-seeking tasks by expanding the focus from accurate prediction of user preferences to identifying a useful set of items to recommend in response to the user's specific information need. Specific research demonstrates the value of diversity in recommendation lists, shows how users value lists of recommendations as something different from the sum of the individual recommendations within, and presents an analytic model for customizing a recommender to match user information-seeking needs.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-267.pdf,Subjects: 1.10 Information Retrieval; 12. Machine Learning and Discovery
274,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Activity-Centric Email: A Machine Learning Approach,"Nicholas Kushmerick, Tessa Lau, Mark Dredze, Rinat Khoussainov","Our use of ordinary desktop applications (such as email, Web, calendars) is often a manifestation of the activities with which we are engaged. Planning a conference trip involves sending travel expense forms, and visits to airline and hotel sites. Renovating a kitchen involves sketches, product specifications, emails with the architect and spreadsheets for tracking expenses. Every enterprise has (often implicit) processes for managing customer queries, requesting maintenance, hiring a new employee, purchasing equipment, and so on. Unfortunately, ordinary desktop applications do not know anything about these activities. Within an enterprise, many activities have been formalized into business workflows such as hiring or ordering equipment. However, the way people interact with these workflows is often through email and desktop applications. If these applications are not aware of the activity context, people bear the burden of organizing their information into activities, typically using crude techniques such as manual search, file directories, and email folders/threads. Email has emerged as the primary tool for people to communicate about their work and manage activities. Motivated by the importance of email in conducting activities, we have recently developed several machine learning algorithms for automatically discovering and tracking activities in email. We observe that activities come in many forms, from structured workflows to informal person-to-person communication. In this paper, we summarize our efforts to provide automated assistance with two types of activities: rigid structured activities, and unstructured conversational activities.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-268.pdf,Subjects: 12. Machine Learning and Discovery; 6.3 User Interfaces
275,2006,New Scientific and Technical Advances in Research (Nectar) Papers,"Controlled Search over Compact State Representations, in Nondeterministic Planning Domains and Beyond","Ugur Kuter, Dana Nau","Two of the most efficient planners for planning in nondeterministic domains are MBP and ND-SHOP2. MBP achieves its efficiency by using Binary Decision Diagrams (BDDs) to represent sets of states that share some common properties, so it can plan for all of these states simultaneously. ND-SHOP2 achieves its efficiency by using HTN task decomposition to focus the search. In some environments, ND-SHOP2 runs exponentially faster than MBP, and in others the reverse is true. In this paper, we discuss the following: (1) We describe how to combine ND-SHOP2's HTNs with MBP's BDDs. Our new planning algorithm, YoYo, performs task decompositions over classes of states that are represented as BDDs. In our experiments, YoYo easily outperformed both MBP and ND-SHOP2, often by several orders of magnitude. (2) HTNs are just one of several techniques that are originally developed for classical planning domains and that can be adapted to work in nondeterministic domains. By combining those techniques with a BDD representation, it should be possible to get great speedups just as we did here. (3) We discuss how these same ideas can be generalized for use in several other research areas, such as planning with Markov Decision Processes, synthesizing controllers for hybrid systems, and composing Semantic Web Services.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-269.pdf,Subjects: 1.11 Planning
276,2006,New Scientific and Technical Advances in Research (Nectar) Papers,A Look At Parsing and Its Applications,"Matthew Lease, Eugene Charniak, Mark Johnson, David McClosky","This paper provides a brief introduction to recent work in statistical parsing and its applications. We highlight successes to date, remaining challenges, and promising future work.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-270.pdf,Subjects: 13.3 Syntax
277,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Beyond Bags of Words: Modeling Implicit User Preferences in Information Retrieval,"Donald Metzler, W. Bruce Croft","This paper reports on recent work in the field of information retrieval that attempts to go beyond the overly simplified approach of representing documents and queries as bags of words. Simple models make it difficult to accurately model a user's information need. The model presented in the paper is based on Markov random fields and allows almost arbitrary features to be encoded. This provides a powerful mechanism for modeling many of the implicit constraints a user has in mind when formulating a query. Simple instantiations of the model that consider dependencies between the terms in a query have shown to significantly outperform bag of words models. Further extensions of the model are possible to incorporate even more complex constraints based other domain knowledge. Finally, we describe what place our model has within the broader realm of artificial intelligence and propose several open questions that may be of general interest to the field.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-271.pdf,Subjects: 1.10 Information Retrieval; 11. Knowledge Representation
278,2006,New Scientific and Technical Advances in Research (Nectar) Papers,The Role of Context in Head Gesture Recognition,"Louis-Philippe Morency, Candace Sidner, Christopher Lee, Trevor Darrell","Head pose and gesture offer several key conversational grounding cues and are used extensively in face-to-face interaction among people. We investigate how dialog context from an embodied conversational agent (ECA) can improve visual recognition of user gestures. We present a recognition framework which (1) extracts contextual features from an ECA's dialog manager, (2) computes a prediction of head nod and head shakes, and (3) integrates the contextual predictions with the visual observation of a vision-based head gesture recognizer. We found a subset of lexical, punctuation and timing features that are easily available in most ECA architectures and can be used to learn how to predict user feedback. Using a discriminative approach to contextual prediction and multi-modal integration, we were able to improve the performance of head gesture detection even when the topic of the test set was significantly different than the training set.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-272.pdf,Subjects: 19.1 Perception; 13.1 Discourse
279,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Supporting Queries with Imprecise Constraints,"Ullas Nambiar, Subbarao Kambhampati","In this paper, we motivate the need for and challenges involved in supporting imprecise queries over Web databases. Then we briefly explain our solution, AIMQ - a domain independent approach for answering imprecise queries that automatically learns query relaxation order by using approximate functional dependencies. We also describe our approach for learning similarity between values of categorical attributes. Finally, we present experimental results demonstrating the robustness, efficiency and effectiveness of AIMQ.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-273.pdf,Subjects: 1.10 Information Retrieval; 12. Machine Learning and Discovery
280,2006,New Scientific and Technical Advances in Research (Nectar) Papers,The Synthy Approach for End to End Web Services Composition: Planning with Decoupled Causal and Resource Reasoning,Biplav Srivastava,"Web services offer a unique opportunity to simplify application integration by defining common, web-based, platform-neutral, standards for publishing service descriptions to a registry, finding and invoking them -- not necessarily by the same parties. Viewing software components as web services, the current solutions to web services composition based on business web services (using WSDL, BPEL, SOAP etc.) or semantic web services (using ontologies, goal-directed reasoning etc.) are both piecemeal and insufficient for building practical applications. Inspired by the work in AI planning on decoupling causal (planning) and resource reasoning (scheduling), we introduced the first integrated work in composing web services end to end from specification to deployment by synergistically combining the strengths of the current approaches. The solution is based on a novel two--staged composition approach that addresses the information modeling aspects of web services, provides support for contextual information while composing services, employs efficient decoupling of functional and non-functional requirements, and leads to improved scalability and failure handling. A prototype of the solution has been implemented in the Synthy service composition system and applied to a number of composition scenarios from the telecom domain. The application of planning to web services has also brought new plan and planner usability-driven research issues to the fore for AI.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-274.pdf,Subjects: 1.11 Planning; 8. Enabling Technologies
281,2006,New Scientific and Technical Advances in Research (Nectar) Papers,AI Support for Building Cognitive Models,"Robert St. Amant, Sean P. McBride, Frank E. Ritter","Cognitive modeling techniques provide a way of evaluating user interface designs, based on what is known about human cognitive strengths and limitations. Cognitive modelers face a tradeoff, however: more detailed models require disproportionately more time and effort to develop than coarser models. In this paper we describe a system, G2A, that automatically produces translations from abstract GOMS models into more detailed ACT-R models. G2A demonstrates how even simple AI techniques can facilitate the construction of cognitive models and suggests new directions for improving modeling tools.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-275.pdf,Subjects: 4. Cognitive Modeling
282,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Optimizing Similarity Assessment in Case-Based Reasoning,"Armin Stahl, Thomas Gabel","The definition of accurate similarity measures is a key issue of every Case-Based Reasoning application. Although some approaches to optimize similarity measures automatically have already been applied, these approaches are not suited for all CBR application domains. On the one hand, they are restricted to classification tasks. On the other hand, they only allow optimization of feature weights. We propose a novel learning approach which addresses both problems, i.e. it is suited for most CBR application domains beyond simple classification and it enables learning of more sophisticated similarity measures.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-276.pdf,Subjects: 3.1 Case-Based Reasoning; 10. Knowledge Acquisition
283,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Real-Time Evolution of Neural Networks in the NERO Video Game,"Kenneth O. Stanley, Bobby D. Bryant, Igor Karpov, Risto Miikkulainen","A major goal for AI is to allow users to interact with agents that learn in real time, making new kinds of interactive simulations, training applications, and digital entertainment possible. This paper describes such a learning technology, called real-time NeuroEvolution of Augmenting Topologies (rtNEAT), and describes how rtNEAT was used to build the NeuroEvolving Robotic Operatives (NERO) video game. This game represents a new genre of machine learning games where the player trains agents in real time to perform challenging tasks in a virtual environment. Providing laymen the capability to effectively train agents in real time with no prior knowledge of AI or machine learning has broad implications, both in promoting the field of AI and making its achievements accessible to the public at large.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-277.pdf,Subjects: 1.8 Game Playing; 1.9 Genetic Algorithms
284,2006,New Scientific and Technical Advances in Research (Nectar) Papers,"Laughing with HAHAcronym, a Computational Humor System","Oliviero Stock, Carlo Strapparava","Computational humor is a challenge with implications for many classical fields in AI such as, for example, natural language processing, intelligent human-computer interaction, reasoning, not to mention cognitive science, linguistics and psychology. In this paper we summarize our experience in developing HAHAcronym, a system devoted to produce humorous acronyms, and we discuss some concrete prospects for this field.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-278.pdf,Subjects: 13. Natural Language Processing
285,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Explanation-Based Learning for Image Understanding,"Qiang Sun, Li-Lun Wang, Gerald DeJong","Existing prior domain knowledge represents a valuable source of information for image interpretation problems such as classifying handwritten characters. Such domain knowledge must be translated into a form understandable by the learner. Translation can be realized with Explanation-Based Learning (EBL) which provides a kind of dynamic inductive bias, combining domain knowledge and training examples. The dynamic bias formed by the interaction of domain knowledge with training examples can yield solution knowledge of potential higher quality than can be anticipated by the static bias designer without seeing training examples. We detail how EBL can be used to dynamically integrate domain knowledge, training examples, and the learning mechanism, and describe the two EBL approaches.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-279.pdf,Subjects: 12. Machine Learning and Discovery
286,2006,New Scientific and Technical Advances in Research (Nectar) Papers,An Introduction to Nonlinear Dimensionality Reduction,"Kilian Q Weinberger, kilianw@seas.upenn.edu","Many problems in AI are simplified by clever representations of sensory or symbolic input. How to discover such representations automatically, from large amounts of unlabeled data, remains a fundamental challenge. The goal of statistical methods for dimensionality reduction is to detect and discover low dimensional structure in high dimensional data. In this paper, we review a recently proposed algorithm maximum variance unfolding - for learning faithful low dimensional representations of high dimensional data. The algorithm relies on modern tools in convex optimization that are proving increasingly useful in many areas of machine learning.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-280.pdf,Subjects: 12. Machine Learning and Discovery
287,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Automatic Wrapper Generation Using Tree Matching and Partial Tree Alignment,"Yanhong Zhai, Bing Liu","This paper is concerned with the problem of structured data extraction from Web pages. The objective of the research is to automatically segment data records in a page, extract data items/fields from these records and store the extracted data in a database. In this paper, we first introduce the extraction problem, and then discuss the main existing approaches and their limitations. After that, we introduce a novel technique (called DEPTA) to automatically perform Web data extraction. The method consists of three steps: (1) identifying data records with similar patterns in a page, (2) aligning and extracting data items from the identified data records and (3) generating tree-based regular expressions to facilitate later extraction from other similar pages. The key innovation is the proposal of a new multiple tree alignment algorithm called partial tree alignment, which was found to be particularly suitable for Web data extraction. It is both highly accurate and efficient. This paper is based on our work published in KDD-03 and WWW-05.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-281.pdf,Subjects: 1.10 Information Retrieval
288,2006,New Scientific and Technical Advances in Research (Nectar) Papers,Responsive Information Architect: Enabling Context-Sensitive Information Seeking,"Michelle Zhou, Keith Houck, Shimei Pan, James Shaw, Vikram Aggarwal, Zhen Wen","Information seeking is an important but often difficult task especially when involving large and complex data sets. We hypothesize that a context-sensitive interaction paradigm can greatly assist users in their information seeking. Such a paradigm allows a system to both understand user data requests and present the requested information in context. Driven by this hypothesis, we have developed a suite of intelligent user interaction technologies and integrated them in a full-fledged, context-sensitive information system. In this paper, we review two sets of key technologies: context-sensitive multimodal input interpretation and automated multimedia output generation. We also share our evaluation results, which indicate that our approaches are capable of supporting context-sensitive information seeking for practical applications.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-282.pdf,Subjects: 6. Computer-Human Interaction; 1.10 Information Retrieval
289,2006,New Scientific and Technical Advances in Research (Nectar) Papers,A Breadth-First Approach to Memory-Efficient Graph Search,"Rong Zhou, Eric A. Hansen","Recent work shows that the memory requirements of A* and related graph-search algorithms can be reduced substantially by only storing nodes that are on or near the search frontier, using special techniques to prevent node regeneration, and recovering the solution path by a divide-and-conquer technique. When this approach is used to solve graph-search problems with unit edge costs, we have shown that a breadth-first search strategy can be more memory-efficient than a best-first strategy. We provide an overview of our work using this approach, which we call breadth-first heuristic search.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-283.pdf,Subjects: 15.7 Search
290,2006,IAAI-06 Deployed Application Papers,Case-Based Reasoning for General Electric Appliance Customer Support,William Cheetham,"A case-based reasoning system was created to support customers who purchased appliances from General Electric. When a customer calls General Electric for help, a call-taker uses the system to diagnose the problem and step the customer through its solution. The system has been in use by 300 call-takers since 1999. It has resulted in a 20 percent increase in the probability the customer’s problem can be solved over the phone. This has greatly improved customer satisfaction and saved GE $44.5 million between 2000 and 2005 from reduced cost of visits of field service technician to customer’s homes.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-284.pdf,Subjects: 3.1 Case-Based Reasoning; 1.5 Diagnosis
291,2006,IAAI-06 Deployed Application Papers,Predicting Electricity Distribution Feeder Failures Using Machine Learning Susceptibility Analysis,"Philip Gross, Albert Boulanger, Marta Arias, David Waltz, Philip M. Long, Charles Lawson , Roger Anderson, Matthew Koenig, Mark Mastrocinque, William Fairechio, John A. Johnson, Serena Lee","A Machine Learning (ML) System known as ROAMS (Ranker for Open-Auto Maintenance Scheduling) was developed to create failure-susceptibility rankings for almost one thousand 13.8kV-27kV energy distribution feeder cables that supply electricity to the boroughs of New York City. In Manhattan, rankings are updated every 20 minutes and displayed on distribution system operators' screens. Additionally, a separate system makes seasonal predictions of failure susceptibility. These feeder failures, known as ""Open Autos"" or ""O/As,"" are a significant maintenance problem. A year's sustained research has led to a system that demonstrates high accuracy: 75% of the feeders that actually failed over the summer of 2005 were in the 25% of feeders ranked as most at-risk. By the end of the summer, the 100 most susceptible feeders as ranked by the ML system were accounting for up to 40% of all O/As that subsequently occurred each day. The system's algorithm also identifies the factors underlying failures which change over time and with varying conditions (especially temperature), providing insights into the operating properties and failure causes in the feeder system.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-285.pdf,Subjects: 1.6 Engineering And Science; 12. Machine Learning and Discovery
292,2006,IAAI-06 Deployed Application Papers,TPBOSCourier: A Transportation Procurement System,"Andrew Lim, Zhou Xu, B. Cheang, W. Ho, Steve Au-Yeung","TPBOSCourier is the Transportation Procurement and Bid Optimization System (TPBOS) for Philips Electronics to automate and optimize its procurement of courier services. It was jointly developed by Red Jasper Limited and the Hong Kong University of Science and Technology, and has been successfully deployed in 2005. Philips typically procures courier services for more than 2500 shipping lanes annually and the use of the software has resulted in significant cost and time savings in analyzing and optimizing procurement decisions. This paper explains the development and design of the TPBOSCourier.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-286.pdf,Subjects: 1. Applications
293,2006,IAAI-06 Deployed Application Papers,Constraint-based Random Stimuli Generation for Hardware Verification,"Yehuda Naveh, Michal Rimon, Itai Jaeger, Yoav Katz, Michael Vinov, Eitan Marcus, Gil Shurek","We report on random stimuli generation for hardware verification in IBM as a major application of various artificial intelligence technologies, including knowledge representation, expert systems, and constraint satisfaction. The application has been developed for almost a decade, with huge payoffs. Research and development around this application is still thriving, as we continue to cope with the ever-increasing complexity of modern hardware systems and demanding business environments.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-287.pdf,Subjects: 1.6 Engineering And Science; 15.2 Constraint Satisfaction
294,2006,IAAI-06 Deployed Application Papers,Machine Translation for Manufacturing: A Case Study at Ford Motor Company,Nestor Rychtyckyj,"Machine Translation was one of the first applications of Artificial Intelligence technology that was deployed to solve real-world problems. Since the early 1960s, researchers have been building and utilizing computer systems that can translate from one language to another without extensive human intervention. In the late 1990s, Ford Vehicle Operations began working with Systran Software Inc to adapt and customize their Machine Translation (MT) technology in order to translate Ford's vehicle assembly build instructions from English to German, Spanish, Dutch and Portuguese. The use of Machine Translation (MT) was made necessary by the vast amount of dynamic information that needed to be translated in a timely fashion. Our MT system has already translated over 5 million instructions into these target languages and is an integral part of our manufacturing process planning to support Ford's assembly plants in Europe, Mexico and South America. In this paper, we focus on how AI techniques, such as knowledge representation and natural language processing, can improve the accuracy of Machine Translation in a dynamic environment such as auto manufacturing.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-288.pdf,Subjects: 13.2 Machine Translation; 13. Natural Language Processing
295,2006,IAAI-06 Deployed Application Papers,Expressive Commerce and Its Application to Sourcing,Tuomas Sandholm,"Sourcing professionals buy several trillion dollars worth of goods and services yearly. We introduced a new paradigm called expressive commerce and applied it to sourcing. It combines the advantages of highly expressive human negotiation with the advantages of electronic reverse auctions. The idea is that supply and demand are expressed in drastically greater detail than in traditional electronic auctions, and are algorithmically cleared. This creates a Pareto efficiency improvement in the allocation (a win-win between the buyer and the sellers) but the market clearing problem is a highly complex combinatorial optimization problem. We developed the world’s fastest tree search algorithms for solving it. We have hosted $16 billion of sourcing using the technology, and created $1.8 billion of hard-dollar savings. The suppliers also benefited by being able to express production efficiencies and creativity, and through exposure problem removal. Supply networks were redesigned, with quantitative understanding of the tradeoffs, and implemented in weeks instead of months.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-289.pdf,Subjects: 15.7 Search; 7.1 Multi-Agent Systems
296,2006,IAAI-06 Emerging Application Papers,CPM: Context-Aware Power Management in WLANs,"Fahd Albinali, Chris Gniady","In this paper, we present a novel approach for tuning power modes of wireless 802.11 interfaces. We use K-means and simple correlation techniques to analyze user's interaction with applications based on mouse clicks. This provides valuable contextual hints that are used to anticipate future network access patterns and intent of users. Based on those hints, we adapt the power mode of the wireless network interface to optimize both energy usage and bandwidth usage. Evaluation results (based on real data gathered from interaction with a desktop) show significant improvements over earlier power management schemes.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-290.pdf,Subjects: 6. Computer-Human Interaction; 19.1 Perception
297,2006,IAAI-06 Emerging Application Papers,Design and Implementation of the CALO Query Manager,"Vinay Chaudhri, Jose-Luis Ambite, Richard Fikes, Jessica Jenkins, Sunil Mishra, Maria Muslea, Tomas Uribe, Guizhen Yang",We report on our experience in developing a query-answering system that integrates multiple knowledge sources. The system is based on a novel architecture for combining knowledge sources in which the sources can produce new subgoals as well as ground facts in the search for answers to existing subgoals. The system uses a query planner that takes into account different query-processing capabilities of individual sources and augments them gracefully. A reusable ontology provides a mediated schema that serves as the basis for integration. We have evaluated the system on a suite of test queries in a realistic application to verify the practicality of our approach.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-291.pdf,Subjects: 2. Architectures; 3. Automated Reasoning
298,2006,IAAI-06 Emerging Application Papers,MedEthEx: A Prototype Medical Ethics Advisor,"Michael Anderson, Susan Leigh Anderson, Chris Armen","As part of a larger Machine Ethics Project, we are developing an ethical advisor that provides guidance to health care workers faced with ethical dilemmas. MedEthEx is an implementation of Beauchamp’s and Childress' Principles of Biomedical Ethics that harnesses machine learning techniques to abstract decision principles from cases in a particular type of dilemma with conflicting prima facie duties and uses these principles to determine the correct course of action in similar and new cases. We believe that accomplishing this will be a useful first step towards creating machines that can interact with those in need of health care in a way that is sensitive to ethical issues that may arise.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-292.pdf,Subjects: 1.7 Expert Systems; 9.4 Philosophical Foundations
299,2006,IAAI-06 Emerging Application Papers,Building Explainable Artificial Intelligence Systems,"Mark G. Core, H. Chad Lane,Michael van Lent,Dave Gomboc,Steve Solomon,Milton Rosenberg","As artificial intelligence (AI) systems and behavior models in military simulations become increasingly complex, it has been difficult for users to understand the activities of computer-controlled entities. Prototype explanation systems have been added to simulators, but designers have not heeded the lessons learned from work in explaining expert system behavior. These new explanation systems are not modular and not portable; they are tied to a particular AI system. In this paper, we present a modular and generic architecture for explaining the behavior of simulated entities. We describe its application to the Virtual Humans, a simulation designed to teach soft skills such as negotiation and cultural awareness.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-293.pdf,Subjects: 2. Architectures; 6.1 Life-Like Characters
300,2006,IAAI-06 Emerging Application Papers,Heuristic Search and Information Visualization Methods for School Redistricting,"Marie desJardins, Blazej Bulka, Ryan Carr, Andrew Hunt, Priyang Rathod, Penny Rheingans","We describe an application of AI search and information visualization techniques to the problem of school redistricting, in which students are assigned to home schools within a county or school district. This is a multicriteria optimization problem in which competing objectives must be considered, such as school capacity, busing costs, and socioeconomic distribution. Because of the complexity of the decision-making problem, tools are needed to help end users generate, evaluate, and compare alternative school assignment plans. A key goal of our research is to aid users in finding multiple qualitatively different redistricting plans that represent different tradeoffs in the decision space. We present heuristic search methods that can be used to find a set of qualitatively different plans, and give empirical results of these search methods on population data from the school district of Howard County, Maryland. We show the resulting plans using novel visualization methods that we have developed for summarizing and comparing alternative plans.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-294.pdf,Subjects: 15.7 Search; 6. Computer-Human Interaction
301,2006,IAAI-06 Emerging Application Papers,Monitoring Food Safety by Detecting Patterns in Consumer Complaints,"Artur Dubrawski, Kimberly Elenberg, Andrew Moore, Maheshkumar Sabhnani","EPFC (Emerging Patterns in Food Complaints) is the analytical component of the Consumer Complaint Monitoring System, designed to help the food safety officials to efficiently and effectively monitor incoming reports of adverse effects of food on its consumers. These reports, collected in a passive surveillance mode, contain multi-dimensional, heterogeneous and sparse snippets of specific information about the consumers' demographics, the kinds, brands and sources of the food involved, symptoms of possible sickness, characteristics of foreign objects which could have been found in food, involved locations and times of occurrences, etc. Statistical data mining component of the system empowers its users, allowing for increased accuracy, specificity and timeliness of detection of naturally occurring problems as well as of potential acts of agro-terrorism. The system’s main purpose is to enhance discovery and mitigation of food borne threats to public health in the USDA Food Safety Inspection Service regulated products. As such, it is being envisioned as one of the key components of the nationwide bio-security protection infrastructure. It has been accepted for use and it is currently going through the final stages of deployment. This paper explains the motivation, key design concepts and reports the system’s utility and performance observed so far.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-295.pdf,Subjects: 1. Applications; 12. Machine Learning and Discovery
302,2006,IAAI-06 Emerging Application Papers,Hand Grip Pattern Recognition for Mobile User Interfaces,"Kee-Eung Kim, Wook Chang, Sung-Jung Cho, Junghyun Shim, Hyunjeong Lee, Joonah Park, Youngbeom Lee, Sangryong Kim","This paper presents a novel user interface for handheld mobile devices by recognizing hand grip patterns. Particularly, we consider the scenario where the device is provided with an array of capacitive touch sensors underneath the exterior cover. In order to provide the users with intuitive and natural manipulation experience, we use pattern recognition techniques for identifying the users' hand grips from the touch sensors. Preliminary user studies suggest that filtering out unintended user hand grip is one of the most important issues to be resolved. We discuss the details of the prototype implementation, as well as engineering challenges for practical deployment.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-296.pdf,Subjects: 6.3 User Interfaces
303,2006,IAAI-06 Emerging Application Papers,Trip Router with Individualized Preferences (TRIP): Incorporating Personalization into Route Planning,"Julia Letchner, John Krumm, Eric Horvitz","Popular route planning systems (Windows Live Local, Yahoo! Maps, Google Maps, etc.) generate driving directions using a static library of roads and road attributes. They ignore both the time at which a route is to be traveled and, more generally, the preferences of the drivers they serve. We present a set of methods for including driver preferences and time-variant traffic condition estimates in route planning. These methods have been incorporated into a working prototype named TRIP. Using a large database of GPS traces logged by drivers, TRIP learns time-variant traffic speeds for every road in a widespread metropolitan area. It also leverages a driver’s past GPS logs when responding to future route queries to produce routes that are more suited to the driver’s individual driving preferences. Using experiments with real driving data, we demonstrate that the routes produced by TRIP are measurably closer to those actually chosen by drivers than are the routes produced by routers that use static heuristics.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-297.pdf,Subjects: 1. Applications
304,2006,IAAI-06 Emerging Application Papers,Local Negotiation in Cellular Networks: From Theory to Practice,"Raz Lin, Daphna Dor-Shifer, Sarit Kraus, David Sarne","This paper describes a novel negotiation protocol for cellular networks, which intelligently improves the performance of the network. Our proposed reactive mechanism enables the dynamic adaptation of the base stations to continuous changes in service demands, thereby improving the overall network performance. This mechanism is important when a frequent global optimization is infeasible or substantially costly. The proposed local negotiation mechanism is incorporated into a simulated network based on cutting-edge industry technologies. Experimental results suggest a rapid adjustment to changes in bandwidth demand and overall improvement in the number of served users over time. Although we tested our algorithm based on the service level, which is measured as the number of covered handsets, our algorithm supports negotiation for any set of parameters, aiming to optimize network's performance according to any measure of performance specified by the service provider.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-298.pdf,Subjects: 1. Applications; 7.2 Software Agents
305,2006,IAAI-06 Emerging Application Papers,Ontology Based Semantic Modeling for Chinese Ancient Architectures,"Liu Yong, Congfu Xu, Qiong Zhang, Yunhe Pan","Modeling complex architectures is quite challenging. We introduce a novel intelligent system, which can generate semi-style or semi-structure Chinese ancient architectures automatically. By using an ontology based approach to analyze the styles of different architectures, geometry primitives (e.g. point, line, triangle, etc.) are converted into semantic architecture components (e.g. window, gate, roof, etc.) as knowledge. The following modeling process can be performed at different semantic levels, and it is appealing to users having domain knowledge. This intelligent architecture modeling system has been successfully applied in the digital heritage project for ancient architectures in southeast China.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-299.pdf,Subjects: 11.2 Ontologies; 1.1 Art And Music
306,2006,IAAI-06 Emerging Application Papers,CM-Extractor: An Application for Automating Medical Quality Measures Abstraction in a Hospital Setting,"Mark Morsch, Joel Vengco, Ronald Sheffer, Daniel Heinze","In the US, health care providers are required to report evidence-based quality measures to various governmental and independent regulatory agencies. Abstracting appropriate facts from a patient’s medical record provides the data for these measures. Finding and maintaining qualified staff for this vital function is a challenge to many healthcare providers. Emerging systems and technologies in large-scale clinical repositories and AI techniques for information extraction have the potential to make the process of collecting measures more consistent, accurate and efficient. This paper presents CM-Extractor, a computerized system that automates the process of quality measures abstraction using natural language processing and a rule-based approach. An evaluation of a deployed system used for hospital inpatient cases is discussed. The results showed that the NLP performed with high accuracy across multiple types of medical documents, and users were able to significantly improve productivity. Challenges remain in the areas of availability of electronic patient data and a model for deploying and supporting solutions on a large scale.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-300.pdf,Subjects: 13. Natural Language Processing; 1.7 Expert Systems
307,2006,IAAI-06 Emerging Application Papers,Visual Explanation of Evidence in Additive Classifiers,"Brett Poulin, Roman Eisner, Duane Szafron, Paul Lu, Russ Greiner, D.S. Wishar, Alona Fyshe, Brandon Pearcy, Cam MacDonell and John Anvik","Machine-learned classifiers are important components of many data mining and knowledge discovery systems. In several application domains, an explanation of the classifier's reasoning is critical for the classifier’s acceptance by the end-user. We describe a framework, ExplainD, for explaining decisions made by classifiers that use additive evidence. ExplainD applies to many widely used classifiers, including linear discriminants and many additive models. We demonstrate our ExplainD framework using implementations of naïve Bayes, linear support vector machine, and logistic regression classifiers on example applications. ExplainD uses a simple graphical explanation of the classification process to provide visualizations of the classifier decisions, visualization of the evidence for those decisions, the capability to speculate on the effect of changes to the data, and the capability, wherever possible, to drill down and audit the source of the evidence. We demonstrate the effectiveness of ExplainD in the context of a deployed web-based system (Proteome Analyst) and using a downloadable Python-based implementation.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-301.pdf,Subjects: 12. Machine Learning and Discovery; 12.2 Scientific Discovery
308,2006,IAAI-06 Emerging Application Papers,A Sequential Covering Evolutionary Algorithm for Expressive Music Performance,"Rafael Ramirez, Amaury Hazan, Jordi Mariner, Esteban Maestre","In this paper, we describe an evolutionary approach to one of the most challenging problems in computer music: modeling the knowledge applied by a musician when performing a score of a piece in order to produce an expressive performance of the piece. We extract a set of acoustic features from Jazz recordings thereby providing a symbolic representation of the musician's expressive performance. By applying a sequential covering evolutionary algorithm to the symbolic representation, we obtain an expressive performance computational model capable of endowing a computer generated music performance with the timing and energy expressiveness that characterizes human generated music.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-302.pdf,Subjects: 1.9 Genetic Algorithms; 1.1 Art And Music
309,2006,IAAI-06 Emerging Application Papers,AWDRAT: A Cognitive Middleware System for Information Survivability,"Howard E Shrobe, Robert Laddaga, Robert Balzer, Bob Balzer, Neil Goldman, Dave Wile, Marcelo Tallis, Tim Hollebeek, Alexander Egyed","The Infrastructure of modern society is controlled by software systems that are vulnerable to attacks. Many such attacks, launched by ""recreational hackers"" have already led to severe disruptions and significant cost. It, therefore, is critical that we find ways to protect such systems and to enable them to continue functioning even after a successful attack. This paper describes AWDRAT, a middleware system for providing survivability to both new and legacy applications. AWDRAT stands for Architectural-differencing, Wrappers, Diagnosis, Recovery, Adaptive software, and Trust-modeling. AWDRAT uses these techniques to gain visibility into the execution of an application system and to compare the application's actual behavior to that which is expected. In the case of a deviation, AWDRAT conducts a diagnosis that figures out which computational resources are likely to have been compromised and then adds these assessments to its trust-model. The trust model in turn guides the recovery process, particularly by guiding the system in its choice among functionally equivalent methods and resources. AWDRAT has been used on an example application system, a graphical editor for constructing mission plans. We present data showing the effectiveness of AWDRAT in detecting a variety of compromises to the application system.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-303.pdf,Subjects: 1. Applications; 1.5 Diagnosis
310,2006,IAAI-06 Emerging Application Papers,Multiagent Coalition Formation for Computer-Supported Cooperative Learning,"Leen-Kiat Soh, Nobel Khandaker, Hong Jiang","In this paper, we describe a computer-supported cooperative learning system in education and the results of its deploy-ment. The system, called I-MINDS, consists of a set of teacher agents, group agents, and student agents. While the agents possess individual intelligent capabilities, the novel invention of I-MINDS lies in multiagent intelligence and coalition formation. I-MINDS supports student participa-tion and collaboration and helps the instructor manage large, distance classrooms. Specifically, it uses a Vickrey auction-based and learning-enabled algorithm called VALCAM to form student groups in a structured coopera-tive learning setting. We have deployed I-MINDS in an in-troductory computer science course (CS1) and conducted experiments in the Spring and Fall semesters of 2005 to study how I-MINDS-supported collaboration fares against traditional, face-to-face collaboration. Results showed that students using I-MINDS performed (and outperformed in some aspects) as well as students in traditional settings.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-304.pdf,Subjects: 7.1 Multi-Agent Systems; 1.3 Computer-Aided Education
311,2006,Student Abstracts,Biconnected Structure for Multi-Robot Systems,"Mazda Ahmadi, Peter Stone","Many applications of distributed autonomous robotic systems can benefit from, or even may require, the team of robots staying within communication connectivity. For example, consider the problem of multirobot surveillance, in which a team of robots must collaboratively patrol a given area. If any two robots can directly communicate at all times, the robots can coordinate for efficient behavior. This condition holds trivially in environments that are smaller than the robots' communication range. However in larger environments, the robots must actively maintain physical locations such that any two robots can communicate — possibly through a series of other robots. Otherwise, the robots may lose track of each others’ activities and become miscoordinated. Furthermore, since robots are relatively unreliable and/or may need to change tasks (for example if a robot is suddenly called by a human user to perform some other task), in a stable multirobot surveillance system, if one of the robots leaves or crashes, the rest should still be able to communicate. Some examples of other tasks that could benefit from any pair of robots being able to communicate with each other, are multirobot exploration, search and rescue, and cleaning robots.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-305.pdf,Subjects: 7.1 Multi-Agent Systems; 17. Robotics
312,2006,Student Abstracts,A Benchmark for Cooperative Learning Agents,"Jason M. Black, Dean F. Hougen","Cooperative multi-agent systems are of current interest due to their relevance to both robotics and networking. Researchers often create machine learning environments to explore these domains; however, the lack of reuse of previous environments prevents comparisons between the works of research groups. Further, while a growing understanding of the relationships between problem domains and machine learning techniques has emerged over time, there have been few attempts to systematically measure the performance of machine learning techniques as domain characteristics vary. Our primary goal is to create TASER, the Team Agent Simulator for Efficient Research—a nontrivial simulation system aimed at the efficient comparison of machine learning algorithms given a wide variety of conditions, concentrating on cooperative tasks. Our secondary goal is the adoption of TASER by other researchers.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-306.pdf,Subjects: 12. Machine Learning and Discovery; 7.1 Multi-Agent Systems
313,2006,Student Abstracts,Performance Evaluation Methods for the Trading Agent Competition,"Brett J. Borghetti, Eric Sodomka","This paper proposes a novel method to characterize the performance of autonomous agents in the Trading Agent Competition for Supply Chain Management (TAC-SCM). We create benchmarking tools that manipulate market environments to control the conditions and provide guidelines to test trading agents. Using these tools, we show how developers can inspect their agents and unveil behaviors that might otherwise have gone undiscovered.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-307.pdf,Subjects: 7.1 Multi-Agent Systems; 15.8 Simulation
314,2006,Student Abstracts,Can We Work Around Numerical Methods? An Insight,"Sandeep Chandana, Rene V. Mayorga",This paper proposes a non ñ conventional technique of analyzing the stability thresholds for certain type of self ñ sustaining oscillations. The revered van-der-Pol equation has been studied in this work with an intention to predict an accurate stability criterion under the effect of a set of parameters and estimation techniques with the help of a novel neural network based approximation module. Three formulated numerical methods and standard Euler and Runge Kutta methods have been used as the preliminary mathematical framework for designing the structure and type of the Neural Network.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-308.pdf,Subjects: 15.3 Control; 14. Neural Networks
315,2006,Student Abstracts,Local Consistency in Junction Graphs for Constraint-Based Inference,"Le Chang, Alan K. Mackworth",The concept of local consistency plays a central role in constraint satisfaction and has been extended to handle general constraint-based inference (CBI) problems. We propose a family of novel generalized local consistency concepts for the junction graph representation of CBI problems. These concepts are based on a general condition that depends only on the existence and property of the multiplicative absorbing element and does not depend on the other semiring properties of CBI problems. We present several local consistency enforcing algorithms and their approximation variants. Theoretical complexity analyses and empirical experimental results for the application of these algorithms to both MaxCSP and probability inference are given. We also discuss the relationship between these local consistency concepts and message passing schemes such as junction tree algorithms and loopy message propagation.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-309.pdf,Subjects: 15.2 Constraint Satisfaction; 3.4 Probabilistic Reasoning
316,2006,Student Abstracts,RL-CD: Dealing with Non-Stationarity in Reinforcement Learning,"Bruno C. da Silva, Eduardo W. Basso, Ana L. C. Bazzan, Paulo M. Engel","This student abstract describes ongoing investigations regarding an approach for dealing with non-stationarity in reinforcement learning (RL) problems. We briefly propose and describe a method for managing multiple partial models of the environment and comment previous results which show that the proposed mechanism has better convergence times comparing to standard RL algorithms. Current efforts include the development of a more robust approach, capable of dealing with noisy environments, and also investigations regarding the possibility of using partial models in order to aliviate learning problems in systems with an explosive number of states.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-310.pdf,Subjects: 12. Machine Learning and Discovery; 12.1 Reinforcement Learning
317,2006,Student Abstracts,Making Autonomous Intersection Management Backwards Compatible,"Kurt Dresner, Peter Stone","Traffic congestion and automobile accidents are two of the leading causes of decreased standard of living and lost productivity in urban settings. Recent advances in artificial intelligence suggest that autonomous vehicle navigation will be possible in the near future. Individual cars can now be equipped with features of autonomy such as adaptive cruise control, GPS-based route planning, and autonomous steering. Once individual cars become autonomous, many of the cars on the road will have such capabilities, thus opening up the possibility of autonomous interactions among multiple vehicles. In earlier work, we proposed a novel Multiagent Systems–based approach to alleviating traffic congestion and collisions, specifically at intersections. In this work, we make three further contributions. First, we augment our existing intersection control mechanism to allow use by human drivers with minimal additional infrastructure. Second, we show that this hybrid mechanism offers performance and safety benefits over traditional traffic light systems. Finally, we show that at each stage, there exists an incentive to use autonomous vehicles over traditional vehicles. All work is fully implemented and tested in our custom simulator and we present experimental results to support its effectiveness.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-311.pdf,Subjects: 7.1 Multi-Agent Systems
318,2006,Student Abstracts,Exploring GnuGo's Evaluation Function with a SVM,"Christopher Fellows, Yuri Malitsky, and Gregory Wojtaszczyk","While computers have defeated the best human players in many classic board games, progress in Go remains elusive. The large branching factor in the game makes traditional adversarial search intractable while the complex interaction of stones makes it difficult to assign a reliable evaluation function. This is why most existing programs rely on handtuned heuristics and pattern matching techniques. Yet none of these solutions perform better than an amateur player. Our work introduces a composite approach, aiming to integrate the strengths of the proved heuristic algorithms, the AIbased learning techniques, and the knowledge derived from expert games. Specifically, this paper presents an application of the Support Vector Machine (SVM) for training the GnuGo evaluation function.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-314.pdf,
319,2006,Student Abstracts,Robot Self-Recognition Using Conditional ProbabilityñBased Contingency,"Kevin M. Godby, Jesse A. Lane","As robots become more sophisticated and pervasive, they will be forced to operate in more dynamic and social environments. In order to develop a theory of mind to account for the intents, beliefs, and motivations of other individuals, a robot needs to be able to distinguish between another entity and itself. One proposed method of learning the difference between self and other is to use contingency, the time dependence of perception and action. Watson suggested contingency as a method used by infants when learning to detect self. He outlined four general methods for detecting contingency: contiguity, temporal correlation, conditional probability, and causal implication. For our experiment, we chose to implement Watson's conditional probability method of contingency detection. Conditional probability keeps track of instances in which the behavior occurs and the stimulus does not, versus instances when the stimulus occurs but the behavior does not.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-313.pdf,Subjects: 17. Robotics
320,2006,Student Abstracts,Multiclass Support Vector Machines for Articulatory Feature Classification,"Brian Hutchinson, Jianna Zhang","This ongoing research project investigates articulatory feature (AF) classification using multiclass support vector machines (SVMs). SVMs are being constructed for each AF in a multi-valued feature set, using speech data and annotation from the IFA Dutch ""Open-Source"" and TIMIT English corpora. The primary objective of this research is to assess the AF classification performance of different multiclass generalizations of the SVM, including one-versus-rest, one-versus-one, Decision Directed Acyclic Graph, and direct methods for multiclass learning. Observing the successful application of SVMs to numerous classification problems, it is hoped that multiclass SVMs will outperform existing state-of-the-art AF classifiers.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-314.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
321,2006,Student Abstracts,Further Investigations into Regular XORSAT,Matti Järvisalo,"Recent years have witnessed rapid progress both in the foun- dations of and in applying state-of-art solvers for the propo- sitional satisfiability problem (SAT). The study of sources for hard SAT instances is motivated by the need for inter- esting benchmarks for solver development and on the other hand by theoretical analysis of different proof systems. In this respect satisfiable instance families are espe- cially interesting. In contrast to unsatis iable instance families, there are few theoretical results for satisfiable formulas; for the successful DPLL method, restricted heuristics need to be considered. While real-world problems serve as best benchmark in- stances in many sense, such instances are typically very large and unavailable in abundance. More artificial empirically hard satisfiable CNF families include regular random k-SAT, encodings of quasi-group completion, XORSAT models inspired by statistical physics, and the regular XORSAT model motivated by expansion properties of random regular bipartite graphs. Experimental comparison with other available generators for notably hard satisfiable 3-CNF formulas shows that the regular XORSAT model gives extremely hard instances for state-of-the art clausal SAT solvers. In this paper we generalize the regular XORSAT model for k > 3, and investigate how this relates to the hardness of the instances. By increasing the degree of the underlying regular constraint graphs, we observe a sharp increase in problem difficulty with respect to the number of variables, motivating further analysis of regular XORSAT.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-315.pdf,Subjects: 15.2 Constraint Satisfaction
322,2006,Student Abstracts,SemNews: A Semantic News Framework,"Akshay Java, Tim Finin, Sergei Niernburg","SemNews is a semantic news service that monitors different RSS news feeds and provides structured representations of the meaning of news. SemNews uses OntoSem Natural Language Processing system to understand the text, and exports the computed facts back to the Web in OWL.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-316.pdf,Subjects: 13. Natural Language Processing; 11. Knowledge Representation
323,2006,Student Abstracts,KDMAS: A Multi-Agent System for Knowledge Discovery via Planning,"Li Jin, Keith Decker","In the real world, there are some domain knowledge discovery problems that can be formulated into knowledge-based planning problems, such as chemical reaction process and biological pathway discovery problems. A view of these domain problems can be re-cast as a planning problem, such that initial and final states are known and processes can be captured as abstract operators that modify the environment. We believe that AI planning technology can provide a modeling formalism for this task such that hypotheses can be generated, tested, queried and qualitatively simulated to improve the domain knowledge and rules. Our approach is to build a general multi-agent system for knowledge discovery (KDMAS) via planning for any domain whose problems can be modeled as AI planning problems. The plans produced are hypotheses capturing relevant qualitative information regarding domain knowledge. We will use the biological pathway domain as a model to present our approach.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-317.pdf,Subjects: 1.11 Planning; 7.1 Multi-Agent Systems
324,2006,Student Abstracts,Kernel Methods for Word Sense Disambiguation and Acronym Expansion,"Mahesh Joshi, Ted Pedersen, Richard Maclin, Serguei Pakhomov","The scarcity of manually labeled data for supervised machine learning methods presents a significant limitation on their ability to acquire knowledge. The use of kernels in Support Vector Machines (SVMs) provides an excellent mechanism to introduce prior knowledge into the SVM learners, such as by using unlabeled text or existing ontologies as additional knowledge sources. Our aim is to develop three kernels ñ one that makes use of knowledge derived from unlabeled text, the second using semantic knowledge from ontologies, and finally a third, additive kernel consisting of the first two kernels ñ and study their effect on the tasks of word sense disambiguation and automatic expansion of ambiguous acronyms.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-318.pdf,Subjects: 13. Natural Language Processing; 10. Knowledge Acquisition
325,2006,Student Abstracts,Memeta: A Framework for Multi-Relational Analytics on the Blogosphere,"Pranam Kolari, Tim Finin","The memeta project is developing a framework for studying the structure and content of the blogosphere. We are particularly interested in how metadata about blogs can be discovered, extracted and computed, and how this metadata can be modeled, represented and analyzed to provide new blog related services.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-319.pdf,Subjects: 1.10 Information Retrieval; 12. Machine Learning and Discovery
326,2006,Student Abstracts,Automatic Heuristic Construction for General Game Playing,"Gregory Kuhlmann, Peter Stone","Creating programs that can play games such as chess, checkers, and backgammon, at a high level has long been a challenge and benchmark for AI. While several game-playing systems developed in the past, such as Deep Blue, Chinook, and TD-gammon have demonstrated competitive play against human players, such systems are limited in that they play only one particular game and they must be supplied with large amounts of expert knowledge. General Game Playing is the more challenging problem of designing an agent capable of playing many different previously unseen games. The first AAAI General Game Playing Competition was held at 2005 AAAI meeting in Pittsburgh in order to promote research in this area. We were one of nine participants in that competition. We survey some of the issues involved in creating a general game playing system and introduce our entry to that event. The main feature of our approach is a novel method for automatically constructing effective search heuristics based on the formal game description. Our agent is fully implemented and tested in a range of different games.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-320.pdf,Subjects: 1.8 Game Playing
327,2006,Student Abstracts,"How Many Different ""“John Smiths,” and Who Are They?","Anagha Kulkarni, Ted Pedersen",In this work we propose three unsupervised measures to automatically identify the number of distinct entities a given ambiguous name refers to in a corpus. We experiment with 22 artificially created name conflations and observe that the measure (PK2) formulated as the ratio of two successive clustering criterion function values outperforms the other two measures. We also describe a method to assign a unique label to each discovered cluster so as to identify the underlying entity that it refers to.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-321.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
328,2006,Student Abstracts,Population and Agent Based Models for Language Convergence,"Kiran Lakkaraju, Les Gasser","Adaptive agents cooperating in rich, open environments will need shared ontologies and linguistic conventions to communicate critical information. In the face of open systems and environmental change, pre-defined ontologies are sub-optimal. In open systems, new agents or web services can require new conventions not captured in existing conceptualizations. A more adaptive and more theoretically interesting approach is to have agents negotiate repertoires of categories, meanings, and linguistic forms among themselves. Many related issues arise in the general arena of ""emergent semantics""; the case of language serves as an excellent ""model organism"" for studying the issues, and results generalize nicely to other domains including ""collaborative tagging"" and bioinformatics. In this paper we look at two approaches to the ""language convergence"" problem, the population based approach and the agent based approach. We are investigating a middle ground between these two approaches that will incorporate the generalizability and tractability of population based models with the fine-grained control that Multi-Agent Systems based models provide.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-322.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
329,2006,Student Abstracts,Boot Camp for Cognitive Systems,Douglas S. Lange,"With traditional engineering projects, evaluation can be done in a straightforward manner determining if the documented requirements of the system have been met. Agent-based capabilities and other network centric capabilities complicate matters because the environment that they will operate under constantly changes. Add to that complication, the ability to learn new capabilities, and testing whether or not a new agent is ready to be deployed becomes a problem beyond the current state of art and practice. In this paper an initial experiment design is discussed as well as a description of a broader approach for evaluation in transitioning cognitive systems that learn into an operational environment.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-323.pdf,Subjects: 12. Machine Learning and Discovery; 2. Architectures
330,2006,Student Abstracts,Algorithms for Control and Interaction of Large Formations of Robots,"Ross Mead, Jerry B. Weinberg",NSF and NASA sponsored a workshop to discuss harvesting solar power in space. One solution considered was the use of a swarm of robots to form a solar reflector. How can these robots organize to form a large parabolic structure and be effectively controlled? The approach of this project is to treat the formation as a lattice of cells. Each cell is in one of a given state governed by a set of rules. A command that indicates the geometric formation is sent to a seed robot; the formation would then transform as neighbors attain their calculated relationship based on the formation definition.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-324.pdf,Subjects: 17. Robotics; 15.4 Reactive Control
331,2006,Student Abstracts,Learning of Agents with Limited Resources,Slawomir Nowaczyk,"In our research we investigate rational agent which consciously balances deliberation and acting, and uses learning to augment its reasoning. It creates several partial plans, uses past experience to choose the best one and, by executing it, gains new knowledge about the world. We analyse a possible application of Inductive Logic Programming to learn how to evaluate partial plans in a resource-constrained way. We also discuss how ILP framework can generalise partial plans.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-325.pdf,Subjects: 2. Architectures; 12. Machine Learning and Discovery
332,2006,Student Abstracts,Unsupervised Order-Preserving Regression Kernel for Sequence Analysis,Young-In Shin,"In this work, a generalized method for learning from sequence of unlabelled data points based on unsupervised order-preserving regression is proposed. Sequence learning is a fundmental problem, which covers a wide area of research topic including, e.g. handwritten character recognition or speech and natural language processing, to name a few. For this, one may compute feature vectors from sequence and learn a function in feature space or directly match sequence using methods like dynamic time warping. The former approach is not general in that they rely on the sets of application dependent features, while, in the latter, matching is often inefficient or ineffective. Our method takes the latter approach, while providing a very simple and robust matching. Results obtained from applying our method on a few different types of data show that training and testing take significantly less time, while accuracy is enhanced or comparable.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-326.pdf,Subjects: 12. Machine Learning and Discovery; 11. Knowledge Representation
333,2006,Student Abstracts,Curiosity-Driven Exploration with Planning Trajectories,Tyler Streeter,"Reinforcement learning (RL) agents can reduce learning time dramatically by planning with learned predictive models. Such planning agents learn to improve their actions using planning trajectories, sequences of imagined interactions with the environment. However, planning agents are not intrinsically driven to improve their predictive models, which is a necessity in complex environments. This problem can be solved by adding a curiosity drive that rewards agents for experiencing novel states. Curiosity acts as a higher form of exploration than simple random action selection schemes because it encourages targeted investigation of interesting situations. In a task with multiple external rewards, we show that RL agents using uncertainty-limited planning trajectories and intrinsic curiosity rewards outperform non-curious planning agents. The results show that curiosity helps drive planning agents to improve their predictive models by exploring uncertain territory. To the author’s knowledge, no previous work has tested the benefits of curiosity with planning trajectories.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-327.pdf,Subjects: 12.1 Reinforcement Learning; 1.11 Planning
334,2006,Student Abstracts,Expectation-Based Vision for Self-Localization on a Legged Robot,"Daniel Stronger, Peter Stone","This paper presents and empirically compares solutions to the problem of vision and self-localization on a legged robot. Specifically, given a series of visual images produced by a camera on-board the robot, how can the robot effectively use those images to determine its location over time? Legged robots, while generally more robust than wheeled robots to locomotion in various terrains~\cite{Wettergreen96}, pose an additional challenge for vision, as the jagged motion caused by walking leads to unusually sharp motion in the camera image. This paper considers two main approaches to this vision and localization problem, which we refer to as the object detection approach and the expectation-based approach. In both cases, we assume that the robot has complete, a priori knowledge of the three-dimensional layout of its environment. These two approaches are described in the following section. They are implemented and compared on a popular legged robotic platform, the Sony Aibo ERS-7. This paper's contributions are an exposition of two competing approaches to vision and localization on a legged robot and an empirical comparison of the two methods.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-328.pdf,Subjects: 19.1 Perception; 17. Robotics
335,2006,Student Abstracts,Inter-Task Action Correlation for Reinforcement Learning Tasks,"Matthew E. Taylor, Peter Stone",None - 2 page paper is an abstract,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-329.pdf,Subjects: 12.1 Reinforcement Learning
336,2006,AAAI / SIGART Doctoral Consortium,A Value Theory of Meta-Learning Algorithms,Abraham Bagherjeiran,We use game theory to analyze meta-learning algorithms. The objective of meta-learning is to determine which algorithm to apply on a given task. This is an instance of a more general problem that consists of allocating knowledge consumers to learning producers. Solving this general problem in the field of meta-learning yields solutions for related fields such as information retrieval and recommender systems.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-330.pdf,Subjects: 12. Machine Learning and Discovery; 1.10 Information Retrieval
337,2006,AAAI / SIGART Doctoral Consortium,A Computational Model of Narrative Generation for Suspense,Yun-Gyung Cheong,This paper doesn't have an abstract due to its space limitation. Please let me know if the abstract is required.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-331.pdf,Subjects: 6.4 Virtual Reality; 1.1 Art And Music
338,2006,AAAI / SIGART Doctoral Consortium,Multi-Resolution Learning for Knowledge Transfer,Eric Eaton,"Related objects may look similar at low-resolutions; differences begin to emerge naturally as the resolution is increased. By learning across multiple resolutions of input, knowledge can be transfered between related objects. My dissertation develops this idea and applies it to the problem of multitask transfer learning.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-332.pdf,Subjects: 12. Machine Learning and Discovery; 19.1 Perception
339,2006,AAAI / SIGART Doctoral Consortium,Learning Models of Macrobehavior in Complex Adaptive Systems,Andrew Fast,"Computational systems often exhibit complex aggregate behaviors, called macrobehaviors, which arise over time from interactions of the individual entities in the system. Macrobehaviors are often not well understood and are difficult to identify and predict without automated tools; however, to date there are very few statistical tools designed for this purpose. In this thesis, I will develop a new class of models for relational data called compositional models that consider the characteristics of aggregations of individuals in addition to the individual attributes and structure present in the data.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-333.pdf,Subjects: 12. Machine Learning and Discovery; 7.1 Multi-Agent Systems
340,2006,AAAI / SIGART Doctoral Consortium,"Techniques for Generating Optimal, Robust Plans when Temporal Uncertainty is Present",Janae N. Foss,"Planning under uncertainty has been well studied, but usually the uncertainty is in action outcomes. This work instead investigates uncertainty in the amount of time that actions require to execute. In addition to this temporal uncertainty, the problems being studied must have robust solution plans that are optimized based on an objective function. This thesis summary details two iterative approaches that have been used to solve these type of problems and discusses future work, including MDP approaches.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-334.pdf,Subjects: 1.11 Planning; 3.6 Temporal Reasoning
341,2006,AAAI / SIGART Doctoral Consortium,Automatic Summarization of Conversational Multi-Party Speech,Michel Galley,"My research interests lie in natural language processing, in particular text-to-text generation, summarization, machine translation, and computational models of syntax. My dissertation addresses the problem of generating abstractive summaries of meeting recordings, for which I am currently exploring probabilistic techniques that capitalize on discourse and syntax-level representations.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-335.pdf,Subjects: 13. Natural Language Processing; 13.3 Syntax
342,2006,AAAI / SIGART Doctoral Consortium,Privatizing Constraint Optimization,Rachel Greenstadt,"My thesis proposes novel schemes for achieving privacy in constraint optimization and new ways of analyzing the privacy properties of constraint optimization algorithms. Thus, it aims to contribute to the fields of constraint processing and multiagent systems.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-336.pdf,Subjects: 15.2 Constraint Satisfaction; 7.1 Multi-Agent Systems
343,2006,AAAI / SIGART Doctoral Consortium,Darshak — An Intelligent Cinematic Camera Planning System,Arnav Jhala,"A virtual camera is a powerful communicative tool in virtual environments. It is a window through which a viewer perceives the virtual world. For virtual environments with an underlying narrative component, there is a need for automated camera planning systems that account for the situational parameters of the interaction and not just the graphical arrangement of the virtual world. I propose a camera planning system called Darshak that takes as input a story in the form of sequence of events and generates a sequence of camera actions based on cinematic idioms. The camera actions, when executed in the virtual environment update a list of geometric constraints on the camera. A constraint solver then places the camera based on these constraints.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-337.pdf,Subjects: 13.1 Discourse; 1.11 Planning
344,2006,AAAI / SIGART Doctoral Consortium,Cross System Personalization by Learning Manifold Alignments,Bhaskar Mehta,"Today, personalization in digital libraries and other information systems occurs separately within each system that one interacts with. However, there are several potential improvements w.r.t. such isolated approaches. Investments of users in personalizing a system, either through explicit provision of information, or through long and regular use are not transferable to other systems. Moreover, users have little or no control over the information that defines their profile, since user profiles are deeply buried in personalization engines. Cross-system personalization, i.e. personalization that shares personalization information across different systems in a user-centric way, overcomes the aforementioned problems. Information about users, which is originally scattered across multiple systems, is combined to obtain maximum leverage. The key idea is that when a large number of users cross over from one system to another, carrying their user profiles with them, a mapping between the user profiles of the two systems can be discovered. In this work, we discuss the use of manifold learning for the purpose of computing recomendations for a new user crossing over from one system to another.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-338.pdf,Subjects: 12. Machine Learning and Discovery; 1.10 Information Retrieval
345,2006,AAAI / SIGART Doctoral Consortium,A Generalized Query Framework for Geospatial Reasoning,Martin Michalowski,"The ability to reason over geospatial entities using publicly available information is greatly enhanced by the abundance of data sources on the Internet. Traditional data sources such as satellite imagery, maps, gazetteers and vector data have long been used in geographic information systems (GIS). However, incorporating non-traditional sources such as phone books and property tax sites brings to light integration issues not previously considered. The ability to answer different types of queries about geospatial entities further complicates the problem. For example, assume we are provided with an image and consider the query ""What is the name of this street?"". There exist many different ways of answering this query depending on the types of data sources and operations available to a system. A mediator system could answer this query. However, in answering the query mentioned above, the traditional mediator would produce one plan of execution and assert that a valid plan produces an answer to the query. Yet, if during the execution of the plan an operation produces no data, we should have the recourse to abandon that plan and begin executing a different one. This capability is not available in current mediated systems and this research attempts to incorporate this type of reasoning into a generalized query-answering framework.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-339.pdf,Subjects: 3. Automated Reasoning; 1.11 Planning
346,2006,AAAI / SIGART Doctoral Consortium,Robust Autonomous Structure-based Color Learning on a Mobile Robot,Mohan Sridharan,This is a submission for the Doctoral Consortium - the paper itself is a 2-page extended abstract...,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-340.pdf,Subjects: 17. Robotics; 19. Vision
347,2006,AAAI / SIGART Doctoral Consortium,Closest Pairs Data Selection for Support Vector Machines,Chaofan Sun,"This paper presents data selection procedures for support vector machines (SVM). The purpose of data selection is to reduce the dataset by eliminating as many non support vectors (non-SVs) as possible. Based on the fact that support vectors (SVs) are those vectors close to the decision boundary, data selection keeps only the closest pair vectors of opposite classes. The selected dataset will replace the full dataset as the training component for any standard SVM algorithm.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-341.pdf,Subjects: 12. Machine Learning and Discovery; 15.7 Search
348,2006,AAAI / SIGART Doctoral Consortium,Action Selection in Bayesian Reinforcement Learning,Tao Wang,"My research attempts to address on-line action selection in reinforcement learning from a Bayesian perspective. The idea is to develop more effective action selection techniques by exploiting information in a Bayesian posterior, while also selecting actions by growing an adaptive, sparse lookahead tree. I further augment the approach by considering a new value function approximation strategy for the belief-state Markov decision processes induced by Bayesian learning.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-342.pdf,Subjects: 12. Machine Learning and Discovery; 12.1 Reinforcement Learning
349,2006,Intelligent Systems Demonstrations,SEMAPLAN: Combining Planning with Semantic Matching to Achieve Web Service Composition,"Rama Akkiraju, Rama Akkiraju1, Biplav Srivastava, Anca-Andreea Ivan, Richard Goodwin, Tanveer Syeda-Mahmood","In this paper, we present a novel algorithm to compose Web services in the presence of semantic ambiguity by combining semantic matching and AI planning algorithms. We use cues from domain-independent and domain-specific ontologies to compute an overall semantic similarity score between ambiguous terms. This semantic similarity score is used by AI planning algorithms to guide the searching process when composing services. Experimental results indicate that planning with semantic matching produces better results than planning or semantic matching alone. The solution is suitable for semi-automated composition tools or directory browsers.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-343.pdf,Subjects: 1.11 Planning; 1.10 Information Retrieval
350,2006,Intelligent Systems Demonstrations,An Interactive Constraint-Based Approach to Minesweeper,"Ken Bayer, Josh Snyder, Berthe Y. Choueiry",We present a Java applet that uses Constraint Processing (CP) techniques to assist a human in playing the popular game Minesweeper. Our goal is to illustrate the power of CP techniques to model and solve combinatorial problems. Our application allows the player to run 3 levels of consistency algorithms to uncover mined and safe squares on the board. This tool is useful to explain CP techniques in a context that is familiar to students and the general public.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-344.pdf,Subjects: 15.2 Constraint Satisfaction; 1.8 Game Playing
351,2006,Intelligent Systems Demonstrations,ScriptEase — Motivational Behaviors for Interactive Characters in Computer Role-Playing Games,"Maria Cutumisu, Duane Szafron, Jonathan Schaeffer, Kevin Waugh, Curtis Onuczko, Jeff Siegel, Allan Schumacher","ScriptEase is a tool that allows authors with no programming experience to create interactive stories for computer role-playing games. Instead of writing scripting code manually, game authors select design patterns that encapsulate frequent game scenarios, creating stories at a higher level of abstraction and being shielded from the underlying scripting language. ScriptEase has been extended to support behavior patterns that generate ambient behaviors for non-player characters. This demonstration shows how ScriptEase creates intricate non-player character scripts to generate compelling and engaging character behaviors. We demonstrate our ScriptEase motivational ambient and PC-interactive behaviors for a guard character using BioWare Corp.'s Neverwinter Nights game.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-345.pdf,Subjects: 6.1 Life-Like Characters; 1.8 Game Playing
352,2006,Intelligent Systems Demonstrations,LOCATE Intelligent Systems Demonstration: Adapting Help to the Cognitive Styles of Users,"Jack L. Edwards, Greg Scott","LOCATE is workspace layout design software that also serves as a testbed for developing and refining principles of adaptive aiding. This demonstration illustrates LOCATE's ability to determine user cognitive styles and provide help matched to those styles. To match LOCATE's help to users' cognitive styles, users are assessed along a Wholist-Analytic dimension and a Verbal-Imagery-Kinesthetic ""trimension"" and scoring places the user's style at a point in the resultant three-dimensional space. That information is stored in a User Model maintained by LOCATE and, whenever help is requested, material is provided in a form consistent with the system's inference about the user's cognitive style. Help options provided to users for selecting alternative forms of help permit the system to track those selections and allow for system adaptation to the user's preferred style of help.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-346.pdf,Subjects: 4. Cognitive Modeling; 1.6 Engineering And Science
353,2006,Intelligent Systems Demonstrations,SemNews: A Semantic News Framework,"Akshay Java, Tim Finin, Sergei Niernburg","SemNews is a semantic news service that monitors different RSS news feeds and provides structured representations of the meaning of news. As new content appears, SemNews extracts the summary from the RSS description and processes it using OntoSem, which is a sophisticated text understanding system. The extracted meaning from the RSS descriptions of the news articles are then converted into Semantic Web representation such as RDF.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-347.pdf,Subjects: 13. Natural Language Processing; 11. Knowledge Representation
354,2006,Intelligent Systems Demonstrations,An End-to-end Supervised Target-Word Sense Disambiguation System,"Mahesh Joshi, Serguei Pakhomov, Ted Pedersen, Richard Maclin, Christopher Chute","We present an extensible supervised Target-Word Sense Disambiguation system that leverages upon GATE (General Architecture for Text Engineering), NSP (Ngram Statistics Package) and WEKA (Waikato Environment for Knowledge Analysis) to present an end-to-end solution that integrates feature identification, feature extraction, preprocessing and classification.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-348.pdf,Subjects: 13. Natural Language Processing; 12. Machine Learning and Discovery
355,2006,Intelligent Systems Demonstrations,Strategic Sales Management in an Autonomous Trading Agent for TAC SCM,"Wolfgang Ketter, Eric Sodomka, Amrudin Agovic, John Collins, Maria Gini",We present methods for an autonomous agent to predict price distributions and price trends in the customer market of the Trading Agent Competition for Supply Chain Management. We describe how these predictions can then be used by the agent to make strategic and tactical sales decisions.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-349.pdf,Subjects: 7.1 Multi-Agent Systems; 7.2 Software Agents
356,2006,Intelligent Systems Demonstrations,Factored MDP Elicitation and Plan Display,"Krol K Mathias, Casey Lengacher,Derek Williams,Austin Cornett,Alex Dekhtyar,Judy Goldsmith","The software suite we will demonstrate at AAAI ’06 was designed around planning with factored Markov decision processes (MDPs). It is a user–friendly suite that facilitates domain elicitation, preference elicitation, planning, and MDP policy display. The demo will concentrate on user interactions for domain experts and those for whom plans are made.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-350.pdf,Subjects: 15.5 Decision Theory; 10. Knowledge Acquisition
357,2006,Intelligent Systems Demonstrations,Phoebus: A System for Extracting and Integrating Data from Unstructured and Ungrammatical Sources,"Matthew Michelson, Craig A. Knoblock","With the proliferation of online classifieds and auctions comes a new need to meaningfully search and organize the items for sale. However, since the seller's item descriptions are not structured and do not conform to a standard set of values (think ""Chevy"" versus ""Chevrolet""), searching and organizing this data is difficult. This paper describes a working demonstration of the Phoebus system which uses both record linkage and information extraction to parse out the meaningful attributes of an item description and assign them standard values. This allows the data to be sorted, searched and linked to other data sources where standard values for the attributes are required to link the sources together.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-351.pdf,Subjects: 1.10 Information Retrieval
358,2006,Intelligent Systems Demonstrations,Using the Semantic Web to Integrate Ecoinformatics Resources,"Cynthia Parr, Andriy Parafiynyk, Joel Sachs, Rong Pan, Lushan Han, Li Ding, Tim Finin, Joel Sachs","We demonstrate an end-to-end use case of the semantic web’s utility for synthesizing ecological and environmental data. ELVIS (the Ecosystem Location Visualization and Information System) is a suite of tools for constructing food webs for a given location. ELVIS functionality is exposed as a collection of web services, and all input and output data is expressed in OWL, thereby enabling its integration with other semantic web resources. In particular, we describe using a Triple Shop application to answer SPARQL queries from a collection of semantic web documents.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-352.pdf,Subjects: 7. Distributed AI; 11.2 Ontologies
359,2006,Intelligent Systems Demonstrations,Demonstration of Music Plus One — A Real-Time System for Automatic Orchestral Accompaniment,Christopher Raphael,"We demonstrate a system that creates a real-time accompaniment for a live musician performing a non-improvisatory piece of music. The system listens to the live player by performing a hidden Markov model analysis of the player's acoustic signal. A belief network uses this information, a musical score, and past rehearsals, to create a sequence of evolving predictions for future note-onsets in the soloist and accompaniment. These predictions are used to guide the time-stretched resynthesis of prerecorded orchestral audio using a phase vocoder.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-353.pdf,Subjects: 1.1 Art And Music; 3.4 Probabilistic Reasoning
360,2006,Intelligent Systems Demonstrations,Real-time Interactive Learning in the NERO Video Game,"Kenneth O. Stanley, Igor Karpov, Risto Miikkulainen, Aliza Gold","In the NeuroEvolving Robotic Operatives (NERO) video game, the player trains a team of virtual robots for combat against other players’ teams. The virtual robots learn in real time through interacting with the player. Since NERO was originally released in June, 2005, it has been downloaded over 50,000 times, appeared on Slashdot, and won several honors. The realtime NeuroEvolution of Augmenting Topologies (rtNEAT) method, which can evolve increasingly complex artificial neural networks in real time as a game is being played, drives the robots’ learning, making possible this entirely new genre of video game. The live demo will show how agents in NERO adapt in real time as they interact with the player. In the future, rtNEAT may allow new kinds of educational and training applications through interactive and adapting games.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-354.pdf,Subjects: 1.8 Game Playing; 1.9 Genetic Algorithms
361,2006,Intelligent Systems Demonstrations,The Tactical Language and Culture Training System: A Demonstration,"Andre Valente, W. Lewis Johnson, Hannes Vilhalmsson","In this demonstration we will present the Tactical Iraqi, one of the implementations of the Tactical Language and Culture Training System (TLTS). The system helps learners acquire basic communicative skills in foreign languages and cultures. Learners practice their communication skills in a simulated village, where they must develop rapport with the local people, who in turn will help them accomplish missions such as post-war reconstruction. Each learner is ac-companied by a virtual aide who can provide assistance and guidance if needed. The aide can also act as a virtual tutor as part of an intelligent tutoring system, giving the learners feedback on their performance. Learners communicate via a multimodal interface, which permits them to speak and choose gestures on behalf of their character in the game. The system employs video game technologies and design techniques, in order to motivate and engage learners.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-355.pdf,Subjects: 1.3 Computer-Aided Education; 6. Computer-Human Interaction
362,2006,Mobile Robot Competition and Exhibition Abstracts,The Keystone Scavenger Team,"Jacky Baltes, John Anderson","Stereo vision for small mobile robots is a challenging problem, particularly when employing embedded systems with limited processing power. However, it holds the promise of greatly increasing the localization, mapping, and navigation ability of mobile robots. To help in scene understanding, objects in the field of vision must be extracted and represented in a fashion useful to the system. At the same time, methods must be in place for dealing with the large volume of data that stereo vision produces, in order that a practical frame rate may be obtained. We have been working on stereo vision as the sole form of perception for Urban Search and Rescue (USAR) domains over the last three years. Recently, we have extended our work to include domains with more complex human robot interactions. Our entry in the 2006 AAAI Robotics competition embodies these ideas.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-356.pdf,Subjects: 17. Robotics; 19. Vision
363,2006,Mobile Robot Competition and Exhibition Abstracts,The Robot Intelligence Kernel,"David J. Bruemmer, Douglas A. Few, Miles C. Walton, Curtis W. Nielsen","The Robot Intelligence Kernel (RIK) is a portable, reconfigurable suite of perceptual, behavioral, and cognitive capabilities that can be used across many different platforms, environments, and tasks. The RIK coupled with a virtual 3D interface have been shown to dramatically improve human-robot interactions across a variety of navigation and exploration tasks.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-357.pdf,Subjects: 17. Robotics; 3. Automated Reasoning
364,2006,Mobile Robot Competition and Exhibition Abstracts,Introductory Computer Science with Robots,"Debra T. Burhans, R. Mark Meyer, Patricia VanVerth, David Puehn, Victoria Steck, John Paul Wiejaczka","Starting in the fall of 2005 our department began a large-scale effort to incorporate hands-on robotics in many of our courses, including our introductory computer science sequence. This followed the establishment of a departmental robotics laboratory and the purchase of a number of different robots. Our efforts include testing our projects and surveying students about their satisfaction with robots as well as significant software development of an algorithmic programming environment for robotics (Robotran) and an associated robot simulator.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-358.pdf,Subjects: 17. Robotics
365,2006,Mobile Robot Competition and Exhibition Abstracts,Using snarpy to Connect a KR System to Pyro,"Debra T. Burhans, Alistair E. R. Campbell","This work involves the development of a layered, heterogeneous architecture for cognitive robotics that can be used to connect a knowledge representation (KR) system to Pyro (Python robotics). We have focused on connecting a Semantic Network Processing System (SNePS) agent to a Pyro robot, however, the framework we have developed, snarpy (an architecture linking SNePS with Pyro), is extremely flexible and allows for the integration of any formal knowledge representation, reasoning, and acting system with Pyro.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-359.pdf,Subjects: 17. Robotics; 11. Knowledge Representation
366,2006,Mobile Robot Competition and Exhibition Abstracts,Erdos: Cost-effective Peripheral Robotics for AI Education,"Zachary Dodds, Ben Tribelhorn","This work combines hardware, software, and curricula in order to create robots capable enough to advance the field of AI yet inexpensive enough to be widely accessible. Costs are kept low by pairing iRobot’s roombas with existing laptop or palmtop computers and their accessories. The result is a sub-$200 untethered physical platform capable of running and testing state-of-the-art AI algorithms.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-360.pdf,Subjects: 17. Robotics; 1.3 Computer-Aided Education
367,2006,Mobile Robot Competition and Exhibition Abstracts,Object-Sorting-by-Color in a Variety of Lighting Conditions Using Neural Networks and Lego Mindstorms Robot,"Natasa Lazetic, Jianna Zhang","Recognizing object color in a variety of lighting conditions is a challenging area of pattern-recognition. Neural networks have been found to be a good solution for that problem, and they are also quick and accurate, and can be used in real-time. We use a LEGO Mindstorms [1] robot to sort objects based on color in a variety of lighting conditions. We will start from simpler objects (LEGO pieces) and move onto more complex objects (apples, oranges, etc). This project is in progress and we hope to achieve classification accuracies of at least 90%.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-361.pdf,Subjects: 17. Robotics; 14. Neural Networks
368,2006,Mobile Robot Competition and Exhibition Abstracts,Towards a Higher Level of Human-Robot Interaction and Integration,"Michaud Francois, Dominic Létourneau, Maxime Fréchette, Éric Beaudry, Carle Côté, Froduald Kabanza","Spartacus, our 2005 AAAI Mobile Robot Challenge entry, integrated planning and scheduling, sound source localization, tracking and separation, message reading, speech recognition and generation, and autonomous navigation capabilities onboard a custom made interactive robot. Integration of such a high number of capabilities revealed interesting new issues such as coordinating audio/visual/graphical capabilities, monitoring the impacts of the capabilities in usage by the robot, and inferring the robot’s intentions and goals. Our 2006 entry will be used to address these issues, to add new capabilities to the robot and to improve our software and computational architectures, with the objective of increasing, evaluating and improving our understanding of human-robot interaction and integration with an autonomous mobile platform.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-362.pdf,Subjects: 17. Robotics; 2. Architectures
369,2006,Mobile Robot Competition and Exhibition Abstracts,DIARC: A Testbed for Natural Human-Robot Interaction,"Paul Schermerhorn, James Kramer, Christopher Middendorff, Matthias Scheutz","Autonomous human-like robots that interact in natural language with people in real-time pose many design challenges, from the functional organization of the robotic architecture, to the computational infrastructure possibly employing middle-ware for distributed computing, to the hardware operating many specialized devices for sensory and effector processing in addition to embedded controllers and standard computational boards. The task is to achieve a functional integration of very diverse modules that operate at different temporal scales using different representations on parallel hardware in a reliable and fault-tolerant manner that allows for natural, believable human-robot interaction (HRI). To achieve reliable, natural interaction with humans, several challenging requirements must be met, two of which are (R1) appropriate interaction capabilities, including natural language capacity (speech recognition and speech production), dialog structure (knowledge about dialogs, teleological discourse, etc.), affect recognition and expression (both for speech as well as facial expressions), and mechanisms for non-verbal communication (via gestures, head movements, gaze, etc.); and (R2) mechanisms for ensuring robust interactions, including recovery from various communication failures (acoustic, syntactic, semantic misunderstandings, dialog failures, etc.) as well as software and hardware failure recovery (crashes of components, internal timing problems, faulty hardware, etc.).  We are developing DIARC, a distributed integrated affect, reflection, cognition architecture for robots that interact naturally with humans. DIARC is a complete architecture that can be employed for HRI experiments without any modifications--robot behaviors can be expressed simply by virtue of scripts that contain general knowledge about conversations and action sequences. DIARC provides several features that are critical for the study of natural human interaction that are not easily found in other robotic systems. Some of these features are described below, and will be featured in the 2006 AAAI Robot Competition and Exhibition. Specifically, the robot will participate in the following categories of the Human-Robot Interaction competition: emotion recognition and appropriate emotion expression, natural language understanding and action execution, perceptual learning, and the integration challenge.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-363.pdf,Subjects: 17. Robotics; 6. Computer-Human Interaction
370,2006,Mobile Robot Competition and Exhibition Abstracts,A Semi-Autonomous Interactive Robot,"Brian Schlesinger, Michael Mensch, Christopher Rindosh, Joe Vottal","Over the last ten months, we have been developing a robot capable of intelligent human-robot interaction. By employing relevant techniques such as speech recognition, natural language processing, and logic-based action, it was possible to design a robotic system capable of interacting with human beings.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-364.pdf,
371,2006,Mobile Robot Competition and Exhibition Abstracts,Collective Construction Using Lego Robots,"Crystal Schuil, Matthew Valente, Justin Werfel, Radhika Nagpal",Robot Exhibition Extended Abstract: We will be demonstrating a system of Lego robots that cooperate to form 2D structures from square building blocks. The robots communicate implicitly through the structure in a way analogous to stigmergy in social insects.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-365.pdf,Subjects: 17. Robotics; 7.1 Multi-Agent Systems
372,2006,Mobile Robot Competition and Exhibition Abstracts,Educational Robotics in Brooklyn,"Elizabeth Sklar, Simon Parsons, M.Q. Azhar, Valerie Andrewlevich","We describe a number of efforts to engage university students with robotics through teaching and outreach. Teaching runs the gamut from undergraduate introductory computer science to graduate-level artificial intelligence courses. Outreach involves collaborations between students and New York City public school classrooms. Our efforts have always involved team-based projects that culminate in demonstrations or competitions, usually based on challenges from RoboCupJunior. Several research projects have followed from these initiatives.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-366.pdf,Subjects: 17. Robotics; 1.3 Computer-Aided Education
373,2006,Mobile Robot Competition and Exhibition Abstracts,A Multi Agent Approach to Vision Based Robot Scavenging,"Kamil Wnuk, Brian Fulkerson, Jeremi Sudol","This paper proposes a design for our entry into the 2006 AAAI Scavenger Hunt Competition and Robot Exhibition. We will be entering a scalable two agent system consisting of off-the-shelf laptop robots, capable of monocular vision. Each robot will demonstrate the ability to localize itself, recognize a set of objects, and communicate with peer robots to share location and coordinate exploration.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-367.pdf,Subjects: 17. Robotics; 19. Vision
374,2006,AAAI Member Abstracts,Semantic Tagging at the Sense Level,"Alina Andreevskaia, Sabine Bergler",This paper summarizes our research in the area of semantic tagging at the word and sense levels and sets the ground for a new approach to text-level sentiment annotation using a combination of machine learning and linguistically-motivated techniques. We describe a system for sentiment tagging of words and senses based on WordNet glosses and advance the treatment of sentiment as a fuzzy category.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-368.pdf,Subjects: 13. Natural Language Processing
375,2006,AAAI Member Abstracts,Slashpack: An Integrated Tool for Gathering and Managing Hypertext Data,"Christopher H. Brooks, Christopher H. Brooks, Monica Agarwal, Jason Endo, Ryan King, Nancy Montanez, Rudd Stevens","Many interesting Web-based AI problems require the ability to collect,store and process large text datasets. To address this problem, we have developed Slashpack, an integrated toolkit for collecting and managing hypertext data. Currently, we are using Slashpack to study the effectiveness of tagging as a mechanism for organizing and searching blogs, and also to study community structure in the blogosphere.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-369.pdf,Subjects: 1.10 Information Retrieval; 8. Enabling Technologies
376,2006,AAAI Member Abstracts,Lookahead Pathology in Real-Time Path-Finding,"Vadim Bulitko, Mitja Lustrek","Path-finding tasks commonly require real-time response, which on large problems precludes the use of complete search methods such as A*. Incomplete single-agent search methods work similarly to minimax-based algorithms used in two-player games. They conduct a limited-depth lookahead search, i.e., expand a part of the space centered on the agent, and heuristically evaluate the distances from the frontier of the expanded space to the goal. Actions selected based on heuristic lookahead search are not necessarily optimal, but both in minimax search and in single-agent search it is generally believed that deeper lookahead increases the quality of decisions. Theoretical analyses of minimax have shown that the opposite is sometimes the case. This phenomenon has been termed the minimax pathology. Recently pathological behavior was observed in single-agent search as well. In this poster we investigate lookahead pathology in real-time path-finding on maps from commercial computer games. Pathology was experimentally observed in more than half of the 1,000 problems considered. This indicates that in single-agent search, pathological behavior is a practical issue - unlike in minimax search, where it seems to be mostly an artifact of the theoretical analyses.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-370.pdf,Subjects: 15.7 Search
377,2006,AAAI Member Abstracts,Explicit Passive Analysis in Electronic Catalogs,"David Portabella Clotet, Martin Rajman","We consider example-critiquing systems that help people search for their most preferred item in a large catalog. We first analyze how such systems can help users in the framework of three existing example-critiquing approaches (RABBIT, Incremental-critiquing and ATA). Afterwards we consider the use of several novel types of explicit passive analysis to guide the users in their search when their original query returns no hits. We suggest that a user-centric search system together with the right explicit passive analysis makes the users feel more confident in their decision and reduces session time and cognitive effort. Finally we present the results of a pilot study.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-371.pdf,Subjects: 6.3 User Interfaces; 1.7 Expert Systems
378,2006,AAAI Member Abstracts,A Negotiation Protocol for Agents with Nonlinear Utility Functions,"Takayuki Ito, Mark Klein, Hiromitsu Hattori","Multi-issue negotiation protocols have been studied widely and represent a promising field since most negotiation problems in the real world involve multiple issues. The vast majority of this work has assumed that negotiation issues are independent, so agents can aggregate the utilities of the issue values by simple summation, producing linear utility functions. In the real world, however, such aggregations are often unrealistic. We cannot, for example, just add up the value of car's carburetor and the value of car's engine when engineers negotiate over the design a car. These value of these choices are interdependent, resulting in nonlinear utility functions. In this paper, we address this important gap in current negotiation techniques. We propose a negotiation protocol where agents employ adjusted sampling to generate proposals, and an auction mechanism is used to find social-welfare maximizing deals. Our experimental results show that our method substantially outperforms existing methods in large nonlinear utility spaces like those found in real world contexts. Further, we show that our protocol is incentive compatible.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-372.pdf,Subjects: 7.1 Multi-Agent Systems; 7. Distributed AI
379,2006,AAAI Member Abstracts,A Decision-Theoretic Planner with Dynamic Component Reconfiguration for Distributed Real-Time Applications,"John S. Kinnebrew, Nishanth Shankaran, Gautam Biswas, Douglas C. Schmidt","Middleware is increasingly being used to develop and deploy components in large-scale distributed real-time and embedded (DRE) systems, such as the proposed NASA sensor web composed of networked remote sensing satellites, atmospheric, oceanic, and terrestrial sensors. Such a system must perform sequences of autonomous coordination and heterogeneous data manipulation tasks to meet specified goals. The efficacy and utility of the task sequences are governed by dynamic factors, such as data analysis results, changing goals and priorities, and uncertainties due to changing environmental conditions. These task sequences can be implemented in DRE systems using component middleware, which automates remoting, lifecycle management, system resource management, and deployment and configuration. To support such DRE systems, we developed the Spreading Activation Partial Order Planner (SA-POP) for dynamic (re)planning under uncertainty. SA-POP operates on a spreading activation network, whose structure captures the functional relationships between tasks (implemented as components) and system/environmental conditions (including goals). In this network, utility values capture the importance of desired goals, and probabilities capture the likelihood of tasks succeeding under different conditions. We use a novel partial-order planning and scheduling algorithm to extract a plan for a complete application from this network. We combine SA-POP with the Resource Allocation and Control Engine (RACE), which is a reusable component middleware framework including resource allocation and control algorithms to enforce quality of service (QoS) requirements. The combination of SA-POP and RACE promises an efficient and scalable architecture supporting autonomy in DRE systems operating in dynamic and uncertain domains.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-373.pdf,Subjects: 1.11 Planning; 1.12 Scheduling
380,2006,AAAI Member Abstracts,Using an Ontology for Knowledge Acquisition,"Stacy Lovell, Webb Stacy",We describe an approach to distributed knowledge acquisition using an ontology. The ontology is used to represent and reason about soldier performance. These methods are embedded in an immersive web based knowledge elicitation and analysis system.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-374.pdf,Subjects: 10. Knowledge Acquisition; 11.2 Ontologies
381,2006,AAAI Member Abstracts,PB-smodels a Pseudo-Boolean Solver,Gayathri Namasivayam,"We show that smodels, a solver originally designed to solve search problems encoded as logic programs can be used as a pseudo-boolean solver (we call it PB-smodels). We compare the performance of PB-smodels with pseudo-boolean solvers MiniSat+ and Pueblo on two benchmarks. We show that in many cases PB-smodels performs better than or is comparable to other solvers.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-375.pdf,Subjects: 15.2 Constraint Satisfaction; 11. Knowledge Representation
382,2006,AAAI Member Abstracts,Bayesian Network based Reparameterization of Haarlike Feature,Hirotaka Niitsuma,"Object detection using Haar-like features is formulated as a maximum likelihood estimation. Object features are described by an arbitrary Bayesian Network (BN) of Haar-like features. We proposed variable translation techniques transform the BN into the likelihood for the object detection. The likelihood is a BN which includes a node that represents the object's position, angle and scale. The object detection can be achieved by inference for the node.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-376.pdf,Subjects: 19. Vision; 4. Cognitive Modeling
383,2006,AAAI Member Abstracts,Locally Optimal Algorithms and Solutions for Distributed Constraint Optimization,Jonathan P. Pearce,"This paper summarizes the author's recent work in distributed constraint optimization (DCOP). New local algorithms, as well as theoretical results about the types of solutions that these algorithms can reach, are discussed.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-377.pdf,Subjects: 7.1 Multi-Agent Systems; 15.2 Constraint Satisfaction
384,2006,AAAI Member Abstracts,Wavelet Statistics for Human Motion Classification,"Kevin Quennesson, Elias Ioup, Charles Isbell",Human motion is as much characterized by its low frequency shape as by its high frequency temporal discontinuities � such as when a joint reaches its physical limit or when a foot touches the floor. Wavelets are particularly efficient at capturing both high and low frequency information. We introduce a method of classifying human motion using wavelet coefficients to build a representation of human motion signals. The representation is computed by finding the histograms of the wavelet coefficients previously scaled according to frequency. We use Support Vector Machines (SVMs) to classify those histograms and demonstrate the accuracy of the method on human motion gathered from both a motion capture systems and accelerometers.,https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-378.pdf,
385,2006,AAAI Member Abstracts,Evaluation of Solving Methods for Conditional Constraint Satisfaction Problems,"Mihaela Sabin, Esther Gelle","Conditional constraint satisfaction problems (CondCSPs) adequately capture problem change at solving time by conditionally identifying those variables and constraints that are relevant to final solutions. Real-world tasks with dynamic behavior, such as configuration, design, diagnosis, planning, and hardware test generation, have been modeled more naturally with CondCSPs. Such interest has been matched by the development of more effective algorithms that depart from classical backtracking and incorporate local consistency checking. Although performance results have been reported for these specialized algorithms, the experimental analysis has been conducted separately, using different test suites, and little is known about the algorithms' relative performance. In this abstract we present a CondCSP solver that implements direct and reformulation-based algorithms, each of which using forward checking and maintaining local consistency. In our experimental analysis we have considered randomly generated CondCSPs of diverse topologies in terms of problem density and satisfiability of the standard and conditional problem components. Execution time results show that there is not one winner but that reformulation solving in conjunction with forward checking performs better on problems with larger solution sets, while direct solving in conjunction with maintaining arc consistency is always preferred over direct solving using forward checking.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-379.pdf,Subjects: 15.2 Constraint Satisfaction; 15.7 Search
386,2006,AAAI Member Abstracts,Machine Life-Long Learning with csMTL Networks,"Daniel Silver, Ryan Poirier","A machine lifelong learning system is described that uses Context-sensitive Multiple Task Learning, or csMTL. csMTL, is a method of inductive transfer that uses a single output neural network and additional contextual inputs for learning multiple tasks. The approach satisfies a number of important requirements for knowledge retention and inductive transfer including the elimination of redundant outputs, representational transfer for rapid but effective short-term learning and functional transfer via task rehearsal for long-term consolidation. An implementation of the csMTL system is tested on a synthetic domain of six non-linearly separable classification tasks. The results indicate that representational transfer using a long-term consolidated csMTL network efficiently produces more effective hypotheses then previous MTL methods.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-380.pdf,Subjects: 12. Machine Learning and Discovery; 14. Neural Networks
387,2006,AAAI Member Abstracts,How to Put the Pieces of AI Together Again,Aaron Sloman,"Since the 1970s AI as a science has progressively fragmented into many activities that are very narrowly focused. It is not clear that work done within these fragments can be combined in the design of a human-like integrated system -- long held as one of the goals of AI as science. A strategy is proposed for reintegrating AI based around a backward-chaining analysis to produce a roadmap with partially ordered milestones, based on detailed scenarios, that everyone can agree are worth achieving, even when they disagree about means.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-381.pdf,Subjects: 4. Cognitive Modeling; 17. Robotics
388,2006,AAAI Member Abstracts,Decision Making in Uncertain Real-World Domains Using DT-Golog,"Mikhail Soutchanski, Huy Pham, John Mylopoulos","DTGolog, a decision-theoretic agent programming language based on the situation calculus, was proposed to ease some of the computational difficulties associated with Markov Decision Processes (MDPs) by using natural ordering constraints on execution of actions. Using DTGolog, domain specific constraints on a set of policies can be expressed in a high-level program to reduce significantly computations required to find a policy optimal in this set. We explore whether the DTGolog framework can be used to evaluate different designs of a decision making agent in a large real-world domain. Each design is understood as combination of a template (expressed as a Golog program) for available policies and a reward function. To evaluate and compare alternative designs we estimate the probability of goal satisfaction for each design. As a domain, we choose the London Ambulance Service (LAS) case study that is well known in software engineering, but remains unknown in AI. We demonstrate that DTGolog can be applied successfully to quantitative evaluation of alternative designs in terms of their ability to satisfy a system goal with a high probability. The full version of this paper includes a detailed axiomatization of the domain in the temporal situation calculus with stochastic actions. The main advantage of this representation is that neither actions, nor states require explicit enumeration. We do an experimental analysis using an on-line implementation of DTGolog coupled with a simulator that models real time actions of many external agents.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-382.pdf,Subjects: 1.4 Design; 1.11 Planning
389,2006,AAAI Member Abstracts,Integrating Clustering and Classification for Estimating Process Variables in Materials Science,"Aparna S. Varde, Elke A. Rundensteiner, Carolina Ruiz, David C. Brown, Mohammed Maniruzzaman and Richard D. Sisson Jr.","In domains such as Materials Science an experimental result is often plotted as a two-dimensional graph of process variables to aid visual analysis. Performing laboratory experiments with specified input conditions and plotting such graphs consumes significant time and resources motivating the need for computational estimation. The goals are to estimate the graph obtained in an experiment given its input conditions, and to estimate the conditions needed to obtain a desired graph. State-of-the-art estimation approaches do not meet the requirements in targeted applications. In this dissertation, an estimation approach, AutoDomainMine, is proposed. In AutoDomainMine, graphs obtained from existing experiments are clustered and decision tree classification is used to learn the clustering criteria in order to build representative pair of input conditions and graph per cluster. Given the conditions of a new experiment, the relevant decision tree path is then traced to estimate its cluster. The representative graph of that cluster is the estimated graph. Given a desired graph, the closest matching representative graph is found. The conditions of the corresponding representative pair are the estimated conditions. One sub-problem of this dissertation is preserving semantics of graphs during clustering. This is addressed through our proposed technique, LearnMet, to learn domain-specific distance metrics for graphs. LearnMet iteratively compares actual clusters of graphs given by experts with predicted clusters obtained from any fixed clustering algorithm. It guesses an initial metric as a weighted sum of metrics, adjusts it in each epoch using error between predicted and actual clusters until error is below threshold, and returns the metric giving lowest error. Another sub-problem is capturing relevant details of each cluster through its representative yet being concise. This is addressed by our proposed methodology, DesRept that designs domain-specific cluster representatives showing different levels of detail, e.g., medoid and summarized representatives and returns the winner determined using an MDL-based encoding. AutoDomainMine is evaluated in the Heat Treating domain that motivated this dissertation. Upon conducting user studies comparing the estimation with laboratory experiments, it is found that AutoDomainMine gives satisfactory estimation accuracy and efficiency. Applications of AutoDomainMine include our QuenchMiner decision support system, simulation tools and intelligent tutors.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-383.pdf,Subjects: 12. Machine Learning and Discovery; 10. Knowledge Acquisition
390,2006,AAAI Member Abstracts,"When Is Constrained Clustering Beneficial, and Why?","Kiri L. Wagstaff, Sugato Basu, Ian Davidson","Several researchers have shown that constraints can improve the results of a variety of clustering algorithms. However, there can be a large variation in this improvement, even for a fixed number of constraints for a given data set. We present the first attempt to provide insight into this phenomenon by characterizing two constraint set properties: informativeness and coherence. We show that these measures can help explain why some constraint sets are more beneficial to clustering algorithms than others. Since they can be computed prior to clustering, these measures can aid in deciding which constraints to use in practice.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-384.pdf,Subjects: 12. Machine Learning and Discovery; 15.2 Constraint Satisfaction
391,2006,AAAI Member Abstracts,Interpretation of Design Drawings by Analogy,"Patrick W. Yaner, Ashok K. Goel","We explore the interpretation of drawings by analogy, and specifically the interpretation of drawings of a design. Given a drawing of an as-yet unknown device, a representation of the shapes and spatial relations in the drawing can be structurally aligned with that of a drawing of a known device, and if they are sufficiently similar, a structural model of that device transferred to the new drawing. This provides not only an identification of what that drawing is of, but also assigns particular roles to each shape in terms of the structure, the causality and behavior, and the function of the device. This process of analogical mapping and transfer is, in general, very hard, and can be guided by the use of functional knowledge. The structural model is part of a structure-behavior-function (SBF) model of the source that is already known. The Archytas system implements this analogical method.",https://aaai.org/Library/AAAI/2006/../../../Papers/AAAI/2006/AAAI06-385.pdf,Subjects: 1.4 Design; 3.1 Case-Based Reasoning
