,conference_year,category,title,author,abstract,download_url,keywords
0,2007,Invited Speakers,Uncertainty in Preference Elicitation and Aggregation,Toby Walsh,"Uncertainty arises in preference aggregation in several ways. There may, for example, be uncertainty in the votes or the voting rule. Such uncertainty can introduce computational complexity in determining which candidate or candidates can or must win the election. In this paper, we survey recent work in this area and give some new results. We argue, for example, that the set of possible winners can be computationally harder to compute than the necessary winner. As a second example, we show that, even if the unknown votes are assumed to be single-peaked, it remains computationally hard to compute the possible and necessary winners, or to manipulate the election.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-001.pdf,"Subjects:  11. Knowledge Representation;
9.2 Computational Complexity"
1,2007,Invited Speakers,Logic for Automated Mechanism Design — A Progress Report,"Michael Wooldridge, Thomas Agotnes, Paul E. Dunne, Wiebe van der Hoek","Over the past half decade, we have been exploring the use of logic in the specification and analysis of computational economic mechanisms. We believe that this approach has the potential to bring the same benefits to the design and analysis of computational economic mechanisms that the use of temporal logics and model checking have brought to the specification and analysis of reactive systems.  In this paper, we give a survey of our work. We first discuss the use of cooperation logics such as Alternating-time Temporal Logic (ATL) for the specification and verification of mechanisms such as social choice procedures. We motivate the approach, and then discuss the work we have done on extensions to ATL to support incomplete information, preferences, and quantification over coalitions. We then discuss is the use of ATL-like cooperation logics in the development of social laws.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-002.pdf,"Subjects:  7.1 Multi-Agent Systems;
11. Knowledge Representation"
2,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Learning Equilibrium in Resource Selection Games,"Itai Ashlagi, Dov Monderer, Moshe Tennenholtz","We consider a resource selection game with incomplete information
about the resource-cost functions. All the players know is the set
of players, an upper bound on the possible costs, and that the cost
functions are positive and nondecreasing. The game is played
repeatedly and after every stage each player observes her cost, and
the actions of all players. For every ε>0 we prove the
existence of a learning ε-equilibrium, which is a profile
of algorithms, one for each player such that a unilateral deviation
of a player is, up to ε not beneficial for her regardless
of the actual cost functions. Furthermore, the learning equilibrium
yields an optimal social cost.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-003.pdf,"Subjects:  7.1 Multi-Agent Systems;
12.1 Reinforcement Learning"
3,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Action-Based Alternating Transition Systems for Arguments about Action,"Katie Atkinson, Trevor Bench-Capon","This paper presents a formalism to describe practical reasoning in terms of an Action-based Alternating Transition System (AATS). The starting point is a previously specified account of practical reasoning that treats reasoning about what action should be chosen as presumptive argumentation using argument schemes and associated critical questions. This paper describes how this account can be extended to situations where the effect of an action is partially dependent upon the choices of another agent. In this context we see practical reasoning as proceeding in three stages. The first involves determining the representation of the particular problem scenario as an AATS. Next the agent must resolve its uncertainties
as to its position in the scenario. Finally, the agent moves to choosing a particular action to achieve its ends, proposing presumptive reasons for particular actions and subjecting them to a critique to establish their suitability, taking into account the choices that can be made by the other agents involved. This account thus provides a well-specified basis for addressing the problems of practical reasoning as presumptive argumentation in a multi-agent context.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-004.pdf,"Subjects:  7.1 Multi-Agent Systems;
7.2 Software Agents"
4,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Implementing the Maximum of Monotone Algorithms,Liad Blumrosen,"Running several sub-optimal algorithms and choosing the optimal one is a common procedure in computer science, most notably in the design of approximation algorithms. This paper deals with one significant flaw of this technique in environments where the inputs are provided by selfish agents: such protocols are not necessarily incentive compatible even when the underlying algorithms are. We characterize sufficient and necessary conditions for such best-outcome protocols to be incentive compatible in a general model for agents with one-dimensional private data. We show how our techniques apply in several settings.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-005.pdf,"Subjects:  1.4 Design;
7. Distributed AI"
5,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Intention Guided Belief Revision,"Timothy W. Cleaver, Abdul Sattar","This paper aims to investigate methodologies to utilize an agent's intentions as a means to guide the revision of its beliefs. For this purpose, we develop a collection of belief revision operators that employ the effect of the revision on the agent's intentions as the selection criteria. These operators are then assessed for rationality against the traditional AGM postulates. There is a large volume of work concerned with classical belief revision, the primary issue of which is the mitigation of the uncertainty inherent in environments in which belief revision is necessary. Traditionall approaches attempt to assess the explanatory power of beliefs and utilize this as a heuristic to resolve this ambiguity. We argue that for practical reasoning systems, whose primary focus lies in the maintenance of behaviour and not information, an agent's intentions provide a better guide.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-006.pdf,"Subjects:  11. Knowledge Representation;
7.2 Software Agents"
6,2007,"Agents, Game Theory, Auctions, and Mechanism Design",The Impact of Network Topology on Pure Nash Equilibria in Graphical Games,"Bistra Dilkina, Carla P. Gomes, Ashish Sabharwal","Graphical games capture some of the key aspects relevant to the study and
design of multi-agent systems. It is often of interest to find the conditions
under which a game is stable, i.e., the players have reached a consensus on
their actions. In this paper, we characterize how different topologies of the
interaction network affect the probability of existence of a pure Nash
equilibrium in a graphical game with random payoffs. We show that for tree
topologies with unbounded diameter the probability of a pure Nash equilibrium
vanishes as the number of players grows large. On the positive side, we define
several families of graphs for which the probability of a pure Nash
equilibrium is at least 1 - 1/e even as the number of players goes to
infinity. We also empirically show that adding a small number of connection
""shortcuts"" can increase the probability of pure Nash.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-007.pdf,"Subjects:  1.8 Game Playing;
7.1 Multi-Agent Systems"
7,2007,"Agents, Game Theory, Auctions, and Mechanism Design","Potential-aware Automated Abstraction of Sequential Games, and Holistic Equilibrium Analysis of Texas Hold’em Poker","Andrew Gilpin, Tuomas Sandholm, Troels Bjerre Sørensen","We present a new abstraction algorithm for sequential imperfect information games. While most prior abstraction algorithms employ a myopic expected-value computation as a similarity metric, our algorithm considers a higher-dimensional space consisting of histograms over abstracted classes of states from later stages of the game. This enables our bottom-up abstraction algorithm to automatically take into account potential: a hand can become relatively better (or worse) over time and the strength of different hands can get resolved earlier or later in the game. We further improve the abstraction quality by making multiple passes over the abstraction, enabling the algorithm to narrow the scope of analysis to information that is relevant given abstraction decisions made for earlier parts of the game. We also present a custom indexing scheme based on suit isomorphisms that enables one to work on significantly larger models than before.
We apply the techniques to heads-up limit Texas Hold'em poker. Whereas all prior game theory-based work for Texas Hold'em poker used generic off-the-shelf linear program solvers for the equilibrium analysis of the abstracted game, we make use of a recently developed algorithm based on the excessive gap technique from convex optimization. This paper is, to our knowledge, the first to abstract and game-theoretically analyze all four betting rounds in one run (rather than splitting the game into phases). The resulting player, GS3, beats BluffBot, GS2, Hyperborean, Monash-BPP, Sparbot, Teddy, and Vexbot, each with statistical significance. To our knowledge, those competitors are the best prior programs for the game.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-008.pdf,"Subjects:  7.1 Multi-Agent Systems;
1.8 Game Playing"
8,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Automated Online Mechanism Design and Prophet Inequalities,"MohammadTaghi Hajiaghayi, Robert Kleinberg, Tuomas Sandholm","Recent work on  online auctions for digital goods has explored the role of optimal stopping theory --- particularly secretary problems --- in the design of approximately optimal online mechanisms.  This work generally assumes that the size of the market (number of bidders) is known a priori, but that the mechanism designer has no knowledge of the distribution of bid values.  However, in many real-world applications (such as online ticket sales), the opposite is true: the seller has distributional knowledge of the bid values (e.g., via the history of past transactions in the market), but there is uncertainty about market size. Adopting the perspective of automated mechanism design, introduced by Conitzer and Sandholm, we develop algorithms that compute an optimal, or approximately optimal, online auction mechanism given access to this distributional knowledge.  Our main results are twofold.  First, we show that when the seller does not know the market size, no constant-approximation to the optimum efficiency or revenue is achievable in the worst case, even under the very strong assumption that bid values are i.i.d. samples from a distribution

known to the seller.  Second, we show that when the seller has

distributional knowledge of the market size as well as the bid

values, one can do well in several senses.  Perhaps most interestingly, by combining dynamic programming with prophet inequalities (a technique from optimal stopping theory) we are able to design and analyze online mechanisms which are temporally strategyproof (even with respect to arrival and departure times) and approximately efficiency(revenue)-maximizing. In exploring the interplay between automated mechanism design and prophet inequalities, we prove new prophet inequalities motivated by the auction setting.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-009.pdf,"Subjects:  7.1 Multi-Agent Systems;
9.3 Mathematical Foundations"
9,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Real Arguments are Approximate Arguments,Anthony Hunter,"There are a number of frameworks for modelling argumentation in logic. They incorporate a formal representation of individual arguments and techniques for comparing conflicting arguments. A common assumption for logic-based argumentation is that an argument is a pair (X,p) where X is minimal subset of the knowledgebase such that X is consistent and X entails the claim p. However, real arguments (i.e. arguments presented by humans) usually do not have enough explicitly presented premises for the entailment of the claim. This is because there is some common knowledge that can be assumed by a proponent of an argument and the recipient of it. This allows the proponent of an argument to encode an argument into a real argument by ignoring the common knowledge, and it allows a recipient of a real argument to decode it into an argument by drawing on the common knowledge. If both the proponent and recipient use the same common knowledge, then this process is straightforward. Unfortunately, this is not always the case, and raises the need for an approximation of the notion of an argument for the recipient to cope with the disparities between the different views on what constitutes common knowledge.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-010.pdf,"Subjects:  3.3 Nonmonotonic Reasoning;
11. Knowledge Representation"
10,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Partial Revelation Automated Mechanism Design,"Nathanael Hyafil, Craig Boutilier","In most mechanism design settings, optimal general-purpose mechanisms
are not known. Thus the automated design of mechanisms tailored to
specific instances of a decision scenario is an important
problem. Existing techniques for automated mechanism design (AMD) require
the revelation of full utility information from agents, which can be
very difficult in practice.
In this work, we study the automated design
of mechanisms that only require partial revelation of utilities. Each
agent's type space is partitioned into a finite set
of partial types, and agents (should) report the partial type within
which their full type lies. We provide a set of optimization routines
that can be combined to address the trade-offs between the amount of
communication, approximation of incentive properties, and objective value
achieved by a mechanism. This allows for the automated design of
partial revelation mechanisms with worst-case guarantees on
incentive properties for any objective function (revenue, social
welfare, etc.).",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-011.pdf,"Subjects:  7.1 Multi-Agent Systems;
7.1 Multi-Agent Systems"
11,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Computing Pure Nash Equilibria in Symmetric Action Graph Games,"Albert Xin Jiang, Kevin Leyton-Brown","We analyze the problem of computing  pure Nash equilibria in action
graph games (AGGs), which are a compact game-theoretic representation.
While the problem is NP-complete in general, for certain classes of
AGGs there exist polynomial time algorithms. We propose a
dynamic-programming approach that constructs equilibria of the game
from equilibria of restricted games played on subgraphs of the
action graph. In particular, if the game is symmetric and the action
graph has bounded treewidth, our algorithm determines the existence
of pure Nash equilibrium in polynomial time.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-012.pdf,"Subjects:  7.1 Multi-Agent Systems;
9.2 Computational Complexity"
12,2007,"Agents, Game Theory, Auctions, and Mechanism Design",A Unification of Extensive-Form Games and Markov Decision Processes,"H. Brendan McMahan, Geoffrey J. Gordon","We describe a generalization of extensive-form games that greatly increases representational power while still allowing efficient computation in the zero-sum setting.  A principal feature of our generalization is that it places arbitrary convex optimization problems at decision nodes, in place of the finite action sets typically considered.  The possibly-infinite action sets mean we must ""forget"" the exact action taken (feasible solution to the optimization problem), remembering instead only some statistic sufficient for playing the rest of the game optimally.  Our new model provides an exponentially smaller representation for some games; in particular, we show how to compactly represent (and solve) extensive-form games with outcome uncertainty and a generalization of Markov decision processes to multi-stage adversarial planning games.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-013.pdf,"Subjects:  1.8 Game Playing;
1.11 Planning"
13,2007,"Agents, Game Theory, Auctions, and Mechanism Design",An Ironing-Based Approach to Adaptive Online Mechanism Design in Single-Valued Domains,"David C. Parkes, Quang Duong","Online mechanism design considers the problem of sequential decision making in a multi-agent system with self-interested agents. The agent population is dynamic and each agent has private information about its value for a sequence of decisions. We introduce a method (``ironing"") to transform an algorithm for 
online stochastic optimization into one that is incentive-compatible. Ironing  achieves this by canceling decisions that violate a form of monotonicity.
The approach is applied to the Consensus algorithm and experimental
results in a resource allocation domain show that not many decisions need to be canceled and that the overhead of ironing is manageable.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-014.pdf,"Subjects:  7. Distributed AI;
9.3 Mathematical Foundations"
14,2007,"Agents, Game Theory, Auctions, and Mechanism Design",On the Reasoning Patterns of Agents in Games,"Avi Pfeffer, Ya'akov Gal","What reasoning patterns do agents use to choose their actions in
games?  This paper studies this question in the context of Multi-Agent Influence Diagrams (MAIDs).  It defines several kinds of reasoning patterns, and associates each with a pattern of paths in a MAID.  We asks the question, what reasoning patterns have to hold in order for an agent to care about its decision?  The answer depends on what strategies are considered for other agents' decisions.  We introduce a new solution concept, called well-distinguishing (WD) strategies, that captures strategies in which all the distinctions an agent makes really make a difference.
We show that when agents are playing WD strategies, all situations in which an agent cares about its decision can be captured by four
reasoning patterns.  We furthermore show that when one of these four patterns holds, there are some MAID parameter values such that the agent actually does care about its decision.  
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-015.pdf,"Subjects:  7.1 Multi-Agent Systems;
4. Cognitive Modeling"
15,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Learning Voting Trees,"Ariel D. Procaccia, Aviv Zohar, Yoni Peleg, Jeffrey S. Rosenschein","Binary voting trees provide a succinct representation for a large and prominent class of voting rules. In this paper, we investigate the PAC-learnability of this class of rules. We show that, while in general a learning algorithm would require an exponential number of samples, if the number of leaves is polynomial in the size of the set of alternatives then a polynomial training set suffices. We apply these results in an emerging theory: automated design of voting rules by learning.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-016.pdf,"Subjects:  7.1 Multi-Agent Systems;
12. Machine Learning and Discovery"
16,2007,"Agents, Game Theory, Auctions, and Mechanism Design",On the Benefits of Exploiting Underlying Goals in Argument-based Negotiation,"Iyad Rahwan, Philippe Pasquier, Liz Sonenberg, Frank Dignum","Interest-based negotiation (IBN) is a form of negotiation in which agents exchange information about their underlying goals, with a view to improving the likelihood and quality of a deal. While this intuition has been stated informally in much previous literature, there is no formal analysis of the types of deals that can be reached through IBN and how they differ from those reachable using (classical) alternating offer bargaining. This paper bridges this gap by providing a formal framework for analysing the outcomes of IBN dialogues, and begins by analysing a specific IBN protocol.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-017.pdf,"Subjects:  7.1 Multi-Agent Systems;
1.11 Planning"
17,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Revenue Monotonicity in Combinatorial Auctions,"Baharak Rastegari, Anne Condon, Kevin Leyton-Brown","Intuitively, one might expect that a seller's revenue from an

auction weakly increases as the number of bidders grows, as this

increases competition. However, it is known that for combinatorial auctions that use the VCG mechanism, a seller can sometimes increase revenue by dropping bidders. In this paper we investigate the extent to which this problem can  occur under other dominant-strategy combinatorial auction mechanisms. Our main result is that such failures of ""revenue monotonicity"" are not limited to mechanisms that achieve efficient allocations. Instead, they can occur under any dominant-strategy direct mechanism that sets prices using critical values, and that always chooses an allocation that cannot be augmented to make some bidder better off, while making none worse off.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-018.pdf,"Subjects:  7.1 Multi-Agent Systems;
15.9 Theorem Proving"
18,2007,"Agents, Game Theory, Auctions, and Mechanism Design",A Multi-Dimensional Trust Model for Heterogeneous Contract Observations,"Steven Reece, Alex Rogers, Stephen Roberts, Nicholas R. Jennings","In this paper we develop a novel probabilistic model of computational trust that allows agents to exchange and combine reputation reports over heterogeneous, correlated multi-dimensional contracts. We consider the specific case of an agent attempting to procure a bundle of services that are subject to correlated quality of service failures (e.g. due to use of shared resources or infrastructure), and where the direct experience of other agents within the system consists of contracts over different combinations of these services. To this end, we present a formalism based on the Kalman filter that represents trust as a vector estimate of the probability that each service will be successfully delivered, and a covariance matrix that describes the uncertainty and correlations between these probabilities. We describe how the agents’ direct experiences of contract outcomes can be represented and combined within this formalism, and we empirically demonstrate that our formalism provides significantly better trustworthiness estimates than the alternative of using separate single-dimensional trust models for each separate service (where information regarding the correlations between each estimate is lost).",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-019.pdf,"Subjects:  7. Distributed AI;
7.1 Multi-Agent Systems"
19,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Reasoning from Desires to Intentions: A Dialectical Framework,"Nicolás D. Rotstein,  Alejandro J. Garca, Guillermo R. Simari","Here, we define a framework where defeasible argumentation is used for reasoning about beliefs, desires and intentions. A dialectical filtering process is introduced to obtain a subset of the agent's desires containing only those that are achievable in the current situation. Different agents types can be defined in the framework affecting the way in which current desires are obtained.

The agent is provided with a set of intention rules that specifies under what conditions an intention could be achieved. When more than one intention is present, a policy will be used to choose among them. Thus, intention policies provide the agent with a mechanism for deciding which intention is selected in the current situation. Several application examples will be given.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-020.pdf,"Subjects:  7.1 Multi-Agent Systems;
3.3 Nonmonotonic Reasoning"
20,2007,"Agents, Game Theory, Auctions, and Mechanism Design",A Logic of Emotions for Intelligent Agents,"Bas R. Steunebrink, Mehdi Dastani, John-Jules Ch. Meyer","This paper formalizes a well-known psychological model of emotions in an agent specification language. This is done by introducing a logical language and its semantics that are used to specify an agent model in terms of mental attitudes including emotions. We show that our formalization renders a number of intuitive and plausible properties of emotions. We also show how this formalization can be used to specify the effect of emotions on an agent's decision making process. Ultimately, the emotions in this model function as heuristics as they constrain an agent's model.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-021.pdf,"Subjects:  4. Cognitive Modeling;
7.2 Software Agents"
21,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Valuation Uncertainty and Imperfect Introspection in Second-Price Auctions,"David R.M. Thompson, Kevin Leyton-Brown","In auction theory, agents are typically presumed to have perfect knowledge of their valuations. In practice, though, they may face barriers to this knowledge due to transaction costs or bounded rationality. Modeling and analyzing such settings has been the focus of much recent work, though a canonical model of such domains has not yet emerged. We begin by proposing a taxonomy of auction models with valuation uncertainty and showing how it categorizes previous work. We then restrict ourselves to single-good sealed-bid auctions, in which agents have (uncertain) independent private values and can introspect about their own (but not others') valuations through possibly costly and imperfect queries.  We investigate second-price auctions, performing equilibrium analysis for cases with both discrete and continuous valuation distributions. We identify cases where every equilibrium involves either randomized or asymmetric introspection. We contrast the revenue properties of different equilibria, discuss steps the seller can take to improve revenue, and identify a form of revenue equivalence across mechanisms.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-022.pdf,"Subjects:  7.1 Multi-Agent Systems;
Please choose a second document classification"
22,2007,"Agents, Game Theory, Auctions, and Mechanism Design",Reasoning about Bargaining Situations,Dongmo Zhang,This paper presents a logical axiomatization of bargaining solutions. A bargaining situation is described in propositional logic and the bargainers' preferences are quantified in terms of the logical structure of the bargaining situation. A solution to the n-person bargaining problems is proposed based on the maxmin rule over the degrees of bargainers' satisfaction. We show that the solution is uniquely characterized by four natural and intuitive axioms as well as three other fundamental assumptions. All the axioms and assumptions are represented in logical statements and most of them have a game-theoretic counterpart. The framework would help us to identify the logical and numerical reasoning behind bargaining processes.,https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-023.pdf,"Subjects:  15.1 Belief Revision;
7.1 Multi-Agent Systems"
23,2007,Constraints and Satisfiability,On Balanced CSPs with High Treewidth,"Carlos Ansótegui, Ramón Béjar, César Fernàndez, Carles Mateu","Tractable cases of the binary CSP are mainly divided in two classes: constraint language restrictions and constraint graph restrictions. To better understand and identify the hardest binary CSPs, in this work we propose methods to increase their hardness by increasing the balance of both the constraint language and the con- straint graph. The balance of a constraint is increased by maximizing the number of domain elements with the same number of occurrences. The balance of the graph is defined using the classical definition from graph theory. In this sense we present two graph models; a first graph model that increases the balance of a graph maximizing the number of vertices with the same degree, and a second one that additionally increases the girth of the graph, because a high girth implies a high treewidth, an important parameter for binary CSPs hardness. Our results show that our more balanced graph models and constraints result in harder instances when compared to typical random binary CSP instances, by several orders of magnitude. Also we detect, at least for sparse constraint graphs, a higher treewidth for our graph models.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-024.pdf,"Subjects:  15. Problem Solving;
15.2 Constraint Satisfaction"
24,2007,Constraints and Satisfiability,Inference Rules for High-Order Consistency in Weighted CSP,"Carlos Ansotegui, Maria L. Bonet, Jordi Levy, F. Manya","Recently defined resolution calculi for Max-SAT and signed Max-SAT
have provided a logical characterization of the solving techniques
applied by Max-SAT and WCSP solvers. In this paper we first define a new resolution rule, called signed Max-SAT parallel resolution, and prove that it is sound and complete for signed Max-SAT. Second, we define a restriction and a generalization of the previous rule called, respectively, signed Max-SAT i-consistency resolution and signed Max-SAT (i,j)-consistency resolution.  These rules have the following property: if a WCSP signed encoding is closed under signed Max-SAT i-consistency, then the WCSP is i-consistent, and if it is closed under signed Max-SAT (i,j)-consistency, then the WCSP is (i,j)-consistent. A new and practical insight derived from the
definition of these new rules is that algorithms for enforcing high
order consistency should incorporate an efficient and effective
component for detecting minimal unsatisfiable cores. Finally, we
describe an algorithm that applies directional soft consistency with the previous rules.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-025.pdf,"Subjects:  15.2 Constraint Satisfaction;
3. Automated Reasoning"
25,2007,Constraints and Satisfiability,Randomized Adaptive Spatial Decoupling For Large-Scale Vehicle Routing with Time Windows,"Pascal Van Hentenryck, Russell Bent","In recent years, the size of combinatorial applications and the need
  to produce high-quality solutions quickly have increased steadily,
  providing significant challenges for optimization algorithms. This
  paper addresses this issue for large-scale vehicle routing problems
  with time windows, a class of very difficult optimization problems
  involving complex spatial and temporal dependencies. It proposes a
  randomized adaptive spatial decoupling (RASD) scheme for
  vehicle routing with time windows in order to produce high-quality
  solutions quickly. Experimental results on hard instances with 1,000
  customers and 90 vehicles show that the RASD scheme,
  together with large neighborhood search, significantly improves the
  quality of the solutions under time constraints. Interestingly, the
  RASD scheme, when allowed to run longer, also improves the
  best available solutions in almost all the tested instances.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-026.pdf,"Subjects:  1. Applications;
1.12 Scheduling"
26,2007,Constraints and Satisfiability,Search Space Reduction and Russian Doll Search,"Kenil C. K. Cheng, Roland H. C. Yap","In a constraint optimization problem (COP), many feasible valuations lead to the same objective value.  This often means a huge search space and poor performance in the propagation between the objective and problem variables.  In this paper, we propose a different modeling and search strategy which focuses on the cost function.  We show that by constructing a dual model on the objective variables, we can get strong propagation between the objective variables and the problem variables which allows search on the objective variables.  We explain why and when searching on the objective variables can lead to large gains.  We present a new Russian Doll Search algorithm, ORDS, which works on objective variables with dynamic variable ordering.  Finally, we demonstrate using the hard Still-Life optimization problem the benefits of changing to the objective function model and ORDS.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-027.pdf,"Subjects:  15.2 Constraint Satisfaction;
15.7 Search"
27,2007,Constraints and Satisfiability,Using More Reasoning to Improve #SAT Solving,"Jessica Davies, Fahiem Bacchus","Many real-world problems, including inference in Bayes Nets, can be reduced to #SAT, the problem of counting the number of models of a propositional theory. This has motivated the need for efficient #SAT solvers. Currently, such solvers utilize a modified version of DPLL that employs decomposition and caching, techniques that significantly increase the time it takes to process each node in the search space. In addition, the search space is significantly larger than when solving SAT since we must continue searching even after the first solution has been found. It has previously been demonstrated that the size of a DPLL search tree can be significantly reduced by doing more reasoning at each node. However, for SAT the reductions gained are often not worth the extra time required. In this paper we verify the hypothesis that for #SAT this balance changes. In particular, we show that additional reasoning can reduce the size of a #SAT solver's search space, that this reduction cannot always be achieved by the already utilized technique of clause learning, and that this additional reasoning can be cost effective.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-028.pdf,"Subjects:  3. Automated Reasoning;
15.2 Constraint Satisfaction"
28,2007,Constraints and Satisfiability,Data Structures for Generalised Arc Consistency for Extensional Constraints,"Ian P. Gent, Chris Jefferson, Ian Miguel, Peter Nightingale","Extensional (table) constraints are an important tool for attacking
combinatorial problems with constraint programming. 
Recently there has been renewed interest in 
fast propagation algorithms for these constraints. 
We describe the use of two alternative data structures for maintaining
generalised arc consistency on extensional constraints. The first,
the Next-Difference list, is novel and has been developed with this application
in mind. The second, the trie, is well known but its use in this context is novel.
Empirical analyses demonstrate the efficiency of the resulting approaches, both 
in GAC-schema, and in the watched-literal table constraint in Minion.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-029.pdf,"Subjects:  15.2 Constraint Satisfaction;
15.7 Search"
29,2007,Constraints and Satisfiability,Approximate Counting by Sampling the Backtrack-free Search Space,"Vibhav Giridhar Gogate, Rina Dechter",We present a new estimator for counting the number of solutions of a Boolean satisfiability problem as a part of an importance sampling framework. The estimator uses the recently introduced SampleSearch scheme that is designed to overcome the rejection problem associated with distributions having a substantial amount of determinism. We show here that the sampling distribution of SampleSearch can be characterized as the backtrack free distribution and propose several schemes for its computation. This allows integrating SampleSearch into the importance sampling framework for approximating the number of solutions and also allows using SampleSearch for computing a lower bound measure on the number of solutions. Our empirical evaluation demonstrates the superiority of our new approximate counting schemes against recent competing approaches.,https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-030.pdf,"Subjects:  15. Problem Solving;
15.2 Constraint Satisfaction"
30,2007,Constraints and Satisfiability,Counting CSP Solutions Using Generalized XOR Constraints,"Carla P. Gomes, Willem-Jan van Hoeve, Ashish Sabharwal, Bart Selman","We present a general framework for determining the number of solutions
of constraint satisfaction problems (CSPs) with a high precision. Our
first strategy uses additional binary variables for the CSP, and
applies an XOR or parity constraint based method introduced previously
for Boolean satisfiability (SAT) problems. In the CSP framework, in
addition to the naive individual filtering of XOR constraints used in
SAT, we are able to apply a global domain filtering algorithm by
viewing these constraints as a collection of linear equalities over
the field of two elements. Our most promising strategy extends this
approach further to larger domains, and applies the so-called
generalized XOR constraints directly to CSP variables. This allows us
to reap the benefits of the compact and structured representation that
CSPs offer. We demonstrate the effectiveness of our counting framework
through experimental comparisons with the solution enumeration
approach (which, we believe, is the current best generic solution
counting method for CSPs), and with solution counting in the context
of SAT and integer programming.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-031.pdf,"Subjects:  15.2 Constraint Satisfaction;
3. Automated Reasoning"
31,2007,Constraints and Satisfiability,Compressing Configuration Data for Memory Limited Devices,"Esben R. Hansen, Peter Tiedemann","The paper introduces a new type of compression for decision diagram
 data structures, such as BDDs, MDDs and AOMDDs. The compression
 takes advantage of repeated substructures within the decision
 diagram in order to lessen redundancy beyond what is possible using
 simple subfunction sharing. The resulting compressed data structure
 allows traversal of the original decision diagram with no
 significant overhead. Specifically it allows the efficient
 computation of valid domains, that is, the assignments for each
 encoded variable that can participate in a solution, which is
 critical when the decision diagram is used to support an interactive
 configurator. We relate these results to applications for
 interactively configurable memory limited devices and give empirical
 results on the amount of saved space for a wide variety of
 instances.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-032.pdf,"Subjects:  15.2 Constraint Satisfaction;
11. Knowledge Representation"
32,2007,Constraints and Satisfiability,Interactive Configuration with Regular String Constraints,"Esben R. Hansen, Henrik Reif Andersen","In this paper we present a generalization of the problem of interactive
 configuration. The usual interactive configuration problem is the
 problem of, given some variables on small finite domains and an increasing
 set of assignment of values to a subset of the variables, to compute
 for each of the unassigned variables which values in its domain that
 participate in some solution for some assignment of values to the
 other unassigned variables.



In this paper we consider how to extend this scheme to handle infinite
 regular domains using string variables and constraints that involves
 regular-expression checks on the string variables. We first show how
 to do this by using one single DFA. Since this approach is vastly
 space consuming, we construct a data structure that simulates the
 large DFA and is much more space efficient. As an example a
 configuration problem on n string variables with only one solution
 in which each string variable is assigned a value of length k the
 former structure will use Omega(k^n) space whereas the latter only
 need O(kn). We also show how this framework can be combined with the
 recent BDD techniques to allow both boolean, integer and string
 variables in the configuration problem.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-033.pdf,"Subjects:  15.2 Constraint Satisfaction;
11. Knowledge Representation"
33,2007,Constraints and Satisfiability,Using Expectation Maximization to Find Likely Assignments for Solving CSP’s,"Eric Hsu, Matthew Kitching, Fahiem Bacchus, Sheila McIlraith","We present a new probabilistic framework for finding likely variable assignments in difficult constraint satisfaction problems. Finding such assignments is key to efficient search, but practical efforts have largely been limited to random guessing and heuristically designed weighting systems. In contrast, we derive a new version of Belief Propagation (BP) using the method of Expectation Maximization (EM). This allows us to differentiate between variables that are strongly biased toward particular values and those that are largely extraneous. Using EM also eliminates the threat of non-convergence associated with regular BP. Theoretically, the derivation exhibits appealing primal/dual semantics. Empirically, it produces an ""EMBP""-based heuristic for solving constraint satisfaction problems, as illustrated with respect to the Quasigroup with Holes domain.  EMBP outperforms existing techniques for guiding variable and value ordering during backtracking search on this problem.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-034.pdf,"Subjects:  15.2 Constraint Satisfaction;
3.4 Probabilistic Reasoning"
34,2007,Constraints and Satisfiability,Propagating Knapsack Constraints in Sublinear Time,"Irit Katriel, Meinolf Sellmann, Eli Upfal, Pascal Van Hentenryck","We develop an efficient incremental version of an existing cost-based filtering algorithm for the knapsack constraint. On a universe of n elements, m invocations of the algorithm require a total of O(n log n + m k log (n/k)) time, where k <= n depends on the specific knapsack instance. We show that the expected value of k is significantly smaller than n on several interesting input
distributions, hence while keeping the same worst-case complexity, on expectation the new algorithm is faster than the previously best
method which runs in amortized linear time. After a theoretical study, we introduce heuristic enhancements and demonstrate the new
algorithm's performance experimentally.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-035.pdf,"Subjects:  15.2 Constraint Satisfaction;
15. Problem Solving"
35,2007,Constraints and Satisfiability,Conservative Dual Consistency,"Christophe Lecoutre, Stephane Cardon, Julien Vion","Consistencies are properties of Constraint Networks (CNs) that can be exploited in order to make inferences.
When a significant amount of such inferences can be performed, CNs are much easier to solve. 
In this paper, we interest ourselves in relation filtering consistencies for binary constraints, i.e. consistencies that allow to identify inconsistent pairs of values.
We propose a new consistency called Dual Consistency (DC) and relate it to Path Consistency (PC).
We show that Conservative DC (CDC, i.e. DC with only relations associated with the constraints of the network considered) is more powerful, in terms of filtering, than Conservative PC (CPC).
Following the approach of Mac Gregor, we introduce an algorithm to establish (strong) CDC with a very low worst-case space complexity.
Even if the relative efficiency of the algorithm introduced to establish (strong) CDC partly depends on the density of the constraint graph, the experiments we have conducted show that, on many series of CSP instances, CDC is largely faster than CPC (up to more than one order of magnitude).
Besides, we have observed that enforcing CDC in a preprocessing stage can significantly speed up the resolution of hard structured instances.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-036.pdf,"Subjects:  15.2 Constraint Satisfaction;
15.7 Search"
36,2007,Constraints and Satisfiability,Transposition Tables for Constraint Satisfaction,"Christophe Lecoutre, Lakhdar Sais, Sebastien Tabary, Vincent Vidal","In this paper, a state-based approach for the Constraint Satisfaction Problem (CSP) is proposed. 
The key novelty is an original use of state memorization during search to prevent the exploration of similar subnetworks. 
Classical techniques to avoid the resurgence of previously encountered conflicts involve recording conflict sets. 
This contrasts with our state-based approach which records subnetworks -- a snapshot of some selected domains -- already explored.
This knowledge is later used to either prune inconsistent states or avoid recomputing the solutions of these subnetworks. 
Interestingly enough, the two approaches present some complementarity: different states can be pruned from the same partial instantiation or conflict set, whereas different partial instantiations can lead to the same state that needs to be explored only once.
Also, our proposed approach is able to dynamically break some kinds of symmetries (e.g. neighborhood interchangeability). 
The obtained experimental results demonstrate the promising prospects of state-based search.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-037.pdf,"Subjects:  15.2 Constraint Satisfaction;
15.7 Search"
37,2007,Constraints and Satisfiability,Multi-objective Russian Doll Search,"Emma Rollon, Javier Larrosa","Russian Doll Search (RDS) is a well-known algorithm for combinatorial optimization.  In this paper we extend it from mono-objective to multi-objective optimization. We demonstrate its practical applicability in the challenging multiple-orbit SPOT5 instances. Besides being much more efficient than any other alternatives, multi-objective RDS can solve an instance which could not have been solved previously.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-038.pdf,"Subjects:  15. Problem Solving;
15.2 Constraint Satisfaction"
38,2007,Constraints and Satisfiability,Learning to Solve QBF,"Horst Samulowitz, Roland Memisevic","We present a novel approach to solving Quantified Boolean Formulas (QBF) that combines a search-based QBF solver with machine learning techniques.
We show how classification methods can be used to predict run-times and to choose optimal heuristics both within a portfolio-based, and within a dynamic, online approach.
In the dynamic method variables are set to a truth value according to a scheme that tries to maximize the probability of successfully solving the remaining sub-problem efficiently. Since each variable assignment can drastically change the problem-structure, new heuristics are chosen dynamically, and a classifier 
is used online to predict the usefulness of each heuristic. Experimental results on a large corpus of example problems show the usefulness of our approach in terms of run-time as well as the ability to solve previously unsolved problem instances.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-039.pdf,"Subjects:  15.7 Search;
12. Machine Learning and Discovery"
39,2007,Constraints and Satisfiability,Solving a Stochastic Queueing Design and Control Problem Using Constraint Programming,"Daria Terekhov, J. Christopher Beck, Kenneth N. Brown","A facility with front room and back room operations has the option of hiring specialized or, more expensive, cross-trained workers. Assuming stochastic customer arrival and service times, we seek a smallest-cost combination of cross-trained and specialized workers satisfying constraints on the expected customer waiting time and expected number of workers in the back room.  A constraint programming approach using logic-based Benders' decomposition is presented. Experimental results demonstrate the strong performance of this approach across a wide variety of problem parameters. This paper provides one of the first links between queueing optimization problems and constraint programming.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-040.pdf,"Subjects:  15.2 Constraint Satisfaction;
3.4 Probabilistic Reasoning"
40,2007,Constraints and Satisfiability,Population-Based Simulated Annealing for Traveling Tournaments,"Pascal Van Hentenryck, Yannis Vergados","This paper reconsiders the travelling tournament problem, a complex
  sport-scheduling application which has attracted significant
  interest recently. It proposes a population-based simulated
  annealing algorithm with both intensification and
  diversification. The algorithm is organized as a series of simulated
  annealing waves, each wave being followed by a
  macro-intensification. The diversification is obtained through the
  concept of elite runs that opportunistically survive waves. A
  parallel implementation of the algorithm on a cluster of
  workstations exhibits remarkable results. It improves the best known
  solutions on all considered benchmarks, sometimes reduces the
  optimality gap by about 60%, and produces novel best solutions on
  instances that had been stable for several years.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-041.pdf,"Subjects:  15. Problem Solving;
15.2 Constraint Satisfaction"
41,2007,Constraints and Satisfiability,Synthesis of Constraint-Based Local Search Algorithms from High-Level Models,"Pascal Van Hentenryck, Laurent Michel","The lack of automation for local search hinders experimentation and
  adoption of these technologies and slows down scientific
  progress. This paper addresses this issue and shows how effective
  local search procedures can be automatically synthesized from
  high-level models. Experimental results suggest that the   synthesized
  procedures only induce a small loss in efficiency on a variety of
  realistic applications in sequencing, resource allocation, and
  facility location.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-042.pdf,"Subjects:  15. Problem Solving;
15.2 Constraint Satisfaction"
42,2007,Knowledge and Information Systems,"Learning by Reading: A Prototype System, Performance Baseline and Lessons Learned","Ken Barker, B. Agashe, S. Chaw, J. Fan, N. Friedland, M. Glass, J. Hobbs, E. Hovy, D. Israel, D.S. Kim, R. Mulkar-Mehta, S. Patwardhan, B. Porter, D. Tecuci, P. Yeh","A traditional goal of Artificial Intelligence research has been a system that can read unrestricted natural language texts on a given topic, build a model of that topic and reason over the model. Natural Language Processing advances in syntax and semantics have made it possible to extract a limited form of meaning from sentences. Knowledge Representation research has shown that it is possible to model and reason over topics in interesting areas of human knowledge. It is useful for these two communities to reunite periodically to see where we stand with respect to the common goal of text understanding.
  In this paper, we describe a coordinated effort among researchers from the Natural Language and Knowledge Representation and Reasoning communities. We routed the output of existing NL software into existing KR software to extract knowledge from texts for integration with engineered knowledge bases. We tested the system on a suite of roughly 80 small English texts about the form and function of the human heart, as well as a handful of ""confuser"" texts from other domains. We then manually evaluated the knowledge extracted from novel texts.
  Our conclusion is that the technology from these fields is mature enough to start producing unified machine reading systems. The results of our exercise provide a performance baseline for systems attempting to acquire models from text.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-043.pdf,"Subjects:  10. Knowledge Acquisition;
13. Natural Language Processing"
43,2007,Knowledge and Information Systems,A Temporal Mereology for Distinguishing between Integral Objects and Portions of Stuff,"Thomas Bittner, Maureen Donnelly","We develop a formal theory of mereology that includes relations that change over time. We show how this theory formalizes reasoning over domains of material objects, which include not only integral objects (my computer, your liver) but also portions of stuff (the water in your glass, the blood in a vial). In particular, we use different mereological summation relations to distinguish between the ways in which i) integral objects, ii) portions of unstructured, homogenous stuffs (e.g. the water in your glass), and iii) mixtures (the blood in a vial)  are linked to their parts over time.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-044.pdf,"Subjects:  11.2 Ontologies;
9.4 Philosophical Foundations"
44,2007,Knowledge and Information Systems,A Qualitative Approach to Multiple Fault Isolation in Continuous Systems,"Matthew Daigle, Xenofon Koutsoukos, Gautam Biswas","The multiple fault diagnosis problem is important, since the single fault assumption can lead to incorrect or failed diagnoses when multiple faults occur. It is challenging for continuous systems, because faults can mask or compensate each other's effects, and the solution space grows exponentially with the number of possible faults. We present a qualitative approach to multiple fault isolation in dynamic systems based on analysis of fault transient behavior. Our approach uses the observed measurement deviations and their temporal orderings to generate multiple fault hypotheses. The approach has polynomial space requirements and prunes diagnoses, resulting in an efficient online fault isolation scheme.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-045.pdf,"Subjects:  1.5 Diagnosis;
3.5 Qualitative Reasoning"
45,2007,Knowledge and Information Systems,Scalable Semantic Retrieval Through Summarization and Refinement,"Julian Dolby, Achille Fokoue, Aditya Kalyanpur, Aaron Kershenbaum, Edith Schonberg, Kavitha Srinivas, Li L Ma","Query processing of OWL-DL ontologies is intractable in the worst case, but we present a novel technique that in practice allows for efficient querying of ontologies with large Aboxes in secondary storage. We focus on the processing of instance retrieval queries, i.e., queries that retrieve individuals in the Abox which are instances of a given concept. Our technique uses summarization and refinement to reduce instance retrieval to a small relevant subset of the original Abox. We demonstrate the effectiveness of this technique in Aboxes with up to 7 million assertions. Our results are applicable to the very expressive description logic SHIN, which correspondes to OWL-DL minus nominals and datatypes.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-046.pdf,"Subjects:  11.1 Description Logics;
3. Automated Reasoning"
46,2007,Knowledge and Information Systems,Diagnosis of Discrete-Event Systems Using Satisfiability Algorithms,"Grastien Alban, Anbulagan, Jussi Rintanen, Elena Kelareva","The diagnosis of a discrete-event system is the problem of computing possible behaviors of the system given observations of  the actual behavior, and testing whether the behaviors are normal or  faulty. We show how the diagnosis problems can be translated into the propositional satisfiability problem (SAT) and solved
by algorithms for SAT. Our experiments demonstrate that current SAT algorithms can solve much bigger diagnosis problems than traditional diagnosis algorithms can.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-047.pdf,"Subjects:  1.5 Diagnosis;
15.9 Theorem Proving"
47,2007,Knowledge and Information Systems,On Capturing Semantics in Ontology Mapping,"Bo  Hu, Srinandan Dasmahapatra, Paul Lewis, Nigel Shadbolt","Ontology mapping is a complex and necessary task for many Semantic Web (SW) applications. The perspective users are faced with a number of challenges including the difficulties of capturing semantics. In this paper we present a three-dimensional ontology mapping model. This model reflects the engineering steps needed to materialise a versatile mapping system in order to meet the demands on semantic interoperability in the SW environment. We solidify the formalisation with specialised algorithms and we analyse their

effectiveness and performance by way of benchmark tests.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-048.pdf,"Subjects:  11.2 Ontologies;
11. Knowledge Representation"
48,2007,Knowledge and Information Systems,TableRank: A Ranking Algorithm for Table Search and Retrieval,"Ying Liu, Kun Bai, Prasenjit Mitra, C. Lee Giles","Tables are ubiquitous in web pages and scientific documents. With
the explosive development of the web, tables have become a valuable
information repository. Therefore, effectively and efficiently
searching tables becomes a challenge. Existing search engines do not provide satisfactory search results largely because the current
ranking schemes are inadequate for table search and automatic table
understanding and extraction are rather difficult in general. In
this work, we design and evaluate a novel table ranking algorithm -- TableRank to improve the performance of our table search
engine TableSeer. Given a keyword based table query,
TableRank facilities TableSeer to return the most
relevant tables by tailoring the classic vector space model.
TableRank adopts an innovative term weighting scheme by
aggregating multiple weighting factors from three levels: term,
table and document. The experimental results show that our table
search engine outperforms existing search engines on table search.
In addition, incorporating multiple weighting factors can
significantly improve the ranking results.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-049.pdf,"Subjects:  1.10 Information Retrieval;
11. Knowledge Representation"
49,2007,Knowledge and Information Systems,Representative Explanations for Over-Constrained Problems,"Barry O'Sullivan, Alexandre Papadopoulos, Boi Faltings and Pearl Pu","In many interactive decision making scenarios there is often no solution that
satisfies all of the user's preferences. The decision process can be helped by
providing explanations.
Relaxations show sets of consistent preferences
and, thus, indicate which preferences can be enforced, while exclusion sets show which
preferences can be relaxed to obtain a solution.
We propose a new approach to explanation based on the notion of a 
 representative set of explanations.
The size of the set of explanations we compute is exponentially
 more compact than that found using common approaches from the literature
 based on finding all minimal conflicts.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-050.pdf,"Subjects:  15.2 Constraint Satisfaction;
6. Computer-Human Interaction"
50,2007,Knowledge and Information Systems,L2R: a Logical method for Reference Reconciliation,"Fatiha Saïs, Nathalie Pernelle, Marie-Christine Rousset","The reference reconciliation problem consists in deciding
whether different identifiers refer to the same data,
i.e., correspond to the same world entity. The L2R system
exploits the semantics of a rich data model, which
extends RDFS by a fragment of OWL-DL and SWRL
rules. In L2R, the semantics of the schema is translated
into a set of logical rules of reconciliation, which are
then used to infer correct decisions both of reconciliation
and no reconciliation. In contrast with other approaches,
the L2R method has a precision of 100% by
construction. First experiments show promising results
for recall, and most importantly significant increases
when rules are added.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-051.pdf,"Subjects:  3. Automated Reasoning;
11.2 Ontologies"
51,2007,Knowledge and Information Systems,A Spectrum of Symbolic On-line Diagnosis Approaches,"Anika Schumann, Yannick Pencolé, Sylvie Thiebaux.","This paper deals with the monitoring and diagnosis of large
discrete-event systems.  The problem is to determine, on-line, all faults and states that explain the flow of observations.  Model-based diagnosis approaches that first compile the diagnosis information off-line suffer from space explosion, and those that operate on-line without any prior compilation have poor time performance.  Our contribution is a broader spectrum of approaches that suits applications with diverse time and space requirements. Approaches on this spectrum differ in the amount of reasoning and compilation performed off-line and therefore in the way they resolve the tradeoff between the space occupied by the compiled information and the time taken to produce a diagnosis. We tackle the space and time complexity of diagnosis by encoding all approaches in a symbolic framework based on binary decision diagrams. This allows for the compact representation of the compiled diagnosis information, and for its handling across many 
states at once rather than for each state individually.  Our experiments demonstrate the diversity and scalability of our symbolic methods spectrum, as well as its superiority over the corresponding enumerative implementations.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-052.pdf,"Subjects:  1.5 Diagnosis;
15.7 Search"
52,2007,Knowledge and Information Systems,Mining Web Query Hierarchies from Clickthrough Data,"Dou Shen, Min Qin, Weizhu Chen, Qiang Yang, Zheng Chen","In this paper, we propose to mine query hierarchies from clickthrough data, which is within the larger area of automatic acquisition of knowledge from the Web. When a user submits a query to a search engine and clicks on the returned Web pages, the user's understanding of the query as well as its relation to the Web pages is encoded in the clickthrough data. With millions of queries being submitted to search engines every day, it is both important and beneficial to mine the knowledge hidden in the queries and their intended Web pages. We can use this information in various ways, such as providing query suggestions and organizing the queries. In this paper, we plan to exploit the knowledge hidden in clickthrough logs by constructing query hierarchies, which can reflect the relationship among queries. Our proposed method consists of two stages: generating candidate queries and determining ""generalization/specialization"" relations between these queries in a hierarchy. We test our method on some labeled data sets and illustrate the effectiveness of our proposed solution empirically.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-053.pdf,"Subjects:  1.10 Information Retrieval;
13. Natural Language Processing"
53,2007,Knowledge and Information Systems,Posterior Probability Profiles for the Automated Assessment of the Recovery of Stroke Patients,"Gert Van Dijck, Jo Van Vaerenbergh, Marc M. Van Hulle.","Assessing recovery from stroke has been so far a time consuming procedure in which highly trained clinicians are required. This paper proposes a mechatronic platform which measures low forces and torques exerted by subjects. Class posterior probabilities are used as a quantitative and statistically sound tool to assess motor recovery from these force and torque measurements. The performance of the patients is expressed in terms of the posterior probability to belong to the class of normal subjects. The mechatronic platform together with the class posterior probabilities enables to automate motor recovery assessment without the need for highly trained clinicians. It is shown that the class posterior probability profiles are highly correlated, r ≈ 0.80, with the well-established Fugl-Meyer scale assessment in motor recovery. These results have been obtained through careful feature subset selection procedures in order to prune the large feature set being generated. The overall approach is general and can be applied to many other health monitoring systems where different categories (diseased vs. healthy) can be identified.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-054.pdf,"Subjects:  1.7 Expert Systems;
12. Machine Learning and Discovery"
54,2007,Knowledge and Information Systems,Learning Causal Models for Noisy Biological Data Mining: An Application to Ovarian Cancer Detection,"Ghim-Eng Yap, Ah-Hwee Tan, Hwee-Hwa Pang","Undetected errors in the expression measurements from

high-throughput DNA microarrays and protein spectroscopy could

seriously affect the diagnostic reliability in disease detection.

In addition to a high resilience against such errors, diagnostic

models need to be more comprehensible so that a deeper

understanding of the causal interactions among biological entities like genes and proteins may be possible. In this paper, we introduce a robust knowledge discovery approach that addresses

these challenges. First, the causal interactions among the genes

and proteins in the noisy expression data are discovered

automatically through Bayesian network learning. Then, the

diagnosis of a disease based on the network is performed using a

novel error-handling procedure, which automatically identifies the noisy measurements and accounts for their uncertainties during diagnosis. An application to the problem of ovarian cancer

detection shows that the approach effectively discovers causal

interactions among cancer-specific proteins. With the proposed

error-handling procedure, the network perfectly distinguishes

between the cancer and normal patients.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-055.pdf,"Subjects:  12. Machine Learning and Discovery;
3.4 Probabilistic Reasoning"
55,2007,Knowledge Representation and Logic,DL-Lite in the Light of First-Order Logic,"Alessandro Artale, Diego Calvanese, Roman Kontchakov, Michael Zakharyaschev","The use of ontologies in various application domains, such as Data  Integration, the Semantic Web, or ontology-based data management,  where ontologies provide the access to large amounts of data, is posing challenging requirements w.r.t. a trade-off between expressive power of a DL and efficiency of reasoning.  The logics of the DL-Lite family were specifically designed to meet such requirements and optimized w.r.t. the data complexity of answering complex types of queries.  In this paper we propose DL-Lite-bool, an extension of DL-Lite with full Booleans and number restrictions, and study the complexity of reasoning in DL-Lite-bool and its significant sub-logics.  We obtain our results, together with useful insights into the properties of the studied logics, by a novel reduction to the one-variable fragment of first-order logic. We study the computational complexity of satisfiability and subsumption, and the data complexity of answering positive existential queries (which extend unions of conjunctive queries).  Notably, we extend the LogSpace upper bound for the data comlexity of answering unions of conjunctive queries in DL-Lite to positive queries and to the possibility of expressing also number restrictions, and hence local functionality in the TBox.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-056.pdf,"Subjects:  11.1 Description Logics;
11. Knowledge Representation"
56,2007,Knowledge Representation and Logic,An Egalitarist Fusion of Incommensurable Ranked Belief Bases under Constraints,"Salem Benferhat, Sylvain Lagrue, Julien Rossit","In  the  last decade,  several  approaches  have  been proposed  for merging  multiple and potentially  conflicting  pieces of  information. Egalitarist  fusion  modes  privilege  solutions that  minimize  the (local) dissatisfaction  of  each  agent (source,  expert)  who  is involved  in  the  fusion   process. This  paper  proposes  useful strategies  for  an  egalitarist  fusion of  incommensurable  ranked belief bases  under constraints. We show that the  fusion process can equivalently be characterized either  by means of the notion of compatible ranked  bases, or by  means of a Pareto-like  ordering on the set  of  possible solutions. Lastly, rational  postulates  for our  merging operator are studied.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-057.pdf,"Subjects:  11. Knowledge Representation;
15.1 Belief Revision"
57,2007,Knowledge Representation and Logic,Possibilistic Causal Networks for Handling Interventions: A New Propagation Algorithm,"Salem Benferhat, Salma Smaoui","This paper contains two important contributions for the development of possibilistic causal networks. The first one concerns the representation of interventions in possibilistic networks. We provide the counterpart of the DO operator, recently introduced by Pearl, in possibility theory framework. We then show that interventions can equivalently be represented in different ways in possibilistic causal networks. The second main contribution is a new propagation algorithm for dealing with both observations and interventions. We show that our algorithm only needs a small extra cost for handling interventions and is more appropriate for handling sequences of observations and interventions.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-058.pdf,"Subjects:  11. Knowledge Representation;
9.1 Causality"
58,2007,Knowledge Representation and Logic,Prime Implicates and Prime Implicants in Modal Logic,Meghyn Bienvenu,"The purpose of this paper is to extend the notions of prime implicates and prime implicants to the basic modal logic K. We consider a number of different potential definitions of clauses and terms for K, which we evaluate with respect to their syntactic, semantic, and complexity-theoretic properties.  We then continue our analysis by comparing the definitions with respect to the properties of the notions of prime implicates and prime implicants that they induce. We provide algorithms and complexity results for the prime implicate generation and recognition tasks for the two most satisfactory definitions.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-059.pdf,"Subjects:  11. Knowledge Representation;
3. Automated Reasoning"
59,2007,Knowledge Representation and Logic,Equilibria in Heterogeneous Nonmonotonic Multi-Context Systems,"Gerhard Brewka, Thomas Eiter","We propose a general framework for multi-context reasoning which allows us to combine arbitrary monotonic and nonmonotonic logics. Nonmonotonic bridge rules are used to specify the information flow among contexts. We investigate several notions of equilibrium representing acceptable belief states for our multi-context systems. The approach generalizes the heterogeneous monotonic multi-context systems developed by F. Giunchiglia and colleagues as well as the homogeneous nonmonotonic multi-context systems of Brewka, Serafini and Roelofsen.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-060.pdf,"Subjects:  11. Knowledge Representation;
3.3 Nonmonotonic Reasoning"
60,2007,Knowledge Representation and Logic,Answering Regular Path Queries in Expressive Description Logics: An Automata-Theoretic Approach,"Diego Calvanese, Thomas Eiter, Magdalena Ortiz","Expressive Description Logics (DLs) have been advocated as formalisms for modeling the domain of interest in various application areas.  An important requirement is the ability to answer complex queries beyond instance retrieval, taking into account constraints expressed in a knowledge base.  We consider this task for positive existential path queries (which generalize conjunctive queries and unions thereof), whose atoms are regular expressions over the roles (and concepts) of a knowledge base in the expressive DL ALCQIbreg.  Using techniques based on two-way tree-automata, we first provide an elegant characterization of TBox and ABox reasoning, which gives us also a tight EXPTIME bound.  We then prove decidability (more precisely, a 2EXPTIMEN upper bound) of query answering, thus significantly pushing the decidability frontier, both with respect to the query language and the considered DL. We also show that query answering is EXPSPACE-hard already in rather restricted settings.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-061.pdf,"Subjects:  11.1 Description Logics;
9.2 Computational Complexity"
61,2007,Knowledge Representation and Logic,Approximate Query Answering in Locally Closed Databases,"Alvaro Cortes-Calabuig, Marc Denecker, Ofer Arieli, Maurice Bruynooghe","The Closed-World Assumption (CWA) on databases expresses that an atom not in the database is false. A more appropriate assumption for databases that are sound but partially incomplete, is the Local Closed-World Assumption (LCWA), which is a local form of the CWA, expressing that the database is complete in a certain area, called the window of expertise.  Databases consisting of a standard database instance augmented with a collection of LCWA's are called locally closed databases. In this paper, we investigate the complexity of certain and possible query answering in such databases.  As it turns out thatthese problems are intractable, we develop efficient approximate methods to underestimate certain answers and overestimate possible answers. We prove that under certain conditions, our methods produce complete answers.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-062.pdf,"Subjects:  11. Knowledge Representation;
9.3 Mathematical Foundations"
62,2007,Knowledge Representation and Logic,On the Approximation of Instance Level Update and Erasure in Description Logics,"Giuseppe De Giacomo, Maurizio Lenzerini, Antonella Poggi, Riccardo Rosati","A Description Logics knowledge base is constituted by two components, called TBox and ABox, where the former expresses general knowledge about the concepts and their relationships, and the latter describes the properties of instances of concepts. We address the problem of how to deal with changes to a Description Logic knowledge base, when these changes affect only its ABox. We consider two types of changes, namely update and erasure, and we characterize the semantics of these operations on the basis of the approaches proposed by Winslett and by Katsuno and Mendelzon. 
It is well known that, in general, Description Logics are not closed with respect to updates, in the sense that the set of models corresponding to an update applied to a knowledge base in a Description Logic L may not be expressible by ABoxes in L. We show that this is true also for erasure. To deal with this problem, we introduce the notion of best approximation of an update (erasure) in a DL L, with the goal of characterizing the L ABoxes that capture the update (erasure) at best. We then focus on $DL-Lite_{\cal F}$, a tractable Description Logic, and present polynomial algorithms for computing the best approximation of 
updates and erasures in this logic, which shows that the nice 
computational properties of $DL-Lite_{\cal F}$ are retained in dealing with the evolution of the ABox.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-063.pdf,"Subjects:  11.1 Description Logics;
11. Knowledge Representation"
63,2007,Knowledge Representation and Logic,Forgetting Actions in Domain Descriptions,"Esra Erdem, Paolo Ferraris","Forgetting irrelevant/problematic  actions in a domain description can be useful in solving reasoning problems, such as query answering, planning, conflict resolution, prediction, postdiction, etc.. Motivated by such applications, we study 

what forgetting is, how forgetting can be done, and for which applications forgetting can be useful and how, in the context of reasoning about actions. We study these questions in the action language C (a formalism based on causal explanations), and relate it to forgetting in classical logic and logic programming.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-064.pdf,"Subjects:  3. Automated Reasoning;
11. Knowledge Representation"
64,2007,Knowledge Representation and Logic,Discovering Near Symmetry in Graphs,"Maria Fox, Derek Long, Julie Porteous","Symmetry is a widespread phenomenon that can offer opportunities for powerful exploitation in areas as diverse as molecular chemistry, pure mathematics, circuit design, biology and architecture. Graphs are an abstract way to represent relational structures. The search for symmetry in many contexts can thus be reduced to the attempt to find graph automorphisms. Brendan McKay's {\sc Nauty} system is an example of one of the highly successful products of research into this task. Erd\H{o}s and R\'{e}nyi showed that almost all large graphs are asymmetric, but it is readily observed that many graphs representing structures of real interest contain symmetry. Even more graphs are {\em nearly} symmetric, in the sense that to each graph there is a closely similar graph that is symmetric. In this paper we explore the problem of finding near symmetries in graphs and describe the techniques we are developing for performing this task.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-065.pdf,"Subjects:  3. Automated Reasoning;
15.7 Search"
65,2007,Knowledge Representation and Logic,A Logical Theory of Coordination and Joint Ability,"Hojjat Ghaderi, Hector Levesque,  Yves Lesperance","A team of agents is jointly able to achieve a goal if despite any
incomplete knowledge they may have about the world or each other, they still know enough to be able to get to a goal state. Unlike in the single-agent case, the mere existence of a working plan is not enough as there may be several incompatible working plans and the agents may not be able to choose a share that coordinates with those of the others.  Some formalizations of joint ability ignore this issue of coordination within a coalition. Others, including those based on game theory, deal with coordination, but require a complete specification of what the agents believe. Such a complete specification is often not available. Here we present a new formalization of joint ability based on logical entailment in the situation calculus that avoids both of these pitfalls.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-066.pdf,"Subjects:  5. Common Sense Reasoning;
7.1 Multi-Agent Systems"
66,2007,Knowledge Representation and Logic,Belief Change and Cryptographic Protocol Verification,"Aaron Hunter, James P. Delgrande","Cryptographic protocols are structured sequences of messages that are used for exchanging information in a hostile environment.  Many protocols have epistemic goals: a successful run of the protocol is intended to cause a participant to hold certain beliefs.  As such, epistemic logics have been employed for the verification of cryptographic protocols.  Although this approach to verification is explicitly concerned with changing beliefs, formal belief change operators have not been incorporated in previous work.  In this paper, we introduce a new approach to protocol verification by combining a monotonic logic with a non-monotonic belief change operator.  In this context, a protocol participant is able to retract beliefs in response to new information and a protocol participant is able to postulate the most plausible event explaining new information.  We illustrate that this kind of reasoning is particularly important when protocol participants have incorrect beliefs.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-067.pdf,"Subjects:  15.1 Belief Revision;
1. Applications"
67,2007,Knowledge Representation and Logic,Generality and Equivalence Relations in Default Logic,"Katsumi Inoue, Chiaki Sakama","Generality or refinement relations between different theories 

have important applications to generalization in inductive 

logic programming, refinement of ontologies, and coordination 

in multi-agent systems.  

We study generality relations in disjunctive default logic by 

comparing the amounts of information brought by default 

theories.  Intuitively, a default theory is considered more 

general than another default theory if the former brings more 

information than the latter.  

Using techniques in domain theory, we introduce different types 

of generality relations over default theories.  

We show that generality relations based on the Smyth and Hoare 

orderings reflect orderings on skeptical and credulous 

consequences, respectively, and that two default theories are 

equivalent if and only if they are equally general under these 

orderings.  

These results naturally extend both generality relations over 

first-order theories and those for answer set programming.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-068.pdf,"Subjects:  3.3 Nonmonotonic Reasoning;
5. Common Sense Reasoning"
68,2007,Knowledge Representation and Logic,Mutual Belief Revision: Semantics and Computation,"Yi
 Jin, Michael Thielscher, Dongmo Zhang","This paper presents both a semantic and a computational model for
multi-agent belief revision. We show that these two models are
equivalent but serve different purposes. The semantic model displays the intuition and construction of the belief revision operation in multi-agent environments, especially in case of just two agents. The logical properties of this model provide strong
justifications for it. The computational model enables us to reassess the operation from a computational perspective. A
complexity analysis reveals that belief revision between two agents
is computationally no more demanding than single agent belief revision.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-069.pdf,"Subjects:  15.1 Belief Revision;
5. Common Sense Reasoning"
69,2007,Knowledge Representation and Logic,Measuring the Level of Transfer Learning by an AP Physics Problem-Solver,"Matthew Klenk, Ken Forbus","Transfer learning is the ability of an agent to apply knowledge learned in previous tasks to new problems or domains.  We approach this problem by focusing on model formulation, i.e., how to move from the unruly, broad set of concepts used in everyday life to a concise, formal vocabulary of abstractions that can be used effectively for problem solving.  This paper describes how the Companions cognitive architecture uses analogical model formulation to learn to solve AP Physics problems.  Our system starts with some basic mathematical skills, a broad common sense ontology, and some qualitative mechanics, but no equations.  Our system uses worked solutions to learn how to use equations and modeling assumptions to solve AP Physics problems.  We show that this process of analogical model formulation can facilitate learning over a range of types of transfer, in an experiment administered by the Educational Testing Service.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-070.pdf,"Subjects:  15. Problem Solving;
3.1 Case-Based Reasoning"
70,2007,Knowledge Representation and Logic,Complexity Boundaries for Horn Description Logics,"Markus Krötzsch, Sebastian Rudolph, Pascal Hitzler","Horn description logics (Horn-DLs) have recently started to
attract attention due to the fact that their (worst-case) data
complexities are in general lower than their overall (i.e. combined) complexities, which makes them attractive for reasoning with large ABoxes. However, the natural question whether Horn-DLs also provide advantages for TBox reasoning has hardly been addressed so far. In this paper, we therefore provide a thorough and comprehensive analysis of the combined complexities of Horn-DLs. While the combined complexity for many Horn-DLs turns out to be the same as for their non-Horn counterparts, we identify subboolean DLs where Hornness simplifies reasoning.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-071.pdf,"Subjects:  11.1 Description Logics;
9.2 Computational Complexity"
71,2007,Knowledge Representation and Logic,Facts Do Not Cease to Exist Because They Are Ignored: Relativised Uniform Equivalence with Answer-Set Projection,"Johannes Oetsch, Hans Tompits, Stefan Woltran","Recent research in answer-set programming (ASP) focuses on different notions of equivalence between programs which are relevant for program optimisation and modular programming. Prominent among these notions is uniform equivalence, which checks whether two programs have the same semantics when joined with an arbitrary set of facts. In this paper, we study a family of more fine-grained versions of uniform equivalence, where the alphabet of the added facts as well as the projection of answer sets is taken into account. The latter feature, in particular, allows the removal of auxiliary atoms in computation, which is important for practical programming aspects. We introduce novel semantic characterisations for the equivalence problems under consideration and analyse the computational complexity for checking these problems. We furthermore provide efficient reductions to quantified propositional logic, yielding a rapid-prototyping system for equivalence checking.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-072.pdf,"Subjects:  3.3 Nonmonotonic Reasoning;
9.2 Computational Complexity"
72,2007,Knowledge Representation and Logic,Learning Large Scale Common Sense Models of Everyday Life,"William Pentney, Matthai Philipose, Jeff Bilmes, Henry Kautz","Recent work has shown promise in using large, publicly available,
hand-contributed commonsense databases as joint models that 
can be used to infer human state from day-to-day sensor data. The
parameters of these models are mined from the web. We show in this
paper that learning these parameters using sensor data (with the mined
parameters as priors) can improve
performance of the models significantly. The primary challenge in
learning is scale. Since the model comprises roughly 50,000 irregularly
connected nodes in each time slice, it is intractable either to
completely label observed data manually or to compute the expected
likelihood of even a single time slice. We show how to solve the
resulting semi-supervised learning 
problem by combining a variety of conventional approximation
techniques and a novel technique for simplifying the model called context-based pruning. We show empirically that the learned model is
substantially better at interpreting sensor data and an detailed
analysis of how various techniques contribute to the performance.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-073.pdf,"Subjects:  5. Common Sense Reasoning;
12. Machine Learning and Discovery"
73,2007,Knowledge Representation and Logic,A Model-based Approach for Merging Prioritized Knowledge Bases in Possibilistic Logic,Guilin Qi,"This paper presents a new approach for merging prioritized
knowledge bases in possibilistic logic. Our approach is
semantically defined by a model-based merging operator in
propositional logic and the merged result of our approach is a
normal possibility distribution. We also give an algorithm
to obtain the syntactical counterpart of the semantic approach.
The logical properties of our approach are considered. Finally, we
analyze the computational complexity of our merging approach.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-074.pdf,"Subjects:  11. Knowledge Representation;
5. Common Sense Reasoning"
74,2007,Knowledge Representation and Logic,Description Logics for Multi-issue Bilateral Negotiation with Incomplete Information,"Azzurra Ragone, Tommaso Di Noia, Eugenio Di Sciascio, Francesco M. Donini","We propose a framework for multi-issue bilateral negotiation, where issues
are expressed and related to each other via Description Logics.
Agents' goals are expressed through (complex) concepts, and  the
worth of goals as weights over concepts. We adopt a very general setting with incomplete information by letting agents keep both goals and worths of goals as private information.  We
introduce a negotiation protocol for such a setting, and discuss different
possible strategies that agents can adopt during the negotiation process.
We show that such a protocol converges, if the Description Logic used
enjoys the finite implicants property.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-075.pdf,"Subjects:  7.1 Multi-Agent Systems;
11. Knowledge Representation"
75,2007,Knowledge Representation and Logic,A Generalized Gelfond-Lifschitz Transformation for Logic Programs with Abstract Constraints,"Yi-Dong Shen, Jia-Huai You","We present a generalized Gelfond-Lifschitz transformation in order to define stable models for a logic program with arbitrary abstract constraints on sets (c-atoms). The generalization is based on a formal semantics and a novel abstract representation of c-atoms, as opposed to the commonly used power set form representation. In many cases, the abstract representation of a c-atom results in a substantial reduction of size from its power set form representation. We show that any c-atom A=(Ad,Ac) in the body of a clause can be characterized using its satisfiable sets, so that given an interpretation I the c-atom can be handled simply by introducing a special atom θA together with a new clause θA ← A1, ..., An for each satisfiable set {A1, ..., An} of A. We also prove that the latest fixpoint approach presented by Son et al. and our approach using the generalized Gelfond-Lifschitz transformation are semantically equivalent in the sense that they define the same set of stable models.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-076.pdf,"Subjects:  11. Knowledge Representation;
3.3 Nonmonotonic Reasoning"
76,2007,Knowledge Representation and Logic,Probabilistic Modal Logic,"Afsaneh H Shirazi, Eyal Amir","A modal logic is any logic for handling modalities: concepts like possibility, necessity, and knowledge. Artificial intelligence uses modal logics most heavily to represent and reason about  
knowledge of agents about others' knowledge. This type of reasoning occurs in dialog, collaboration, and competition. In many applications it is also important to be able to reason about the probability of beliefs and events.

In this paper we provide a formal system that represents probabilistic knowledge about probabilistic knowledge. %(a model is a probabilistic Kripke structure). We also present exact and approximate algorithms for reasoning about the truth value of queries that are encoded as probabilistic modal logic formulas. We provide an exact algorithm which takes a probabilistic Kripke structure and answers probabilistic modal queries in polynomial-time in the size of the model. Then, we introduce
an approximate method for applications in which we have very many or infinitely many states. Exact methods are impractical in these applications and we show that our method returns a close estimate efficiently.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-077.pdf,"Subjects:  3.4 Probabilistic Reasoning;
11. Knowledge Representation"
77,2007,Knowledge Representation and Logic,A Modal Logic for Beliefs and Pro Attitudes,"Su K, Abdul Sattar, Han Lin, Mark Reynolds","Agents' pro attitudes such as goals, intentions, desires, wishes, and judgements of satisfactoriness play an important role in how agents act rationally. To provide a natural and satisfying formalization of these attitudes is a longstanding problem in the community of agent theory. Most of existing modal logic approaches are based on Kripke structures and have to face the so-called side-effect problem. This paper presents a new modal logic formalizing agents' pro attitudes, based on neighborhood models. There are three distinguishing features of this logic. Firstly, this logic naturally satisfies Bratman's

requirements} for agents' beliefs and pro attitudes, as well as

some interesting properties that have not been discussed before.

Secondly, we give a sound and complete axiom system for

characterizing all the valid properties of beliefs and pro attitudes. We introduce for the first time the notion of linear neighborhood frame for obtaining the semantic model, and this brings a new member to the family of non-normal modal logics. Finally, we argue that the present logic satisfies an important requirement proposed from the viewpoint of computation, that is, computational grounding, which means that properties in this logic can be given an interpretation in terms of some concrete computational model. Indeed, the presented neighborhood frame can be naturally derived from probabilistic

programming with utilities.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-078.pdf,"Subjects:  3. Automated Reasoning;
7. Distributed AI"
78,2007,Knowledge Representation and Logic,Knowledge Compilation Properties of Tree-of-BDDs,"Sathiamoorthy Subbarayan, Lucas Bordeaux, Youssef Hamadi","We present a CNF to Tree-of-BDDs (ToB) compiler with complexity at
most exponential in the tree width. We then present algorithms for
interesting queries on ToB. Although some of the presented query
algorithms are in the worst case exponential in the tree width, our
experiments show that ToB can answer non-trivial queries like
clausal entailment in reasonable time for several realistic
instances. While our ToB-tool compiles all the used 91 instances,
d-DNNF compilation failed for 12 or 8 of them based on the
decomposition heuristic used. Also, on the succeeded instances, a
d-DNNF is up to 1000 times larger than the matching ToB. The ToB
compilations are often an order of magnitude faster than the d-DNNF
compilation. This makes ToB a  quite interesting knowledge
compilation form.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-079.pdf,"Subjects:  11. Knowledge Representation;
15.2 Constraint Satisfaction"
79,2007,Knowledge Representation and Logic,"The Modal Logic S4F, the Default Logic, and the Logic Here-and-There",Miroslaw Truszczynski,"The modal logic S4F provides an account for the default logic of Reiter, and several modal nonmonotonic logics of knowledge and belief. In this paper we focus on a fragment of the logic S4F concerned with modal formulas called modal defaults, and on sets of modal defaults - modal default theories. We present characterizations of S4F-expansions of modal default theories, and show that strong and uniform equivalence of modal default theories can be expressed in terms of the logical equivalence in the logic S4F. We argue that the logic S4F can be viewed as the general default logic of nested defaults. We also study special modal default theories called modal programs, and show that this fragment of the logic S4F generalizes the logic here-and-there.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-080.pdf,"Subjects:  11. Knowledge Representation;
3.3 Nonmonotonic Reasoning"
80,2007,Machine Learning,Particle Filtering for Dynamic Agent Modelling in Simplified Poker,"Nolan Bard, Michael Bowling","Agent modelling is a challenging problem in many modern artificial intelligence applications.  The agent modelling task is especially difficult when handling stochastic choices, deliberately hidden information, dynamic agents, and the need for fast learning.  State estimation techniques, such as Kalman filtering and particle filtering, have addressed many of these challenges, but have received little attention in the agent modelling literature.  This paper looks at the use of particle filtering for modelling a dynamic opponent in Kuhn poker, a simplified version of Texas Hold’em poker.  We demonstrate effective modelling both against static opponents as well as dynamic opponents, when the dynamics are known.  We then examine an application of Rao-Blackwellized particle filtering for doing dual estimation, inferring both the opponent’s state as well as a model of its dynamics.  Finally, we examine the robustness of the approach to incorrect beliefs about the opponent and compare it to previous work on opponent modelling in Kuhn poker.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-081.pdf,"Subjects:  3.4 Probabilistic Reasoning;
1.8 Game Playing"
81,2007,Machine Learning,A Mathematical Programming Formulation for Sparse Collaborative Computer Aided Diagnosis,"Jinbo Bi, Tao Xiong","A mathematical programming formulation is proposed to eliminate
irrelevant and redundant features for collaborative computer aided
diagnosis which requires to detect multiple clinically-related
malignant structures from medical images. A probabilistic
interpretation is described to justify our formulations. The
proposed formulation is optimized through an effective alternating
optimization algorithm that is easy to implement and relatively fast to solve.  This collaborative prediction approach has been
implemented and validated on the automatic detection of solid lung
nodules by jointly detecting ground glass opacities.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-082.pdf,"Subjects:  12. Machine Learning and Discovery;
1. Applications"
82,2007,Machine Learning,Isometric Projection,"Deng Cai, Xiaofei He, Jiawei Han","Recently the problem of dimensionality reduction has received a lot

of interests in many fields of information processing. We consider

the case where data is sampled from a low dimensional manifold which

is embedded in high dimensional Euclidean space. The most popular

manifold learning algorithms include Locally Linear Embedding,

ISOMAP, and Laplacian Eigenmap. However, these algorithms are

nonlinear and only provide the embedding results of training

samples. In this paper, we propose a novel linear dimensionality

reduction algorithm, called Isometric Projection. Isometric

Projection constructs a weighted data graph where the weights are

discrete approximations of the geodesic distances on the data

manifold. A linear subspace is then obtained by preserving the

pairwise distances. In this way, Isometric Projection can be defined

everywhere. Comparing to Principal Component Analysis (PCA) which is

widely used in data processing, our algorithm is more capable of

discovering the intrinsic geometrical structure. Specially, PCA is

optimal only when the data space is linear, while our algorithm has

no such assumption and therefore can handle more complex data space.

Experimental results on two real life data sets illustrate the

effectiveness of the proposed method.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-083.pdf,"Subjects:  12. Machine Learning and Discovery;
12.2 Scientific Discovery"
83,2007,Machine Learning,Active Algorithm Selection,"Feilong Chen, Rong Jin","Most previous studies on active learning focused on the problem of
model selection, i.e., how to identify the optimal classification
model from a family of predefined models using a small, carefully
selected training set. In this paper, we address the problem of
active algorithm selection. The goal of this problem is to
efficiently identify the optimal learning algorithm for a given
dataset from a set of algorithms using a small training set. In this study, we present a general framework for active algorithm selection by extending the idea of the Hedge algorithm. It employs the worst case analysis to identify the example that can effectively increase the weighted loss function defined in the Hedge algorithm. We further extend the framework by incorporating the correlation information among unlabeled examples to accurately estimate the change in the weighted loss function, and Maximum Entropy Discrimination to automatically determine the combination weights used by the Hedge algorithm. Our empirical study with the datasets of WCCI 2006 performance prediction challenge shows promising performance of the proposed framework for active algorithm selection.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-084.pdf,"Subjects:  12. Machine Learning and Discovery;
Please choose a second document classification"
84,2007,Machine Learning,Transferring Naive Bayes Classifiers for Text Classification,"Wenyuan Dai, Gui-Rong Xue, Qiang Yang, Yong Yu","A basic assumption in traditional machine learning is that the training and test data distributions be identical. This assumption may not hold in many situations in practice, but we may be forced to rely on a different-distribution data to learn a prediction model. For example, this may be the case when it is expensive to label the data in a domain of interest, although in a related but different domain there may be plenty of labeled data available. In this paper, we propose a novel transfer-learning algorithm for text classification based on an EM-based Naive Bayes classifier. Our solution is to first estimate the initial probabilities under a distribution of one labeled data set, and then use an EM algorithm to revise the model for a different distribution of the test data which are unlabeled. We show that our algorithm is very effective in several different pairs of domains, where the distances between the different distributions are measured using the Kullback-Leibler (KL) divergence. Moreover, KL-divergence is used to decide the trade-off parameters in our algorithm. In the experiment, our algorithm outperforms the traditional supervised and semi-supervised learning algorithms when the distributions of the training and test sets are increasingly different.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-085.pdf,"Subjects:  12. Machine Learning and Discovery;
13. Natural Language Processing"
85,2007,Machine Learning,Relationship Identification for Social Network Discovery,"Christopher P. Diehl, Galileo Namata, Lise Getoor","In recent years, informal, online communication has transformed
the ways in which we connect and collaborate with friends and
colleagues.  With millions of individuals communicating online
each day, we have a unique opportunity to observe the formation
and evolution of roles and relationships in networked groups and
organizations.  Yet a number of challenges arise when attempting
to infer the underlying social network from data that is often
ambiguous, incomplete and context-dependent.  In this paper, we
consider the problem of collaborative network discovery from
domains such as intelligence analysis and litigation support where
the analyst is attempting to construct a validated representation
of the social network.  We specifically address the challenge of
relationship identification where the objective is to identify
relevant communications that substantiate a given social
relationship type.  We propose a supervised ranking approach to
the problem and assess its performance on a manager-subordinate
relationship identification task using the Enron email corpus.  By
exploiting message content, the ranker routinely cues the analyst
to relevant communications relationships and message traffic that
are indicative of the social relationship.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-086.pdf,"Subjects:  12. Machine Learning and Discovery;
1.10 Information Retrieval"
86,2007,Machine Learning,A Reinforcement Learning Algorithm with Polynomial Interaction Complexity for Only-Costly-Observable MDPs,"Roy Fox, Moshe Tennenholtz","An Unobservable MDP (UMDP) is a POMDP in which there are no observations. An Only-Costly-Observable MDP (OCOMDP) is a POMDP which extends an UMDP by allowing a particular costly action which completely observes the state. We introduce UR-max, a reinforcement learning algorithm with polynomial interaction complexity for unknown OCOMDPs.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-087.pdf,"Subjects:  12. Machine Learning and Discovery;
12.1 Reinforcement Learning"
87,2007,Machine Learning,Compact Spectral Bases for Value Function Approximation Using Kronecker Factorization,"Jeff Johns, Sridhar Mahadevan, Chang Wang","A new spectral approach to value function approximation has recently been proposed to automatically construct basis functions from samples.  Global basis functions called proto-value functions are generated by diagonalizing a diffusion operator, such as a reversible random walk or the Laplacian, on a graph formed from connecting nearby samples.  This paper addresses the challenge of scaling this approach to large domains.  We propose using Kronecker factorization coupled with the Metropolis-Hastings algorithm to decompose reversible transition matrices.  The result is that the basis functions can be computed on much smaller matrices and combined to form the overall bases.  We demonstrate that in several continuous Markov decision processes, compact basis functions can be constructed without significant loss in performance.  In one domain, basis functions were compressed by a factor of 36.  A theoretical analysis relates the quality of the approximation to the spectral gap.  Our approach generalizes to other basis constructions as well.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-088.pdf,"Subjects:  12.1 Reinforcement Learning;
12. Machine Learning and Discovery"
88,2007,Machine Learning,A Method for Large-Scale l1-regularized Logistic Regression,"Kwangmoo Koh, Seung-Jean Kim, Stephen Boyd","Logistic regression with l1 regularization has been proposed as a promising method for feature selection in classification problems. Several specialized solution methods have been proposed for l1-regularized logistic regression problems (LRPs). However, existing methods do not scale well to large problems that arise in many practical settings. In this paper we describe an efficient interior-point method for solving l1-regularized LRPs. Small problems with up to a thousand or so features and examples can be solved in seconds on a PC. A variation on the basic method, that uses a preconditioned conjugate gradient method to compute the search step, can solve large sparse problems, with a million features and examples (e.g., the 20 Newsgroups data set), in a few tens of minutes, on a PC. Numerical experiments show that ourmethod outperforms standard methods for solving convex optimization problems as well as other methods specifically designed for l1-regularized LRPs.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-089.pdf,"Subjects:  12. Machine Learning and Discovery;
15. Problem Solving"
89,2007,Machine Learning,Efficient Reinforcement Learning with Relocatable Action Models,"Bethany R. Leffler, Michael L. Littman, Timothy Edmunds","Realistic domains for learning possess regularities that make it
possible to generalize experience across related states.  This paper explores an environment-modeling framework that represents transitions as state-independent outcomes that are common to all states that share the same type.  We analyze a set of novel learning problems that arise in this framework, providing lower and upper bounds.  We single out one particular variant of practical interest and provide an efficient algorithm and experimental results in both simulated and robotic environments.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-090.pdf,"Subjects:  12.1 Reinforcement Learning;
17. Robotics"
90,2007,Machine Learning,Graph Partitioning Based on Link Distributions,"Bo Long, Zhongfei (Mark) Zhang, Philip S. Yu","Existing graph partitioning approaches are mainly based on

optimizing edge cuts and do not take the distribution of edge

weights (link distribution) into consideration. In this paper, we

propose a general model to partition  graphs based on link

distributions. This model formulates graph partitioning under a

certain distribution assumption as approximating the graph affinity matrix under the corresponding distortion measure. Under this model, we derive a novel graph partitioning algorithm to approximate a graph affinity matrix under various Bregman divergences, which correspond to a large exponential family of  distributions. We also establish the connections between  edge cut objectives and the proposed model to provide a unified view to graph partitioning.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-091.pdf,"Subjects:  12. Machine Learning and Discovery;
1.10 Information Retrieval"
91,2007,Machine Learning,Refining Rules Incorporated into Knowledge-Based Support Vector Learners Via Successive Linear Programming,"Richard Maclin, Edward Wild, Jude Shavlik, Lisa Torrey, Trevor Walker","Knowledge-based classification and regression methods
are especially powerful forms of learning. They allow
a system to take advantage of prior domain knowledge
supplied either by a human user or another algorithm,
combining that knowledge with data to produce accurate
models. A limitation of the use of prior knowledge
occurs when the provided knowledge is incorrect. Such
knowledge likely still contains useful information, but
knowledge-based learners might not be able to fully exploit
such information. In fact, incorrect knowledge can
lead to poorer models than result from knowledge-free
learners. We present a support-vector method for incorporating
and refining domain knowledge that not only
allows the learner to make use of that knowledge, but
also suggests changes to the provided knowledge. Our
approach is built on the knowledge-based classification
and regression methods presented by Fung, Mangasarian,
and Shavlik (2002; 2003) and by Mangasarian, Shavlik,
and Wild (2004). Experiments on artificial data sets
with known properties, as well as on a real-world data
set, demonstrate that our method learns more accurate
models while also adjusting the provided rules in intuitive
ways. Our new algorithm provides an appealing
extension to knowledge-based, support-vector learning
that is not only able to combine knowledge from rules
with data, but is also able to use the data to modify and
change those rules to better fit the data.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-092.pdf,"Subjects:  12. Machine Learning and Discovery;
Please choose a second document classification"
92,2007,Machine Learning,Improving Learning in Networked Data by Combining Explicit and Mined Link,Sofus A. Macskassy,"This paper is about using multiple types of information for classification of networked data in a semi-supervised setting: given a fully described network (nodes and edges) with known labels for some of the nodes, predict the labels of the remaining nodes.  One method recently developed for doing such inference is a guilt-by-association model.  This method has been independently developed in two different settings--relational learning and semi-supervised learning.  In relational learning, the setting assumes that the networked data has explicit links such as hyperlinks between web-pages or citations between research papers.  The semi-supervised setting assumes a corpus of non-relational data and creates links based on similarity measures between the instances.  Both use only the known labels in the network to predict the remaining labels but use very different information sources.  The thesis of this paper is that if we combine these two types of links, the resulting network will carry more information than either type of link by itself.  We test this thesis on six benchmark data sets, using a within-network learning algorithm, where we show that we gain significant improvements in predictive performance by combining the links.  We describe a principled way of combining multiple types of edges with different edge-weights and semantics using an objective graph measure called node-based assortativity.  We investigate the use of this measure to combine text-mined links with explicit links and show that using our approach significantly improves performance of our classifier over naively combining these two types of links.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-093.pdf,"Subjects:  12. Machine Learning and Discovery;
Please choose a second document classification"
93,2007,Machine Learning,Cautious Inference in Collective Classification,"Luke K. McDowell, Kalyan Moy Gupta, David W. Aha","Collective classification can significantly improve accuracy by exploiting relationships among instances. Although several collective inference procedures have been reported, they have not been thoroughly evaluated for their commonalities and differences. We introduce novel generalizations of three existing algorithms that allow such algorithmic and empirical comparisons. Our generalizations permit us to examine how cautiously or aggressively each algorithm exploits intermediate relational data, which can be noisy. We conjecture that cautious approaches that identify and preferentially exploit the more reliable intermediate data should outperform aggressive approaches. We explain why caution is useful and introduce three parameters to control the degree of caution. An empirical evaluation of collective classification algorithms, using two base classifiers on three data sets, supports our conjecture.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-094.pdf,"Subjects:  12. Machine Learning and Discovery;
3. Automated Reasoning"
94,2007,Machine Learning,Nonmyopin Informative Path Planning in Spatio-Temporal Models,"Alexandra Meliou, Andreas Krause, Carlos Guestrin, Joseph M. Hellerstein","In many sensing applications, like environmental monitoring, we must continuously gather information in order to provide a good estimate of the state of the environment at every point in time. A robot may tour an environment, gathering information every hour. In a wireless sensor network, these tours correspond to packets being transmitted. In these settings, we are often faced with resource restrictions, like energy constraints. When users issue queries, they have certain expectations on the answer quality. Thus, we must optimize the tours in order to ensure the satisfaction of the user constraints, while at the same time minimize the cost of the query plan. For a single timestep, this optimization problem is NP-hard, but recent approximation algorithms with theoretical guarantees provide good solutions. In this paper, we present a new efficient algorithm, exploiting dynamic programming and submodularity of the information being collected, that efficiently plans data collection tours for an entire (finite) horizon. Our algorithm can use any single step
procedure as a black box, and provides strong theoretical guarantees about the solution, based on the properties of the single step approach. We also provide an extensive empirical analysis demonstrating the benefits of nonmyopic planning in two real world sensing applications.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-095.pdf,"Subjects:  12. Machine Learning and Discovery;
1.11 Planning"
95,2007,Machine Learning,Mapping and Revising Markov Logic Networks for Transfer Learning,"Lilyana Mihalkova, Tuyen Huynh, Raymond J. Mooney","Transfer learning addresses the problem of how to leverage knowledge acquired in a source domain to improve the accuracy and speed of learning in a related target domain. This paper considers transfer learning with Markov logic networks (MLNs), a powerful formalism for learning in relational domains. We present a complete MLN transfer system that first autonomously maps the predicates in the source MLN to the target domain and then revises the mapped structure to further improve its accuracy. Our results in several real-world domains demonstrate that our approach successfully reduces the amount of time and training data needed to learn an accurate model of a target domain over learning from scratch.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-096.pdf,"Subjects:  12. Machine Learning and Discovery;
15.1 Belief Revision"
96,2007,Machine Learning,Discovering Multivariate Motifs using Subsequence Density Estimation and Greedy Mixture Learning,"David Minnen, Charles L. Isbell, Irfan Essa, Thad Starner","The problem of locating motifs in real-valued, multivariate time
series data involves the discovery of sets of recurring patterns
embedded in the time series.  Each set is composed of several
non-overlapping subsequences and constitutes a motif because all of
the included subsequences are similar.  The ability to automatically
discover such motifs allows intelligent systems to form endogenously
meaningful representations of their environment through unsupervised
sensor analysis.  In this paper, we formulate a unifying view of motif
discovery as a problem of locating regions of high density in the
space of all time series subsequences.  Our approach is efficient
(sub-quadratic in the length of the data), requires fewer
user-specified parameters than previous methods, and naturally allows
variable length motif occurrences and non-linear temporal warping.  We
evaluate the performance of our approach using four data sets from
different domains including on-body inertial sensors and speech.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-097.pdf,"Subjects:  12. Machine Learning and Discovery;
19.1 Perception"
97,2007,Machine Learning,M2ICAL Analyses HC-Gammon,"Wee-Chong Oon, Martin Henz","We analyse Pollack and Blair's HC-Gammon backgammon program using a new technique that performs {M}onte Carlo simulations to derive a {M}arkov Chain model for {I}mperfect {C}omparison {AL}gorithms, called the M2ICAL method, which models the behavior of the algorithm using a Markov chain, each of whose states represents a class of players of similar strength. The Markov chain transition matrix is populated using Monte Carlo simulations. Once generated, the matrix allows fairly accurate predictions of the expected solution quality, standard deviation and time to convergence of the algorithm. This allows us to make some observations on the validity of Pollack and Blair's conclusions, and also shows the application of the M2ICAL method on a previously published work.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-098.pdf,"Subjects:  12. Machine Learning and Discovery;
1.8 Game Playing"
98,2007,Machine Learning,A Randomized String Kernel and Its Application to RNA Interference,"Shibin Qiu, Terran Lane, Ljubomir Buturovic","String kernels directly model sequence similarities without the
necessity of extracting numerical features in a vector space. Since they better capture complex traits in the sequences, string kernels often achieve better prediction performance. RNA interference is an important biological mechanism with many therapeutical applications, where strings can be used to represent target messenger RNAs and initiating short RNAs and string kernels can be applied for learning and prediction. However, existing string kernels are not particularly developed for RNA applications. Moreover, most existing string kernels are n-gram based and suffer from high dimensionality and inability of preserving subsequence orderings. We propose a randomized string kernel for use with support vector regression with a purpose of better predicting silencing efficacy scores for the candidate sequences and eventually improving the efficiency of biological experiments. We show the positive definiteness of this kernel and give an analysis of randomization error rates. Empirical results on biological data demonstrate that the proposed kernel performed better than existing string kernels and achieved significant improvements over kernels computed from numerical descriptors extracted according to structural and thermodynamic rules. In addition, it is computationally more efficient.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-099.pdf,"Subjects:  12. Machine Learning and Discovery;
12. Machine Learning and Discovery"
99,2007,Machine Learning,COD: Online Temporal Clustering for Outbreak Detection,"Tomas Singliar, Denver Dash","We present Cluster Onset Detection (COD), a novel algorithm
to aid in detection of epidemic outbreaks. COD employs unsupervised learning techniques in an online setting to partition the population into subgroups, thus increasing the ability to make a detection over the population as a whole by decreasing the signal-to-noise ratio. The method is adaptive and able to alter its clustering in real-time without the need for detailed background knowledge of the population. COD attempts to detect a cluster made up primarily of infected hosts. We argue that this technique is largely complementary to the existing methods for outbreak detection and can generally be combined with one or more of them. We show empirical results applying COD to the problem of detecting a worm attack on a system of networked computers, and show that this method results in approximately 40% lower infection rate at a false positive rate of 1 per week than the best previously reported results on this data set achieved using an HMM model customized for the outbreak detection task.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-100.pdf,"Subjects:  12. Machine Learning and Discovery;
3.6 Temporal Reasoning"
100,2007,Machine Learning,Abstraction in Predictive State Representations,"Vishal Soni, Satinder Singh","Most work on Predictive Representations of State (PSRs) focuses on learning a complete model of the system that can be used to answer any question about the future. However, we may be interested only in answering certain kinds of abstract questions. For instance, we may only care about the presence of objects in an image rather than pixel level details. In such cases, we may be able to learn substantially smaller models that answer only such abstract questions. 

We present the framework of PSR homomorphisms for model abstraction in PSRs. A homomorphism transforms a given PSR into a smaller PSR that provides exact answers to abstract questions in the original PSR. As we shall show, this transformation captures structural and temporal abstractions in the original PSR.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-101.pdf,"Subjects:  12. Machine Learning and Discovery;
12.1 Reinforcement Learning"
101,2007,Machine Learning,Efficient Structure Learning in Factored-state MDPs,"Alexander L. Strehl, Carlos Diuk, Michael L. Littman",We consider the problem of reinforcement learning in factored-state MDPs in the setting in which learning is conducted in one long trial with no resets allowed.  We show how to extend existing efficient algorithms that learn the conditional probability tables of dynamic Bayesian networks (DBNs) given their structure to the case in which DBN structure is not known in advance.  Our method learns the DBN structures as part of the reinforcement-learning process and provably provides an efficient learning algorithm when combined with factored Rmax.,https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-102.pdf,"Subjects:  12.1 Reinforcement Learning;
10. Knowledge Acquisition"
102,2007,Machine Learning,Semi-supervised Learning by Mixed Label Propagation,"Wei Tong, Rong Jin","Recent studies have shown that graph-based approaches are effective for semi-supervised learning. The key idea behind many graph-based approaches is to enforce the consistency between the class assignment of unlabeled examples and the pairwise similarity between examples. One major limitation with most graph-based approaches is that they are unable to explore dissimilarity or negative similarity. This is because the dissimilar relation is not transitive, and therefore is difficult to be propagated. Furthermore, negative similarity could result in unbounded energy functions, which makes most graph-based algorithms unapplicable. In this paper, we propose a new graph-based approach, termed as ""mixed label propagation"" which is able to effectively explore both similarity and dissimilarity simultaneously. In particular, the new framework determines the assignment of class labels by (1) minimizing the energy function associated with positive similarity, and (2) maximizing the energy function associated with negative similarity. Our empirical study with collaborative filtering shows promising performance of the proposed approach.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-103.pdf,"Subjects:  12. Machine Learning and Discovery;
Please choose a second document classification"
103,2007,Machine Learning,Clustering with Local and Global Regularization,"Fei Wang, Changshui Zhang, Tao Li","Clustering is an old research topic in data mining and machine

learning communities. Most of the traditional clustering methods can be categorized local or global ones. In this paper, a novel clustering method that can explore both the local and global information in the dataset is proposed. The method,  Clustering with Local and Global Consistency (CLGR), aims to minimize a cost function that properly trades off the local and global costs. We will show that such an optimization problem can be solved by the eigenvalue decomposition of a sparse symmetric matrix, which can be done efficiently by some iterative methods. Finally the experimental results on several datasets are presented to show the effectiveness of our method.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-104.pdf,"Subjects:  12. Machine Learning and Discovery;
9.3 Mathematical Foundations"
104,2007,Machine Learning,Probabilistic Community Discovery Using Hierarchical Latent Gaussian Mixture Model,"Haizheng Zhang, C. Lee Giles, Henry C. Foley, John Yen.","Complex networks exist in a wide array of diverse domains, ranging from biology, sociology, and computer science. These real-world networks, while disparate in nature, often comprise of a set of loose clusters(a.k.a communities), whose members are better connected to each other than to the rest of the network. Discovering such inherent community structures can lead to deeper understanding about the networks and therefore has raised increasing interests among researchers from various disciplines. This paper describes GWN-LDA(Generic weighted network-Latent Dirichlet Allocation) model, a hierarchical Bayesian model derived from the widely-received LDA model, for discovering probabilistic community profiles in social networks. In this model, communities are modeled as latent variables and defined as distributions over the social actor space. In addition, each social actor belongs to every community with different probability. This paper also proposes two different network encoding approaches and explores the impact of these two approaches to the community discovery performance. This model is evaluated on two research collaborative networks: CiteSeer and NanoSCI. The experimental results demonstrate that this
approach is promising for discovering community structures in
large-scale networks.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-105.pdf,"Subjects:  12. Machine Learning and Discovery;
3.4 Probabilistic Reasoning"
105,2007,Machine Learning,Multi-Label Learning by Instance Differentiation,"Min-Ling Zhang, Zhi-Hua Zhou","Multi-label learning deals with ambiguous examples each may belong to several concept classes simultaneously. In this learning framework, the inherent ambiguity of each example is explicitly expressed in the output space by being associated with multiple class labels. While on the other hand, its ambiguity is only implicitly encoded in the input space by being represented by only a single instance. Based on this recognition, we hypothesize that if the inherent ambiguity can be explicitly expressed in the input space appropriately, the problem of multi-label learning can be solved more effectively. We justify this hypothesis by proposing a novel multi-label learning approach named INSDIF. The core of INSDIF is instance differentiation that transforms an example into a bag of instances each of which reflects the example's relationship with one of the possible classes. In this way, INSDIF directly addresses the inherent ambiguity of each example in the input space. A two-level classification strategy is employed to learn from the transformed examples. Applications to automatic web page categorization, natural scene classification and gene functional analysis show that our approach outperforms several well-established multi-label learning algorithms.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-106.pdf,"Subjects:  12. Machine Learning and Discovery;
12. Machine Learning and Discovery"
106,2007,Machine Learning,Semi-Supervised Learning with Very Few Labeled Training Examples,"Zhi-Hua Zhou, De-Chuan Zhan, Qiang Yang","In semi-supervised learning, a number of labeled examples are usually required for training an initial weakly useful predictor which is in turn used for exploiting the unlabeled examples. However, in many real-world applications there may exist very few labeled training examples, which makes the weakly useful predictor difficult to generate, and therefore these semi-supervised learning methods cannot be applied. This paper proposes a method working under a two-view setting. By taking advantages of the correlations between the views using canonical component analysis, the proposed method can perform semi-supervised learning with only one labeled training example. Experiments and an application to content-based image retrieval validate the effectiveness of the proposed method.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-107.pdf,"Subjects:  12. Machine Learning and Discovery;
1.10 Information Retrieval"
107,2007,Machine Learning,Kernel Regression with Order Preferences,"Xiaojin Zhu, Andrew Goldberg","We propose a novel kernel regression algorithm which takes into account order preferences on unlabeled data.  Such preferences have the form that point x1 has a larger target value than that of x2, although the target values for x1, x2 are unknown.  The order preferences can be viewed as side information or a form of weak labels, and our algorithm can be related to semi-supervised learning.  Learning consists of formulating the order preferences as additional regularization in a risk minimization framework.  We define a linear program to effectively solve the optimization problem.  Experiments on benchmark datasets, sentiment analysis, and housing price problems show that the proposed algorithm outperforms standard regression, even when the order preferences are noisy.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-108.pdf,"Subjects:  12. Machine Learning and Discovery;
9.3 Mathematical Foundations"
108,2007,Multiagents,Agent Influence as a Predictor of Difficulty for Decentralized Problem-Solving,"Martin Allen, Shlomo Zilberstein","We study the effect of problem structure on the practical performance of optimal dynamic programming for decentralized decision problems.  It is shown that restricting agent influence over problem dynamics can make the problem easier to solve.  Experimental results establish that agent influence correlates with problem difficulty:  as the gap between the influence of different agents grows, problems tend to become much easier to solve.  The measure thus provides a general-purpose, automatic characterization of decentralized problems, identifying those for which optimal methods are more or less likely to work.  Such a measure is also of possible use as a heuristic in the design of algorithms that create task decompositions and control hierarchies in order to simplify multiagent problems.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-109.pdf,"Subjects:  7.1 Multi-Agent Systems;
9. Foundational Issues"
109,2007,Multiagents,Computational Aspects of Covering in Dominance Graphs,"Felix Brandt, Felix Fischer","Various problems in AI and multiagent systems can be tackled by finding the “most desirable” elements of a set given some binary relation.  Examples can be found in areas as diverse as voting theory, game theory, and argumentation theory.  Some particularly attractive solution sets are defined in terms of a covering relation---a transitive subrelation of the original relation.  We consider three different types of covering (upward, downward, and bidirectional) and the corresponding solution concepts known as the uncovered set and the minimal covering set.  We present the first polynomial-time algorithm for finding the minimal bidirectional covering set (an acknowledged open problem) and prove that deciding whether an alternative is in a minimal upward or downward covering set is NP-hard.  Furthermore, we obtain various set-theoretical inclusions, which reveal a strong connection between von Neumann-Morgenstern stable sets and upward covering on the one hand, and the Banks set and downward covering on the other hand.  In particular, we show that every stable set is also a minimal upward covering set.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-110.pdf,"Subjects:  7.1 Multi-Agent Systems;
9.2 Computational Complexity"
110,2007,Multiagents,Allocating Goods on a Graph to Eliminate Envy,"Yann Chevaleyre, Ulle Endriss, Nicolas Maudet","We introduce a distributed negotiation framework for multiagent resource allocation where interactions between agents are limited by a graph defining a negotiation topology. A group of agents may only contract a deal if that group is fully connected according to the negotiation topology. An important criterion for assessing the quality of an allocation of resources, in terms of fairness, is envy-freeness: an agent is said to envy another agent if it would prefer to swap places with that other agent. We analyse under what circumstances a sequence of deals respecting the negotiation topology may be expected to converge to a state where no agent envies any of the agents it is directly connected to. We also analyse the computational complexity of a related decision problem, namely the problem of checking whether a given negotiation state admits any deal that would both be beneficial to every agent involved and reduce envy in the agent society.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-111.pdf,"Subjects:  7. Distributed AI;
7.1 Multi-Agent Systems"
111,2007,Multiagents,Evolutionary and Lifetime Learning in Varying NK Fitness Landscape Changing Environments: An Analysis of both Fitness and Diversity,"Dara Curran, Colm O'Riordan, Humphrey Sorensen","This paper examines the effects of lifetime learning on populations evolving genetically in a series of changing environments. The analysis of both fitness and diversity of the populations provides an insight into the improved performance provided by lifetime learning. The NK fitness landscape model is employed as the problem task, which has the advantage of being able to generate a variety of fitness landscapes of varying difficulty. Experiments observe the response of populations in an environment where problem difficulty increases and decreases with varying frequency. Results show that lifetime learning is capable of overall higher fitness levels and, in addition, that lifetime learning stimulates the diversity of the population. This increased diversity allows lifetime learning a greater level of recovery and stability than evolutionary learning alone.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-112.pdf,"Subjects:  7.1 Multi-Agent Systems;
1.9 Genetic Algorithms"
112,2007,Multiagents,Improved State Estimation in Multiagent Settings with Continuous or Large Discrete State Spaces,Prashant Doshi,"State estimation in multiagent settings involves updating an agent's belief over the physical states and the space of other agents' models. Performance of the previous approach to state estimation, the interactive particle filter, degrades with large state spaces because it distributes the particles over both, the physical state space and the other agents' models. We present an improved method for estimating the state in a class of  multiagent settings that are characterized in part by continuous or large discrete state spaces.  We factor out the models of the other agents and update the agent's belief over these models, as exactly as possible. Simultaneously, we sample particles from the distribution over the large physical state space and project the particles in time. This approach is equivalent to Rao-Blackwellising the interactive particle filter. We focus our analysis on the special class of problems where the nested beliefs are represented using Gaussians, the problem dynamics using conditional linear Gaussians (CLGs) and the observation functions using softmax or CLGs. These distributions adequately represent many realistic applications.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-113.pdf,"Subjects:  7.1 Multi-Agent Systems;
3.4 Probabilistic Reasoning"
113,2007,Multiagents,Computational Complexity of Weighted Threshold Games,"Edith Elkind, Leslie Ann Goldberg, Paul Goldberg, Michael Wooldridge","Weighted threshold games are coalitional games in which each player
has a weight (intuitively corresponding to its voting power), and a
coalition is successful if the sum of its weights exceeds a given
threshold.  Key questions in coalitional games include finding
coalitions that are stable (in the sense that no member of the
coalition has any rational incentive to leave it), and finding a
division of payoffs to coalition members (an imputation) that is fair.
We investigate the computational complexity of such questions for
weighted threshold games. We study the core, the least
core, and the nucleolus, distinguishing those problems that
are polynomial-time computable from those that are NP-hard, and
providing pseudopolynomial and approximation algorithms for the
NP-hard problems.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-114.pdf,"Subjects:  7.1 Multi-Agent Systems;
9.2 Computational Complexity"
114,2007,Multiagents,Llull and Copeland Voting Broadly Resist Bribery and Control,"Piotr Faliszewski, Edith Hemaspaandra, Lane Hemaspaandra, Joerg Rothe","Control of elections refers to attempts by an agent to, via such
actions as addition/deletion/partition of candidates or voters, ensure that a given candidate wins (Bartholdi, Tovey, and Trick 1992). An election system in which such an agent's computational task is NP-hard is said to be resistant to the given type of control.  Aside from election systems with an NP-hard winner problem, the only systems known to be resistant to all the standard control types are highly artificial election systems created by hybridization (Hemaspaandra, Hemaspaandra, and Rothe 2007). In this paper, we prove that an election system developed by the 13th century mystic Ramon Llull and the well-studied Copeland election system are both resistant to all the standard types of (constructive) electoral control other than one variant of addition of candidates. This is the most comprehensive resistance to control yet achieved by any natural election system whose winner problem is in P. In addition, we show that Llull and Copeland voting are very broadly resistant to bribery attacks,
and we integrate the potential irrationality of voter preferences into many of our results.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-115.pdf,"Subjects:  7.1 Multi-Agent Systems;
9.2 Computational Complexity"
115,2007,Multiagents,Towards a Cognitive Model of Crowd Behavior Based on Social Comparison Theory,"Natalie Fridman, Gal A. Kaminka","Models of crowd

behavior facilitate analysis and prediction of human group behavior, where people

are affected by each other's

presence.  Unfortunately, existing models leave many open challenges.

In particular, psychology models often offer only qualitative description, while computer science models are often simplistic, and are not reusable from one simulated phenomenon to the next. We propose a novel model of crowd behavior, based on Festinger's Social Comparison Theory (SCT). We propose a concrete algorithmic

framework for SCT, and evaluate its implementation in several crowd behavior scenarios. Results from task measures and human judges evaluation shows

that the SCT model produces improved results compared to base models from the literature.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-116.pdf,"Subjects:  7.1 Multi-Agent Systems;
4. Cognitive Modeling"
116,2007,Multiagents,"Centralized, Distributed or Something Else? Making Timely Decisions in Multi-Agent Systems","Tim Harbers, Rajiv T. Maheswaran, Pedro Szekely","In multi-agent systems, agents need to share information in order to make good decisions. Who does what in order to achieve this matters a lot. The assignment of responsibility influences delay and consequently affects agents' abilities to make timely decisions. It is often unclear which approaches are best.
We develop a model where one can easily test the impact of different assignments and information sharing protocols by focusing only on the delays caused by computation and communication. Using the model, we obtain interesting results that provide insight about the types of assignments that perform well in various domains and how slight variations in protocols can make great differences in feasibility.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-117.pdf,"Subjects:  7.1 Multi-Agent Systems;
7. Distributed AI"
117,2007,Multiagents,An α-approximation Protocol for the Generalized Mutual Assignment Problem,Katsutoshi Hirayama,"This paper presents a new distributed solution protocol, called
DisLRPα, for the Generalized Mutual Assignment Problem (GMAP). The GMAP is a typical distributed combinatorial optimization problem whose goal is to maximize social welfare of the agents. Unlike the previous protocol for the GMAP, DisLRPα can provide a theoretical guarantee on global solution quality. In DisLRPα, as with in the previous protocol, the agents repeatedly solve their local problems while coordinating their local solutions using a distributed constraint satisfaction technique. The key difference is that, in DisLRPα, each agent is required to produce a feasible solution whose local objective value is not lower than α (0 < α ≤ 1) times the local optimal value. Our experimental results on benchmark problem instances show that DisLRPα can certainly find a solution whose global objective value is higher than that theoretically guaranteed. Furthermore, they also show that, while spending extra communication and computation costs, DisLRPα can produce a significantly better solution than the previous protocol if we set α appropriately.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-118.pdf,"Subjects:  7. Distributed AI;
15. Problem Solving"
118,2007,Multiagents,Anytime Coordination Using Separable Bilinear Programs,"Marek Petrik, Shlomo Zilberstein","Developing scalable coordination algorithms for multi-agent

systems is a hard computational challenge. One useful approach,

demonstrated by the Coverage Set Algorithm (CSA), exploits structured interaction to produce significant computational gains. Empirically, CSA exhibits very good anytime performance, but an error bound on the results has not been established. We reformulate the algorithm and derive both online and offline error bounds for approximate solutions. Moreover, we propose an effective way to automatically reduce the complexity of the interaction. Our experiments show that this is a promising approach to solve a broad class of decentralized decision problems. The general formulation used by the algorithm makes it both easy to implement and widely applicable to a variety of other AI problems.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-119.pdf,"Subjects:  7.1 Multi-Agent Systems;
9.3 Mathematical Foundations"
119,2007,Multiagents,Active Imitation Learning,"Aaron P Shon, Deepak Verma, Rajesh P. N. Rao","Imitation learning, also called learning by watching or
programming by demonstration, has emerged as a means of accelerating many reinforcement learning tasks.  Previous work has shown the value of imitation in domains where a single mentor demonstrates execution of a known optimal policy for the benefit of a learning agent.  We consider the more general scenario of learning from mentors who are themselves agents seeking to maximize their own rewards.  We propose a new algorithm based on the concept of transferable utility for ensuring that an observer agent can learn efficiently in the context of a selfish, not necessarily helpful, mentor.  We also address the questions of when an imitative agent should request help from a mentor, and when the mentor can be expected to acknowledge a request for help.  In analogy with other types of active learning, we call the proposed approach active imitation learning.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-120.pdf,"Subjects:  12.1 Reinforcement Learning;
7.1 Multi-Agent Systems"
120,2007,Multiagents,Dynamic DFS Tree in ADOPT-ing,"Marius C Silaghi, Makoto Yokoo","Several distributed constraint reasoning algorithms employ Depth First
Search (DFS) trees on the constraint graph that spans involved agents.
In this article we show that it is possible to dynamically detect a
minimal DFS tree, compatible with the current order on agents, during
the distributed constraint reasoning process of the ADOPT algorithm. 
This also allows for
shorter DFS trees during the initial steps of the algorithm, while
some constraints did not yet prove useful given visited combinations
of assignments. Earlier distributed algorithms for finding spanning
trees on agents did not look to maintain compatibility with an order
already used. 
We also show that announcing a nogood to a single optional agent
is bringing significant improvements in the total number of
messages. The dynamic detection of the DFS tree brings
improvements in simulated time.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-121.pdf,"Subjects:  7.1 Multi-Agent Systems;
15.2 Constraint Satisfaction"
121,2007,Multiagents,Efficient Statistical Methods for Evaluating Trading Agent Performance,"Eric Sodomka, John Collins, Maria Gini","Market simulations, like their real-world counterparts, are typically
domains of high complexity, high variability, and incomplete
information. 
The performance of autonomous agents in these markets depends both upon the
strategies of their opponents
and on various market conditions, such as supply and
demand.
Because the space for possible strategies and market conditions is
very large, empirical analysis in these domains becomes
exceedingly difficult. Researchers who wish to evaluate their agents must
run many test games across multiple opponent sets and market conditions
to verify that agent performance has actually improved. 
Our approach is to improve the statistical power of market simulation
experiments by controlling their complexity, thereby creating
an environment more conducive to structured agent testing and
analysis. We develop a tool that controls variability across games
in one such
market environment, the Trading Agent Competition for Supply Chain
Management (TAC SCM),
and demonstrate how it provides an efficient, systematic method 
for TAC SCM
researchers to analyze agent performance.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-122.pdf,"Subjects:  7.1 Multi-Agent Systems;
Please choose a second document classification"
122,2007,Multiagents,Strongly Decomposable Voting Rules on Multiattribute Domains,"Lirong Xia, Jerome Lang, Mingsheng Ying","Sequential composition of voting rules, by making use of structural
properties of the voters' preferences, provide computationally
economical ways for making a common decision over a Cartesian
product of finite local domains. A sequential composition is usually defined on a set of legal profiles following a fixed order. In this paper, we generalize this by order-independent sequential composition and  strong decomposability, which are independent of the chosen order. We study to which extent some usual properties of voting rules transfer from the local rules to their order-independent sequential composition. Then, to capture the idea that a voting rule is neutral or decomposable on a slightly smaller domain, we define  nearly neutral, nearly decomposable rules for both sequential composition and order-independent sequential composition, which leads us to defining and studying  decomposable permutations. We prove that any sequential composition of neutral local rules and any order-independent sequential composition of neutral local rules satisfying a necessary condition are nearly neutral.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-123.pdf,"Subjects:  7.1 Multi-Agent Systems;
15.5 Decision Theory"
123,2007,Multiagents,Approximate Solutions of Interactive Dynamic Influence Diagrams Using Model Clustering,"Yifeng Zeng, Prashant Doshi, Qiongyu Chen","Interactive dynamic influence diagrams (I-DIDs) offer a transparent and semantically clear representation for the sequential decision-making problem over multiple time steps in the presence of other interacting agents. Solving I-DIDs exactly involves knowing the solutions of possible models of the other agents, which increase exponentially with the number of time steps. We present a method of solving I-DIDs approximately by limiting the number of other agents' candidate models at each time step to a constant. We do this by clustering the models and selecting a representative set from the clusters. We discuss the error bound of the approximation technique and demonstrate its empirical performance.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-124.pdf,"Subjects:  7.1 Multi-Agent Systems;
15.5 Decision Theory"
124,2007,Multiagents,A New Algorithm for Generating Equilibria in Massive Zero-Sum Games,"Martin Zinkevich, Michael Bowling, Neil Burch","In normal scenarios, computer scientists often consider the number

of states in a game to capture the difficulty of learning an

equilibrium. However, players do not see games in the same light:

most consider Go or Chess to be more complex than Monopoly. In this

paper, we discuss a new measure of game complexity that links

existing state-of-the-art algorithms for computing approximate

equilibria to a more human measure. In particular, we consider the

range of skill in a game, i.e. how many different skill levels exist.

We then modify existing techniques to design a new algorithm to

compute approximate equilibria whose performance can be captured by

this new measure. We use it to develop the first near Nash

equilibrium for a four round abstraction of poker, and show that it

would have been able to win handily the bankroll competition from

last year's AAAI poker competition.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-125.pdf,"Subjects:  1.8 Game Playing;
7.1 Multi-Agent Systems"
125,2007,Multidisciplinary Topics and Applications,A Logic of Agent Programs,"Natasha  Alechina, Mehdi Dastani, Brian Logan, John-Jules Ch. Meyer","We present a sound and complete logic for reasoning about SimpleAPL programs. SimpleAPL is a fragment of the agent programming language 3APL designed for the implementation of cognitive agents with beliefs, goals and plans.  Our logic is a variant of PDL, and allows the specification of safety and liveness properties of agent programs. We prove a correspondence between the operational semantics of SimpleAPL and the models of the logic for two example program execution strategies. We show how to translate agent programs written in SimpleAPL into expressions of the logic, and give an example in which we show how to verify correctness properties for a simple agent program.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-126.pdf,"Subjects:  7.1 Multi-Agent Systems;
9.3 Mathematical Foundations"
126,2007,Multidisciplinary Topics and Applications,Acquiring Visibly Intelligent Behavior with Example-Guided Neuroevolution,"Bobby D. Bryant, Risto Miikkulainen","Much of artificial intelligence research is focused on devising
optimal solutions for challenging and well-defined but highly
constrained problems.  However, as we begin creating autonomous agents to operate in the rich environments of modern videogames and computer simulations, it becomes important to devise agent behaviors that display the visible attributes of intelligence, rather than simply performing optimally.  Such visibly intelligent behavior is difficult to specify with rules or characterize in terms of quantifiable objective functions, but it is possible to utilize human intuitions to directly guide a learning system toward the desired sorts of behavior.  Policy induction from human-generated examples is a promising approach
to training such agents.  In this paper, such a method is
developed and tested using Lamarckian neuroevolution. Artificial
neural networks are evolved to control autonomous agents in a strategy game. The evolution is guided by human-generated examples of play, and the system effectively learns the policies that were used by the player to generate the examples.  I.e., the agents learn visibly intelligent behavior.  In the future, such methods are likely to play a central role in creating autonomous agents for complex environments, making it possible to generate rich behaviors derived from nothing more formal than the intuitively generated examples of designers, players, or subject-matter experts.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-127.pdf,"Subjects:  1.8 Game Playing;
14. Neural Networks"
127,2007,Multidisciplinary Topics and Applications,ActivelyExploring Creation of Face Space(s) for Improved Face Recognition,"Nitesh Chawla, Kevin Bowyer","We propose a 
learning framework that actively explores creation of face
space(s) by selecting images that are complementary to the
images already represented in the face space. We also construct
ensembles of classifiers learned from such actively 
sampled image sets, which further provides improvement in the
recognition rates. We not only significantly reduce
the number of images required in the training set but also
improve the accuracy over learning from all the images.
We also show that the single face space or ensemble of
face spaces, thus constructed, has a higher generalization
performance across different illumination and expression conditions.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-128.pdf,"Subjects:  12. Machine Learning and Discovery;
1. Applications"
128,2007,Multidisciplinary Topics and Applications,Modeling  Reciprocal Behavior in Human Bilateral Negotiation,"Ya'akov Gal, Avi Pfeffer","Reciprocity is a key determinant of human behavior and has been well
  documented in the psychological and behavioral economics literature.
  This paper shows that reciprocity has significant implications for
  computer agents that interact with people over time. It proposes a
  model for predicting people's actions in multiple bilateral rounds
  of interactions. The model represents reciprocity as a tradeoff
  between two social factors: the extent to which players reward and
  retaliate others' past actions (retrospective reasoning), and their
  estimate about the future ramifications of their actions
  (prospective reasoning).  The model is trained and evaluated over a
  series of negotiation rounds that vary players'  possible strategies as well
  as their benefit from potential strategies at each round.
  Results show that reasoning about reciprocal behavior significantly
  improves the predictive power of the model, enabling it to
  outperform alternative models that do not reason about reciprocity, or that
  play various game theoretic equilibria.  These results indicate that
  computers that interact with people need to represent and to learn
  the social factors that affect people's play when they interact over
  time.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-129.pdf,"Subjects:  4. Cognitive Modeling;
7.1 Multi-Agent Systems"
129,2007,Multidisciplinary Topics and Applications,Gender-Sensitive Automated Negotiators,"Ron Katz, Sarit Kraus","This paper introduces an innovative approach for automated

negotiating using the gender of human opponents. Our approach

segments the information acquired from previous opponents, stores it in two databases, and models the typical behavior of males and of females. The two models are used  in order to match an optimal strategy to each of the two sub-populations. In addition to the basic separation, we propose a learning algorithm which supplies an online indicator for the gender separability-level of the population, which tunes the level of separation the algorithm activates. The algorithm we present can be generally applied in different environments with no need for configuration of parameters. Experiments in 4 different one-shot domains, comparing the performance of the gender based separation approach with a basic approach which is not gender sensitive, revealed  higher payoffs of the former in almost all the domains. Moreover, using the proposed learning algorithm further improved the results.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-130.pdf,"Subjects:  6. Computer-Human Interaction;
7.1 Multi-Agent Systems"
130,2007,Multidisciplinary Topics and Applications,A Connectionist Cognitive Model for Temporal Synchronisation and Learning,"Luis C. Lamb, Rafael V. Borges, Artur S. d'Avila Garcez","The importance of the efforts towards integrating the symbolic and connectionist paradigms of artificial intelligence has been widely recognised. Integration may lead to more effective and richer cognitive computational models, and to a better understanding of the processes of artificial intelligence across the field. 
This paper presents a new model for the representation, computation, and learning of temporal logic in connectionist systems. The model allows for the encoding of past and future temporal logic operators in neural networks, through a neural-symbolic translation algorithms introduced in the paper. The networks are relatively simple and can be used for reasoning about time and for learning by examples with the use of standard neural learning algorithms. 
We validate the model in a well-known application dealing with temporal synchronisation in distributed knowledge systems. This opens several interesting research paths in cognitive modelling, with potential applications in agent technology, learning and reasoning.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-131.pdf,"Subjects:  4. Cognitive Modeling;
14. Neural Networks"
131,2007,Multidisciplinary Topics and Applications,Enabling Domain-Awareness for a Generic Natural Language Interface,"Yunyao Li, Ishan Chaudhuri, Huahai Yang, Satinder Singh, H. V. Jagadish","In this paper, we present a learning-based approach for enabling
domain-awareness for a generic natural language interface. Our
approach automatically acquires domain knowledge from user
interactions and incorporates the knowledge learned to improve the
generic system. We have embedded our approach in a generic natural
language interface and evaluated the extended system against two
benchmark datasets. We found that the performance of the original
generic system can be substantially improved through automatic
domain knowledge extraction and incorporation. We also show that the generic system with domain-awareness enabled by our approach can achieve performance similar to that of previous learning-based
domain-specific systems.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-132.pdf,"Subjects:  10. Knowledge Acquisition;
6.3 User Interfaces"
132,2007,Multidisciplinary Topics and Applications,A Corpus-Based Hybrid Approach to Music Analysis and Composition,"Bill Manaris, Patrick Roos, Penousal Machado, Dwight Krehbiel, Luca Pellicoro, Juan Romero","We present a corpus-based hybrid approach to music analysis and composition, which incorporates statistical, connectionist, and evolutionary components. Our framework employs artificial music critics, which may be trained on large music corpora, and then pass aesthetic judgment on music artifacts.  Music artifacts are generated by an evolutionary music composer, which utilizes music critics as fitness functions.  To evaluate this approach we conducted three experiments.  First, using music features based on Zipf’s law, we trained artificial neural networks to predict the popularity of 992 musical pieces with 87.85% accuracy. Then, assuming that popularity correlates with aesthetics, we incorporated such neural networks into a genetic-programming system, called NEvMuse.  NEvMuse autonomously ""composed"" novel variations of J.S. Bach's Invention #13 in A minor (BWV 784), variations which many listeners found to be aesthetically pleasing.  Finally, we compared aesthetic judgments from an artificial music critic with emotional responses from 23 human subjects.  Significant correlations were found.  We provide evaluation results and samples of generated music.  These results have implications for music information retrieval and computer-aided music composition.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-133.pdf,"Subjects:  1.1 Art And Music;
1.9 Genetic Algorithms"
133,2007,Multidisciplinary Topics and Applications,Recognition of Hand Drawn Chemical Diagrams,"Tom Y. Ouyang, Randall Davis","Chemists often use hand-drawn structural diagrams to capture and communicate ideas about organic compounds. However, the software available today for specifying these structures to a computer relies on a traditional mouse and keyboard interface, and as a result lacks the ease of use, naturalness, and speed of drawing on paper. In response, we have developed a novel sketch-based system capable of interpreting hand-drawn organic chemistry diagrams, allowing users to draw molecules with a pen-based input device in much the same way that they would on paper. The system's ability to interpret a sketch is based on knowledge about both chemistry and chemical drawing conventions. The system employs a trainable symbol recognizer incorporating both feature-based and image-based methods to locate and identify symbols in the sketch. Analysis of the spatial context around each symbol allows the system to choose among competing interpretations and determine an initial structure for the molecule. Finally, knowledge of chemistry (in particular chemical valence) enables the system to check the validity of its interpretation and, when necessary, refine it to recover from inconsistencies. We demonstrate that the system is capable of recognizing diagrams of common organic molecules and show that using domain knowledge produces a noticeable improvement in recognition accuracy.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-134.pdf,"Subjects:  6.3 User Interfaces;
6. Computer-Human Interaction"
134,2007,Multidisciplinary Topics and Applications,Authorial Idioms for Target Distributions in TTD-MDPs,"David L. Roberts, Sooraj Bhat, Kenneth St. Clair, Charles L. Isbell","In designing Markov Decision Processes (MDP), one must define the world, its dynamics, a set of actions, and a reward function.  MDPs are often applied in situations where there is a clear choice of reward functions and in these cases significant care must be taken to construct a reward function that induces the desired behavior.  In this paper, we consider an analogous design problem: crafting a target distribution in Targeted Trajectory Distribution MDPs (TTD-MDPs). TTD-MDPs produce probabilistic policies that minimize divergence from a target distribution of trajectories from an underlying MDP.  They are an extension of MDPs that provide variety of experience during  repeated execution.  Here, we present a brief overview of TTD-MDPs with approaches for constructing target distributions. Then we present a novel authorial idiom for creating target distributions using prototype trajectories. We evaluate these approaches on a drama manager for an interactive game.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-135.pdf,"Subjects:  12. Machine Learning and Discovery;
15.3 Control"
135,2007,Multidisciplinary Topics and Applications,Visualization and Adjustment of Evaluation Functions Based on Evaluation Values and Win Probability,"Shogo Takeuchi, Tomoyuki Kaneko, Kazunori Yamaguchi, Satoru Kawai","We present a method of visualizing and adjusting the evaluation
functions in game programming in this paper.  It is widely recognized that an
evaluation function should assign a higher evaluation value
to a position with greater probability of a win.  However, 
this relation has not been utilized directly to tune evaluation functions
because of the difficulty of measuring the probability of wins in
deterministic games.
We present the use of win percentage to utilize this relation
in positions having the same evaluation value as win probability, where
the positions we used were stored in a large database of game records.  
We introduce an evaluation curve
formed by evaluation values and win probabilities,
to enable evaluation functions to be visualized. 
We observed that evaluation curves form a sigmoid in various kinds of games
and that these curves may split depending on the properties of positions.
Because such splits indicate that an evaluation function that is 
visualized misestimates positions with less probability of winning,
we can improve this by fitting evaluation curves to one. 
Our experiments with Chess and Shogi revealed that deficiencies in evaluation
functions could be successfully visualized, and that improvements by
automatically adjusting their weights were confirmed by self-plays.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-136.pdf,"Subjects:  1.8 Game Playing;
12. Machine Learning and Discovery"
136,2007,Multidisciplinary Topics and Applications,Humans Perform Semi-Supervised Classification Too,"Xiaojin Zhu, Timothy Rogers, Ruichen Qian, Chuck Kalish","We explore the connections between machine learning and human learning in one form of semi-supervised classification. 22 human subjects completed a novel 2-class categorization task in which they were first taught to categorize a single labeled example from each category, and subsequently were asked to categorize, without feedback, a large set of additional items. Stimuli were visually complex and unrecognizable shapes.  The unlabeled examples were sampled from a bimodal distribution with modes appearing either to the left (left-shift condition) or right (right-shift condition) of the two labeled examples. Results showed that, although initial decision boundaries were near the middle of the two labeled examples, after exposure to the unlabeled examples, they shifted in different directions in the two groups. In this respect, the human behavior conformed well to the predictions of a Gaussian mixture model for semi-supervised learning. The human behavior differed from model predictions in other interesting respects, suggesting some fruitful avenues for future inquiry.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-137.pdf,"Subjects:  4. Cognitive Modeling;
12. Machine Learning and Discovery"
137,2007,Natural-Language Processing,Semantic Inference at the Lexical-Syntactic Level,"Roy Bar-Haim, Ido Dagan,Iddo Greental,Eyal Shnarch","Semantic inference is an important component in many natural language understanding applications. Classical approaches to semantic inference rely on complex logical representations. However, practical applications usually adopt shallower lexical or lexical-syntactic representations, but lack a principled inference framework. We propose a generic semantic inference framework that operates directly on syntactic trees. New trees are inferred by applying entailment rules, which provide a unified representation for varying types of inferences. Rules were generated by manual and automatic methods, covering generic linguistic structures as well as specific lexical-based inferences. Initial empirical evaluation in a Relation Extraction setting supports the validity of our approach.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-138.pdf,"Subjects:  13. Natural Language Processing;
11. Knowledge Representation"
138,2007,Natural-Language Processing,Turning Lectures into Comic Books Using Linguistically Salient Gestures,"Jacob Eisenstein, Regina Barzilay, Randall Davis","Creating video recordings of events such as lectures or meetings is increasingly inexpensive and easy. However, reviewing the content of such video may be time-consuming and difficult. Our goal is to produce a ""comic book"" summary, in which a transcript is augmented with keyframes that disambiguate and clarify accompanying text. Unlike most previous keyframe extraction systems which rely primarily on visual cues, we present a linguistically-motivated approach that selects keyframes that contain salient gestures. Rather than learning gesture salience directly, it is estimated by measuring the contribution of gesture to understanding other discourse phenomena. More specifically, we bootstrap from multimodal coreference resolution to identify gestures that improve performance. We then select keyframes that capture these gestures. Our model predicts gesture salience as a hidden variable in a conditional framework, with observable features from both the visual and textual modalities. This approach significantly outperforms competitive baselines that do not use gesture information.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-139.pdf,"Subjects:  13.1 Discourse;
13. Natural Language Processing"
139,2007,Natural-Language Processing,A Robot That Uses Existing Vocabulary to Infer Non-Visual Word Meanings from Observation,"Kevin Gold, Brian Scassellati","The authors present TWIG, a visually grounded word-learning system that uses its existing knowledge of vocabulary, grammar, and action schemas to help it learn the meanings of new words from its environment.  Most systems built to learn word meanings from sensory data focus on the ""base case"" of learning words when the robot knows nothing, and do not incorporate grammatical knowledge to aid the process of inferring meaning.  The present study shows how using existing language knowledge can aid the word-learning process in three ways.  First, partial parses of sentences can focus the robot's attention on the correct item or relation in the environment. Second, grammatical inference can suggest whether a new word refers to a unary or binary relation.  Third, the robot's existing predicate schemas can suggest possibilities for a new predicate.  The authors demonstrate that TWIG can use its understanding of the phrase ""got the ball"" while watching a game of catch to learn that ""I"" refers to the speaker, ""you"" refers to the addressee, and the names refer to particular people.  The robot then uses these new words to learn that ""am"" and ""are"" refer to the identity relation.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-140.pdf,"Subjects:  18. Speech Understanding;
17. Robotics"
140,2007,Natural-Language Processing,ASKNet: Automated Semantic Knowledge Network,"Brian Harrington, Stephen Clark","The ASKNet system is an attempt to automatically generate large scale semantic knowledge networks from natural language text. State-of-the-art language processing tools, including parsers and semantic analysers, are used to turn input sentences into fragments of semantic network. These network fragments are combined using spreading activation-based algorithms which utilise both lexical and semantic information. The emphasis of the system is on wide-coverage and speed of construction. In this paper we show how a network consisting of over 1.5 million nodes and 3.5 million edges, more than twice as large as any network currently available, can be created in less than 3 days. We believe that the methods proposed here will enable the construction of semantic networks on a scale never seen before, and in doing so reduce the knowledge acquisition bottleneck for AI.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-141.pdf,"Subjects:  13. Natural Language Processing;
10. Knowledge Acquisition"
141,2007,Natural-Language Processing,Learning Language Semantics from Ambiguous Supervision,"Rohit J. Kate, Raymond J. Mooney","This paper presents a method for learning a semantic parser from ambiguous supervision. Training data consists of natural language sentences annotated with multiple potential meaning representations, only one of which is correct. Such ambiguous supervision models the type of supervision that can be more naturally available to language-learning systems. Given such weak supervision, our approach produces a semantic parser that maps sentences into meaning representations. An existing semantic
parsing learning system that can only learn from unambiguous supervision is augmented to handle ambiguous supervision. Experimental results show that the resulting system is able to cope up with ambiguities and learn accurate semantic parsers.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-142.pdf,"Subjects:  13. Natural Language Processing;
12. Machine Learning and Discovery"
142,2007,Natural-Language Processing,Disambiguating Noun Compounds,"Su Nam Kim, Timothy Baldwin","This paper is concerned with the interaction between word sense disambiguation and the interpretation of noun compounds (NCs) in   English.  We develop techniques for disambiguating word sense specifically in NCs, and then investigate whether word sense information can aid in the semantic relation interpretation of NCs. To disambiguate word sense, we combine the one sense per collocation heuristic with the grammatical role of polysemous nouns and analysis of word sense combinatorics. We built supervised and unsupervised classifiers for the task and demonstrate that the supervised methods are superior to a number of baselines and also a benchmark state-of-the-art WSD system.  Finally, we show that WSD can significantly improve the accuracy of NC interpretation.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-143.pdf,"Subjects:  13. Natural Language Processing;
10. Knowledge Acquisition"
143,2007,Natural-Language Processing,A Meta-learning Approach for Selecting between Response Automation Strategies in a Help-desk Domain,"Yuval Marom, Ingrid Zukerman, Nathalie Japkowicz","We present a corpus-based approach for the automation of help-desk
responses to users' email requests. Automation is performed
on the basis of the similarity between a request and previous
requests, which affects both the content included in a response
and the strategy used to produce it.  The latter is the focus
of this paper, which introduces a meta-learning mechanism that selects between different information-gathering strategies, such as document retrieval and multi-document summarization. Our results show that this mechanism outperforms a random strategy-selection policy, and performs competitively with a gold baseline that always selects the best strategy.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-144.pdf,"Subjects:  13. Natural Language Processing;
12. Machine Learning and Discovery"
144,2007,Natural-Language Processing,Joint Inference in Information Extraction,"Hoifung Poon, Pedro Domingos","The goal of information extraction is to extract database records from text or semi-structured sources. Traditionally, information extraction proceeds by first segmenting each candidate record separately, and then merging records that refer to the same entities. While computationally efficient, this approach is suboptimal, because it ignores the fact that segmenting one candidate record can help to segment similar ones. For example, resolving a well-segmented field with a less-clear one can disambiguate the latter's boundaries. In this paper we propose a joint approach to information extraction, where segmentation of all records and entity resolution are performed together in a single integrated inference process. While a number of previous authors have taken steps in this direction (e.g., Pasula et al (2003), Wellner et al. (2004)), to our knowledge this is the first fully joint approach. In experiments on the CiteSeer and Cora citation matching datasets, joint inference improved accuracy, and our approach outperformed previous ones. Further, by using Markov logic and the existing algorithms for it, our solution consisted mainly of writing the appropriate logical formulas, and required much less engineering than previous ones.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-145.pdf,"Subjects:  13. Natural Language Processing;
3.4 Probabilistic Reasoning"
145,2007,Natural-Language Processing,Content Analysis for Proactive Intelligence: Marshaling Frame Evidence,"Antonio Sanfilippo, Andrew Cowell, Stephen Tratz, Annie Boek, Amanda Cowell, Christian Posse, Line Pouchard","Modeling and simulation have great potential as technologies capable of aiding analysts in making accurate predictions of future situations to help provide competitive advantage and avoid strategic surprise. However, to make modeling and simulation effective, an evidence-marshaling process is needed that addresses the information needs of the modeling task, as detailed by subject matter experts. We suggest that such an evidence-marshaling process can be obtained by combining natural language processing and content analysis techniques to provide quantified qualitative content assessments, and describe a case study on the acquisition and marshaling of frames from unstructured text.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-146.pdf,"Subjects:  13. Natural Language Processing;
10. Knowledge Acquisition"
146,2007,Natural-Language Processing,Mining Sequential Patterns and Tree Patterns to Detect Erroneous Sentences,"Guihua Sun, Gao Cong, Xiaohua Liu, Chin-Yew Lin, Ming Zhou","An important application area of detecting erroneous sentences is to provide feedback for writers of English as a Second Language. This problem is difficult since both erroneous and correct sentences are diversified. In this paper, we propose a novel approach to identifying erroneous sentences. We first mine labeled tree patterns and sequential patterns to characterize both erroneous and correct sentences. Then the discovered patterns are utilized in two ways to distinguish correct sentences from erroneous sentences: (1) the patterns are transformed into sentence features for existing classification models, e.g., SVM; (2) the patterns are used to build a rule-based classification model. Experimental results show that both techniques are promising while the second technique outperforms the first approach. Moreover, the classification model in the second proposal is easy to understand, and we can provide intuitive explanation for classification results.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-147.pdf,"Subjects:  13. Natural Language Processing;
12. Machine Learning and Discovery"
147,2007,Natural-Language Processing,Single Document Summarization with Document Expansion,"Xiaojun Wan, Jianwu Yang","Existing methods for single document summarization usually make use of only the information contained in the specified document. This paper proposes the technique of document expansion to provide more knowledge to help single document summarization. A specified document is expanded to a small document set by adding a few neighbor documents close to the document, and then the graph-ranking based algorithm is applied on the expanded document set for extracting sentences from the single document, by making use of both the within-document relationships between sentences of the specified document and the cross-document relationships between sentences of all documents in the document set. The experimental results on the DUC2002 dataset demonstrate the effectiveness of the proposed approach based on document expansion. The cross-document relationships between sentences in the expanded document set are validated to be very important for single document summarization.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-148.pdf,"Subjects:  13. Natural Language Processing;
1.10 Information Retrieval"
148,2007,Natural-Language Processing,Recognizing Textual Entailment Using a Subsequence Kernel Method,"Rui Wang, Günter Neumann","We present a novel approach to recognizing Textual Entailment. Structural features are constructed from abstract tree descriptions, which are automatically extracted from syntactic dependency trees. These features are then applied in a subsequence-kernel-based classifier to learn whether an entailment relation holds between two texts. Our method makes use of machine learning techniques using a limited data set, no external knowledge bases (e.g. WordNet), and no handcrafted inference rules. We achieve an accuracy of 74.5% for text pairs in the Information Extraction and Question Answering task, 63.6% for the RTE-2 test data, and 66.9% for the RET-3 test data.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-149.pdf,"Subjects:  13. Natural Language Processing;
12. Machine Learning and Discovery"
149,2007,"Reasoning about Plans, Processes, and Actions",Incorporating Observer Biases in Keyhole Plan Recognition (Efficiently!),"Dorit Avrahami-Zilberbrand, Gal A. Kaminka","Plan recognition is the process of inferring other agents’ plans
and goals based on their observable actions. Essentially all
previous work in plan recognition has focused on the recognition
process itself, with no regard to the use of the information
in the recognizing agent. As a result, low-likelihood
recognition hypotheses that may imply significant meaning to
the observer, are ignored in existing work. In this paper, we
present novel efficient algorithms that allows the observer to
incorporate her own biases and preferences—in the form of
a utility function — into the plan recognition process. This
allows choosing recognition hypotheses based on their expected
utility to the observer. We call this Utility-based Plan
Recognition (UPR). While reasoning about such expected
utilities is intractable in the general case, we present a hybrid
symbolic/decision-theoretic plan recognizer, whose complexity
is O(NDT), where N is the plan library size, D is the
depth of the library and T is the number of observations. We
demonstrate the efficacy of this approach with experimental
results in several challenging recognition tasks.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-150.pdf,"Subjects:  3.6 Temporal Reasoning;
15.5 Decision Theory"
150,2007,"Reasoning about Plans, Processes, and Actions",Concurrent Action Execution with Shared Fluents,"Michael Buro, Alexander Kovarsky","Concurrent action execution is important for plan-length minimization. However, action specifications are often limited to avoid conflicts arising from precondition/effect interactions.  PDDL - the planning domain definition language - for example, implements the ``no moving targets'' rule, which means that no two actions can simultaneously make use of a value if one of the two is updating the value. This rule poses problems for resource allocation planning in which resource values are accessed in preconditions and effects. A simple example is construction actions that consume certain amounts of a resource. For
speeding up plan execution, we would like to be able to dispatch
several construction actions simultaneously. Because action
preconditions depend on resource values and action effects change
them, the ``no moving targets'' rule does not allow concurrent
execution. However, if sufficient resources are available, executing actions simultaneously poses no problems. This paper addresses the problem of deciding whether a set of actions produced by a planning system can be executed concurrently in the presence of fluent variables that occur in both action preconditions and effects. We first motivate the concurrent action execution problem by introducing a fair action scheduling algorithm for real-time strategy (RTS) games. Then we prove that the general decision problem, when restricting effects and preconditions to polynomial time computations, is co-NP complete. Thereafter, we focus on problem restrictions based on commutative operators which allow us to specify sufficient conditions for concurrent executability that can be checked quickly if the number of shared fluents is small. Finally, we apply these findings to action execution with shared resources in RTS games.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-151.pdf,"Subjects:  1.11 Planning;
1.12 Scheduling"
151,2007,"Reasoning about Plans, Processes, and Actions",A Situation-Calculus Semantics for an Expressive Fragment of PDDL,"Jens Classen, Yuxiao Hu, Gerhard Lakemeyer","The Planning Domain Definition Language (PDDL) has become a common language to specify planning problems, facilitating the formulation of benchmarks and a direct comparison of planners.  Over the years PDDL has been extended beyond STRIPS and ADL in various directions, for example, by adding time and concurrent actions. The current semantics of PDDL is purely meta-theoretic and quite complex, which makes an analysis difficult. Moreover, relating the language to other action formalisms is also nontrivial. We propose an alternative semantics for an expressive fragment of PDDL within the situation calculus. This yields at least two advantages. For one, the new semantics is purely declarative, making it amenable to an analysis in terms of logical entailments. For another, it facilitates the comparison with and mapping to other formalisms that are defined on top of the same logic, such as the agent control language Golog. In particular we obtain the semantical foundation for embedding efficient PDDL-based planners into the more expressive, yet computationally expensive Golog, thus combining the benefits of both. Other by-products of our investigations are a simpler account of durative actions in the situation calculus and a new notion of compulsory actions.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-152.pdf,"Subjects:  11. Knowledge Representation;
3.3 Nonmonotonic Reasoning"
152,2007,"Reasoning about Plans, Processes, and Actions",A Modular Action Description Language for Protocol Composition,"Nirmit Desai, Munindar P. Singh","Protocols are modular abstractions that capture patterns of interaction among agents.  The compelling vision behind protocols is to enable creating customized interactions by refining and composing existing protocols.  Realizing this vision presupposes (1) maintaining repositories of protocols and (2) refining and composing selected protocols.  To this end, this paper synthesizes recent advances on protocols and on the knowledge representation of actions.  This paper presents MAD-P, a modular action description language tailored for protocols.  MAD-P enables building an aggregation hierarchy of protocols via composition.  This paper demonstrates the value of such compositions via a simplified, but realistic, business scenario.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-153.pdf,"Subjects:  7. Distributed AI;
3.3 Nonmonotonic Reasoning"
153,2007,"Reasoning about Plans, Processes, and Actions",Detecting Execution Failures Using Learned Action Models,"Maria Fox, Jonathan Gough, Derek Long","Planners reason with abstracted models of the behaviours they use to construct plans. When plans are turned into the instructions that drive an executive, the real behaviours interacting with the unpredictable uncertainties of the environment can lead to failure. One of the challenges for intelligent autonomy is to recognise when the actual execution of a behaviour has diverged so far from the expected behaviour that it can be considered to be a failure. In this paper we present an approach by which a trace of the execution of a behaviour is monitored by tracking its most likely explanation through a learned model of how the behaviour is normally executed. In this way, possible failures are identified as deviations from common patterns of the execution of the behaviour. We perform an experiment in which we inject errors into the behaviour of a robot performing a particular task, and explore how well a learned model of the task can detect where these errors occur.  
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-154.pdf,"Subjects:  12. Machine Learning and Discovery;
1.5 Diagnosis"
154,2007,"Reasoning about Plans, Processes, and Actions","ESP: A Logic of Only-Knowing, Noisy Sensing and Acting","Alfredo Gabaldon,  Gerhard Lakemeyer","When reasoning about actions and sensors in realistic
domains, the ability to cope with uncertainty often plays
an essential role. Among the approaches dealing with
uncertainty, the one by Bacchus, Halpern and Levesque,
which uses the situation calculus, is perhaps the most
expressive. However, there are still some open issues. For
example, it remains unclear what an agent's knowledge base
would actually look like. The formalism also requires
second-order logic to represent uncertain beliefs, yet a
first-order representation clearly seems preferable. In
this paper we show how these issues can be addressed by
incorporating noisy sensors and actions into an existing
logic of only-knowing.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-155.pdf,"Subjects:  11. Knowledge Representation;
3.4 Probabilistic Reasoning"
155,2007,"Reasoning about Plans, Processes, and Actions",Action-Space Partitioning for Planning,"Natalia H. Gardiol, Leslie Pack Kaelbling","For autonomous artificial decision-makers to solve realistic tasks,
they need to deal with searching through large state and action spaces under time pressure. We study the problem of planning in such domains and show how structured representations of the environment's dynamics can help partition the action space into a set of equivalence classes at run time. The partitioned action space is then used to produce a reduced set of actions. This technique speeds up search and can yield significant gains in planning efficiency.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-156.pdf,"Subjects:  1.11 Planning;
1.11 Planning"
156,2007,"Reasoning about Plans, Processes, and Actions",Planning as Satisfiability with Preferences,"Enrico Giunchiglia, Marco Maratea","Planning as Satisfiability is one of the most well-known and effective technique for classical planning: SATPLAN has been the winning system in the deterministic track for optimal planners in the 4th International Planning Competition (IPC) and a co-winner in the 5th IPC.

In this paper we extend the Planning as Satisfiability approach  in order to handle preferences and SATPLAN in order to solve problems with simple preferences. The resulting system, SATPLAN(P) is competitive with SGPLAN, the winning system in the category ``simple preferences'' at the last IPC. Further, we show that SATPLAN(P) performances are (almost) always comparable to those of SATPLAN when solving the same problems without preferences: in other words, introducing simple
preferences in SATPLAN does not affect its performances.
This latter result is due both to the particular mechanism we use in order to incorporate preferences in SATPLAN and to the relative low number of soft goals (each corresponding to a simple preference) usually present in planning problems. Indeed, if we consider the issue of determining minimal plans
(corresponding to problems with thousands of preferences) the performances of SATPLAN(P) are comparable to those of SATPLAN in many cases, but can be significantly worse when the number of preferences is very high compared to the total number of variables in the problem. Our analysis is conducted
considering both qualitative and quantitative preferences, different reductions from quantitative to qualitative ones, and most of the propositional planning domains from the IPCs and that
SATPLAN can handle. 
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-157.pdf,"Subjects:  1.11 Planning;
15.2 Constraint Satisfaction"
157,2007,"Reasoning about Plans, Processes, and Actions","Filtering, Decomposition and Search Space Reduction for Optimal Sequential Planning","Stéphane Grandcolas, Cyril Pain-Barre","We present in this paper a hybrid planning system which combines constraint satisfaction techniques and planning heuristics to produce optimal sequential plans.
It integrates its own consistency rules and filtering and decomposition mechanisms suitable for planning.
Given a fixed bound on the plan length, our planner works directly on a structure related to Graphplan's planning graph.
This structure is incrementally built: Each time it is extended, a sequential plan is searched.
Different search strategies may be employed.
Currently, it is a forward chaining search based on problem decomposition with action sets partitioning.Various techniques are used to reduce the search space, such as memorizing nogood states or estimating goals reachability.
In addition, the planner implements two different techniques to avoid enumerating some equivalent action sequences.
Empirical evaluation shows that our system is very competitive on many problems, especially compared to other optimal sequential planners.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-158.pdf,"Subjects:  1.11 Planning;
15.7 Search"
158,2007,"Reasoning about Plans, Processes, and Actions",Stochastic Filtering in a Probabilistic Action Model,"Hannaneh Hajishirzi, Eyal Amir","Stochastic filtering is the problem of estimating the state of a  dynamic system after time passes and given partial observations.  It is fundamental to automatic tracking, planning, and control of  real-world stochastic systems such as robots, programs, and  autonomous agents. This paper presents a novel sampling-based filtering algorithm. Its expected error is smaller than sequential Monte Carlo sampling techniques given a fixed number of samples, as we prove and show empirically. It does so by sampling deterministic action sequences and then performing exact filtering on those sequences. These results are promising for applications in   stochastic planning, natural language processing, and robot control.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-159.pdf,"Subjects:  3.4 Probabilistic Reasoning;
3.6 Temporal Reasoning"
159,2007,"Reasoning about Plans, Processes, and Actions",Domain-Independent Construction of Pattern Database Heuristics for Cost-Optimal Planning,"Patrik Haslum, Adi Botea, Malte Helmert, Blai Bonet, Sven Koenig","Heuristic search is a leading approach to domain-independent planning. For cost-optimal planning, however, existing admissible heuristics are generally too weak to effectively guide the search. Pattern database heuristics (PDBs), which are based on abstractions of the search space, are currently one of the most promising approaches to developing better admissible heuristics.
The informedness of PDB heuristics depends crucially on the selection of appropriate abstractions (patterns). Although PDBs have been applied to many search problems, including planning, there are not many insights into how to select good patterns, even manually. What constitutes a good pattern depends on the problem domain, making the task even more difficult for domain-independent planning, where the process needs to be completely automatic and general.
We present a novel way of constructing good patterns automatically from the specification of planning problem instances. We demonstrate that this allows a domain-independent planner to solve planning problems optimally in some very challenging domains, including a STRIPS formulation of the Sokoban puzzle.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-160.pdf,"Subjects:  1.11 Planning;
15.7 Search"
160,2007,"Reasoning about Plans, Processes, and Actions","Web Service Composition as Planning, Revisited: In Between
Background Theories and Initial State Uncertainty","Joerg Hoffmann, Piergiorgio Bertoli, Marco Pistore","Thanks to recent advances, AI Planning has become the underlying
technique for several applications. Amongst these, a prominent one is
automated Web Service Composition (WSC). One important issue in this
context has been hardly addressed so far: WSC requires dealing with
background ontologies. The support for those is severely limited in
current planning tools. We introduce a planning formalism that
faithfully represents WSC. We show that, unsurprisingly, planning in
such a formalism is very hard. We then identify an interesting special
case that covers many relevant WSC scenarios, and where the semantics
are simpler and easier to deal with. This opens the way to the
development of effective support tools for WSC. Furthermore, we show
that if one additionally limits the amount and form of outputs that
can be generated, then the set of possible states becomes static, and
can be modelled in terms of a standard notion of initial state
uncertainty. For this, effective tools exist; these can realize
scalable WSC with powerful background ontologies. In an initial
experiment, we show how scaling WSC instances are comfortably solved
by a tool incorporating modern planning heuristics.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-161.pdf,"Subjects:  1.11 Planning;
15.7 Search"
161,2007,"Reasoning about Plans, Processes, and Actions",Understanding Performance Tradeoffs in Algorithms for Solving Oversubscribed Scheduling,"Laurence A. Kramer, Laura V. Barbulescu, Stephen F. Smith","In recent years, planning and scheduling research has paid increasing attention to problems that involve resource oversubscription, where cumulative demand for resources outstrips their availability and some subset of goals or tasks must be excluded. Two basic classes of techniques to solve oversubscribed scheduling problems have emerged: searching directly in the space of possible schedules and searching in an alternative space of task permutations (by relying on a schedule builder to provide a mapping to schedule space). In some problem contexts, permutation-based search methods have been shown to outperform schedule-space search methods, while in others the opposite has been shown to be the case. We consider two techniques for which this behavior has been observed: TaskSwap (TS), a schedule-space repair search procedure, and Squeaky Wheel Optimization (SWO), a permutation-space scheduling procedure. We analyze the circumstances under which one can be expected to dominate the other. Starting from a real-world scheduling problem where SWO has been shown to outperform TS, we construct a series of problem instances that increasingly incorporate characteristics of a second real-world scheduling problem, where TS has been found to outperform SWO. Experimental results provide insights into when schedule-space methods and permutation-based methods may be most appropriate.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-162.pdf,"Subjects:  1.12 Scheduling;
15.7 Search"
162,2007,"Reasoning about Plans, Processes, and Actions",The Semantics of Variables in Action Descriptions,"Vladimir Lifschitz, Wanwan Ren","Action description language C+ is more expressive than ADL in many ways; for instance, it addresses the ramification problem. On the other hand, ADL is based on first-order logic, while C+ is only propositional; expressions with variables, which are frequently used when action domains are described in C+, are merely schemas describing finite sets of causal laws that are formed according to the same pattern. In this paper we propose a new approach to the semantics of action descriptions with variables that combines attractive features of ADL and C+.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-163.pdf,"Subjects:  3.3 Nonmonotonic Reasoning;
5. Common Sense Reasoning"
163,2007,"Reasoning about Plans, Processes, and Actions",On the Partial Observability of Temporal Uncertainty,Michael D. Moffitt,"We explore a means to both model and reason about partial observability within the scope of constraint-based temporal reasoning. Prior studies of uncertainty in Temporal CSPs have required the realization of all exogenous processes to be made entirely visible to the agent. We relax this assumption and propose an extension to the Simple Temporal Problem with Uncertainty (STPU), one in which the executing agent is made aware of the occurrence of only a subset of uncontrollable events. We argue that such a formalism is needed to encode those complex environments whose external phenomena share a common, hidden source of temporal causality.  After characterizing the levels of controllability in the resulting Partially Observable STPU and various special cases, we generalize a known family of reduction rules to account for this relaxation, introducing the properties of extended contingency and sufficient observability. We demonstrate that these modifications enable a polynomial filtering algorithm capable of determining a local form of dynamic controllability; however, we also show that there do remain some instances whose global controllability cannot yet be correctly identified by existing inference rules, leaving the true computational complexity of dynamic controllability an open problem for future research.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-164.pdf,"Subjects:  3.6 Temporal Reasoning;
15.2 Constraint Satisfaction"
164,2007,"Reasoning about Plans, Processes, and Actions",Minimal Mental Models,"David V. Pynadath, Stacy C. Marsella","Agents must form and update mental models about each other in a wide range of domains: team coordination, plan recognition, social simulation, user modeling, games of incomplete information, etc.  Existing research typically treats the problem of forming beliefs about other agents as an isolated subproblem, where the modeling agent starts from an initial set of possible models for another agent and then maintains a belief about which of those models applies.  This initial set of models is typically a full specification of possible agent types.  Although such a rich space gives the modeling agent high accuracy in its beliefs, it will also incur high cost in maintaining those beliefs.  In this paper, we demonstrate that by taking this modeling problem out of its isolation and placing it back within the overall decision-making context, the modeling agent can drastically reduce this rich model space without sacrificing any performance.  Our approach comprises three methods.  The first method clusters models that lead to the same behaviors in the modeling agent's decision-making context.  The second method clusters models that may produce different behaviors, but produce equally preferred outcomes with respect to the utility of the modeling agent.  The third technique sacrifices a fixed amount of accuracy by clustering models that lead to performance losses that are below a certain threshold.  We illustrate our framework using a social simulation domain and demonstrate its value by showing the minimal mental model spaces that it generates.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-165.pdf,"Subjects:  7.1 Multi-Agent Systems;
15.5 Decision Theory"
165,2007,"Reasoning about Plans, Processes, and Actions",Asymptotically Optimal Encodings of Conformant Planning in QBF,Jussi Rintanen,"The world is unpredictable, and acting intelligently requires anticipating possible consequences of actions that are taken. Assuming that the actions and the world are deterministic, planning can be represented in the classical propositional logic. Introducing nondeterminism (but not probabilities) or several initial states increases the complexity of the planning problem and requires the use of quantified Boolean formulae (QBF).

The currently leading logic-based approaches to conditional planning use explicitly or implicitly a QBF with the prefix EAE. We present formalizations of the planning problem as QBF which have an asymptotically optimal linear size and the optimal number of quantifier alternations in the prefix: EA and AE. This is in accordance with the fact that the planning problem (under the restriction to polynomial size plans) is on the second level of the polynomial hierarchy, not on the third.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-166.pdf,"Subjects:  1.11 Planning;
15.9 Theorem Proving"
166,2007,"Reasoning about Plans, Processes, and Actions",Expressiveness of ADL and Golog: Functions Make a Difference,"Gabriele Röger, Bernhard Nebel","The main focus in the area of action languages, such as GOLOG, was put on expressive power, while the development in the area of action planning was focused on efficient plan generation.
An integration of GOLOG and planning languages would provide great
advantages. A user could constrain a system's behavior on a high level using GOLOG, while the actual low-level actions are planned by an efficient planning system.
First endeavors have been made by Eyerich et al. by identifying a
subset of the situation calculus (which is the basis of GOLOG) with the same expressiveness as the ADL fragment of PDDL. However, it was not proven that the identified restrictions define a maximum subset. The most severe restriction appears to be that functions are limited to constants. We will show that this restriction is indeed necessary in most cases.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-167.pdf,"Subjects:  11. Knowledge Representation;
1.11 Planning"
167,2007,"Reasoning about Plans, Processes, and Actions",Purely Epistemic Markov Decision Processes,"Régis Sabbadin, Jérome Lang, Nasolo Ravoanjanahry","Planning under uncertainty involves two distinct sources of uncertainty: uncertainty about the effects of actions and uncertainty about the current state of the world. The most widely developed model that deals with both sources of uncertainty is that of Partially Observable Markov Decision Processes (POMDPs). 
Simplifying POMDPs by getting rid of the second source of uncertainty leads to the well-known framework of fully observable MDPs. Getting rid of the first source of uncertainty leads to a less widely studied framework, namely, decision processes where actions cannot change the state of the world and are only intended to bring some information about the (static) state of the world. Such  ``purely epistemic'' processes are very relevant, since many practical problems (such as diagnosis, database querying, or preference elicitation) fall into this class. However, it is not known whether this specific restriction of POMDP is computationally simpler than POMDPs. In this paper we establish several complexity results for purely epistemic MDPs (EMDPs). We first show that short-horizon policy existence in EMDPs is PSPACE-complete. Then we focus on the specific case of EMDPs with reliable observations and show that in this case, policy existence is ``only'' NP-complete; however, we show that this problem cannot be approximated with a bounded performance ratio by a polynomial-time algorithm.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-168.pdf,"Subjects:  15.5 Decision Theory;
3.4 Probabilistic Reasoning"
168,2007,"Reasoning about Plans, Processes, and Actions","Automatic Synthesis of a Global Behavior from Multiple Distributed
Behaviors","Sebastian Sardina, Fabio Patrizi, Giuseppe De Giacomo","We consider the problem of synthesizing a team of local behavior controllers to realize a fully controllable target behavior from a set of available partially controllable behaviors that execute distributively within a shared partially predictable, but fully observable, environment. Available behaviors stand for existing distributed components and are
represented with (finite) nondeterministic transition systems. The target behavior is assumed to be fully deterministic and stands for the collective behavior that the system as a whole needs to guarantee. We formally define the problem within a general framework, characterize its computational complexity, and propose techniques to actually generate a solution. Also, we investigate the relationship between the distributed solutions and the centralized ones, in which a single global controller is conceivable.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-169.pdf,"Subjects:  3. Automated Reasoning;
15.3 Control"
169,2007,"Reasoning about Plans, Processes, and Actions",Optimal Regression for Reasoning about Knowledge and Actions,"Hans van Ditmarsch,  Andreas Herzig, Tiago de Lima","We show how in the propositional case both Reiter's and Scherl and Levesque's solutions to the frame problem can be modelled in dynamic epistemic logic (DEL), and provide an optimal regression algorithm for the latter. Our method is as follows: we extend Reiter's framework by integrating observation actions and modal operators of knowledge, and encode the resulting formalism in DEL with announcement and assignment operators. By extending Lutz' recent satisfiability-preserving reduction to our logic, we establish optimal decision procedures for both Reiter's and Scherl amd Levesque's approaches: satisfiability is NP-complete for one agent, PSPACE-complete for multiple agents and EXPTIME-complete when common knowledge is involved.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-170.pdf,"Subjects:  11. Knowledge Representation;
3. Automated Reasoning"
170,2007,Robotics and Perception,A Vision-Based System for a UGV to Handle a Road Intersection,"Javed Ahmed, Mubarak Shah, Andrew Miller, Don Harper, M. N. Jafri","We propose a real-time computer vision system that enables a UGV to safely cross urban road-intersections. Specifically, when the UGV approaches the stop sign at a 4-way intersection, it must be aware of the vehicles at the other three roads and adhere to traffic rules by waiting for its turn to proceed. The proposed solution consists of three main components: a vehicle detector, a tracker, and a finite-state-machine to model the traffic. We use an OT-MACH filter to detect the leading vehicle in each of three camera-views of the corresponding roads. Then, we track the vehicles using an edge-enhanced dynamic correlation tracker, which estimates the current and next positions, velocities, and accelerations of the vehicles. Finally, the finite-state-machine describes the traffic in each road with one of four possible states (i.e. No Vehicle Waiting, Arriving, Waiting, and Passing), and signals an autopilot system when it is safe to pass the intersection. We provide the results from an actual intersection with real traffic to demonstrate that the UGV is able to automatically navigate the intersection using the proposed system.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-171.pdf,"Subjects:  19. Vision;
17. Robotics"
171,2007,Robotics and Perception,Topological Mapping with Weak Sensory Data,"Gregory  Dudek, Dimitri Marinakis","In this paper, we consider the exploration of topological environments by a robot with weak sensory capabilities. We assume only that the robot can recognize when it has reached a vertex, and can assign a cyclic ordering to the edges leaving a vertex with reference to the edge it arrived from. Given this limited sensing capability, and without the use of any markers or additional information, we will show that the construction of a topological map is still feasible.  This is accomplished through both the exploration strategy which is designed to reveal model 
inconsistencies and by a search process that maintains a bounded set of believable world models throughout the exploration process.  Plausible models are selected through the use of a ranking 
heuristic function based on the principle of Occam's Razor. 
We conclude with numerical simulations demonstrating the performance of the algorithm. 
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-172.pdf,"Subjects:  17. Robotics;
3.2 Geometric Or Spatial Reasoning"
172,2007,Robotics and Perception,Hybrid Inference for Sensor Network Localization using a Mobile Robot,"Dimitri Marinakis, David Meger, Ioannis Rekleitis, Gregory Dudek","In this paper, we consider a hybrid solution to the sensor network position inference problem, which combines a real-time filtering system with information from a more expensive, global inference procedure to improve accuracy and prevent divergence. Many online solutions for this problem make use of simplifying assumptions, such as Gaussian noise models and linear system behaviour and also adopt a filtering strategy which may not use available information optimally. These assumptions allow near real-time inference, while also limiting accuracy and introducing the potential for ill-conditioning and divergence. We consider augmenting a particular real-time estimation method, the extended Kalman filter (EKF), with a more complex, but more highly accurate, inference technique based on Markov Chain Monte Carlo (MCMC) methodology. Conventional MCMC techniques applied to this problem can entail significant and time consuming computation to achieve convergence. To address this, we propose an intelligent bootstrapping process and the use of parallel, communicative chains of different temperatures, commonly referred to as parallel tempering. The combined approach is shown to provide substantial improvement in a realistic simulated mapping environment and when applied to a complex physical system involving a robotic platform moving in an office environment instrumented with a camera sensor network.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-173.pdf,"Subjects:  17. Robotics;
1. Applications"
173,2007,Robotics and Perception,Autonomous Development of a Grounded Object Ontology by a Learning Robot,"Joseph Modayil, Benjamin Kuipers","We describe how a physical robot can learn about objects from its own autonomous experience in the continuous world. The robot identifies statistical regularities that allow it to represent a physical object with a cluster of sensations that violate a static world model, track that cluster over time, extract percepts from that cluster, form concepts from similar percepts, and learn reliable actions that can be applied to objects. We present a formalism for representing the ontology for objects and actions, a learning algorithm, and the results of an evaluation with a physical robot.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-174.pdf,"Subjects:  17. Robotics;
12. Machine Learning and Discovery"
174,2007,Robotics and Perception,Online Co-Localization in Indoor Wireless Networks by Dimension Reduction,"Jeffrey Junfeng Pan, Qiang Yang, Sinno Jialin Pan","This paper addresses the problem of recovering the locations of both mobile devices and access points from radio signals that come in a stream manner, a problem which we call online co-localization, by exploiting both labeled and unlabeled data from mobile devices and access points. Many tracking systems function in two phases: an offline training phase and an online localization phase. In the training phase, models are built from a batch of data that are collected offline. Many of them can not cope with a dynamic environment in which calibration data may come sequentially. In such case, these systems may gradually become inaccurate without a manually costly re-calibration. To solve this problem, we proposed an online co-localization method that can deal with labeled and unlabeled data stream based on semi-supervised manifold-learning techniques. Experiments conducted in wireless local area networks show that we can achieve high accuracy with less calibration effort as compared to several previous systems. Furthermore, our method can deal with online stream data relatively faster than its two-phase counterpart.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-175.pdf,"Subjects:  17. Robotics;
1. Applications"
175,2007,Robotics and Perception,Adaptive Localization in a DynamicWiFi Environment Through Multi-view Learning,"Sinno Jialin Pan, James T. Kwok, Qiang Yang, Jeffrey Junfeng Pan","Accurately locating users in a wireless environment is an important task for many pervasive computing and AI applications, such as activity recognition. In a WiFi environment, a mobile device can be localized using signals received from various transmitters, such as access points (APs). Most localization approaches build a map between the signal space and the physical location space in a offline phase, and then using the received-signal-strength (RSS) map

to estimate the location in an online phase. However, the map can be outdated when the signal-strength values change with time due to environmental dynamics. It is infeasible or expensive to repeat data calibration for reconstructing the RSS map. In such a case, it is important to adapt the model learnt in one time period to another time period without too much re-calibration. In this paper, we present a location-estimation approach based on Manifold co-Regularization, which is a machine learning technique for building a mapping function between data. We describe LeManCoR, a system for adapting the mapping function between the signal space and physical location space over different time periods based on Manifold Co-Regularization. We show that LeManCoR can effectively transfer the knowledge between two time periods without requiring too much new calibration effort.We illustrate LeManCoR's effectiveness in a real 802.11 WiFi environment.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-176.pdf,"Subjects:  17. Robotics;
12. Machine Learning and Discovery"
176,2007,Robotics and Perception,Simple Robots with Minimal Sensing: From Local Visibility to Global Geometry,"Subhash Suri, Elias Vicari, Peter Widmayer","We consider problems of geometric exploration and self-deployment
for simple robots that can only sense the combinatorial (non-metric) features of their surroundings. Even with such a limited sensing, we show that robots can achieve complex geometric reasoning and perform many non-trivial tasks. Specifically, we show that one robot equipped with a single pebble can decide whether the workspace environment is a simply-connected polygon and, if not, it can also count the number of holes in the environment. Highlighting the subtleties of our sensing model, we show that a robot can decide whether
the environment is a convex polygon, yet it cannot resolve whether a particular vertex is convex.
Finally, we show that using such local and minimal sensing, a robot can compute a proper triangulation of a polygon, and that the triangulation algorithm can be implemented collaboratively by a group of $m$ such robots, each with $\Theta (n/m)$ memory. As a corollary of the triangulation algorithm, we derive a distributed analog of the well-known Art Gallery Theorem: a group of $\lfloor n/3 \rfloor$ (bounded memory) robots in our minimal sensing model can self-deploy to achieve visibility coverage of an $n$-vertex art gallery (polygon).  This resolves an open question raised recently by Ganguli et al.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-177.pdf,"Subjects:  17. Robotics;
3.2 Geometric Or Spatial Reasoning"
177,2007,Robotics and Perception,Photometric and Geometric Restoration of Document Images Using Inpainting and Shape-from-Shading,"Li Zhang, Andy M. Yip, Chew Lim Tan","The popularity of current hand-held digital imaging devices such as camera phones, PDAs, camcorders has promoted the use of digital cameras to capture document images for daily information recording purpose. However, the captured images often contain photometric and geometric distortions when the documents are of non-planar shapes, which cause significant problems to various document image analysis (DIA) tasks such as OCR. In this paper, we propose a restoration framework that removes both photometric and geometric distortions in smoothly warped document images to facilitate human perception and machine recognition. First, the photometric distortions are corrected by separating the shading image from the reflectance image using inpainting and surface fitting techniques. Next, a 2-pass Shape-from-Shading (SFS) method is exploited to recover the document's surface shape based on the extracted shading image. Once the document's shape is obtained, the geometric distortions are rectified through a physically-based flattening process. Experiments on real document images show the performance of each sub-task and demonstrate a complete solution to the restoration of physically-distorted document images.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-178.pdf,"Subjects:  19. Vision;
19.1 Perception"
178,2007,Robotics and Perception,Detection of Multiple Deformable Objects using PCA-SIFT,"Stefan Zickler, Alexei Efros","In this paper, we address the problem of identifying and localizing multiple instances of highly deformable objects in real-time video data. We present an approach which uses PCA-SIFT (Scale Invariant Feature Transform) in combination with a clustered voting scheme to achieve detection and localization of multiple objects while providing robustness against rapid shape deformation, partial occlusion, and perspective changes. We test our approach in two highly deformable robot domains and evaluate its performance using ROC (Receiver Operating Characteristic) statistics.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-179.pdf,"Subjects:  19. Vision;
17. Robotics"
179,2007,Search and Metareasoning,Heuristic Evaluation Functions for General Game Playing,James Clune,"A general game playing program plays games that it has not previously encountered. A game manager program sends the game playing programs a description of a game's rules and objectives in a well-defined game description language. A central challenge in creating effective general game playing programs is that of constructing heuristic evaluation functions from game descriptions. This paper describes a method for constructing evaluation functions that represent exact values of simplified games. The simplified games are abstract models that incorporate the most essential
aspects of the original game, namely payoff, control, and termination. Results of applying this method to a sampling of games suggest that heuristic evaluation functions based on our method are both comprehensible and effective.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-180.pdf,"Subjects:  1.8 Game Playing;
15.7 Search"
180,2007,Search and Metareasoning,On the Value of Good Advice: The Complexity of A* Search with Accurate Heuristics,"Hang Dinh, Alexander Russell, Yuan Su","We study the behavior of the classical A* search algorithm

when coupled with a heuristic that provides estimates, accurate

to within a small multiplicative factor, of the distance to

a solution. We prove general upper bounds on the complexity

of A* search, for both admissible and unconstrained heuristic

functions, that depend only on the distribution of solution

objective values. We go on to provide nearly matching lower

bounds that are attained even by non-adversarially chosen solution sets induced by a simple stochastic model.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-181.pdf,"Subjects:  15.7 Search;
9.2 Computational Complexity"
181,2007,Search and Metareasoning,Best-First Search for Treewidth,"P. Alex Dow, Richard E. Korf","Finding the exact treewidth of a graph is central to many operations in a variety of areas, including probabilistic reasoning and constraint satisfaction. Treewidth can be found by searching over the space of vertex elimination orders. This search space differs from those where best-first search is typically applied, because a solution path is evaluated by its maximum edge cost instead of the sum of its edge costs. We show how to make best-first search admissible on max-cost problem spaces. We also employ breadth-first heuristic search to reduce the memory requirement while still eliminating all duplicate nodes in the search space. Our empirical results show that our algorithms find the exact treewidth an order of magnitude faster than the previous state-of-the-art algorithm on hard benchmark graphs.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-182.pdf,"Subjects:  15.7 Search;
3.4 Probabilistic Reasoning"
182,2007,Search and Metareasoning,Automatic Algorithm Configuration based on Local Search,"Frank Hutter, Holger Hoos, Thomas Stuetzle","The determination of appropriate values for free algorithm
parameters is a challenging and tedious task in the design of
effective algorithms for hard problems. Such parameters include
categorical choices (e.g., neighborhood structure in local
search or variable/value ordering heuristics in tree search),
as well as numerical parameters (e.g., noise or restart timing).
In practice, tuning of these parameters is largely carried
out manually by applying rules of thumb and crude heuristics,
while more principled approaches are only rarely used.
In this paper, we present a local search approach for algorithm
configuration and prove its convergence to the globally
optimal parameter configuration. Our approach is very versatile:
it can, e.g., be used for minimising run-time in decision
problems or for maximising solution quality in optimisation
problems. It further applies to arbitrary algorithms,
including heuristic tree search and local search algorithms,
with no limitation on the number of parameters. Experiments
in four algorithm configuration scenarios demonstrate
that our automatically determined parameter settings always
outperform the algorithm defaults, sometimes by several orders
of magnitude. Our approach also shows better performance
and greater flexibility than the recent CALIBRA system.
Our ParamILS code, along with instructions on how to
use it for tuning your own algorithms, is available on-line at
http://www.cs.ubc.ca/labs/beta/Projects/ParamILS.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-183.pdf,"Subjects:  15. Problem Solving;
15.7 Search"
183,2007,Search and Metareasoning,Near-Optimal Search in Continuous Domains,"Samuel Ieong, Nicolas Lambert, Yoav Shoham, Ronen Brafman","We investigate search problems in continuous state and action spaces with no uncertainty.  Actions have costs and can only be taken at discrete time steps (unlike the case with continuous control).  Given an admissible heuristic function and a starting state, the objective is to find a minimum-cost plan that reaches a goal state.  As the continuous domain does not allow the tight optimality results that are possible in the discrete case (for example by A*), we instead propose and analyze an approximate forward-search algorithm that has the following provable properties.  Given a desired accuracy ε, and a bound d on the length of the plan, the algorithm computes a lower bound L on the cost of any plan.  It either (a) returns a plan of cost L that is at most ε more than the optimal plan, or (b) if, according to the heuristic estimate, there may exist a plan of cost L of length > d, returns a partial plan that traces the first d steps of such plan. To our knowledge, this is the first algorithm that provides optimality guarantees in continuous domains with discrete control and without uncertainty.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-184.pdf,"Subjects:  15.7 Search;
1.11 Planning"
184,2007,Search and Metareasoning,Analyzing the Performance of Pattern Database Heuristics,Richard E. Korf,"We introduce a model for predicting the performance of IDA* using pattern database heuristics, as a function of the branching factor of the problem, the solution depth, and the size of the pattern databases.  While it is known that the larger the pattern database, the more efficient the search, we provide a quantitative analysis of this relationship.  In particular, we show that for a single goal state, the number of nodes expanded by IDA* is a fraction of $(\log_bs+1)/s$ of the nodes expanded by a brute-force search, where $b$ is the branching factor, and $s$ is the size of the pattern database.  We also show that by taking the maximum of at least two pattern databases, the number of node expansions decreases linearly with $s$ compared to a brute-force search.  We compare our theoretical predictions with empirical performance data on Rubik's Cube.  Our model is conservative, and overestimates the actual number of node expansions.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-185.pdf,"Subjects:  15.7 Search;
Please choose a second document classification"
185,2007,Search and Metareasoning,Best-First AND/OR Search for Graphical Models,"Radu Marinescu, Rina Dechter","The paper presents and evaluates the power of best-first search  over AND/OR search spaces in graphical models. The main virtue of  the AND/OR representation is its sensitivity to the structure of the graphical model, which can translate into significant time  savings. Indeed, in recent years depth-first AND/OR ranch-and-Bound  algorithms were shown to be very effective when exploring such  search spaces, especially when using caching. Since best-first  strategies are known to be superior to depth-first when memory is  utilized, exploring the best-first control strategy is called  for. In this paper we introduce two classes of best-first AND/OR  search algorithms: those that explore a context-minimal AND/OR search graph and use static variable orderings, and those that use dynamic variable orderings but explore an AND/OR search tree. The superiority of the best-first search approach is demonstrated empirically on various real-world benchmarks.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-186.pdf,"Subjects:  3. Automated Reasoning;
15.7 Search"
186,2007,Search and Metareasoning,Theta*: Any-Angle Path Planning on Grids,"Alex Nash, Kenny Daniel, Sven Koenig, Ariel Felner","Grids with blocked and unblocked cells are often used to represent terrain in computer games and robotics. However, paths formed by grid edges can be sub-optimal and unrealistic looking, since the possible headings are artificially constrained. We present Theta*, a variant of A*, that propagates information along grid edges without constraining the paths to grid edges. Theta* is simple, fast and finds short and realistic looking paths. We compare Theta* against both Field D*, the only other variant of A* that propagates information along grid edges without constraining the paths to grid edges, and A* with post-smoothed paths. Although neither path planning method is guaranteed to find shortest paths, we show experimentally that Theta* finds shorter and more realistic looking paths than either of these existing techniques.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-187.pdf,"Subjects:  15.7 Search;
15. Problem Solving"
187,2007,Search and Metareasoning,Anytime Optimal Coalition Structure Generation,"Talal Rahwan, Sarvapali Ramchurn, Viet D. Dang, Andrea Giovannucci, Nicholas R. Jennings","A key problem when forming effective coalitions of autonomous agents is determining the best groupings, or the optimal coalition structure, to select to achieve some goal. To this end, we present a novel, anytime algorithm for this task that is significantly faster than current solutions. Specifically, we empirically show that we are able to find solutions that are optimal in 0.082 % of the time taken by the state of the art dynamic programming algorithm (for 27 agents), using much less memory (O(2^n) instead of O(3^n) for  n agents). Moreover, our algorithm is the first to be able to find solutions for more than 17 agents in reasonable time (less than 90 minutes for 27 agents, as opposed to around 2 months for the best previous solution).",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-188.pdf,"Subjects:  7.1 Multi-Agent Systems;
15.7 Search"
188,2007,Search and Metareasoning,Fluxplayer: A Successful General Game Player,"Stephan Schiffel, Michael Thielscher","General Game Playing (GGP) is the art of designing programs that are capable of playing previously unknown games of a wide variety by being told nothing but the rules of the game. This is in contrast to traditional computer game players like Deep Blue, which are designed for a particular game and can't adapt automatically to modifications of the rules, let alone play completely different games.
General Game Playing is intended to foster the development of integrated cognitive information processing technology. In this article we present an approach to General Game Playing using a novel way of automatically constructing a position evaluation function from a formal game description. Our system is being tested with a wide range of different games. Most notably, it is the winner of the AAAI GGP Competition 2006.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-189.pdf,"Subjects:  1.8 Game Playing;
15.7 Search"
189,2007,Search and Metareasoning,Combining Multiple Heuristics Online,"Matthew Streeter, Daniel Golovin, Stephen F. Smith","We present black-box techniques for learning how to interleave the execution of multiple heuristics in order to improve average-case performance.  In our model, a user is given a set of heuristics whose only observable behavior is their running time.  Each heuristic can compute a solution to any problem instance, but its running time varies across instances.  The user solves each instance by interleaving runs of the heuristics according to a task-switching schedule.  We present (i) exact and approximation algorithms for computing an optimal task-switching schedule offline, (ii) sample complexity bounds for learning a task-switching schedule from training data, and (iii) a no-regret strategy for selecting task-switching schedules online.  We demonstrate the power of our results using data from recent solver competitions.  We outline how to extend our results to the case in which the heuristics are randomized, and the user may periodically restart each heuristic with a fresh random seed.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-190.pdf,"Subjects:  12. Machine Learning and Discovery;
15.5 Decision Theory"
190,2007,Search and Metareasoning,Restart Schedules for Ensembles of Problem Instances,"Matthew Streeter, Daniel Golovin, Stephen F. Smith","The mean running time of a Las Vegas algorithm can often be dramatically reduced by periodically restarting it with a fresh random seed.  The optimal restart schedule depends on the Las Vegas algorithm's run length distribution, which in general is not known in advance and may differ across problem instances.  We consider the problem of selecting a single restart schedule to use in solving each instance in a set of instances.  We present offline algorithms for computing an (approximately) optimal restart schedule given knowledge of each instance's run length distribution, generalization bounds for learning a restart schedule from training data, and online algorithms for selecting a restart schedule adaptively as new problem instances are encountered.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-191.pdf,"Subjects:  12. Machine Learning and Discovery;
15.5 Decision Theory"
191,2007,Search and Metareasoning,Inconsistent Heuristics,"Uzi Zahavi, Ariel Felner, Jonathan Schaeffer, Nathan Sturtevant.","In the field of heuristic search it is well-known that improving the quality of an admissible heuristic can significantly decrease the search effort required to find an optimal solution. Existing literature often assumes that admissible heuristics are consistent, implying that consistency is a desirable attribute. To the contrary, this paper shows that an inconsistent heuristic can be preferable to a consistent heuristic. Theoretical and empirical results show that, in many cases, inconsistency can be used to achieve large performance improvements. The conventional wisdom about inconsistent heuristics is wrong.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-192.pdf,"Subjects:  15.7 Search;
15.7 Search"
192,2007,Search and Metareasoning,Parallel Structured Duplicate Detection,"Rong Zhou, Eric A. Hansen","We describe a novel approach to parallelizing graph search using structured duplicate detection. Structured duplicate detection was originally developed as an approach to external-memory graph search that reduces the number of expensive disk I/O operations needed to check stored nodes for duplicates, by using an abstraction of the search graph to localize memory references. In this paper, we show that this approach can also be used to reduce the number of slow synchronization operations needed in parallel graph search. In addition, we describe several techniques for integrating parallel and external-memory graph search in an efficient way. We demonstrate the effectiveness of these techniques in a graph-search algorithm for domain-independent STRIPS planning.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-193.pdf,"Subjects:  15.7 Search;
1.11 Planning"
193,2007,Uncertainty in AI,VOILA: Efficient Feature-value Acquisition for Classification,"Mustafa Bilgic, Lise Getoor","We address the problem of efficient feature-value acquisition for classification in domains in which there are varying costs associated with both feature acquisition and misclassification. The objective is to minimize the sum of the information acquisition cost and misclassification cost. Any decision theoretic strategy tackling this problem needs to compute value of information for sets of features. Having calculated this information, different acquisition strategies are possible (acquiring one feature at time, acquiring features in sets, etc.). However, because the value of information calculation for arbitrary subsets of features is computationally intractable, most traditional approaches have been greedy, computing values of features one at a time. We make the problem of value of information calculation tractable in practice by introducing a novel data structure called the Value of Information Lattice (VOILA). VOILA exploits dependencies between missing features and makes sharing of information value computations between different feature subsets possible. To the best of our knowledge, performance differences between greedy acquisition, acquiring features in sets, and a mixed strategy have not been investigated empirically in the past, due to inherit intractability of the problem. With the help of VOILA, we are able to evaluate these strategies on five real world datasets under various cost assumptions. We show that VOILA reduces computation time dramatically. We also show that the mixed strategy outperforms both greedy acquisition and acquisition in sets.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-194.pdf,"Subjects:  12. Machine Learning and Discovery;
15.5 Decision Theory"
194,2007,Uncertainty in AI,Computing Optimal Subsets,"Maxim Binshtok, Ronen I. Brafman, Solomon E. Shimony, Ajay Martin, Craig Boutilier","Various tasks in decision making and decision support require

selecting a preferred subset of items from a given set of feasible

items. Recent work in this area considered methods for specifying

such preferences based on the attribute values of individual

elements within the set. Of these, the approach of Brafman et. al. (2006)

appears to be the most general. In this paper, we consider the

problem of computing an optimal subset given such a specification.

The problem is shown to be NP-hard in the general case,

necessitating heuristic search methods. We consider two algorithm

classes for this problem: direct set construction, and implicit

enumeration as solutions to appropriate CSPs. New algorithms are

presented in each class and compared empirically against previous

results.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-195.pdf,"Subjects:  15.5 Decision Theory;
15.2 Constraint Satisfaction"
195,2007,Uncertainty in AI,Indefinite-Horizon POMDPs with Action-Based Termination,Eric A. Hansen,"For decision-theoretic planning problems with an indefinite horizon, plan execution terminates after a finite number of steps with probability one, but the number of steps until termination (i.e., the horizon) is uncertain and unbounded. In the traditional approach to modeling such problems, called a stochastic shortest-path problem, plan execution terminates when a particular state is reached, typically a goal state. We consider a model in which plan execution terminates when a stopping action is taken. We show that an action-based model of termination has several advantages for partially observable planning problems. It does not require a goal state to be fully observable; it does not require achievement of a goal state to be guaranteed; and it allows a proper policy to be found more easily. This framework allows many partially observable planning problems to be modeled in a more realistic way that does not require an artificial discount factor.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-196.pdf,"Subjects:  1.11 Planning;
15.5 Decision Theory"
196,2007,Uncertainty in AI,Point-Based Policy Iteration,"Shihao Ji, Ronald Parr, Hui Li, Xuejun Liao, Lawrence Carin","We describe a point-based policy iteration (PBPI) algorithm for

infinite-horizon POMDPs. PBPI replaces the exact policy improvement step of Hansen's policy iteration with point-based value iteration (PBVI).  Despite being an approximate algorithm, PBPI is monotonic: At each iteration before convergence, PBPI produces a policy for which the values increase for at least one of a finite set of initial belief states, and decrease for none of these states. In contrast, PBVI cannot guarantee monotonic improvement of the value function or the policy.  In practice PBPI generally needs a lower density of point coverage in the simplex and tends to produce superior policies with less computation. Experiments on several benchmark problems (up to 12,545 states) demonstrate the scalability and robustness of the PBPI algorithm.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-197.pdf,"Subjects:  1.11 Planning;
3.4 Probabilistic Reasoning"
197,2007,Uncertainty in AI,"Thresholded Rewards: Acting Optimally in Timed, Zero-Sum Games","Colin McMillen, Manuela Veloso","In timed, zero-sum games, the goal is to maximize the probability of winning, which is not necessarily the same as maximizing our expected reward.  We consider cumulative intermediate reward to be the difference between our score and our opponent's score; the ""true"" reward of a win, loss, or tie is determined at the end of a game by applying a threshold function to the cumulative intermediate reward. We introduce thresholded-rewards problems to capture this dependency of the final reward outcome on the cumulative intermediate reward. Thresholded-rewards problems reflect different real-world stochastic planning domains, especially zero-sum games, in which time and score need to be considered.  We investigate the application of thresholded rewards to finite-horizon Markov Decision Processes (MDPs). In general, the optimal policy for a thresholded-rewards MDP will be nonstationary, depending on the number of time steps remaining and the cumulative intermediate reward.  We introduce an efficient value iteration algorithm that solves thresholded-rewards MDPs exactly, but with running time quadratic on the number of states in the MDP and the length of the time horizon. We investigate a number of heuristic-based techniques that efficiently find approximate solutions for MDPs with large state spaces or long time horizons.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-198.pdf,"Subjects:  3.4 Probabilistic Reasoning;
3.6 Temporal Reasoning"
198,2007,Uncertainty in AI,Macroscopic Models of Clique Tree Growth for Bayesian Networks,Ole J. Mengshoel,"In clique tree clustering, inference consists of propagation 

in a clique tree compiled from a Bayesian network. In this 

paper, we develop an analytical approach to characterizing 

clique tree growth as a function of increasing Bayesian 

network connectedness, specifically: (i) the expected number of 

moral edges in their moral graphs or (ii) the ratio of the 

number of non-root nodes to the number of root nodes.  In experiments, we systematically increase the connectivity of 

bipartite Bayesian networks, and find that clique tree size growth is well-approximated by Gompertz growth curves.  This 

research improves the understanding of the scaling behavior of clique tree clustering, provides a foundation for benchmarking 

and developing improved BN inference algorithms, and presents 

an aid for analytical trade-off studies of tree clustering using growth curves.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-199.pdf,"Subjects:  3. Automated Reasoning;
3.4 Probabilistic Reasoning"
199,2007,Uncertainty in AI,Sampling with Memoization,Avi Pfeffer,"Memoization is a fundamental technique in computer science, providing the basis for dynamic programming.  This paper explores using memoization to improve the performance of rejection sampling algorithms.  It is shown that reusing values produced in previous samples and stored in a cache is beneficial.  The paper goes on to explore the idea of recursive memoization, in which values are aggressively reused from the cache even in the process of computing a value to store in the cache.  This leads to the values in the cache becoming dependent on each other, and therefore produces a biased sampler.  However in practice this seems to be quite beneficial. Furthermore, we show that the error in the cache tends to zero in the long run.  We demonstrate the usefulness of memoized sampling in a duplicate bridge simulation, and in experiments with probabilistic grammars.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-200.pdf,"Subjects:  3.4 Probabilistic Reasoning;
3. Automated Reasoning"
200,2007,Uncertainty in AI,"Logical Generative Models for Probabilistic Reasoning about Existence, Roles and Identity",David Poole,"In probabilistic reasoning, the problems of existence and identity
  are important to many different queries; for example, the
  probability that something that fits some description exists, the
  probability that some description refers to an object you know about
  or to a new object, or the probability that an object fulfils some
  role.  Many interesting queries reduce to reasoning about the role
  of objects. Being able to talk about the existence of parts and
  sub-parts and the relationships between these parts, allows for
  probability distributions over complex descriptions.  Rather than
  trying to define a new language, this paper shows how the
  integration of multiple objects, ontologies and roles can be
  achieved cleanly. This solves two main problems: reasoning about
  existence and identity while preserving the clarity principle that
  specifies that probabilities must be over well defined propositions,
  and the correspondence problem that means that we don't need to
  search over all possible correspondences between objects said to
  exist and things in the world.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-201.pdf,"Subjects:  3.4 Probabilistic Reasoning;
11. Knowledge Representation"
201,2007,Uncertainty in AI,Learning Graphical Model Structure using L1-Regularization Paths,"Mark W. Schmidt, Alexandru Niculescu-Mizil, Kevin P. Murphy","Sparsity-promoting L1-regularization has recently been succesfully
used to learn the structure of undirected graphical
models. In this paper, we apply this technique to learn the
structure of directed graphical models. Specifically, we make
three contributions. First, we show how the decomposability
of the MDL score, plus the ability to quickly compute entire
regularization paths, allows us to efficiently pick the optimal
regularization parameter on a per-node basis. Second, we
show how to use L1 variable selection to select the Markov
blanket, before a DAG search stage. Finally, we show how
L1 variable selection can be used inside of an order search algorithm.
The effectiveness of these L1-based approaches are
compared to current state of the art methods on 10 datasets.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-202.pdf,"Subjects:  12. Machine Learning and Discovery;
Please choose a second document classification"
202,2007,Uncertainty in AI,On the Identification of a Class of Linear Models,Jin Tian,"This paper deals with the problem of identifying direct causal effects in recursive linear structural equation models. The paper provides a procedure for solving the identification problem in a special class of models.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-203.pdf,"Subjects:  9.1 Causality;
3.4 Probabilistic Reasoning"
203,2007,Uncertainty in AI,Scaling Up: Solving POMDPs through Value Based Clustering,"Yan Virin, Guy Shani, Solomon Eyal Shimony, Ronen Brafman","Partially Observable Markov Decision Processes (POMDPs) provide an

appropriately rich model for agents operating under partial knowledge

of the environment. Since finding an optimal POMDP policy is

intractable, approximation techniques have been a main focus of research,

among them point-based algorithms, which scale up

relatively well - up to thousands of states.

An important decision in a point-based algorithm is the order of

backup operations over belief states.



Prioritization techniques for ordering the sequence of backup operations 

reduce the number of needed backups considerably, but involve significant overhead.

This paper suggests a new way to order backups, based on a soft

clustering of the belief space. Our novel soft clustering method

relies on the solution of the underlying MDP. Empirical evaluation

verifies that our method rapidly computes a good order of backups,

showing orders of magnitude improvement in runtime

over a number of benchmarks.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-204.pdf,"Subjects:  3. Automated Reasoning;
3.4 Probabilistic Reasoning"
204,2007,Uncertainty in AI,Generalized Evidence Pre-propagated Importance Sampling for Hybrid Bayesian Networks,"Changhe Yuan, Marek J. Druzdzel","In this paper, we first provide a new theoretical understanding of the Evidence Pre-propagated Importance Sampling algorithm(EPIS-BN) and show that its importance function minimizes the KL-divergence between the function itself and the exact posterior probability distribution in Polytrees. We then generalize the method to deal with inference in

general hybrid Bayesian networks consisting of deterministic

equations and arbitrary probability distributions. Using a novel

technique called soft arc reversal, the new algorithm can also

handle evidential reasoning with observed deterministic variables.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-205.pdf,"Subjects:  3.4 Probabilistic Reasoning;
15.8 Simulation"
205,2007,Special Track on Artificial Intelligence and the Web,A Semantic Importing Approach to Knowledge Reuse from Multiple Ontologies,"Jie Bao, Giora Slutzki, Vasant Honavar","We present the syntax and semantics of a modular ontology
language SHOIQP to support context-specific reuse
of knowledge from multiple ontologies. A SHOIQP ontology
consists of multiple ontology modules (each of which
can be viewed as a SHOIQ ontology) and concept, role and
nominal names can be shared by importing relations among
modules. SHOIQP supports contextualized interpretation,
i.e., interpretation from the point of view of a specific package.
We establish the necessary and sufficient constraints on
domain relations (i.e., the relations between individuals in
different local domains) to preserve the satisfiability of concept
formulae, monotonicity of inference, and transitive reuse
of knowledge.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-206.pdf,"Subjects:  11.1 Description Logics;
11.2 Ontologies"
206,2007,Special Track on Artificial Intelligence and the Web,Modeling Contextual Factors of Click Rates,"Hila Becker, Christopher Meek, David Maxwell Chickering","In this paper, we develop and evaluate several probabilistic models of user click-through behavior that are appropriate for modeling the click-through rates of items that are presented to the user in a list. Potential applications include modeling the click-through rates of search results from a search engine, items ranked by a recommendation system, and search advertisements returned by a search engine. Our models capture contextual factors related to the presentation as well as the underlying relevance or quality of the item. We focus on two types of contextual factors for a given item; the positional context of the item and the quality of the other results. We evaluate our models on a search advertising dataset from Microsoft's Live search engine and demonstrate that modeling contextual factors improves the accuracy of click-through models.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-207.pdf,"Subjects:  12. Machine Learning and Discovery;
1. Applications"
207,2007,Special Track on Artificial Intelligence and the Web,Harvesting Relations from the Web - Quantifiying the Impact of Filtering Functions,"Sebastian Blohm, Philipp Cimiano, Egon Stemle","Several bootstrapping-based relation extraction algorithms working on large corpora or on the Web have been presented in the literature. A crucial issue for such algorithms is to avoid the introduction of too much noise into further iterations. Typically, this is achieved by applying appropriate pattern and tuple evaluation measures, henceforth called {\it filtering functions}, thereby selecting only the most promising patterns and tuples. In this paper, we systematically compare different filtering functions proposed across the literature. Although we also discuss our own implementation of a pattern learning algorithm, the main contribution of the paper is actually the extensive comparison and evaluation of the different filtering functions proposed in the literature with respect to seven datasets. Our results indicate that some of the commonly used filters do not outperform a trivial baseline filter in a statistically significant manner.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-208.pdf,"Subjects:  10. Knowledge Acquisition;
13. Natural Language Processing"
208,2007,Special Track on Artificial Intelligence and the Web,KA-CAPTCHA: An Opportunity for Knowledge Acquisition on the Web,"Bruno da Silva, Ana Cristina Garcia","Any Web user is a potential knowledge contributor, but it remains a challenge to make them devote their time contributing to some purpose. In order to align individual with social interests, we selected the CAPTCHA Web resource protection application to embed knowledge elicitation within the users' main task of accessing a Web resource. Consequently, unlike previous knowledge acquisition approaches, no extra effort is expected from users since they are already willing to use a CAPTCHA to perform some particular task. We present an application where we extract pictorial knowledge from Web users, and experiments suggest that our approach enables knowledge acquisition while still satisfying CAPTCHA's security requirements.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-209.pdf,"Subjects:  10. Knowledge Acquisition;
1. Applications"
209,2007,Special Track on Artificial Intelligence and the Web,Representing and Reasoning about Commitments in Business Processes,"Nirmit Desai, Amit K. Chopra, Munindar P. Singh","A variety of business relationships in open settings can be understood in terms of the creation and manipulation of commitments among the participants.  These include B2C and B2B contracts and processes, as realized via Web services and other such technologies.  Business protocols, an interaction-oriented approach for modeling business processes, are
formulated in terms of the commitments.  Commitments can support other forms of semantic service composition as well.  This paper shows how to represent and reason about commitments in a general manner.  Unlike previous formalizations, the proposed formalization accommodates complex and nested commitment conditions, and concurrent commitment operations.  In this manner, a rich variety of open business scenarios are enabled.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-210.pdf,"Subjects:  7. Distributed AI;
11. Knowledge Representation"
210,2007,Special Track on Artificial Intelligence and the Web,Topic Segmentation Algorithms for Text Summarization and Passage Retrieval: An Exhaustive Evaluation,"Gael Dias, Elsa Alves, Jose Gabriel Pereira Lopes","In order to solve problems of reliability of systems based on lexical repetition and problems of adaptability of language-dependent systems, we present a context-based topic segmentation system based on a new informative similarity measure based on word co-occurrence. In particular, our evaluation with the state-of-the-art in the domain i.e. the c99 and the TextTiling algorithms shows improved results both with and without the identification of multiword units.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-211.pdf,"Subjects:  1.10 Information Retrieval;
13. Natural Language Processing"
211,2007,Special Track on Artificial Intelligence and the Web,The Impact of Time on the Accuracy of Sentiment Classifiers Created from a Web Log Corpus,"Kathleen T.  Durant, Michael D. Smith","We investigate the impact of time on the predictability of sentiment classification research for models created from web logs. We show that sentiment classifiers are time dependent and through a series of methodical experiments quantify the size of the dependence. In particular, we measure the accuracies of 25 different time-specific sentiment classifiers on 24 different testing timeframes. We use the Naive Bayes induction technique and the holdout validation technique using equal-sized but separate training and testing data sets. We conducted over 600 experiments and organize our results by the size of the interval (in months) between the training and testing timeframes. Our findings show a significant decrease in accuracy as this interval grows. Using a paired t-test we show classifiers trained on future data and tested on past data significantly outperform classifiers trained on past data and tested on future data. These findings are for a topic-specific corpus created from political web log posts originating from 160 different web logs. We then define concepts that classify months as exemplar, infrequent thread, frequent thread or outlier; this classification reveals knowledge on the topic’s evolution and the utility of the month’s data for the timeframe.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-212.pdf,"Subjects:  12. Machine Learning and Discovery;
1.6 Engineering And Science"
212,2007,Special Track on Artificial Intelligence and the Web,A Distributed Constraint Optimization Solution to the P2P Video Streaming Problem,"Theodore Elhourani, Nathan Denny, Michael Marefat","The future success of application layer video multicast depends on the availability of video stream distribution methods that can scale in the number of stream senders and receivers. Previous work on the problem of application layer video streaming has not effectively addressed scalability in the number of receivers and senders. Therefore, new solutions that are amenable to analysis and can achieve scalable P2P video streaming are needed. In this work we propose the use of automated negotiation algorithms to construct video streaming trees at the application layer. We show that automated negotiation can effectively solve the problem of distributing a video stream to a large number of receivers.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-213.pdf,"Subjects:  7. Distributed AI;
6.2 Multimedia"
213,2007,Special Track on Artificial Intelligence and the Web,Analyzing Reading Behavior by Blog Mining,"Tadanobu Furukawa, Yutaka Matsuo, Ikki Ohmukai, Koki Uchiyama, Mitsuru Ishizuka","This paper presents a study of the various aspects of blog reading behavior.

The analyzed data are obtained from a Japanese weblog hosting service, Doblog. Four kinds of social networks are generated and analyzed: citation, comment, trackback, and blogroll networks. 

In addition, the user log data are used to identify readership relations among bloggers.

After analysis of more than 50,000 users for about two years, 

we reveal some interactions between social relations and readership relations.

We first show that 

bloggers read other weblogs on a regular basis (50% of weblogs that are read at least three times are read every five times a user logs in). We call this relation a regular reading relation (RR relation). Then, prediction of RR relations is done using features from the four kinds of social networks. Lastly, information diffusion on RR relations is analyzed and characterized.

Results of this study show that the blogs in RR relations have an important role in bloggers' activities. We find the features which have a correlation with RR relations.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-214.pdf,"Subjects:  12. Machine Learning and Discovery;
10. Knowledge Acquisition"
214,2007,Special Track on Artificial Intelligence and the Web,PhotoSlap: A Multi-player Online Game for Semantic Annotation,"Chien-Ju Ho, Tsung-Hsiang Chang, Jane Yung-jen Hsu","Multimedia content presents special challenges for the search engines, and could benefit from semantic annotation of images. Unfortunately, manual labeling is too tedious and time-consuming for humans, whereas automatic image annotation is too difficult for the computers. In this paper, we explore the power of human computation by designing a multi-player online game, PhotoSlap, to achieve the task of annotating metadata for a collection of digital photos. PhotoSlap engages users in an interactive game that capitalizes on human ability in deciphering quickly whether the same person shows up in two consecutive images presented by the computer. The game mechanism supports the objection and trap actions to encourage truthful input from the players. This research extends human computation research in two aspects: game-theoretic design principles and quantitative evaluation metrics.  In particular, PhotoSlap can be shown to reach subgame perfect equilibrium with the target strategy when players are rational and without collusion. Experiments involving four focus groups have been conducted, and the preliminary results demonstrated the game to be fun and effective in annotating people metadata for photo collections.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-215.pdf,"Subjects:  1.8 Game Playing;
6.2 Multimedia"
215,2007,Special Track on Artificial Intelligence and the Web,Mobile Service for Reputation Extraction from Weblogs - Public Experiment and Evaluation,"Takahiro Kawamura, Shinichi Nagano, Masumi Inaba, Yumiko Mizoguchi","In this paper, we introduce a mobile service that extracts reputations of a product from weblogs by cellular phones during shopping. If the user takes a photo of a product barcode on the package with a cellular phone camera, Ubiquitous Metadata Scouter first gets the product metadata (name, manufacturer, etc.) from the internet and collects blogs that review the product. Also, it analyzes the blog contents with NLP techniques and ontologies. Then, it indicates the overall reputation (positive or negative), and other related products that are the subject of much discussion in the blogs. This paper illustrates each function of this service and a public experiment and evaluation at a real consumer electronics store and book-store in Tokyo in March 2006.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-216.pdf,"Subjects:  11.2 Ontologies;
13. Natural Language Processing"
216,2007,Special Track on Artificial Intelligence and the Web,Extracting Influential Nodes for Information Diffusion on a Social Network,"Masahiro Kimura, Kazumi Saito, Ryohei Nakano.","We consider the combinatorial optimization problem of 
finding the most influential nodes
on a large-scale social network
for two widely-used fundamental stochastic diffusion models.
It was shown that
a natural greedy strategy
can give a good approximate solution
to this optimization problem.
However,
a conventional method under the greedy algorithm
needs a large amount of computation,
since it estimates the marginal gains
for the expected number of nodes influenced by a set of nodes
by simulating the random process of each model many times.
In this paper,
we propose a method of efficiently estimating
all those quantities
on the basis of bond percolation and graph theory,
and apply it to approximately solving the optimization problem
under the greedy algorithm.
Using real-world large-scale networks including blog networks,
we experimentally demonstrate that the proposed method can
outperform the conventional method, and achieve a large reduction
in computational cost.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-217.pdf,"Subjects:  12. Machine Learning and Discovery;
3.4 Probabilistic Reasoning"
217,2007,Special Track on Artificial Intelligence and the Web,SUNNY: A New Algorithm for Trust Inference in Social Networks Using Probabilistic Confidence Models,"Ugur Kuter, Jennifer Golbeck","In many computing systems, information is produced and processed by many people. 
Knowing how much a user trusts a source can be very useful for aggregating, filtering, and ordering of information. Furthermore, if trust is used to support decision making, it is important to have an accurate estimate of trust when it is not directly available, as well as a measure of confidence in that estimate. This paper describes a new approach that gives an explicit probabilistic interpretation for confidence in social networks.
We describe SUNNY, a new trust inference algorithm that uses a probabilistic sampling technique to estimate our confidence in the trust information from some designated sources.  SUNNY computes an estimate of trust based on only those information sources with high confidence estimates. In our experiments, SUNNY produced more accurate trust estimates than the well known trust inference algorithm TidalTrust (Golbeck, 2005), demonstrating its effectiveness.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-218.pdf,"Subjects:  8. Enabling Technologies;
3.4 Probabilistic Reasoning"
218,2007,Special Track on Artificial Intelligence and the Web,Making the Difference in Semantic Web Service Composition,"Freddy Lecue, Alexandre Delteil","Automation of Web service composition is one of the most interesting challenges facing the Semantic Web today. In this paper we propose a mean of performing automated Web service composition by exploiting semantic matchmaking between Web service parameters (i.e., outputs and inputs) to enable their connection and interaction. The key idea is that the matchmaking enables, at run time, finding semantic compatibilities among independently defined Web service descriptions. To this end, our approach extends existing methods in order to explain misconnections between Web services. From this we generate Web service compositions that realize the goal, satisfying and optimizing the semantic connections between Web services. Moreover a process of relaxing the hard constraints is introduced in case the composition process failed. Our system is implemented and interacting with Web services dedicated on a Telecom scenario. The preliminary evaluation results showed high efficiency and effectiveness of the proposed approach.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-219.pdf,"Subjects:  3. Automated Reasoning;
11.1 Description Logics"
219,2007,Special Track on Artificial Intelligence and the Web,A Planning Approach for Message-Oriented Semantic Web Service Composition,"Zhen Liu, Anand Ranganathan, Anton Riabov","In this paper, we consider the problem of composing a set of web services, where the requirements are specified in terms of the input and output messages of the composite workflow. We propose a semantic model of messages using RDF graphs that encode OWL ABox assertions. We also propose a model of web service operations where the input message requirements and output message characteristics are modeled using RDF graph patterns. We formulate the message-oriented semantic web service composition problem and show how it can be translated into a planning problem. There are, however, significant challenges in scalably doing planning in this domain, especially since DL reasoning may be performed to check if an operation can be given a certain input message. We propose a two-phase planning algorithm that incorporates DLP reasoning and evaluate the performance of this planning algorithm.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-220.pdf,"Subjects:  1.11 Planning;
11.1 Description Logics"
220,2007,Special Track on Artificial Intelligence and the Web,Robust Estimation of Google Counts for Social Network Extraction,"Yutaka Matsuo, Hironori Tomobe, Takuichi Nishimura","Various studies within NLP and Semantic Web use the so-called Google count, which is the hit count on a query returned by a search engine (not only Google).

However, sometimes the Google count is unreliable, especially when the count is large, or when advanced operators such as OR and NOT are used.

In this paper, we propose a novel algorithm that estimates the Google count robustly. It (i) uses the co-occurrence of terms as evidence to estimate the occurrence of a given word, and (ii) integrates multiple evidence

for robust estimation. 

We evaluated our algorithm for more than 2000 queries 

on three datasets using Google, Yahoo! and MSN search engine.

Our algorithm also provides estimate counts for any classifier that judges a web page as positive or negative. Consequently, we can estimate the number of documents with included references of a particular person (among namesakes) on the entire web.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-221.pdf,"Subjects:  1.10 Information Retrieval;
10. Knowledge Acquisition"
221,2007,Special Track on Artificial Intelligence and the Web,Unsupervised Shilling Detection for Collaborative Filtering,Bhaskar  Mehta,"Collaborative Filtering systems are essentially social systems
which base their recommendation on the judgment of a large
number of people. However, like other social systems, they
are also vulnerable to manipulation. Lies and Propaganda
may be spread by malicious users who may have an interest
in promoting an item, or downplaying the popularity of
another one. By doing this systematically, with either multiple
identities, or by involving more people, malicious shilling
user profiles can be injected into a collaborative recommender
system which can significantly affect the robustness of a recommender system. While current detection algorithms are
able to use certain characteristics of shilling profiles to detect
them, they suffer from low precision, and require a large
amount of training data. The aim of this work is to explore
simpler unsupervised alternatives which exploit the nature of
shilling profiles, and can be easily plugged into collaborative
filtering framework to add robustness. Two statistical methods
are developed and experimentally shown to provide high
accuracy in shilling attack detection.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-222.pdf,"Subjects:  1.10 Information Retrieval;
12. Machine Learning and Discovery"
222,2007,Special Track on Artificial Intelligence and the Web,Repairing Ontology Mappings,"Christian Meilicke, Heiner Stuckenschmidt, Andrei Tamilin","Automatically discovering semantic relations between ontologies is an important task with respect to overcoming semantic heterogeneity on the semantic web. Existing ontology matching systems, however, often produce erroneous mappings. In this paper, we address the problem of errors in mappings by proposing a completely automatic debugging method for ontology mappings. The method uses logical reasoning to discover

and repair logical inconsistencies caused by erroneous mappings. We describe the debugging method and report experiments on mappings submitted to the ontology alignment evaluation challenge that show that the proposed method actually improves mappings created by different matching systems without any human intervention.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-223.pdf,"Subjects:  11.2 Ontologies;
3. Automated Reasoning"
223,2007,Special Track on Artificial Intelligence and the Web,Relation Extraction from Wikipedia Using Subtree Mining,"Dat P.T. Nguyen, Yutaka Matsuo, Mitsuru Ishizuka","The exponential growth and reliability of Wikipedia have made it a promising data source for intelligent systems. The first challenge of Wikipedia is to make the encyclopedia machine-processable. In this study, we address the problem of extracting relations among entities from Wikipedia's English articles, which in turn 

can serve for intelligent systems to satisfy users' information needs. Our proposed method first anchors the appearance of entities in Wikipedia articles using some heuristic rules that are supported by their encyclopedic style. Therefore, it uses neither the Named Entity Recognizer (NER) nor the Coreference Resolution tool, which are sources of errors for relation extraction. It then classifies the relationships among entity pairs using SVM with features extracted from the web structure and subtrees mined from the syntactic structure of text. The innovations behind our work are the following: a) our method makes use of Wikipedia characteristics for entity allocation and entity classification, which are essential for relation extraction; b) our algorithm extracts a core tree, which accurately reflects a relationship between a given entity pair, and subsequently identifies key features with respect to the relationship from the core tree. We demonstrate the effectiveness of our approach through evaluation of manually annotated data from actual Wikipedia articles.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-224.pdf,"Subjects:  10. Knowledge Acquisition;
1.10 Information Retrieval"
224,2007,Special Track on Artificial Intelligence and the Web,From Whence Does Your Authority Come? Utilizing Community Relevance in Ranking,"Lan Nie, Brian D. Davison, Baoning Wu","A web page may be relevant to multiple topics; even when nominally on a single topic, the page may attract attention (and thus links) from multiple communities.  Instead of indiscriminately summing the
authority provided by all pages, we decompose a web page into separate subnodes with respect to each community pointing to it.  Utilizing the relevance of such communities allows us to better model the semantic structure of the Web, leading to better estimates of authority for a given query. We apply a total of eighty queries over two real-world datasets to demonstrate that the use of community decomposition can consistently and significantly improve upon PageRank's top-ten results.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-225.pdf,"Subjects:  1.10 Information Retrieval;
12. Machine Learning and Discovery"
225,2007,Special Track on Artificial Intelligence and the Web,Finding Related Pages Using Green Measures: An Illustration with Wikipedia,"Yann Ollivier, Pierre Senellart","We introduce a new method for finding nodes semantically related to a given node in a hyperlinked graph: the Green method, based on a classical Markov chain tool. It is generic, adjustment-free and easy to implement. We test it in the case of the hyperlink structure of the English version of Wikipedia, the on-line encyclopedia. We present an extensive comparative study of the performance of our method versus several other classical methods in the case of Wikipedia. The Green method is found to have both the best average results and the best robustness.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-226.pdf,"Subjects:  10. Knowledge Acquisition;
9.3 Mathematical Foundations"
226,2007,Special Track on Artificial Intelligence and the Web,Approximating OWL-DL Ontologies,"Jeff Z Pan, Edward Thomas","Efficient query answering over ontologies is one of the most useful and important services to support Semantic Web applications. Approximation has been identified as a potential way to reduce the complexity of query answering over OWL DL ontologies. Existing approaches are mainly based on syntactic approximation of ontological axioms and queries. In this paper, we propose to recast the idea of knowledge compilation into approximating OWL DL ontologies with DL-Lite ontologies, against which query answering has only polynomial data complexity. We identify a useful category of queries for which our approach guarantees also completeness. Furthermore, this paper reports on the implementation of our approach in the ONTOSEARCH2 system and preliminary, but encouraging, benchmark results which compare ONTOSEARCH2's response times on a number of queries with those of existing ontology reasoning systems.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-227.pdf,"Subjects:  11.2 Ontologies;
11.1 Description Logics"
227,2007,Special Track on Artificial Intelligence and the Web,Deriving a Large Scale Taxonomy from Wikipedia,"Simone Paolo Ponzetto, Michael Strube","We take the category system in Wikipedia as a conceptual network. We label the semantic relations between categories using methods based on connectivity in the network and lexico-syntactic matching. As a result we are able to derive a large scale taxonomy containing a large amount of subsumption, i.e.\ \emph{isa}, relations.  We evaluate the quality of the created resource by comparing it with ResearchCyc, one of the largest manually annotated ontologies, as well as computing semantic similarity between words in benchmarking datasets.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-228.pdf,"Subjects:  11.2 Ontologies;
13. Natural Language Processing"
228,2007,Special Track on Artificial Intelligence and the Web,Towards Large Scale Argumentation Support on the Semantic Web,"Iyad Rahwan, Fouad Zablith, Chris Reed","This paper lays theoretical and software foundations for a World Wide Argument Web (WWAW): a large-scale Web of inter-connected arguments posted by individuals to express their opinions in a structured manner. First, we extend the recently proposed Argument Interchange Format (AIF) to express arguments with a structure based on Walton's theory of argumentation schemes. Then, we describe an implementation of this ontology using the RDF Schema language, and demonstrate how our ontology enables the representation of networks of arguments on the Semantic Web. Finally, we present a pilot Semantic Web-based system, ArgDF, through which users can create arguments using different argumentation schemes and can query arguments using a Semantic Web query language. Users can also attack or support parts of existing arguments, use existing parts of an argument in the creation of new arguments, or create new argumentation schemes. As such, this initial public-domain tool is intended to seed a variety of future applications for authoring, linking, navigating, searching, and evaluating arguments on the Web.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-229.pdf,"Subjects:  11.2 Ontologies;
8. Enabling Technologies"
229,2007,Special Track on Artificial Intelligence and the Web,Provisioning Heterogeneous and Unreliable Providers for Service Workflows,"Sebastian Stein, Nicholas R. Jennings, Terry R. Payne","Service-oriented technologies enable software agents to dynamically discover and provision remote services for their workflows. Current work has typically assumed these services to be reliable and deterministic, but this is unrealistic in open systems, such as the Web, where they are offered by autonomous agents and are, therefore, inherently unreliable. To address this  potential unreliability (in particular, uncertain service durations and failures), we consider the provisioning of abstract workflows, where many heterogeneous providers offer services at differing levels of quality. More specifically, we show that service provisioning is NP-hard, and then devise two heuristic strategies that use service redundancy in a flexible manner to address uncertainty and failure. In empirical experiments, we show that these heuristic strategies can achieve significant improvements over standard approaches in a wide range of environments.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-230.pdf,"Subjects:  7.1 Multi-Agent Systems;
7.2 Software Agents"
230,2007,Special Track on Artificial Intelligence and the Web,Partial Matchmaking Using Approximate Subsumption,Heiner  Stuckenschmidt,"Description Logics, and in particular the web ontology language OWL has been proposed as an appropriate basis for computing matches between structured objects for the sake of information integration and service discovery. A drawback of the direct use of subsumption as a matching criterion is the inability to compute partial matches and qualify the degree of mismatch. In

this paper, we describe a method for overcoming these problems that is based on approximate logical reasoning. In particular, we approximate the subsumption relation by defining the notion of subsumption with respect to a certain subset of the concept and relation names. We present the formal semantics of this relation, describe a sound and complete algorithm for computing approximate subsumption and discuss its application to matching tasks.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-231.pdf,"Subjects:  11.1 Description Logics;
3. Automated Reasoning"
231,2007,Special Track on Artificial Intelligence and the Web,GRIN: A Graph Based RDF Index,"Octavian Udrea, Andrea Pugliese, V.S. Subrahmanian","RDF (""Resource Description Framework"") is now a widely used World Wide Web Consortium standard.  However, methods to index large volumes of RDF data are still in their infancy. In this paper, we focus on providing a very lightweight indexing mechanism for certain kinds of RDF queries, namely graph-based queries where there is a need to traverse edges in the graph determined by an RDF database. Our approach uses the idea of drawing circles around selected ""center"" vertices in the graph where the circle would encompass those vertices in the graph that are within a given distance of the ""center"" vertex.  We come up with methods of finding such ""center"" vertices and identifying the radius of the circles and then leverage this to build an index called GRIN.  We
compare GRIN with three existing RDF indexex: Jena, Sesame, and RDFBroker. We compared (i) the time to answer graph based queries, (ii) memory needed to store the index, and (iii) the time to build the index.  GRIN outperforms Jena, Sesame and RDFBroker on all three measures for graph based queries
(for other types of queries, it may be worth building one of these other indexes and using it), at the expense of using a larger amount of memory when answering queries.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-232.pdf,"Subjects:  11. Knowledge Representation;
11.2 Ontologies"
232,2007,Special Track on Artificial Intelligence and the Web,"Comprehending and Generating Apt Metaphors: A Web-driven, Case-based Approach to Figurative Language","Tony Veale, Yanfen Hao","Examples of figurative language can range from the explicit and the obvious to the implicit and downright enigmatic. Some simpler forms, like simile, often wear their meanings on their sleeve, while more challenging forms, like metaphor, can make cryptic allusions more akin to those of riddles or crossword puzzles. In this paper we argue that because the same concepts and properties are described in either case, a computational agent can learn from the easy cases (explicit similes) how to comprehend and generate the hard cases (nonexplicit metaphors). We demonstrate that the markedness of similes allows for a large case-base of illustrative examples to be easily acquired from the web, and present a system, called Sardonicus, that uses this casebase both to understand property-attribution metaphors and to generate apt metaphors for a given target on demand. In each case, we show how the text of the web is used as a source of tacit knowledge about what categorizations are allowable and what properties are most contextually appropriate. Overall, we demonstrate that by using the web as a primary knowledge source, a system can achieve a robust and scalable competence with metaphor while minimizing the need for hand-crafted resources like WordNet.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-233.pdf,"Subjects:  13. Natural Language Processing;
1.10 Information Retrieval"
233,2007,Special Track on Artificial Intelligence and the Web,Reasoning about Attribute Authenticity in a Web Environment,Thomas Wolfl,"The reliable authentication of user attributes is an important prerequisite for the security of web based applications. Digital certificates are widely used for that purpose. However, practical certification scenarios can be very complex. Each certificate carries a validity period and can be revoked during this period. Furthermore, the verifying user has to trust the issuers of certificates and revocations. This work presents a formal model which covers these aspects and provides a theoretical foundation for the decision about attribute authenticity even in complex scenarios. The model is based on the event calculus, an AI technique from the field of temporal reasoning. It uses Clark's completion to address the frame problem. An example illustrates the application of the model.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-234.pdf,"Subjects:  1. Applications;
3.6 Temporal Reasoning"
234,2007,Special Track on Artificial Intelligence and the Web,Towards Efficient Dominant Relationship Exploration of the Product Items on the Web,"Zhenglu Yang, Lin Li, Botao Wang, Masaru Kitsuregawa","In recent years, there has been a prevalence of search engines being employed to find useful information in the Web as they efficiently explore hyperlinks between web pages which define a natural graph structure that yields a good ranking. Unfortunately, current search engines cannot effectively rank those relational data, which exists on dynamic websites supported by online databases. In this study, to rank such structured data (i.e., find the ``best'' items), we propose an integrated online system consisting of compressed data structure to encode the dominant relationship of the relational data. Efficient querying strategies and updating scheme are devised to facilitate the ranking process. Extensive experiments illustrate the effectiveness and efficiency of our methods. As such, we believe the work in this paper can be complementary to traditional search engines.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-235.pdf,"Subjects:  15.7 Search;
1.10 Information Retrieval"
235,2007,Special Track on Artificial Intelligence and the Web,Improving Similarity Measures for Short Segments of Text,"Wen-tau Yih, Christopher Meek","In this paper we improve previous work on measuring the similarity of short segments of text in two ways. First, we introduce a Web-relevance similarity measure and demonstrate its effectiveness. This measure extends the Web-kernel similarity function introduced by Sahami and Heilman (2006) by using relevance weighted inner-product of term occurrences rather than TF$\times$IDF. Second, we show that one can further improve the accuracy of similarity measures by using a machine learning approach. Our methods outperform other state-of-the-art methods in a general query suggestion task for multiple evaluation metrics.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-236.pdf,"Subjects:  1.10 Information Retrieval;
12. Machine Learning and Discovery"
236,2007,Special Track on Artificial Intelligence and the Web,Design of a Mechanism for Promoting Honesty in E-Marketplaces,"Jie Zhang, Robin Cohen","In this paper, we explore the use of the web as an environment for   electronic commerce. In particular, we develop a novel mechanism that creates incentives for honesty in electronic marketplaces where human users are represented by buying and selling agents. In our mechanism, buyers model other buyers and select the most trustworthy ones as their neighbors from which they can ask advice  about sellers. In addition, however, sellers model the reputation of buyers. Reputable buyers provide fair ratings of sellers, and are likely to be neighbors of many other buyers. Sellers will provide more attractive products to reputable buyers, in order to build their reputation. We discuss how a marketplace operating with our mechanism leads to better profit both for honest buyers and sellers. With honesty encouraged, our work promotes the acceptance of web-based agent-oriented e-commerce by human users.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-237.pdf,"Subjects:  7.1 Multi-Agent Systems;
7.2 Software Agents"
237,2007,Special Track on Artificial Intelligence and the Web,Temporal and Information Flow Based Event Detection From Social Text Streams,"Qiankun Zhao, Prasenjit Mitra, Bi Chen","Recently, social text streams (e.g., blogs, web forums,
and emails) have become ubiquitous with the evolution
of the web. In some sense, social text streams are sensors
of the real world. Often, it is desirable to extract
real world events from the social text streams. However,
existing event detection research mainly focused
only on the stream properties of social text streams but
ignored the contextual, temporal, and social information
embedded in the streams. In this paper, we propose to
detect events from social text streams by exploring the
content as well as the temporal, and social dimensions.
We define the term event as the information flow between
a group of social actors on a specific topic over a
certain time period. We represent social text streams as
multi-graphs, where each node represents a social actor
and each edge represents the information flow between
two actors. The content and temporal associations
within the flow of information are embedded in the
corresponding edge. Events are detected by combining
text-based clustering, temporal segmentation, and information
flow-based graph cuts of the dual graph of the
social networks. Experiments conducted with the Enron
email dataset and the political blog dataset from
Dailykos show the proposed event detection approach
outperforms the other alternatives.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-238.pdf,"Subjects:  1.10 Information Retrieval;
3.4 Probabilistic Reasoning"
238,2007,Special Track on Artificial Intelligence and the Web,Template-Independent News Extraction Based on Visual Consistency,"Shuyi Zheng, Ruihua Song, Ji-Rong Wen","Wrapper is a traditional method to extract useful information from Web pages. Most previous works rely on the similarity between HTML tag trees and induced template-dependent wrappers. When hundreds of information sources need to be extracted in a specific domain like news, it is costly to generate and maintain the wrappers. In this paper, we propose a novel template-independent news extraction approach to easily identify news articles based on visual consistency. We first represent a page as a visual block tree. Then, by extracting a series of visual features, we can derive a composite visual feature set that is stable in the news domain. Finally, we use a machine learning approach to generate a template-independent wrapper. Experimental results indicate that our approach is effective in extracting news across websites, even from unseen websites. The performance is as high as around 95% in terms of F1-value.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-239.pdf,"Subjects:  1.10 Information Retrieval;
12.2 Scientific Discovery"
239,2007,Special Track on Integrated Intelligence,PLOW: A Collaborative Task Learning Agent,"James Allen, Nathanael Chambers, George Ferguson, Lucian Galescu, Hyuckchul Jung, Mary Swift, William Taysom","To be effective, an agent that collaborates with humans needs to be able to learn new tasks from humans they work with. This paper describes a system that learns executable task models from a single collaborative learning session consisting of demonstration, explanation and dialogue. To accomplish this, the system integrates a range of AI technologies: deep natural language understanding, knowledge representation and reasoning, dialogue systems, planning/agent-based systems and machine learning. A formal evaluation shows the approach has great promise.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-240.pdf,"Subjects:  6. Computer-Human Interaction;
13. Natural Language Processing"
240,2007,Special Track on Integrated Intelligence,An Architecture for Adaptive Algorithmic Hybrids,"Nicholas Cassimatis, Magda Bugajska, Scott Dugas, Arthi Murugesan, Paul Bello","We describe a cognitive architecture for creating more robust intelligent systems by executing hybrids of algorithms based on different computational formalisms.  The architecture is motivated by the belief that (1) most existing computational methods often exhibit some of the characteristics desired of intelligent systems at the cost of other desired characteristics and (2) a system exhibiting robust intelligence can be designed by implementing hybrids of these computational methods.  The main obstacle to this approach is that the various relevant computational methods are based on data structures and algorithms that are very difficult to integrate into one system.  We describe a new method of executing hybrids of algorithms using the focus of attention of multiple modules.  This approach has been embodied in the Polyscheme cognitive architecture.   Systems based on Polyscheme can integrate reactive robotic controllers, logical and probabilistic inference algorithms, frame-based formalisms and sensor-processing algorithms into one system.  Existing applications involve human-robot interaction, heterogeneous information retrieval and natural language understanding.  Systems built using Polyscheme demonstrate that algorithmic hybrids implemented using a focus of attention can (1) exhibit more characteristics of intelligence than individual computational methods alone and (2) deal with problems that have formerly been beyond the reach of synthetic computational intelligence.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-241.pdf,"Subjects:  2. Architectures;
3. Automated Reasoning"
241,2007,Special Track on Integrated Intelligence,Learning to Sing Like a Bird: Self-Supervised Acquisition of Birdsong,Michael H.  Coen,"This paper presents a new framework for self-supervised sensorimotor learning.  We demonstrate this framework with a system that learns to mimic a zebra finch, directly modeled on the dynamics of how male fledglings acquire birdsong from their fathers. Our system first listens to the song of an adult finch. By listening to its own initially nascent attempts at mimicry through an articulatory synthesizer, the system organizes motor maps generating its vocalizations. Our approach is founded on the notion of cross-modal clustering, introduced in (Coen 2005, 2006a), and is unusual for its recursive reuse of perceptual mechanisms in developing motor control.  In this paper, we outline this framework, present its results on the unsupervised acquisition of birdsong, and discuss other potential applications.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-242.pdf,"Subjects:  17. Robotics;
12. Machine Learning and Discovery"
242,2007,Special Track on Integrated Intelligence,R-CAST: Integrating Team Intelligence for Human-Centered Teamwork,"Xiaocong Fan, John Yen","Developing human-centered agent architectures requires the integral consideration of architectural flexibility, teamwork adaptability, and context reasoning capability. With the integration of various forms of team intelligence including shared teamwork process and progress, dynamic context management and information dependency reasoning, and recognition-primed collaborative decision mechanism, R-CAST offers a flexible solution to developing cognitive aids for the support of human-centered teamwork in information and knowledge intensive domains. In this paper, we present the key features of R-CAST. As evidence of its applications in complex real-world problems, we give two experimental evaluations of R-CAST as teammates and decision aids of human Command and Control teams.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-243.pdf,"Subjects:  7.1 Multi-Agent Systems;
2. Architectures"
243,2007,Special Track on Integrated Intelligence,"Integrating Natural Language, Knowledge Representation and Reasoning, and Analogical Processing to Learn by Reading","Kenneth D. Forbus, Christopher Riesbeck, Lawrence Birnbaum, Kevin Livingston, Abhishek Sharma, Leo Ureel","Learning by reading requires integrating several strands of AI research.  We describe a prototype system, Learning Reader, which combines natural language processing, a large-scale knowledge base, and analogical processing to learn by reading simplified language texts.  We outline the architecture of Learning Reader and some of system-level results, then explain how these results arise from the components.  Specifically, we describe the design, implementation, and performance characteristics of a natural language understanding model (DMAP) that is tightly coupled to a knowledge base three orders of magnitude larger than previous attempts.  We show that knowing the kinds of questions being asked and what might be learned can help provide more relevant, efficient reasoning.  Finally, we show that analogical processing provides a means of generating useful new questions and conjectures when the system ruminates off-line about what it has read.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-244.pdf,"Subjects:  13. Natural Language Processing;
12. Machine Learning and Discovery"
244,2007,Special Track on Integrated Intelligence,Towards an Integrated Robot with Multiple Cognitive Functions,"Nick Hawes, Aaron Sloman, Jeremy Wyatt, Michael Zillich, Henrik Jacobsson, Geert-Jan M. Kruijff, Michael Brenner, Gregor Berginc, Danijel Skocaj","We present integration mechanisms for combining heterogeneous
components in a situated information processing system, illustrated by a cognitive robot able to collaborate with a human and display some understanding of its surroundings. These mechanisms include an architectural schema that encourages parallel and incremental information processing, and a method for binding information from distinct representations that when faced with rapid change in the world can maintain a coherent, though distributed, view of it. Provisional results are demonstrated in a robot combining vision, manipulation, language, planning and reasoning capabilities interacting with a human and manipulable objects.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-245.pdf,"Subjects:  2. Architectures;
17. Robotics"
245,2007,Special Track on Integrated Intelligence,Spatial Representation and Reasoning for Human-Robot Collaboration,"William G. Kennedy, Magdalena D. Bugajska, Matthew Marge, William Adams, Benjamin R. Fransen, Dennis Perzanowski, Alan C. Schultz, J. Gregory Trafton","How should a robot represent and reason about spatial information when it needs to collaborate effectively with a human? The form of spatial representation that is useful for robot navigation may not be useful in higher-level reasoning or working with humans as a team member. To explore this question, we have extended previous work on how children and robots learn to play hide and seek to a human-robot team covertly approaching a moving target. We used the cognitive modeling system, ACT-R, with an added spatial module to support the robot’s spatial reasoning. The robot interacted with a team member through voice, gestures, and movement during the team’s covert approach of a moving target. This paper describes the new robotic system and its integration of metric, symbolic, and cognitive layers of spatial representation and reasoning for its individual and team behavior.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-246.pdf,"Subjects:  2. Architectures;
3.2 Geometric Or Spatial Reasoning"
246,2007,Special Track on Integrated Intelligence,Extending Cognitive Architecture with Episodic Memory,"Andrew Nuxoll, John Laird","In this paper, we explore the hypothesis that episodic memory is a critical component for cognitive architectures that support general intelligence. Episodic memory overlaps with case-based reasoning (CBR) and can be seen as a task-independent, architectural approach to CBR. We define the design space for episodic memory systems and the criteria any implementation must meet to be useful in a cognitive architecture. We present an implementation and demonstrate how episodic memory, combined with other components of a cognitive architecture, supports a wealth of cognitive capabilities that are difficult to attain without it.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-247.pdf,"Subjects:  2. Architectures;
3. Automated Reasoning"
247,2007,Special Track on Integrated Intelligence,Integrated Introspective Case-Based Reasoning for Intelligent Tutoring Systems,Leen-Kiat Soh,"Many intelligent tutoring systems (ITSs) have been developed, deployed, assessed, and proven to facilitate learning.  However, most of these systems do not generally adapt to new circumstances, do not self-evaluate and self-configure their own strategies, and do not monitor the usage history of the learning content being delivered or presented to the stu-dents.  These shortcomings force ITS developers to often spend much development time in manual revision and fine-tuning of the learning and instructional contents of an ITS.  In this paper, we describe an intelligent agent that delivers learning material adaptively to different students, factoring in the usage history of the learning materials and student profiles as observed by the agent.  Student-tutor interaction includes the activities of going through learning material, such as a topical tutorial, a set of examples, and a set of problems.  Our assumption is that our agent will be able to capture and utilize these student activities as the primer to select the appropriate examples or problems to administer to the student. Using an integrated introspective case-based reasoning approach, our agent further learns from its experience and refines its reasoning process — including the instructional strategies — to adapt to student needs.  Moreover, our agent monitors the usage history of the learning materials to improve its performance.  We have built an end-to-end ITS using an agent powered by this integrated introspective case-based reasoning engine.  We have deployed the ITS in a CS course. Results indicate that the ITS was able to learn to deliver more appropriate examples and problems to the students.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-248.pdf,"Subjects:  1.3 Computer-Aided Education;
3.1 Case-Based Reasoning"
248,2007,Special Track on Integrated Intelligence,Predicate Projection in a Bimodal Spatial Reasoning System,"Samuel Wintermute, John E. Laird","Spatial reasoning is a fundamental aspect of intelligent behavior, which cognitive architectures must address in a problem-independent way. Bimodal systems, employing both qualitative and quantitative representations of spatial information, are efficient and psychologically plausible means for spatial reasoning. Any such system must employ a translation from the qualitative level to the quantitative, where new objects (images) are created through the process of predicate projection. This translation has received little scrutiny. We examine this issue in the context of a bimodal spatial reasoning system integrated with a cognitive architecture (Soar). As part of this system, we define an expressive language for predicate projection that supports general and flexible image creation. We demonstrate this system on multiple spatial reasoning problems in the ORTS real-time strategy game environment.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-249.pdf,"Subjects:  2. Architectures;
3.5 Qualitative Reasoning"
249,2007,Special Track on Integrated Intelligence,An Intelligent System for Chinese Calligraphy,"Songhua Xu, Hao Jiang, Francis C.M. Lau, Yunhe Pan","Our work links Chinese calligraphy to computer science through an integrated intelligence approach. We first extract strokes of existent calligraphy using a semi-automatic, twophase mechanism: the first phase tries to do the best possible extraction using a combination of algorithmic techniques; the second phase presents an intelligent user interface to allow the user to provide input to the extraction process for the difficult cases such as those in highly random, cursive, or distorted styles. Having derived a parametric representation of calligraphy, we employ a supervised learning based method to explore the space of visually pleasing calligraphy. A numeric grading method for judging the beauty of calligraphy is then applied to the space. We integrate such a grading unit into an existent constraint-based reasoning system for calligraphy generation, which results in a significant enhancement in terms of visual quality in the automatically generated calligraphic characters. Finally, we construct an intelligent calligraphy tutoring system making use of the above. This work represents our first step towards understanding the human process of appreciating beauty through modeling the process with an integration of available AI techniques. More results and supplementary materials are provided at http://www.cs.hku.hk/~songhua/calligraphy.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-250.pdf,"Subjects:  1.1 Art And Music;
1. Applications"
250,2007,Special Track on Integrated Intelligence,An Integrated Robotic System for Spatial Understanding and Situated Interaction in Indoor Environments,"Hendrik Zender, Patric Jensfelt, Oscar Martinez Mozos, Geert-Jan M. Kruijff, Wolfram Burgard","A major challenge in robotics and artificial intelligence lies in
creating robots that are to cooperate with people in human-populated environments, e.g. for domestic assistance or elderly care. Such robots need skills that allow them to interact with the world and the humans living and working therein. In this paper we investigate the question of spatial understanding of human-made environments. The functionalities of our system comprise perception of the world, natural language, learning, and reasoning. For this purpose we integrate state-of-the-art components from different disciplines in AI, robotics and cognitive systems into a mobile robot system.  The work focuses on the description of the principles we used for the integration, including cross-modal integration, ontology-based mediation, and multiple levels of abstraction of perception. Finally, we present experiments with the integrated CoSy Explorer (http://www.cognitivesystems.org) system
and list some of the major lessons that were learned from its design, implementation, and evaluation.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-251.pdf,"Subjects:  17. Robotics;
1.6 Engineering And Science"
251,2007,Special Track on Integrated Intelligence,A Text-to-Picture Synthesis System for Augmenting Communication,"Xiaojin Zhu, Andrew B. Goldberg, Mohamed Eldawy, Charles R. Dyer, Bradley Strock","We present a novel Text-to-Picture system that synthesizes a picture from general, unrestricted natural language text.  The process is analogous to Text-to-Speech synthesis, but with pictorial output that conveys the gist of the text.  Our system integrates multiple AI components, including natural language processing, computer vision, computer graphics, and machine learning.  We present an integration framework that combines these components by first identifying informative and `picturable' text units, then searching for the most likely image parts conditioned on the text, and finally optimizing the picture layout conditioned on both the text and image parts.  The effectiveness of our system is assessed in two user studies using children's books and news articles.  Experiments show that the synthesized pictures convey as much information about children's stories as the original artists' illustrations,  and much more information about news articles than their original photos alone.  These results suggest that Text-to-Picture synthesis has great potential in augmenting human-computer and human-human communication modalities, with applications in education and health care, among others.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-252.pdf,"Subjects:  6. Computer-Human Interaction;
6.3 User Interfaces"
252,2007,Senior Member Papers,On the Prospects for Building a Working Model of the Visual Cortex,"Thomas Dean, Glenn Carroll, Rich Washington","Human visual capability has remained largely beyond the reach of                                      engineered systems despite intensive study and considerable progress in problem understanding, algorithms and computing power.  We positthat significant progress can be made by combining existing                                                         
technologies from computer vision, ideas from theoretical neuroscience and the availability of large-scale computing power for experimentation.  From a theoretical standpoint, our primary point of departure from current practice is our reliance on exploiting time in order to turn an otherwise intractable unsupervised problem into a                                                  locally semi-supervised, and plausibly tractable, learning problem.                                                 From a pragmatic perspective, our system architecture follows what we                                               know of cortical neuroanatomy and provides a solid foundation for                                                   scalable hierarchical inference.  This combination of features                                                      promises to provide a range of robust object-recognition capabilities.                                              
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-253.pdf,"Subjects:  14. Neural Networks;
19. Vision"
253,2007,Senior Member Papers,Model-lite Planning for the Web Age Masses: The Challenges of Planning with Incomplete and Evolving Domain Models,Subbarao Kambhampati,"The automated planning community has traditionally focused on the
efficient synthesis of plans given a complete domain theory. In the
past several years, this line of work met with significant successes,
and the future course of the community seems to be set on efficient
planning with even richer models.  While this line of research has its
applications, there are also many domains and scenarios where the
first bottleneck is getting the domain model at any level of
completeness. In these scenarios, the modeling burden automatically
renders the planning technology unusable.  To counter this, I will
motivate model-lite planning technology aimed at reducing the
domain-modeling burden (possibly at the expense of reduced functionality), and
outline the research challenges that need to be addressed to realize
it.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-254.pdf,"Subjects:  1.11 Planning;
Please choose a second document classification"
254,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Online Collective Entity Resolution,"Indrajit Bhattacharya, Lise Getoor","Entity resolution is a critical component of data integration where the goal is to reconcile database references corresponding to the same real-world entities. Given the abundance of publicly available databases that have unresolved entities, we motivate the problem of quick and accurate resolution for answering queries over such `unclean' databases. Since collective entity resolution approaches--where related references are resolved jointly--have been shown to be more accurate than independent attribute-based resolution, we focus on adapting collective resolution for answering queries. We propose a two-stage collective resolution strategy for processing queries. We then show how it can be performed on-the-fly by adaptively extracting and resolving those database references that are the most helpful for resolving the query. We validate our approach on two large real-world publication databases where we show the usefulness of collective resolution and at the same time demonstrate the need for adaptive strategies for query processing. We then show how the same queries can be answered in real time using our adaptive approach while preserving the gains of collective resolution.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-255.pdf,"Subjects:  12. Machine Learning and Discovery;
1.10 Information Retrieval"
255,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Learning by Combining Observations and User Edits,"Vittorio Castelli, Lawrence Bergman, Daniel Oblinger","We introduce a new collaborative machine learning paradigm in which the user directs a learning algorithm by manually editing the automatically induced model.  We identify a generic architecture that supports seamless interweaving of automated learning from training samples and manual edits of the model, and we discuss the main difficulties that  the framework addresses.  We describe Augmentation-Based Learning (ABL), the first learning algorithm that supports interweaving of edits and learning from training samples.  We  use examples based on ABL to outline selected advantages of the approach---dealing with bad data by manually removing their effects from the model, and learning a model with fewer training samples.

",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-256.pdf,"Subjects:  12. Machine Learning and Discovery;
6.3 User Interfaces"
256,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Using Eye-Tracking Data for High-Level User Modeling in Adaptive Interfaces,"Cristina Conati, Christina Merten, Saleema Amershi, Kasia Muldner","In recent years, there has been substantial research on exploring how AI can contribute to Human-Computer Interaction by enabling an interface to understand a user's needs and act accordingly. Understanding user needs is especially challenging when it involves assessing the user's high-level mental states not easily reflected by interface actions. In this paper, we present our results on using eye-tracking data to model such mental states during interaction with adaptive educational software. We then discuss the implications of our research for Intelligent User Interfaces.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-257.pdf,"Subjects:  4. Cognitive Modeling;
6. Computer-Human Interaction"
257,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Informed Case Base Maintenance: A Complexity Profiling Approach,"Susan Craw, Stewart Massie, Nirmalie Wiratunga","Knowledge maintenance for Case-Based Reasoning systems is an important knowledge engineering task despite the availability of initial case knowledge and new cases to extend it. For classification systems it is essential that different scenarios for the various classes are well represented and decision boundaries are well defined in the case knowledge. A complexity-based competence metric is proposed that identifies redundant and error-causing cases to be deleted. The metric informs a maintenance tool that enables the engineer to experiment and balance conflicting objectives. Complexity-informed maintenance outperforms benchmark algorithms for redundancy and error reduction tasks.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-258.pdf,"Subjects:  3.1 Case-Based Reasoning;
10. Knowledge Acquisition"
258,2007,New Scientific and Technical Advances in Research Papers (NECTAR),An Experimental Comparison of Constraint Logic Programming and Answer Set Programming,"Agostino Dovier, Andrea Formisano, Enrico Pontelli","Answer Set Programming (ASP) and Constraint Logic Programming over
finite domains (CLP(FD)) are two declarative programming paradigms
that have been extensively used to encode applications involving 
search, optimization, and reasoning (e.g., commonsense reasoning
and planning).
This paper presents experimental comparisons between the 
declarative encodings of various computationally hard problems in 
both frameworks.
The objective is to investigate how the solvers in the two domains 
respond to different problems, highlighting strengths and 
weaknesses of their implementations, and suggesting criteria for 
choosing one approach over  the other. Ultimately, the work in this 
paper is expected to lay the foundations for transfer of technology 
between the two domains, e.g., suggesting ways to use CLP(FD) in
the execution of ASP.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-259.pdf,"Subjects:  11. Knowledge Representation;
3.3 Nonmonotonic Reasoning"
259,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Efficient Datalog Abduction through Bounded Treewidth,"Georg Gottlob, Reinhard Pichler, Fang Wei","Abductive diagnosis is an important method for identifying possible causes which explain a given set of observations. 
Unfortunately, abduction suffers from the fact that most of the algorithmic problems in this area are intractable. 

We have recently obtained very promising results 
for a strongly related problem in the database area.
Specifically, the PRIMALITY problem becomes 
efficiently solvable and highly parallelizable 
if the underlying functional dependencies have bounded treewidth.

In the current paper, we show that these favorable results can be 
carried over to logic-based abduction. In fact, we even show a 
further generalization of these results.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-260.pdf,"Subjects:  3. Automated Reasoning;
9.2 Computational Complexity"
260,2007,New Scientific and Technical Advances in Research Papers (NECTAR),The Pyramid Match: Efficient Learning with Partial Correspondences,Kristen Grauman,"It is often useful to represent a single example by a set of the

local features that comprise it. However, this representation poses a challenge to many conventional learning techniques, since sets may vary in cardinality and the elements are unordered.  To compare sets of features, researchers often resort to solving for the least-cost correspondences, but this is computationally expensive and becomes impractical for large set sizes. We have developed a general approximate matching technique called the pyramid match that measures partial match similarity in time linear in the number of feature vectors per set.  The matching forms a Mercer kernel, making it valid for use in many existing kernel-based learning methods. We have demonstrated the approach for various learning tasks in vision and text processing, and find that it is accurate and significantly more efficient than previous approaches.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-261.pdf,"Subjects:  12. Machine Learning and Discovery;
19. Vision"
261,2007,New Scientific and Technical Advances in Research Papers (NECTAR),A Kernel Approach to Comparing Distributions,"Arthur Gretton, Karsten Borgwardt, Malte Rasch, Bernhard Schoelkopf, Alex Smola","We describe a technique for comparing distributions without
  the need for density estimation as an intermediate step. Our approach relies on
  mapping the distributions into a Reproducing Kernel Hilbert Space. We apply
  this technique to construct  a two-sample test, which is used for
  determining whether two sets of observations arise from the same
  distribution.  We use this test in attribute matching for
  databases using the Hungarian marriage method, where it performs strongly.
  We also demonstrate excellent
  performance when comparing distributions over graphs, for which no
  alternative tests currently exist.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-262.pdf,"Subjects:  12. Machine Learning and Discovery;
Please choose a second document classification"
262,2007,New Scientific and Technical Advances in Research Papers (NECTAR),A* Search via Approximate Factoring,"Aria Haghighi, John DeNero, Dan Klein","We present a novel method for creating A* estimates for structured search problems originally described in Haghighi, DeNero, and Klein (2007). In our approach, we project a complex model onto multiple simpler models for which exact inference is efficient. We use an optimization framework to estimate parameters for these projections in a way which bounds the true costs. Similar to Klein and Manning (2003), we then combine completion estimates from the simpler models to guide search in the original complex model. We apply our approach to bitext parsing and demonstrate its effectiveness.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-263.pdf,"Subjects:  15.7 Search;
13. Natural Language Processing"
263,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Manifold Denoising As Preprocessing for Finding Natural Representations of Data,"Matthias Hein, Markus Maier","A natural representation of data is given by the parameters which

generated the data. If the space of parameters is continuous, then

we can regard it as a manifold. In practice, we usually do not

know this manifold but we just have some representation of the

data, often in a very high-dimensional feature space. Since the

number of internal parameters does not change with the

representation, the data will effectively lie on a low-dimensional

submanifold in feature space. However, the data is usually

corrupted by noise, which particularly in high-dimensional feature

spaces makes it almost impossible to find the manifold structure.

This paper reviews a method called Manifold Denoising,

which projects the data onto the submanifold using a diffusion

process on a graph generated by the data. We will demonstrate that

the method is capable of dealing with non-trival high-dimensional

noise. Moreover, we will show that using the denoising method as a

preprocessing step, one can significantly improve the results of a

semi-supervised learning algorithm.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-264.pdf,"Subjects:  12. Machine Learning and Discovery;
9.3 Mathematical Foundations"
264,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Near-optimal Observation Selection using Submodular Functions,"Andreas Krause, Carlos Guestrin","AI problems such as autonomous robotic exploration, automatic diagnosis and activity recognition have in common the need for choosing among a set of informative but possibly expensive observations. When monitoring spatial phenomena with sensor networks or mobile robots, for example, we need to decide which locations to observe in order to most effectively decrease the uncertainty, at minimum cost. These problems usually are NP-hard. Many observation selection objectives satisfy submodularity, an intuitive diminishing returns property -- adding a sensor to a small deployment helps more than adding it to a large deployment. In this paper, we survey recent advances in systematically exploiting this submodularity property to efficiently achieve near-optimal observation selections, under complex constraints. We illustrate the effectiveness of our approaches on problems of monitoring environmental phenomena and water distribution networks.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-265.pdf,"Subjects:  12. Machine Learning and Discovery;
17. Robotics"
265,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Dominance and Equivalence for Sensor-Based Agents,"Jason M. O'Kane, Steven M. LaValle","This paper describes recent results from the robotics community that develop a theory, similar in spirit to the theory of computation, for analyzing sensor-based agent systems.  The central element to this work is a notion of dominance of one such system over another.  This relation is formally based on the agents' progression through a derived information space, but may informally be understood as describing one agent's ability to ""simulate"" another.  We present some basic properties of this dominance relation and demonstrate its usefulness by applying it to a basic problem in robotics.  We argue that this work is of interest to a broad audience of artificial intelligence researchers for two main reasons.  First, it calls attention to the possibility of studying belief spaces in way that generalizes both probabilistic and nondeterministic uncertainty models.  Second, it provides a means for evaluating the information that an agent is able to acquire (via its sensors and via conformant actions), independent of any optimality criterion and of the task to be completed.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-266.pdf,"Subjects:  17. Robotics;
1.11 Planning"
266,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Modeling and Learning Vague Event Durations for Temporal Reasoning,"Feng Pan, Rutu Mulkar-Mehta, Jerry R. Hobbs","This paper reports on our recent work on modeling and automatically extracting vague, implicit event durations from text (Pan et al., 2006a, 2006b). It is a kind of commonsense knowledge that can have a substantial impact on temporal reasoning problems. We have also proposed a method of using normal distributions to model judgments that are intervals on a scale and measure their inter-annotator agreement; this should extend from time to other kinds of vague but substantive information in text and commonsense reasoning.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-267.pdf,"Subjects:  13. Natural Language Processing;
3.6 Temporal Reasoning"
267,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Learning and Inference for Hierarchically Split PCFGs,"Slav Petrov, Dan Klein","Treebank parsing can be seen as the search for an optimally refined grammar consistent with a coarse training treebank.  We describe a method in which a minimal grammar is hierarchically refined using EM to give accurate, compact grammars.  The resulting grammars are extremely compact compared to other high-performance parsers, yet the parser gives the best published accuracies on several languages, as well as the best generative parsing numbers in English.  In addition, we give an associated coarse-to-fine inference scheme which vastly improves inference time with no loss in test set accuracy.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-268.pdf,"Subjects:  13. Natural Language Processing;
13.3 Syntax"
268,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Refutation by Randomised General Resolution,"Steven Prestwich, Ines Lynce","Local search is widely applied to satisfiable SAT problems, and on some problem classes outperforms backtrack search.  An intriguing challenge posed by Selman, Kautz and McAllester in 1997 is to use it instead to prove unsatisfiability.  We design a greedy randomised resolution algorithm called RANGER that will eventually refute any unsatisfiable instance while using only bounded memory.  RANGER can refute some problems more quickly than systematic resolution or backtracking with clause learning.  We believe that non-systematic but greedy inference is an interesting research direction for powerful proof systems such as general resolution.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-269.pdf,"Subjects:  15.2 Constraint Satisfaction;
15.7 Search"
269,2007,New Scientific and Technical Advances in Research Papers (NECTAR),"Beyond Individualism: Modeling Team Playing Behavior
Beyond Individualism: Modeling Team Playing Behavior in Robot Soccer Through Case-Based Reasoning","Raquel Ros, Manuela Veloso, Ramon Lopez de Mantaras, Carles Sierra, Josep Lluis Arcos","We propose a Case-Based Reasoning approach for action selection in the robot soccer domain presented in the 8th European Conference on Case-Based Reasoning (2006). Based on the current state of a game, the robots retrieve the most similar past situation and then the team reproduces the sequence of actions performed in that occasion. In this domain we have to deal with all the difficulties that a real environment involves.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-270.pdf,"Subjects:  3.1 Case-Based Reasoning;
17. Robotics"
270,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Temporal Difference and Policy Search Methods for Reinforcement Learning:An Empirical Comparison,"Matthew E. Taylor, Shimon Whiteson, Peter Stone","Reinforcement learning (RL) methods have become popular in recent years because of their ability to solve complex tasks with minimal feedback. Both genetic algorithms (GAs) and temporal difference (TD) methods have proven effective at solving difficult RL problems, but few rigorous comparisons have been conducted. Thus, no general guidelines describing the methods' relative strengths and weaknesses are available. This paper summarizes a detailed empirical comparison between a GA and a TD method in Keepaway, a standard RL benchmark domain based on robot soccer. The results from this study help isolate the factors critical to the performance of each learning method and yield insights into their general strengths and weaknesses.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-271.pdf,"Subjects:  12.1 Reinforcement Learning;
1.9 Genetic Algorithms"
271,2007,New Scientific and Technical Advances in Research Papers (NECTAR),Making VCG More Robust in Combinatorial Auctions via Submodular Approximation,"Makoto Yokoo, Atsushi Iwasaki","The Vickrey-Clarke-Groves (VCG) protocol is a theoretically
well-founded protocol that can be used for combinatorial
auctions.  However, the VCG has several limitations such as
(a) vulnerability to false-name bids, (b) vulnerability to
loser collusion, and (c) the outcome is not in the core.
Yokoo, Matsutani, and Iwasaki (2006) presented a new
combinatorial auction protocol called the Groves Mechanism
with SubModular Approximation (GM-SMA).  This protocol
satisfies the following characteristics: (1) it is
false-name-proof, (2) each winner is included in a Pareto
efficient allocation, and (3) as long as a Pareto efficient
allocation is achieved, the protocol is robust against the
collusion of losers and the outcome is in the core.  The
GM-SMA is the first protocol that satisfies all three of
these characteristics.  The basic ideas of the GM-SMA are as
follows: (i) it is based on the VCG protocol, i.e., the
payment of a winner in this protocol is identical to the
payment in one instance of the Groves mechanism, which is a
class of protocols that includes the VCG, and (ii) when
calculating the payment of a bidder, we approximate the
valuations of other bidders by using a submodular valuation
function (submodular approximation).

This paper shows a high-level presentation of the GM-SMA
protocol, and discusses open problems and the relationship
to other works in AI.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-272.pdf,"Subjects:  7.1 Multi-Agent Systems;
7. Distributed AI"
272,2007,Deployed Applications,Using AI for e-Government Automatic Assessment of Immigration Application Forms,Andy HW Chun,"This paper describes an e-Government AI project that provides a range of intelligent AI services to support automated assessment of various types of applications submitted to an immigration agency. The ""AI Module"" is integrated into the agency's next generation application form processing system which includes a workflow and document management system. AI services provided include rule-based assessment, workflow processing, schema-based suggestions, data mining, case-based reasoning, and machine learning. The objective is to use AI to provide faster and higher quality service to millions of citizens and visitors in processing their requests. The AI Module streamlines processes and workflows while at the same time ensuring all applications are processed fairly and accurately and that all relevant laws and regulations have been considered. It greatly shortens turnaround time and indirectly helps facilitate economic growth of the city. This is probably the first time any immigration agency in the world is using AI for automatic application assessment in such a large and broad scale.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-273.pdf,Subjects:  1.7 Expert Systems; 3. Automated Reasoning
273,2007,Deployed Applications,The VITA Financial Services Sales Support Environment,"Alexander Felfernig, Klaus Isak, Kalman Szabo, Peter Zachar","Knowledge-based recommender technologies support customers and sales representatives in the identification of appropriate products and services. These technologies are especially useful for complex and high involvement products such as cars, computers, or financial services. In this paper we present the VITA (Virtualis Tanacsado)
financial services recommendation environment which has been deployed for the Fundamenta building and loan association in Hungary. On the basis of knowledge-based recommender technologies, VITA supports sales dialogs between Fundamenta sales representatives and customers interested in financial services (e.g., loans). VITA has been developed and is maintained on the basis of an environment which supports automated testing and debugging of knowledge bases and recommender process definitions.
Besides presenting the VITA environment we focus on reporting empirical results which clearly show the payoffs of the deployed application in terms of time savings in the conduction of sales dialogs.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-274.pdf,Subjects:  1. Applications; 10. Knowledge Acquisition
274,2007,Deployed Applications,Biomind ArrayGenius and GeneGenius:Web Services Offering Microarray and SNP Data Analysis via Novel Machine Learning Methods,"Ben Goertzel, Cassio Pennachin, Lucio Coelho, Leonardo Shikida, Murilo Queiroz","Analysis of  postgenomic biological data (such as microarray and SNP data) is a subtle art and science, and the statistical methods most commonly utilized  sometimes prove inadequate.  Machine learning techniques can provide superior understanding in many cases, but are rarely used due to their relative complexity and obscurity.  A challenge, then, is to make machine learning approaches to data analysis available to the average biologist in a user-friendly way.  This challenge is addressed by the Biomind ArrayGenius product, an easy-to-use Web-based system providing microarray analysis based on genetic programming, kernel methods, and incorporation of knowledge from biological ontologies; and GeneGenius, its sister product for SNP data. This paper focuses on the obstacles faced and lessons learned in the course of creating, deploying, maintaining and selling ArrayGenius and GeneGenius — many of which are generic to any effort involving the creation of complex AI-based products addressing complex domain problems.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-275.pdf,Subjects:  1.6 Engineering And Science; 1.9 Genetic Algorithms
275,2007,Deployed Applications,MasDISPO: A Multiagent Decision Support System for Steel Production and Control,"Sven Jacobi, Esteban Leon-Soto, Cristian Madrigal-Mora, Klaus Fischer","In the majority of cases, steel production constitutes the inception of the Supply Chains they are involved just as in automotive clusters or aerospace. Steel manufacturing companies are affected strongest by bull whip effects or other unpredictable influences along the production chain to the customers. Therefore, flexible planning and realisation as well as fast reorganisation after interferences are indispensable requirements for a competitive position on the market. In this paper, MasDISPO, an agent-based decision support system for production and control inside the steel works of Saarstahl AG, a globally respected steel manufacturer, is presented. It is based on a distributed online planning and online scheduling algorithm to calculate solutions supporting production and control inside the melting shop. It monitors the execution of their chosen solutions and responds to unpredicted changes during production by dynamically adapting the schedules.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-276.pdf,Subjects:  7.1 Multi-Agent Systems; 1. Applications
276,2007,Deployed Applications,Custom DY — A Web Based Business User Driven Automated Underwriting System,"Srinivas Krovvidy, Robin Landsman, Steve Opdahl, Nancy Templeton, Sydnor Smalera","Custom DY is an automated underwriting system that enables mortgage lenders to build their own business rules that facilitate assessing borrower eligibility for different mortgage products. Developed by Fannie Mae, Custom DU has been used since 2004 by several lenders to automate the underwriting of numerous mortgage products. Custom DU uses rule specification language techniques and a web-based, user-friendly interface for implementing business rules that represent business policy.  Via the user interface, lenders can also customize their underwriting findings reports, test the rules that they have defined and publish changes to business rules on a real-time basis, all without any software modifications. The user interface enforces structure and consistency, enabling business users to focus on their underwriting guidelines when converting their business policy to rules. Once a lender has created their rules, loans are routed to the appropriate rulesets and customized, but consistent results are always returned to the lender. Using Custom DU, lenders can create different rulesets for their products and assign them to different channels of the business, allowing for centralized control of underwriting policies and procedures — even if lenders have decentralized operations.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-277.pdf,Subjects:  1.7 Expert Systems; 10. Knowledge Acquisition
277,2007,Deployed Applications,Journal-Ranking.com: An Online Interactive Journal Ranking System,"Andrew Lim, Hong Ma, Qi Wen, Zhou Xu, Brenda Cheang, Bernard Tan, Wenbin Zhu","Journal-Ranking.com is perhaps the first online journal ranking system in the world which allows any individual to conduct citation analyses among more than 7000 academic journals with regards to his/her own interests. Besides classical statistics on citation quantity, the system also allows taking citation quality into consideration after extending on the well known PageRank method, which has been successfully applied to evaluate the impact of web pages by Google. Journal-Ranking.com was developed by Red Jasper Limited and the Hong Kong University of Science and Technology. The system underwent a soft launch in June 2006 and has been successfully deployed in 2007. The website has registered an average of a million hits per month since its official launch. This paper explains the development and design of Journal-Ranking.com and its impacts to the global research community.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-278.pdf,Subjects:  1. Applications; 15. Problem Solving
278,2007,Deployed Applications,The Virtual Solar-Terrestrial Observatory: A Deployed Semantic Web Application Case Study for Scientific Research,"Deborah L. McGuinness, Peter Fox, Luca Cinquini, Patrick West, Jose Garcia, James L. Benedict,  and Don Middleton","The Virtual Solar-Terrestrial Observatory is a production semantic web data framework providing access to observational datasets from fields spanning upper atmospheric terrestrial physics to solar physics. The observatory allows virtual access to a highly distributed and heterogeneous set of data that appears as if all resources are organized, stored and retrieved/used in a common way. The end-user community comprises scientists, students, data providers numbering over 600 out of an estimated community of 800. We present details on the case study, our technological approach including the semantic web languages, tools and infrastructure deployed, benefits of AI technology to the application, and our present evaluation after the initial nine months of use.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-279.pdf,Subjects:  1.6 Engineering And Science; 8. Enabling Technologies
279,2007,Deployed Applications,Fish Inspection Systems using Parallele Neural Network Chips and an Image Knowledge Builder.,"Anne  Menendez, Guy Paillet","A generic image learning system, CogniSight, is being used for inspecting fishes before filleting. More than thirty systems have been deployed on seven fishing vessels in Norway and Iceland. Each CogniSight is using four hardware neural networks chips (312 neurons) based on natively parallel hardwired architecture performing real time training and non-linear classification (RBF). These systems are trained and the learning can be reinforced directly by the ship crew using Image Knowledge Builder, show and tell training and validation software. Most of the systems have been deployed for three years or more. They reduce significantly the number of crew (up to six persons) and are reducing the time at sea by up to 15%. These systems brought a strong return of the investment to the fishing fleet and, in turn, increased significantly the market shares of Pisces Industries, the company manufacturing the filleting machines.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-280.pdf,Subjects:  19.1 Perception; 14. Neural Networks
280,2007,Deployed Applications,Enabling Intelligent Content Discovery on the Mobile Internet,"Barry Smyth, Paul Cotter, Stephen Oman","The mobile Internet is a massive opportunity for mobile operators and content providers, but despite significant improvements in handsets, infrastructure, content, and charging models, mobile users are still struggling to access and locate relevant content and services. The core of this so-called content discovery problem is the navigation effort that users must invest in browsing and searching for mobile content. In this paper we describe one successfully deployed solution, which uses personalization technology to profile subscriber interests in order to automatically adapt mobile portals to their learned preferences. We present summary results, from our deployment experiences with more than 40 mobile operators and millions of subscribers around the world, which demonstrate how this solution can have a significant impact on portal usability, subscriber usage, and mobile operator revenues.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-281.pdf,Subjects:  6. Computer-Human Interaction; 6.3 User Interfaces
281,2007,Deployed Applications,"Coordinating Hundreds of Cooperative, Autonomous Vehicles in Warehouses","Peter Wurman, Raffaello D'Andrea, Mick Mountz","The Kiva warehouse management system creates a new paradigm for pick-pack-and-ship warehouses that significantly improves worker productivity.  The Kiva system uses movable storage shelves that can be lifted by small, autonomous robots.  By bringing the product to the worker, productivity is increased by a factor of two or more, while simultaneously improving accountability and flexibility.  A Kiva installation for a large distribution center may require 500 or more vehicles.  As such, the Kiva system represents the first commercially available, large-scale autonomous robot system.  The first permanent installation of a Kiva system was deployed in the summer of 2006.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-282.pdf,Subjects:  17. Robotics; 7.1 Multi-Agent Systems
282,2007,Emerging Applications,Real-Time Identification of Operating Room State from Video,"Beenish Bhatia, Tim Oates, Yan Xiao, Peter Hu","Managers of operating rooms (ORs) and of units upstream (e.g., ambulatory surgery) and downstream (e.g., intensive care and post-anesthesia care) of the OR require real-time information about OR occupancy.  Which ORs are in use, and when will each ongoing operation end?  This information is used to make decisions about how to assign staff, when to prepare patients for the OR, when to schedule add-on cases, when to move cases, and how to prioritize room cleanups.  It is typically gathered by OR managers manually, by walking to each OR and estimating the time to case completion. This paper presents a system for determining the state of an ongoing operation automatically from video.  Support vector machines are trained to identify relevant image features, and hidden Markov models are trained to use these features to compute a sequence of OR states from the video.  The system was tested on video captured over a 24 hour period in one of the 19 operating rooms in Baltimore's R. Adams Crowley Shock Trauma Center.  It was found to be more accurate and have less delay while providing more fine-grained state information than the current state-of-the-art system based on patient vital signs used by the Shock Trauma Center.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-283.pdf,Subjects:  12. Machine Learning and Discovery; 19. Vision
283,2007,Emerging Applications,Wings for Pegasus: Creating Large-Scale Scientific Applications Using Semantic Representations of Computational Workflows,"Yolanda Gil, Varun Ratnakar, Ewa Deelman, Gaurang Mehta, Jihie Kim","Scientific workflows are being developed for many domains as a useful paradigm to manage complex scientific computations.  In our work, we are challenged with efficiently generating and validating workflows that contain large amounts (hundreds to thousands) of individual computations to be executed over distributed environments.  This paper describes a new approach to workflow creation that uses semantic representations to describe compactly complex scientific applications in a data-independent manner, then automatically generates workflows of computations for given data sets, and finally maps them to available computing resources.  The semantic representations are used to automatically generate descriptions for each of the thousands of new data products.  We interleave the creation of the workflow with its execution, which allows intermediate execution data products to influence the generation of the following portions of the workflow.  We have implemented this approach in Wings, a workflow creation system that combines semantic representations with planning techniques.  We have used Wings to create workflows of thousands of computations, which are submitted to the Pegasus mapping system for execution over distributed computing environments.  We show results on an earthquake simulation workflow that was automatically created with a total number of 24,135 jobs and that executed for a total of 1.9 CPU years.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-284.pdf,Subjects:  1.6 Engineering And Science; 11. Knowledge Representation
284,2007,Emerging Applications,A Multi-Agent Approach to Distributed Rendering Optimization,"Carlos Gonzalez-Morcillo, Gerhard Weiss, Luis Jimenez, David Vallejo","Physically based rendering is the process of generating a 2D image from the abstract description of a 3D Scene. Despite the development of various new techniques and algorithms, the computational requirements of generating photorealistic images still do not allow to render in real time. Moreover, the configuration of good render quality parameters is very difficult and often too complex to be done by non-expert users. This paper describes a novel approach called MAgarRO (standing for Multi-Agent AppRoach to Rendering Optimization) which utilizes principles and techniques known from the field of multi-agent systems to optimize the rendering process. Experimental results are presented which show the benefits of MAgarRO-based rendering optimization.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-285.pdf,Subjects:  7. Distributed AI; 7.1 Multi-Agent Systems
285,2007,Emerging Applications,Optimizing Anthrax Outbreak Detection Using Reinforcement Learning,"Masoumeh Izadi, David Buckeridge","The potentially catastrophic impact of a bioterrorist attack makes developing effective detection methods essential for public health. In the case of anthrax attack, a delay of hours in making a right decision can lead to hundreds of lives lost. Current detection methods trade off reliability of alarms for early detection of outbreaks. The performance of these methods can be improved by modern disease-specific modeling techniques which take into account the potential costs and effects of an attack to provide optimal warnings. We study this optimization problem in the reinforcement learning framework. The key contribution of this paper is to apply Partially Observable Markov Decision Processes (POMDPs) on outbreak detection mechanism for improving alarm function in anthrax outbreak detection. Our approach relies on estimating the future benefit of true alarms and the costs of false alarms and using these quantities to identify an optimal decision. We present empirical evidence illustrating that the performance of detection methods with respect to sensitivity and timeliness is improved significantly by utilizing POMDPs.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-286.pdf,Subjects:  1. Applications; 12.1 Reinforcement Learning
286,2007,Emerging Applications,Supporting Feedback and Assessment of Digital Ink Answers to In-Class Exercises,"Kimberle Koile, Kevin Chevalier, Michel Rbeiz, Adam Rogal, David Singer, Jordan Sorensen, Amanda Smith, Kah Seng Tay, Kenneth Wu","Effective teaching involves treating the presentation of new material and the assessment of students' mastery of this material as part of a seamless and continuous feedback cycle.  We have developed a computer system, called Classroom Learning Partner (CLP), that supports this methodology, and we have used it in teaching an introductory computer science course at MIT over the past year.  Through evaluation of controlled classroom experiments, we have demonstrated that this approach reaches students who would have otherwise been left behind, and that it leads to greater attentiveness in class, greater student satisfaction, and better interactions between the instructor and student.  The current CLP system consists of a network of Tablet PCs, and software for posing questions to students, interpreting their handwritten answers, and aggregating those answers into equivalence classes, each of which represents a particular level of understanding or misconception of the material.  The current system supports a useful set of recognizers for specific types of answers, and employs AI techniques in the knowledge representation and reasoning necessary to support interpretation and aggregation of digital ink answers.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-287.pdf,Subjects:  1.3 Computer-Aided Education; 6. Computer-Human Interaction
287,2007,Emerging Applications,Adaptive Timeout Policies for Fast Fine-Grained Power Management,"Branislav Kveton, Prashant Gandhi, Georgios Theocharous, Shie Mannor, Barbara Rosario, Nilesh Shah","Power management techniques for mobile appliances put the components of the systems into low power states to maximize battery life while minimizing the impact on the perceived performance of the devices. Static timeout policies are the state-of-the-art approach for solving power management problems. In this work, we propose adaptive timeout policies as a simple and efficient solution for fine-grained power management. As discussed in the paper, the policies reduce the latency of static timeout policies by nearly one half at the same power savings. This result can be also viewed as increasing the power savings of static timeout policies at the same latency target. The main objective of our work is to propose practical adaptive policies. Therefore, our adaptive solution is fast enough to be executed within less than one millisecond, and sufficiently simple to be deployed directly on a microcontroller. We validate our ideas on two recorded CPU activity traces, which involve more than 10 million entries each.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-288.pdf,Subjects:  1. Applications; 12. Machine Learning and Discovery
288,2007,Emerging Applications,RETALIATE: Learning Winning Policies in First-Person Shooter Games,"Megan Smith, Stephen Lee-Urban, Hector Munoz-Avila","In this paper we present RETALIATE, an online reinforcement learning algorithm for developing winning policies in team first-person shooter games. RETALIATE has three crucial characteristics: (1)  individual BOT behavior is fixed although not known in advance, therefore individual BOTS work as plug-ins, (2) RETALIATE models the problem of learning team tactics through a simple state formulation, (3) discount rates commonly used in Q-learning are not used. As a result of these characteristics, the application of the Q-learning algorithm results in the rapid exploration towards a winning policy against an opponent team. In our empirical evaluation we demonstrate that RETALIATE adapts well when the environment changes.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-289.pdf,Subjects:  1.8 Game Playing; 12.1 Reinforcement Learning
289,2007,Emerging Applications,Machine Learning for Automatic Mapping of Planetary Surfaces,"Tomasz Stepinski, Soumya Ghosh, Ricardo Vilalta","We describe an application of machine learning to the problem of geomorphic mapping of planetary surfaces. Mapping landforms on planetary surfaces is an important task and the first step to deepen our understanding of many geologic processes. Until now such maps have been manually drawn by a domain expert. We describe a framework to automate the mapping process by means of segmentation and classification of landscape datasets. We propose and implement a number of extensions to the existing methodology with particular emphasis on the incorporation of machine learning techniques. These extensions result in a robust and practical mapping system that we apply on six sites on Mars. Support Vector Machines show the best mapping results with an accuracy rate of approx. 91%. The resultant maps reflect the geomorphology of the sites and have appearance reminiscent of traditional, manually drawn maps. The system is capable of mapping numerous sites using a limited training set. Immediate and eventual applications of this automated mapping system are discussed in the context of planetary science and other domains.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-290.pdf,Subjects:  12. Machine Learning and Discovery; 12.2 Scientific Discovery
290,2007,Emerging Applications,Optimal Multi-Agent Scheduling with Constraint Programming,"Willem-Jan van Hoeve, Carla P. Gomes, Michele Lombardi, Bart Selman","We consider the problem of computing optimal schedules in multi-agent systems. In these problems, actions of one agent can influence the actions of other agents, while the objective is to maximize the total `quality' of the schedule. More specifically, we focus on multi-agent scheduling problems with time windows, hard and soft precedence relations, and a nonlinear objective function. We show how we can model and efficiently solve these problems with constraint programming technology. Elements of our proposed method include constraint-based reasoning, search strategies, problem decomposition, scheduling algorithms, and a linear programming relaxation. We present experimental results on realistic problem instances to display the different elements of the solution process.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-291.pdf,Subjects:  7.1 Multi-Agent Systems; 15.2 Constraint Satisfaction
291,2007,Emerging Applications,Stochastic Optimization for Collision Selection in High Energy Physics,"Shimon Whiteson, Daniel Whiteson","Artificial intelligence has begun to play a critical role in basic science research.  In high energy physics, AI methods can aid precision measurements that elucidate the underlying structure of matter, such as measurements of the mass of the top quark.  Top quarks can be produced only in collisions at high energy particle accelerators.  Most collisions, however, do not produce top quarks and making precise measurements requires culling these collisions into a sample that is rich in collisions producing top quarks (signal) and spare in collisions producing other particles (background).  Collision selection is typically performed with heuristics or supervised learning methods.  However, such approaches are suboptimal because they assume that the selector with the highest classification accuracy will yield a mass measurement with the smallest statistical uncertainty.  In practice, however, the mass measurement is more sensitive to some backgrounds than others.  This paper presents a new approach that uses stochastic optimization techniques to directly search for selectors that minimize statistical uncertainty in the top quark mass measurement.  Empirical results confirm that stochastically optimized selectors have much smaller uncertainty.  This new approach contributes substantially to our knowledge of the top quark's mass, as the new selectors are currently in use selecting real collisions.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-292.pdf,Subjects:  12. Machine Learning and Discovery; 14. Neural Networks
292,2007,Emerging Applications,An Integrated Development Environment and Architecture for Soar-Based Agents,"Ari Yakir, Gal Kaminka","It is well known how challenging is the task of coding complex agents for virtual environments. This difficulty in developing and maintaining complex agents has been plaguing commercial applications of advanced agent technology in virtual environments. In this paper, we discuss development of a commercial-grade integrated development environment (IDE) and agent architecture for simulation and training in a high-fidelity virtual environment. Specifically, we focus on two key areas of contribution. First, we discuss the addition of an explicit recipe mechanism to Soar, allowing reflection. Second, we discuss the development and usage of an IDE for building agents using our architecture; the approach we take is to tightly-couple the IDE to the architecture. The result is a complete development and deployment environment for agents situated in a complex dynamic virtual world.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-293.pdf,Subjects:  7.1 Multi-Agent Systems; 15.8 Simulation
293,2007,Emerging Applications,Adaptive Traitor Tracing with Bayesian Networks,"Philip Zigoris, Hongxia Jin","The practical success of broadcast encryption hinges on the ability to (1) revoke the access of compromised keys and (2) determine which keys have been compromised.  In this work we focus on the latter, the so-called \emph{traitor tracing} problem. We present an adaptive tracing algorithm that selects forensic tests according to the information gain criteria. The results of the tests refine an explicit, Bayesian model of our beliefs that certain keys are compromised. In choosing tests based on this criteria, we significantly reduce the number of tests, as compared to the state-of-the-art techniques, required to identify compromised keys.  As part of the work we developed an efficient, distributable inference algorithm that is suitable for our application and also give an efficient heuristic for choosing the optimal test.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-294.pdf,Subjects:  1.5 Diagnosis; 3.4 Probabilistic Reasoning
294,2007,Student Abstracts,Data Clustering with a Relational Push-Pull Model,"Adam  Anthony, Marie desJardins",Relational data clustering is the task of grouping data objects together when both attributes and relations between objects are present.  We present a new generative model for relational data in which relations between objects can have either a binding or separating effect.,https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-295.pdf,"Subjects:  12. Machine Learning and Discovery;
3.4 Probabilistic Reasoning"
295,2007,Student Abstracts,UNDERTOW: Multi-Level Segmentation of Real-Valued Time Series,"Tom Armstrong, Tim Oates","The discovery of meaningful change points, finding segments, in both categorical and real-value data time series is a well-studied problem.  Prior segmentation algorithms and tasks operate under overly restrictive assumptions (e.g., a priori knowledge of the number of segments, trivial inputs) and in singular domains (e.g., finding common regions in images, speaker change detection).  We introduce a domain-independent algorithm, UNDERTOW, which discovers segment boundaries in real-valued time series and constructs hierarchies of segments to form macro segments.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-296.pdf,"Subjects:  12. Machine Learning and Discovery;
Please choose a second document classification"
296,2007,Student Abstracts,Explanation Support for the Case-Based Reasoning Tool myCBR,"Daniel Bahls, Thomas Roth-Berghofer","Case-Based Reasoning, in short, is the process of solving new problems based on solutions of similar past problems, much like humans solve many problems. myCBR, an extension of the ontology editor Protege, provides such similarity-based retrieval functionality. Moreover, the user is supported in modelling appropriate similarity measures by forward and backward explanations.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-297.pdf,"Subjects:  3.1 Case-Based Reasoning;
6.3 User Interfaces"
297,2007,Student Abstracts,A Markovian Model for Dynamic and Constrained Resource Allocation Problems,"Camille Besse, Brahim Chaib-draa","An autonomous agent, allocating stochastic resources to incoming tasks, faces increasingly complex situations when formulating its control policy. These situations are often constrained by limited resources of the agent, time limits, physical constraints or other agents. All these reasons explain why complexity and state space dimension increase exponentially in size of considered problem. Unfortunately, models that already exist either consider the sequential aspect of the environment, or its stochastic one or its constrained one. To the best of our knowledge, there is no model that take into account all these three aspects.
In this paper, we introduce a new model based on Dynamic Constraint Satisfaction Problems (DCSP) and Markov Decision Processes to address constrained stochastic resource allocation problems by using expressiveness and powerfulness of CSPs. We thus propose a framework which aims to model dynamic and stochastic environments for constrained resources allocation decisions and present some complexity and experimental results.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-298.pdf,"Subjects:  15. Problem Solving;
15.3 Control"
298,2007,Student Abstracts,Implementing Modal Extensions of Defeasible Logic for the Semantic Web,"Nikos  Dimaresis, Grigoris Antoniou","Defeasible logic is a simple, efficient but flexible non-monotonic formalism that offers many reasoning capabilities, embodies the concept of preference and it has low computational complexity. Nonmonotonic rule systems are expected to play an important role in the layered development of the Semantic Web.Semantic Web community has performed extensive research in the area of policies.In the current work, we develop a nonmonotonic rulebased system that can reason in Semantic Web applications associated with policies and business rules. It is based on an extension of defeasible logic with modalities and supports reasoning with RDF/S ontologies.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-299.pdf,"Subjects:  3.3 Nonmonotonic Reasoning;
11. Knowledge Representation"
299,2007,Student Abstracts,Ungreedy Methods for Chinese Deterministic Dependency Parsing,"Xiangyu Duan, Jun Zhao, Bo Xu","Deterministic dependency parsing has often been regarded as an efficient parsing algorithm while its parsing accuracy is a little lower than the best results reported by more complex parsing models. In this paper, we compare deterministic dependency parsers with complex parsing methods such as generative and discriminative parsers on the standard data set of Penn Chinese Treebank. The results show that, for Chinese dependency parsing, deterministic parsers outperform generative and discriminative parsers. Furthermore, basing on the observation that deterministic parsing algorithms are greedy algorithms which choose the most probable parsing action at every step, we propose three kinds of ungreedy deterministic dependency parsing algorithms to globally model parsing actions. We take the original deterministic dependency parsers as baseline systems. Results show that ungreedy deterministic dependency parsers perform better than the baseline systems while maintaining the same time complexity, and the best result improves much over baseline.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-300.pdf,"Subjects:  13. Natural Language Processing;
13.3 Syntax"
300,2007,Student Abstracts,Using Multiresolution Learning for Transfer in Image Classification,"Eric Eaton, Marie desJardins, John Stevenson","Our work explores the transfer of knowledge at multiple levels of abstraction to improve learning. By exploiting the similarities between objects at various levels of detail, multiresolution learning can facilitate transfer between image classification tasks.
We extract features from images at multiple levels of resolution, then use these features to create models at different resolutions. Upon receiving a new task, the closest-matching stored model can be generalized (adapted to the appropriate resolution) and transferred
to the new task.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-301.pdf,"Subjects:  12. Machine Learning and Discovery;
19. Vision"
301,2007,Student Abstracts,Robust Estimation of 3-D Line Segments from Satellite Images for Model Building and Change Detection,"Ibrahim Eden, David B. Cooper",This paper addresses how to automatically match and reconstruct line segments from multiple satellite images and detect changes in man-made structures by using reconstructed 3-D line segments. We propose a new approach to line reconstruction and use wireframe models to better estimate the actual 3-D geometry by using the incidence relations between reconstructed line segments. Our change detection method is widely applicable as man-made structures are the main focus of most change detection applications.,https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-302.pdf,"Subjects:  19. Vision;
3.2 Geometric Or Spatial Reasoning"
302,2007,Student Abstracts,Classifiers Fusion for EEG Signals Processing in Human-Computer Interface Systems,Maryam Esmaeili,"In this paper we study the effectiveness of using multiple classifier combination for EEG signals classification aiming to obtain more accurate results than it possible from single classifier system. The developed system employs different features vectors fused at the abstract and measurement levels for integrating information to reach a collective decision. For making decision, the majority voting scheme has been used. While at the measurement level, fuzzy integral, majority vote, decision template and some other types of combination methods have been investigated. The ensemble classification task is completed by feeding the Support Vectors Machines with Redial Basis Kernel functions classifiers with  different features extracted from the EEG signal for imagination of right and left hands movements (i.e., at EEG channels C3 and C4). The parameters of SVM classifiers were optimized by genetic algorithm. The results show that using classifier fusion methods improved the overall classification performance.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-303.pdf,"Subjects:  12. Machine Learning and Discovery;
6. Computer-Human Interaction"
303,2007,Student Abstracts,On Policy Learning in restricted Policy Spaces,"Robby Goetschalckx, Jan Ramon","We discuss the problem of policy learning in a Markov Decision Process where only a restricted, limited subset of the full policy space can be used.
In this way useful background knowledge can be incoorporated to reduce the search space. This is useful when we know the optimal policy will belong to a specific subset of
the full policy space, or when only a limited part of the policy space is useable in practice. We suggest and discuss a number of different approaches based onexisting work in
policy search methods. None of these methods can be easily adapted to handle the setting of a restricted policy space. We point out a number of difficulties which arise and
assumptions which have to be made for some approaches to work.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-304.pdf,"Subjects:  12.1 Reinforcement Learning;
15.2 Constraint Satisfaction"
304,2007,Student Abstracts,Two Approaches for Building an Unsupervised Dependency Parser and their Other Applications,"Jagadeesh Gorla, Amit Goyal, Rajeev Sangal","Much work has been done on building a parser for natural languages, but most of this work has concentrated on supervised parsing. Unsupervised parsing is a less explored area, and unsupervised dependency parser has hardly been tried. In this paper we present two approaches for building an unsupervised dependency parser. One approach is based on learning dependency relations and the other on learning subtrees. We also propose some other applications of these approaches.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-305.pdf,"Subjects:  13. Natural Language Processing;
12. Machine Learning and Discovery"
305,2007,Student Abstracts,ASKNet: Automated Semantic Knowledge Network,Brian Harrington,"The ASKNet project is an attempt to automatically generate semantic knowledge networks from natural language text. NLP tools such as parsers and semantic analysers are used to turn input sentences into fragments of semantic network, and these network fragments are combined using spreading activation algorithms that utilise both lexical and semantic information. The ultimate goal of the project is to create a semantic resource on a scale that has never before been possible.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-306.pdf,"Subjects:  13. Natural Language Processing;
10. Knowledge Acquisition"
306,2007,Student Abstracts,TeamTalk: A Platform for Multi-human-robot Dialog Research in Coherent Real and Virtual Spaces,"Thomas K. Harris, Alexander I. Rudnicky","Performing experiments with human-robot interfaces often requires the allocation of expensive and complex hardware and large physical spaces. Those costs constrain development and research to the currently affordable resources, and they retard the testing-and-redevelopment cycle. In order to explore research free  the mundane allocation constraints, and to speed-up our platform development cycle, we have developed a platform for research of multi-human-robot spoken dialog in coherent real and virtual spaces. We describe the system, and speculate on how it will further research in this domain.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-307.pdf,"Subjects:  18. Speech Understanding;
17. Robotics"
307,2007,Student Abstracts,Reputation in the Venture Games,"Philip Hendrix, Barbara J. Grosz","In many settings agents need to identify competent partners to assist them in accomplishing tasks.  Direct experience may not provide sufficient data to learn the competence of other agents.  Reputation---a community-based assessment of agent competence---can augment direct experience, but is prone to error.  This work provides a systematic study of how the utility of reputation varies by group size, group competency, competency distribution, and reputation error.  It provides a systematic study of how the utility of reputation varies by group size, group competency, and reputation uses.  Results demonstrate that the relative usefulness of direct experience and reputation depends on the particular multi-agent setting.  They confirm that the utility received from reputation increases as group size increases.  Interestingly, results include a ``pigeonholing phenomenon"" in which reputation wrongly identifies some agents as having sub-par competence, based on early random sequences, even when agents are generally highly capable. This effect can be countered by introducing systematic positive bias to the system.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-308.pdf,"Subjects:  7.1 Multi-Agent Systems;
15.8 Simulation"
308,2007,Student Abstracts,"Evolutionary Rhythm Composition 
Evolutionary Rhythm Composition with Trajectory-based Fitness Evaluation","John Huddleston, Dr. Jianna Zhang",Evaluating creativity in musical genetic algorithms (GAs) requires a balance between objective and subjective fitness measures.  This research investigates the use of user-defined compositional rules for composition of rhythmic pieces of any length.  Complete pieces of music can be created according to personal definitions of creativity without direct human involvement in the evolutionary process.,https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-309.pdf,"Subjects:  1.1 Art And Music;
6.2 Multimedia"
309,2007,Student Abstracts,Identifying Protein Interaction Abstracts with Contextual Bag of Words,"Hsi-Chuan Hung, Richard Tzong-Han Tsai, Wen-Lian Hsu","In this paper, we focus on the identification of biomedical abstracts related to protein-protein interactions. We propose a novel feature representation, contextual-bag-of-words, to exploit named entity information. Our method outperforms well-known methods that use named entity information as additional features. Furthermore, we have improved the performance by extracting reliable and informative instances from unlabeled and likely-positive data to provide additional training data.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-310.pdf,"Subjects:  1.10 Information Retrieval;
13. Natural Language Processing"
310,2007,Student Abstracts,Modeling User Perception of Interaction Opportunities in Collaborative Human-Computer Settings,"Ece Kamar, Barbara J. Grosz, David Sarne","In this paper, we propose a new model for interruption management that aims to help to maximize the efficiency of collaboration between the agent and the person by having a better estimation of interruption outcome. We investigate the factors that affect the way people perceive the effectiveness of interruptions initiated by a collaborative computer agent in task-oriented settings. Our experimental design includes an innovative and abstract collaborative setting, based on the proven Colored Trails (CT) infrastructure.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-311.pdf,"Subjects:  6. Computer-Human Interaction;
7.1 Multi-Agent Systems"
311,2007,Student Abstracts,Towards an Adaptive Approach for Distributed Resource Allocation in a Multi-agent System for Solving Dynamic Vehicle Routing Problems,"Igor Kiselev, Andrey Glaschenko, Alexander Chevelev, Petr Skobelev","The existing problem of continuous planning in transportation logistics requires the solving of dynamic Vehicle Routing Problems (dynamic VRPs) which is an NP-complete optimization problem. The task of continuous planning assumes the existence of individual commit times for orders to be released for execution with specific commitment strategies and is similar to the problem of maintaining a guaranteed response time in real-time systems that, in a dynamic environment, applies additional restrictions on planning algorithms. This paper describes the developed multi-agent platform for solving the dynamic multi-vehicle pickup and delivery problem with soft time windows dynamic m-PDPSTW) that supports goal-driven behavior of autonomous agents with a multi-objective decision-making model. Further research on the design of adaptive mechanisms for run-time feedback-directed adjustment of scheduling algorithms through learning and experience of applied decision options is outlined. An agent-based near real-time knowledge management support engine for solving time-critical data-mining problems in complex dynamic environments, currently being developed to work concurrently with the scheduling component, is based on the proposed approach to adaptive continuous unsupervised learning and a knowledge-based competitive multi-agent system for implementing it.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-312.pdf,"Subjects:  7.1 Multi-Agent Systems;
12. Machine Learning and Discovery"
312,2007,Student Abstracts,On Possible Applications of Rough Mereology to Handling Granularity in Ontological Knowledge,"Pavel Klinov, Lawrence Mazlack","The paper proposes an approach to approximating hierarchical relationships between imprecise concepts in knowledge representation systems. The approach is based on Rough Mereology and is complemented by Interval Analysis to formally capture the imprecision caused by the granularity of knowledge. Interval rough inclusion functions for membership and subsumption are defined. It is demonstrated that the subsumption function can be used to compute the ""is-a"" relationships by measuring the degree of containment of one approximate concept into another.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-313.pdf,"Subjects:  11. Knowledge Representation;
11.2 Ontologies"
313,2007,Student Abstracts,Fuzzy Set Theory-Based Belief Processing for Natural Language Texts,"Ralf Krestel, Rene Witte, Sabine Bergler","The growing number of publicly available information sources makes it
impossible for individuals to keep track of all the various opinions
on one topic. The goal of our artificial believer
system we
present in this paper is to extract and analyze opinionated
statements from newspaper articles.
Beliefs are modeled with a fuzzy-theoretic approach applied after
NLP-based information extraction. A fuzzy believer models a human
agent, deciding what statements to believe or reject based on
different, configurable strategies.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-314.pdf,"Subjects:  13. Natural Language Processing;
15.1 Belief Revision"
314,2007,Student Abstracts,Knowledge-Driven Learning and Discovery,"Benjamin Lambert, Scott E. Fahlman","The goal of our current research is machine learning with the help and guidance of a knowledge base (KB).   Rather than learning numerical models, our approach generates explicit symbolic hypotheses.  These hypotheses are subject to the constraints of the KB and are easily human-readable and verifiable.  Toward this end, we have implemented algorithms that hypothesize new relations and new types of entities in a KB by examining structural regularities in the KB that represent implicit knowledge.  We evaluate these algorithms on a publications KB and a zoology KB.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-315.pdf,"Subjects:  12. Machine Learning and Discovery;
11. Knowledge Representation"
315,2007,Student Abstracts,Reinforcement using Supervised Learning for Policy Generalization,Julien Laumonier,"Applying reinforcement learning in large Markov Decision Process (MDP) is an important issue for solving very large problems. Since the exact resolution is often intractable, many approaches have been proposed to approximate the value function or to approximate directly the policy by gradient methods. Such approaches provide a policy on all the state space whereas classical reinforcement learning algorithms do not guarantee in finite time the exploration of all states. However, these approaches often need a manual definition of the parameter for approximation functions. Recently, Lagoudakis introduced the problem of approximating policy by a policy iteration algorithm using a mix between a rollout algorithm and Support Vector Machines (SVM). The work presented in this paper is an extension of Lagoudakis' idea. We propose a new and more general formalism which combines reinforcement learning and supervised learning formalism. To learn an approximation of an optimal policy, we propose some combinations of various algorithms (reinforcement and supervised learning). Contrary to Lagoudakis' approach, we are not restricted to an approximated policy iteration but we can use any reinforcement learning algorithms. One of the arguments for this approach is that in reinforcement learning, the most important result to obtain is the optimal policy, i.e a total order of actions for each state. That is why, we do not focus on the value of a state but on direct policy approximation.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-316.pdf,"Subjects:  12. Machine Learning and Discovery;
12.1 Reinforcement Learning"
316,2007,Student Abstracts,Aggregating User-Centered Rankings to Improve Web Search,"Lin Li, Zhenglu Yang,  Masaru Kitsuregawa","This paper is to investigate rank aggregation based on multiple
user-centered measures in the context of the web search. We
introduce a set of techniques to combine ranking lists in order of user interests termed as a user profile. Moreover, based on the click-history data, a kind of taxonomic hierarchy automatically models the user profile which can include a variety of attributes of user interests. We mainly focus on the topics a user is interested in and the degrees of user interests in these topics. The primary goal of our work is to form a broadly acceptable ranking list, rather than that determined by an individual ranking measure. Experiment results on a real click-history data set show the effectiveness of our aggregation techniques to improve the web search.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-317.pdf,"Subjects:  1.10 Information Retrieval;
Please choose a second document classification"
317,2007,Student Abstracts,Recommending Travel Packages Upon Distributed Knowledge,"Fabiana Lorenzi, Ana L. C. Bazzan, Mara Abel","This paper presents a multiagent recommender approach where the agents work in a distributed and cooperative way, sharing and negotiating knowledge with the global objective of recommending the best travel package to the user. This approach explores the use of truth maintenance system in order to keep the integrity of the agent knowledge-bases.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-318.pdf,"Subjects:  7.1 Multi-Agent Systems;
15.1 Belief Revision"
318,2007,Student Abstracts,BlogVox: Learning Sentiment Classifiers,"Justin Martineau, Akshay Java, Pranam Kolari, Tim Finin, Anupam Joshi, James Mayfield","Performing sentiment analysis upon a topic, specified by key words, without prior knowledge about the key words is a difficult task. With the growth of the blogosphere researchers, corporations, and politicians, among others are very interested in applying sentiment detection to blogs. To accommodate the demands from myriad users, with similarly diverse desires, a sentiment analysis engine for blogs must discover domain specific features relevant to queries in order to accurately assess the sentiment of blogs. Using meta-learning upon the results of web searches, as BlogVox does, can accomplish this goal",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-319.pdf,"Subjects:  12. Machine Learning and Discovery;
1.10 Information Retrieval"
319,2007,Student Abstracts,Impromptu Teams of Heterogeneous Mobile Robots,"Ross Mead, Jerry B. Weinberg","As robots become more involved in assisting us in large and hazardous operations, such as search and rescue, we can anticipate that diverse robots will come together with the need to coordinate their efforts. These robots will come from different organizations, creating a heterogeneous team, varying in shape, size, and functionality. How can diverse robots forming such an impromptu team collaborate to accomplish a joint objective? If they are to organize and work together, methods must be developed that allow them to share knowledge in a meaningful way. We propose an ontology-based symbolic communication protocol to provide a shared understanding of physical concepts between units. Coordination is then accomplished through a negotiation of tasks to complete individual and joint goals.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-320.pdf,"Subjects:  17. Robotics;
11.2 Ontologies"
320,2007,Student Abstracts,Time-Delay Neural Networks and Independent Component Analysis for EEG-Based Prediction of Epileptic Seizures Propagation,"Piotr W Mirowski, Deepak Madhavan, Yann LeCun","This research focuses on the development of a machine learning technique based on Time-Delay Neural Networks (TDNN) and Independent Component Analysis (ICA), to analyze EEG signal dynamics related to the initiation and propagation of epileptic seizures. We aim at designing a generative model to simulate EEG time-series after alteration of specific localized channels (electrodes) in order to explore the effects of brain surgery ex-vivo.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-321.pdf,"Subjects:  1.5 Diagnosis;
14. Neural Networks"
321,2007,Student Abstracts,Using Iterated Best-Response to Find Bayes-Nash Equilibrium in Auctions,"Victor Naroditskiy, Amy Greenwald",Bayes-Nash equilibria (BNE) have been derived analytically only for the simplest auction settings. Such settings include single-item first- and second-price auctions with continuous distributions of bidders' values. Very little research has been devoted to auctions with discrete bids and values. We take some important first steps in this direction by computationally investigating when an iterated best-response procedure might lead to a BNE.,https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-322.pdf,"Subjects:  1.8 Game Playing;
7.1 Multi-Agent Systems"
322,2007,Student Abstracts,The Marchitecture: A Cognitive Architecture for a Robot Baby,"Marc Pickett, Tim Oates","The Marchitecture is a cognitive architecture for autonomous development of representations.  The goals of The Marchitecture are
domain independence, operating in the absence of knowledge
engineering, learning an ontology of parameterized relational
concepts, and elegance of design.  To this end, The Marchitecture
integrates classification, parsing, reasoning, and explanation.  The Marchitecture assumes an ample amount of raw data to develop its representations, and it is therefore appropriate for long lived
agents.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-323.pdf,"Subjects:  2. Architectures;
12. Machine Learning and Discovery"
323,2007,Student Abstracts,Integrative Construction and Analysis of Condition-specific Biological Networks,"Sushmita Roy, Terran Lane, Margaret Werner-Washburne","To understand how a cell responds and adapts itself to changing environmental conditions, we must build context-specific networks — networks of genes, proteins and metabolites that are re-wired according to particular environmental conditions. Existing machine learning algorithms for biological networks either infer statistical correlation with no physical interpretation of the edges, or infer physical attributes of the network assuming the structure to be fixed. Moreover, these algorithms do not account for condition-specific properties of the networks.
We propose a multi-stage, data-driven approach, which combines classification, probabilistic network structure and parameter learning, and graph-theoretic algorithms to construct high-resolution, condition-specific networks. We use classification to predict parts of the physical network that are absent in the physical interaction databases. The physical network is incorporated as prior knowledge in the network structure learning algorithms to construct biologically plausible networks. The structure learning algorithms construct coarse-grained networks from condition-specific measurements of the genes, proteins and metabolites. This is followed by hidden variable inference and structure refinement of the coarse condition-specific network by annotating the edges with values of physical attributes, such as directionality and type of interaction. The high resolution, condition-specific networks are then compared using graph-theoretic concepts to reveal the range of network-level behavior under different environmental conditions.
In this abstract, we show results from the preliminary stages of our work, (a) classification-based prediction of physical protein interactions and (b) description of a novel pathwise score that can be used to evaluate how well structure learning algorithms capture long range dependencies.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-324.pdf,"Subjects:  12. Machine Learning and Discovery;
12.2 Scientific Discovery"
324,2007,Student Abstracts,Extracting Student Models for Intelligent Tutoring Systems,"John Stamper, Tiffany Barnes, Marvin Croy","Intelligent Tutoring Systems that adapt to an individual student’s needs have been shown to be effective, showing significant improvement in achievement over non-adaptive instruction. The most successful of these systems require the construction of complex cognitive models that are applicable only to a specific tutorial in a specific field, requiring the time of experts to create and test these models on students. In order to achieve the benefits that ITSs provide, we must find a way to simplify their creation.  Therefore, we are creating a framework to automate the generation of ITS student models. The goal is to provide a simple way to allow developers of computer-based training to add adaptive capabilities with minimal work while still maintaining the effectiveness of a true Intelligent Tutoring System.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-325.pdf,"Subjects:  1.3 Computer-Aided Education;
4. Cognitive Modeling"
325,2007,Student Abstracts,Unscented Message Passing for Arbitrary Continuous Variables in Bayesian Networks,"Wei Sun, Kuo-Chu Chang","Since Bayesian network (BN) was introduced in the field of artificial intelligence in 1980s, a number of inference algorithms have been developed for probabilistic reasoning. However, when continuous variables are present in Bayesian networks, their dependence relationships could be nonlinear and their probability distributions could be arbitrary. So far no efficient inference algorithm could deal with this case except Monte Carlo simulation methods such as Likelihood Weighting. But with unlikely evidence, simulation methods could be very slow to converge. In this paper, we propse an efficient approximate inference algorithm called Unscented Message Passing (UMP-BN) for Bayesian networks with arbitrary continuous variables. UMP-BN combines unscented transformation --- a deterministic sampling method, and Pearl's message passing algorithm to provide the estimates of the first two moments of the posterior distributions. We test this algorithm with several networks including the ones with nonlinear and/or non-Gaussian variables. The numerical experiments show that UMP-BN converges very fast and produces promising results.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-326.pdf,"Subjects:  3.4 Probabilistic Reasoning;
11. Knowledge Representation"
326,2007,Student Abstracts,An Investigation into Computational Recognition of Children’s Jokes,"Julia M. Taylor, Lawrence J. Mazlack","This paper presents an overview of a model for computational recognition of two-sentence-long jokes that are based on phonological similarity of words.  The model takes into account orthographic, phonological and semantic representation of words.  The joke recognition is based on knowledge that is provided by an ontology.  The ontology is created by using entries from a children’s dictionary.  Each noun in the dictionary is an instance of a concept in a concept hierarchy.  An instance belongs to each concept to a certain degree.  The concept hierarchy is modeled from WordNet.  Semantic relationships between concepts are added from a collection of children’s texts and definitions in a children’s dictionary.  Any two-sentence-long text is considered a joke if it contains two scripts that both overlap and oppose; and if there is a pair of similar sounding words (w1, w2), in which w1 is an instance of a concept of one script, and w2 is an instance of a concept of another.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-327.pdf,"Subjects:  13. Natural Language Processing;
11.2 Ontologies"
327,2007,Student Abstracts,Representation Transfer via Elaboration,"Matthew E. Taylor, Peter Stone","A key component of any reinforcement learning (RL)  algorithm is the underlying representation used by the agent for learning (e.g. the parameterization of its function approximator). Transfer learning tasks typically look at speeding up a target task after learning in a source task. This paper considers a different, but related, question: is it possible, and desirable, for agents to transfer from a source representation to a target representation? Elaboration, presented below, is a representation transfer (RT) algorithm that may allow an agent to learn faster than learning with a single representation.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-328.pdf,"Subjects:  12.1 Reinforcement Learning;
Please choose a second document classification"
328,2007,Student Abstracts,Situated Conversational Agents,William K. Thompson,"A Situated Conversational Agent (SCA) is an agent that engages in dialog about the context within which it is embedded. Situated dialog is characterized by its deep connection to the embedding context, and the precise cross-timing of linguistic and non-linguistic actions. This paper describes initial research into the construction of an SCA that engages in dialog about collaborative physical tasks, in which agents engage in dialog with the joint goal of manipulating the physical context in some manner. Constructing an SCA that can interact naturally in such tasks requires an agent with the ability to interleave planning, action, and observation while operating in a partially observable environment. Consequently, I propose to model an SCA as a Partially Observable Markov Decision Process (POMDP).",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-329.pdf,"Subjects:  6. Computer-Human Interaction;
6.1 Life-Like Characters"
329,2007,Student Abstracts,Scaling Up: Solving POMDPs through Value Based Clustering,"Yan Virin, Guy Shani, Shimony Eyal, Brafman Ronen","We present here a point-based value iteration algorithm for solving
POMDPs, that orders belief state backups smartly based on a
clustering of the underlying MDP states. We show our SCVI algorithm
to converge faster than state of the art point-based algorithms.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-330.pdf,"Subjects:  3. Automated Reasoning;
3.4 Probabilistic Reasoning"
330,2007,Student Abstracts,Learn to Compress and Restore Sequential Data,"Yi Wang, Jianhua Feng, Shixia Liu","Data compression methods can be classified into two
groups: lossless and lossy. Usually the latter achieves a
higher compression ratio than the former. However, to develop
a lossy compression method, we have to know, for a
given type of data, what information can be discarded without
significant degradation of the data quality.
A usual way to obtain such knowledge is by experiments.
For example, from user statistics, we know that human eyes
are insensitive to some frequency channels of the light signal.
Thus we can compress image data by decomposing
them into various frequency channels using a DCT transformation,
and neglect the coefficients of the channels that
are insensitive to human eyes. However, it is complex and
expensive for human analysts to conduct and study so many
experiments.
Alternatively, we propose to learn the knowledge automatically
by using machine learning techniques. Under the
framework of Bayesian learning, general prior knowledge is
expressed by designing the statistical models, and the refined
posterior knowledge can be learned automatically from data
to be compressed. More particularly, we consider the compression
of some input data as learning a statistical model
from the data, and consider the restoration of data as sampling
from the learned model. Therefore, only the estimated
model parameters are saved as the compressed version.
A key to this idea is to design a statistical model that can
accurately describe the data (so it is possible to recover the
data precisely) and is defined by a compact set of parameters
(so to achieve high compression ratio).
For a general application of compressing sequential data,
we designed the Variable-length Hidden Markov Model
(VLHMM), whose learning algorithm automatically learns
a minimal set of parameters (by optimizing a Minimum-
Entropy criterion) that accurately models the sequential data
(by optimizing a Maximum-Likelihood criterion). The selfadaption
ability of the learning algorithm makes VLHMM able to accurately model highly varied sequential data.
Moreover, as a hidden Markovian model, VLHMM is generally
applicable to all kinds of sequences, whatever discrete/
continuous and univariate/multivariate.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-331.pdf,"Subjects:  12. Machine Learning and Discovery;
1.10 Information Retrieval"
331,2007,Student Abstracts,Interest-Matching Comparisons using CP-nets,"Andrew W. Wicker, Jon Doyle","The formation of internet-based social networks has revived research on traditional social network models as well as interest-matching, or match-making, systems. In order to automate or augment the process of interest-matching, we describe a method for the comparison of preference orderings represented by CP-nets, which allows one to determine a shared interest level between agents. Empirical results suggest that this distance measure for preference orderings agrees with the intuitive assessment of shared interest levels.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-332.pdf,"Subjects:  4. Cognitive Modeling;
7.1 Multi-Agent Systems"
332,2007,Student Abstracts,Counting Models Using Extension Rules,"Minghao Yin, Hai Lin, Jigui Sun","Resolution principle is the rule of inference at the basis of most procedures for both satisfiability testing and model counting. This paper is aimed to challenge this traditional idea by using the inverse of resolution and using the inclusion-exclusion principle to circumvent the problem of space complexity. We present exact and approximate algorithms for model counting and weighted model counting, which are all sound and complete. We showed that extension-based method outperformed resolution-based method in some cases and analyze the reason. Thus it is potentially a complementary method to resolution-based method",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-333.pdf,"Subjects:  15. Problem Solving;
15.9 Theorem Proving"
333,2007,Student Abstracts,User Model and Utility Based Power Management,"Chih-Han Yu, Shie Mannor, Georgios Theocharous, Avi Pfeffer","Advances in hardware and wireless technology have made mobile
devices ubiquitous in our daily life. Consequently, extending the battery life has become a major challenge needed to improve the usability of laptops. The purpose of a power management (PM) policy is to prolong a laptop's battery life while not affecting the system performance as perceived by the user. The optimal strategy is to turn off certain components when their services are not going to be needed and turning them back on just before they are needed. This uncertainty about the future is the core challenge in PM.

The main contribution of our work is to demonstrate the importance of incorporating a user model into adaptive PM. We use a Dynamic Bayesian Network (DBN) to capture the relationship between the latent state of the user and his/her observable activities. The DBN model is learned from the user's data and is therefore adapted to individual user. Besides, the future idle duration probability density functions (PDF) differ significantly when conditioned on different latent states. Based on the PDF associated with each individual latent state, our estimated future idle duration is more accurate. This information allows us to estimate the expected power savings and the expected next service requested time. By trading-off these two factors, the devised PM strategy is able to adjust to different level of aggressiveness. Furthermore, the PM decisions are also calibrated according to the latent states of different users.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-334.pdf,"Subjects:  1.6.1 Automated Device Modeling;
3.4 Probabilistic Reasoning"
334,2007,Student Abstracts,Measuring the Uncertainty of Differences for Contrasting Groups,"Jilian Zhang, Shichao Zhang, Xiaofeng Zhu, Xindong Wu,  Chengqi Zhang","In this paper, we propose an empirical likelihood (EL) based strategy for building confidence intervals for differences between two contrasting groups. The proposed method can deal with the situations when we know little prior knowledge about the two groups, which are referred to as non-parametric situations. We experimentally evaluate our method on UCI datasets and observe that proposed EL based method outperforms other methods.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-335.pdf,"Subjects:  12. Machine Learning and Discovery;
12. Machine Learning and Discovery"
335,2007,Student Abstracts,Cost-Sensitive Imputing Missing Values with Ordering,"Xiaofeng Zhu, Shichao Zhang, Jilian Zhang, Chengqi Zhang","Various approaches for dealing with missing data have been developed so far. In this paper, two strategies are proposed for cost-sensitive iterative imputing missing values with optimal ordering. Experimental results demonstrate that proposed strategies outperform the existing methods in terms of imputation cost and accuracy.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-336.pdf,"Subjects:  12. Machine Learning and Discovery;
12. Machine Learning and Discovery"
336,2007,AAAI / SIGART Doctoral Consortium,Continuous State POMDPs for Object Manipulation Tasks,Emma Brunskill,"My research focus is on using continuous state partially
observable Markov decision processes (POMDPs) to
perform object manipulation tasks using a robotic arm.
During object manipulation, object dynamics can be extremely
complex, non-linear and challenging to specify.
To avoid modeling the full complexity of possible dynamics,
I instead use a model which switches between a
discrete number of simple dynamics models. By learning
these models and extending Porta’s continuous state
POMDP framework (Porta et al. 2006) to incorporate
this switching dynamics model, we hope to handle tasks
that involve absolute and relative dynamics within a single
framework. This dynamics model may be applicable
not only to object manipulation tasks, but also to a
number of other problems, such as robot navigation. By
using an explicit model of uncertainty, I hope to create
solutions to object manipulation tasks that more robustly
handle the noisy sensory information received by
physical robots.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-337.pdf,"Subjects:  1.11 Planning;
3.4 Probabilistic Reasoning"
337,2007,AAAI / SIGART Doctoral Consortium,Approximate Inference in Probabilistic Graphical Models with Determinism,Vibhav Giridhar Gogate,"In the proposed thesis, we study a special class of belief networks which contain both probabilistic and deterministic information. Deterministic information occurs as zero probabilities in the belief network. A majority of the work in the belief network community (see for example papers in conferences like UAI, AAAI, IJCAI and NIPS) addresses probabilistic inference tasks under the assumption that the underlying joint distribution represented by the belief network is strictly positive i.e. devoid of any determinism. The positivity assumption is problematic because (a) modeling many real-world problems such as genetic linkage analysis requires that the inference method reason with both probabilistic and deterministic information and (b) inference is harder in presence of determinism or extreme probabilities. The purpose of the proposed thesis is to study both the representational and algorithmic issues involved in modeling deterministic information along with the usual probabilistic information in a belief network.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-338.pdf,"Subjects:  3. Automated Reasoning;
3.4 Probabilistic Reasoning"
338,2007,AAAI / SIGART Doctoral Consortium,Handling Non-Sentential Utterances in a Continuous Understanding Framework,Carlos Gomez Gallo,"The goal of my research is to understand speech input in a continuous manner by treating the input stream as fragmental utterances. This allows us to use various approaches to predict what comes downstream. Possible interpretations are trimmed by such predictions which in turn also allow us to complete information not readily available in the fragmental utterance. Semantic frames can encode all possible arguments for domain actions. As utterances are processed continuously, appropriate frames can be activated so that fragment interpretations can fill, correct or extend frames under consideration. In turn, feedback can be provided to the parser as the frames are manipulated possibly based on the completeness of the semantic frame construction.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-339.pdf,"Subjects:  13. Natural Language Processing;
13.1 Discourse"
339,2007,AAAI / SIGART Doctoral Consortium,ASKNet: Automatically Generating Semantic Knowledge Networks,Brian Harrington,"The ASKNet project uses a combination of NLP tools and spreading activation to transform natural language text into semantic knowledge networks. Network fragments are generated from input sentences using a parser and semantic analyser, then these fragments are combined using spreading activation based algorithms.

The ultimate goal of the project is to create a semantic resource on a scale that has never before been possible. We have already managed to create networks more than twice as large as any comparable resource(1.5 million nodes, 3.5 million edges) in less than 3 days. This report provides a summary of the project and its current state of development.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-340.pdf,"Subjects:  13. Natural Language Processing;
10. Knowledge Acquisition"
340,2007,AAAI / SIGART Doctoral Consortium,"A Framework for Modeling Influence, Opinions and Structure in Social Media",Akshay  Java,"The Blogosphere provides an interesting opportunity to study social 
interactions. Blogs provide a channel to express opinions, facts and thoughts. Through these pieces of information, also known as memes, bloggers influence each other and engage in conversations that ultimately lead to exchange of ideas and spread of information. We aim to characterize and model the Blogosphere to study the spread of influence, opinion formation and social interaction. Further, we propose a simple generative process that models creation and evolution of blogs. This model is an extension of existing preferential attachment and random surfer model. Using available samples of the Blogosphre (represented as a blog graph) and the proposed generative model, we hypothesize, compare and 
validate different approaches to modeling influence and opinion formation in social media.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-341.pdf,"Subjects:  1.10 Information Retrieval;
1. Applications"
341,2007,AAAI / SIGART Doctoral Consortium,Empirical Game-Theoretic Methods for Strategy Design and Analysis in Complex Games,Christopher Kiekintveld,"The goal of my thesis work is to develop game analysis techniques capable of informing strategy design in large, complex games. Complex games often defy exact solution using the conventional tools of game theory because of their size and uncertainty about the possible outcomes. Empirical game theory offers a principled approach to analysis of such games, but there are many open questions about the best methods for exploring and analyzing empirical games.  I contribute to the growing body of evidence that empirical game theory can offer useful strategic guidance in very complex multi-agent domains through empirical game-theoretic analyses of two specific games, TAC SCM and a four-player variant of chess. I propose an experimental framework for evaluating candidate methods for empirical game analysis, and apply this framework to conduct two experiments. In the first, I consider applying solution concepts to noisy estimates of games. I hypothesize that solution concepts that model noise and thus produce broader predictions of the outcome will yield relatively robust solutions, even if the exact structure of the underlying noise is unknown. In the second experiment I explore the ability of serveral candidate algorithms to exploit independence structure to direct exploration of a game to more relevant regions of the outcome space, enabling more data-efficient analysis.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-342.pdf,"Subjects:  7.1 Multi-Agent Systems;
1.8 Game Playing"
342,2007,AAAI / SIGART Doctoral Consortium,Using Spatial Language in Multi-Modal Knowledge Capture,Kate Lockwood,"The ability to understand and communicate spatial relationships is central to many human-level reasoning tasks.  People often describe spatial relationships using prepositions (i.e., in, on, under).  Being able to use and interpret spatial prepositions could help create interactive systems for many tasks, including knowledge capture.  Here I describe my thesis work modeling the learning and use of spatial prepositions and applying this model to the task of knowledge capture.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-343.pdf,"Subjects:  4. Cognitive Modeling;
3.2 Geometric Or Spatial Reasoning"
343,2007,AAAI / SIGART Doctoral Consortium,Responding to Student Affect and Efficacy through Empathetic Companion Agents in Interactive Learning Environments,Scott W. McQuiggan,"Because many students experience frustration during learning, it is important to develop affective strategies to support students’ coping with frustration in interactive learning environments.  First, we must devise affect recognition models to detect student affect.  Second, we need to determine when to intervene; these conditions are likely to be different for each student.  To determine how much frustration a student can persist through, we should utilize models of student self-efficacy to predict a student’s frustration threshold.  Third, we should devise techniques for responding empathetically before the student reaches her threshold of frustration.  We propose an approach to support students’ coping with frustration in intelligent tutoring systems that utilizes induced models of affect, self-efficacy and empathetic behavior to effectively reason about precisely when and how to intervene in frustration-ridden learning situations.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-344.pdf,"Subjects:  1.3 Computer-Aided Education;
6. Computer-Human Interaction"
344,2007,AAAI / SIGART Doctoral Consortium,The Übercruncher: Concept Formation by Analogy Discovery,Marc Pickett,"I present a novel approach to unsupervised concept formation based on analogy discovery, and guided by the principle of minimum description length.  Preliminary results include autonomous creation of conceptual structures using a special case of analogy discovery, and a demonstration of a complete but inefficient batch version of the algorithm.  I describe some shortcomings of the preliminary results, mostly concerning efficiency and local optima, and discuss how to address them.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-345.pdf,"Subjects:  12. Machine Learning and Discovery;
11.2 Ontologies"
345,2007,AAAI / SIGART Doctoral Consortium,Harnessing Algorithm Bias in Classical Planning,Mark Roberts,"A planning system's performance is biased due to many factors related to its design. For example, the representation, decision points, search control, memory usage, heuristic guidance, and stopping criteria all can have implications for performance. Problem instance characteristics also impact system performance.  The interaction of the design choices with the problem instance makes it difficult to select the most efficient system from the array of choices.  It seems natural to apply learning to the algorithm selection problem of allocating computational resources among a portfolio of planners that may have complementing (or competing) search technologies.  Such selection is called the portfolio strategy.

Our working thesis is that we can study a portfolio of planning systems for clues about why one algorithm is favored over another.  A secondary thesis is that we can uncover algorithmic and problem structure dependencies by examining algorithm performance on specific instances.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-346.pdf,"Subjects:  1.11 Planning;
Please choose a second document classification"
346,2007,AAAI / SIGART Doctoral Consortium,Reacting to Agreement and Error in Spoken Dialogue Systems Using Degrees of Groundedness,Antonio Roque,"Computational models of grounding are extended to include representations of degrees of groundedness.  These representations are then used for decision-making in dialogue management for spoken dialogue systems.  Several domains will be explored with this model, and an implementation will be tested and evaluated.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-347.pdf,"Subjects:  13. Natural Language Processing;
6. Computer-Human Interaction"
347,2007,AAAI / SIGART Doctoral Consortium,A Framework For Ontology-Based Service Selection In Dynamic Environments,Murat Sensoy,"Previous approaches to service selection are mainly based on capturing and exchanging the ratings of consumers to providers.  However, ratings reflect tastes of the raters. Therefore, service selection using ratings may mislead the consumers having a taste different than that of the raters. We propose to use experiences instead of the ratings. Experiences are the representation of what is requested by a consumer and what is received at the end. Unlike ratings, experiences do not reflect the opinion of the others, but the actual story between consumers and providers concerning a service demand. Using experiences, the consumer models the services of a provider for a specific service demand and selects the provider that is expected to satisfy the consumer the most. Our simulations show that proposed approach significantly increases the overall satisfaction of the service consumers.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-348.pdf,"Subjects:  7.1 Multi-Agent Systems;
1. Applications"
348,2007,AAAI / SIGART Doctoral Consortium,Flexible Provisioning of Service Workflows,Sebastian Stein,"The aim of my thesis is to apply agent-oriented techniques to the dynamic execution of service workflows in large distributed systems (such as the Web or computational Grids). In particular, my work addresses the fact that service providers in such systems are increasingly likely to be autonomous agents that do not behave in a deterministic manner and may therefore take uncertain amounts of time to complete their services or fail completely. To deal with this unreliability, I focus on the provisioning of workflows, during which a consumer agent decides what providers to rely on, how to invoke them, and whether to carry out advance negotiations or even rely on multiple, redundant providers for particularly critical tasks.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-349.pdf,"Subjects:  7.1 Multi-Agent Systems;
7.2 Software Agents"
349,2007,AAAI / SIGART Doctoral Consortium,Autonomous Inter-Task Transfer in Reinforcement Learning Domains,Matthew E. Taylor,"In reinforcement learning (RL) problems, agents take sequential actions with the goal of maximizing a reward signal, which may be time-delayed. In recent years RL tasks have been gaining in popularity as learning methods able to handle complex problems. RL algorithms, unlike many machine learning approaches, do not require correctly labeled training examples and thus may address a wide range of difficult and interesting problems. If RL agents begin their learning tabula rasa, mastering tasks may be slow or infeasible. A significant amount of current research in RL thus focuses on improving the speed of learning by exploiting domain expertise with varying degrees of autonomy.

My thesis will examine one such general method for speeding up learning: transfer learning. In transfer learning problems, a source task can be used to improve performance on, or speed up learning in, a target task. An agent may thus leverage experience from an earlier task to learn the current task. A common formulation of this problem presents an agent with a pair of tasks and the agent is told explicitly to train on one before the other. Alternately, in the spirit of multitask learning or lifelong learning, an agent could consult a library of past tasks that it has mastered and transfer knowledge from one or more of them to speed up the current task.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-350.pdf,"Subjects:  12.1 Reinforcement Learning;
12. Machine Learning and Discovery"
350,2007,AAAI / SIGART Doctoral Consortium,Predictive Exploration for Autonomous Science,David R. Thompson,"Often remote investigations use autonomous agents to observe an environment on behalf of absent scientists.  Predictive exploration improves these systems' efficiency with onboard data analysis.  Agents can learn the structure of the environment and predict future observations, reducing the remote exploration problem to one of experimental design.  In our formulation information gain over a map guides exploration decisions, while a similar criterion suggests the most informative data products for downlink.  Ongoing work will develop appropriate models for surface exploration by planetary robots.  Experiments will demonstrate these algorithms for autonomous geology on kilometer scales.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-351.pdf,"Subjects:  12.2 Scientific Discovery;
17. Robotics"
351,2007,AAAI / SIGART Doctoral Consortium,Spatial Reference Resolution for an Embodied Dialogue Agent,Timothy Weale,"In this work, I propose a system for reference resolution that focuses on descriptions that utilize spatial information.  This work is based on linguistic theory and is supported by corpus evidence.  The resulting agent will be designed to function as a participant in a human-computer, two-bodied, box-rearranging task, which will be implemented in a virtual environment.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-352.pdf,"Subjects:  13.1 Discourse;
3.2 Geometric Or Spatial Reasoning"
352,2007,AAAI / SIGART Doctoral Consortium,An Incentive Mechanism for Promoting Honesty in E-Marketplaces,Jie Zhang,"Our research is within the subfield of modeling trust and reputation in multi-agent systems for electronic commerce. More specifically, we are interested in addressing two problems that may arise in trust and reputation models where buying agents elicit opinions about selling agents from other buyers (known as advisors) in the marketplace: (1) Unfair ratings of sellers provided to buyers. (2) Developing incentives for buyers to report their ratings of sellers.
",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-353.pdf,"Subjects:  7.1 Multi-Agent Systems;
7.2 Software Agents"
353,2007,Intelligent Systems Demonstrations,AURA: Enabling Subject Matter Experts to Construct Declarative Knowledge Bases from Science Textbooks,"Vinay K Chaudhri, Ken Barker, Shaw-Yi Chaw, Peter E. Clark, Daniel Hansch, Bonnie E. John, Sunil Mishra, John Pacheco, Bruce Porter, Aaron Spaulding, Moritz Weiten","The long-term goal of Project Halo is to build an application called Digital Aristotle that can answer questions on a variety of science topics and provide user and domain appropriate explanations.  As a near-term goal, we are focusing on enabling Subject Matter Experts (SMEs) to construct declarative knowledge bases (KBs) from 50 pages of a science textbook in the domains of Physics, Chemistry and Biology in a way that the system can answer questions similar to those on an Advanced Placement (AP) exam. We will demonstrate the current state of a system called AURA that we have been developing as a contributing technology toward the goal of Digital Aristotle. The innovative features of AURA are that it supports knowledge formulation for a mixture of textual and nontextual knowledge, and question formulation using an interactive dialog based on simplified English. The nontextual knowledge may contain tables, chemical reactions, and mathematical equations. In an extensive usability testing of AURA, we have established the basic viability of the approach.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-354.pdf,"Subjects:  10. Knowledge Acquisition;
3. Automated Reasoning"
354,2007,Intelligent Systems Demonstrations,Freebase: A Shared Database of Structured General Human Knowledge,"Kurt Bollacker, Robert Cook, Patrick Tufts","Freebase is a practical, scalable, graph-shaped database of
  structured general human knowledge, inspired by Semantic Web
  research and collaborative data communities such as the Wikipedia.
  Freebase allows public read and write access through an HTTP-based
  graph-query API for research, the creation and maintenance of
  structured data, and application building.  Access is free and all
  data in Freebase has a very open (e.g. Creative Commons, GFDL)
  license.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-355.pdf,"Subjects:  8. Enabling Technologies;
11. Knowledge Representation"
355,2007,Intelligent Systems Demonstrations,Disaster Evacuation Support,"Christopher J Carpenter, Christopher J. Dugan, Joseph B. Kopena, Robert N. Lass, Gaurav Naik,  Duc N Nguyen, Evan Sultanik, Pragnesh Jay Modi, William C. Regli","This demonstration presents an application of distributed
constraint optimization and wireless networking
to the task of assigning evacuees to available shelters
during an emergency evacuation.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-356.pdf,"Subjects:  15.2 Constraint Satisfaction;
7.1 Multi-Agent Systems"
356,2007,Intelligent Systems Demonstrations,The PhotoSlap Game: Play to Annotate,"Tsung-Hsiang Chang, Chien-Ju Ho, Jane Yung-jen Hsu","This paper presents PhotoSlap, an intelligent system for semanticannotation of photos. The system contains a semi-automatic facedetector, a bulk annotation tool, and a multi-player online game,PhotoSlap. By exploring the design principles of gameplay andapplying game theoretic analysis, PhotoSlap is designed as a funand productive game, which adapts itself to different players toproduce the desired output. Experiments involving four focusgroups showed the game to be fun and effective in annotatingpeople metadata for personal photo collections.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-357.pdf,"Subjects:  1.8 Game Playing;
6.2 Multimedia"
357,2007,Intelligent Systems Demonstrations,A Demonstration of ScriptEase Interruptible and Resumable Behaviors for CRPGs,"Maria Cutumisu, Duane Szafron, Jonathan Schaeffer, Kevin Waugh, Curtis Onuczko, Jeff Siegel, Allan Schumacher","Intelligent non-player characters that exhibit realistic ambient behaviors produce more captivating and immersive stories for the player. However, the creation of non-repetitive and entertaining behaviors is challenging, since it involves writing complex custom scripting code for thousands of characters in a common game adventure. This demonstration describes the generation of motivational behavior scripts using generative behavior patterns with ScriptEase. We demonstrate interruptible and resumable motivational ambient and latent behaviors for a tavern scene in a custom Neverwinter Nights game module.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-358.pdf,"Subjects:  6.1 Life-Like Characters;
7.2 Software Agents"
358,2007,Intelligent Systems Demonstrations,The More the Merrier: Multi-Party Negotiation with Virtual Humans,"Patrick Kenny, Arno Hartholt, Jonathan Gratch, David Traum, Stacy Marsella, Bill Swartout","The goal of the Virtual Humans Project at the University of Southern California′s Institute for Creative Technologies is to enrich virtual training environments with virtual humans – autonomous agents that support face–to–face interaction with trainees in a variety of roles – through bringing together many different areas of research including speech recognition, natural language understanding, dialogue management, cognitive modeling, emotion modeling, non–verbal behavior and speech and knowledge management. The demo at AAAI will focus on our work using virtual humans to train negotiation skills. Conference attendees will negotiate with a virtual human doctor and elder to try to move a clinic out of harm′s way in single and multi–party negotiation scenarios using the latest iteration of our Virtual Humans framework. The user will use natural speech to talk to the embodied agents, who will respond in accordance with their internal task model and state. The characters will carry out a multi–party dialogue with verbal and non–verbal behavior. A video of a single–party version of the scenario was shown at AAAI–06. This new interactive demo introduces several new features, including multi–party negotiation, dynamically generated non–verbal behavior and a central ontology.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-359.pdf,"Subjects:  6.1 Life-Like Characters;
1.6 Engineering And Science"
359,2007,Intelligent Systems Demonstrations,A Deployed Semantically-Enabled Interdisciplinary Virtual Observatory,"Deborah L. McGuinness, Peter Fox, Luca Cinquini, Patrick West, Jose Garcia, James L. Benedict,  and Don Middleton","We have used semantic technologies to design, implement, and deploy an interdisciplinary virtual observatory.  The Virtual Solar-Terrestrial Observatory is a production data framework providing access to observational datasets.  It is in use by a community of scientists, students, and data providers interested in the middle and upper Earth’s atmosphere, and the Sun.   The data sets span upper atmospheric terrestrial physics to solar physics.  The observatory allows virtual access to a highly distributed and heterogeneous set of data that appears as if all resources are organized, stored and accessible from a local machine.  The system has been operational since the summer of 2006 and has shown registered data access by over 75% of the active community (last count over 600 of the estimated 800 person active research community). This demonstration will highlight how semantic technologies are being used to support data integration and more efficient data access in a multi-disciplinary setting.  A full paper on this work is being published in the IAAI 07 deployed paper track.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-360.pdf,"Subjects:  1.6 Engineering And Science;
11.2 Ontologies"
360,2007,Intelligent Systems Demonstrations,Generating and Solving Logic Puzzles through Constraint Satisfaction,"Barry O'Sullivan, John Horan","Solving logic puzzles has become a very popular past-time,
 particularly since the Sudoku puzzle started appearing in
 newspapers all over the world.
We have developed a puzzle generator for a modification of
 Sudoku, called Jidoku, in which clues are binary disequalities
 between cells on a 9x9 grid.
Our generator guarantees that puzzles have unique solutions,
 have graded difficulty, and can be solved using inference alone.
This demonstration provides a fun application of many standard
 constraint satisfaction techniques, such as problem formulation,
 global constraints, search and inference.
It is ideal as both an education and outreach tool.
Our demonstration will allow people to generate and interactively
 solve puzzles of user-selected difficulty, with the aid of hints
 if required, through a specifically built Java applet.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-361.pdf,"Subjects:  15.2 Constraint Satisfaction;
1. Applications"
361,2007,Intelligent Systems Demonstrations,An Interactive Constraint-Based Approach to Sudoku,"Christopher Reeson, Ken Bayer, Berthe Y. Choueiry, Kai-Chen Huang","We present a Java applet, Solver, that allows a user to interactively solve a Sudoku problem using Constraint Processing (CP) techniques. We also present a companion Java applet, Constructor, that allows human users to enter and store new puzzle instances.  Our system showcases the power of CP techniques in solving problems through a widely familiar and easily approachable puzzle. Our Solver is built to maximize the interactions between the human users and CP techniques.  It allows the users to apply different consistency algorithms, work specifically on certain constraints, and make assignments and domain reductions on their own.  We also designed a hint functionality that uses increasingly complex propagation algorithms, in a controlled manner, to guide the users and train them playing the game.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-362.pdf,"Subjects:  15.2 Constraint Satisfaction;
1.3 Computer-Aided Education"
362,2007,Mobile Robot Competition and Exhibition,A Mixed Reality Approach to Undergraduate Robotics Education,"John Anderson, Jacky Baltes","Teaching robotics to undergraduate students requires a course
framework that allows students to learn about robotics in stages, without being overwhelmed with details.  Such a framework must also
provide the students with a motivating application environment that challenges them to apply what they have learned. Robotics competitions have proven to be an excellent method for motivating students, so the framework should be portable and robust enough to be used for competitions, and flexible enough to provide a range of environments that can become more challenging as students become more adept.  Finally, the framework should provide repeatability and control for evaluating the student's work, as well as for performing research.  In this paper, we overview a mixed reality approach that meets these criteria, and describe its use in an advanced undergraduate course.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-363.pdf,"Subjects:  17. Robotics;
1.3 Computer-Aided Education"
363,2007,Mobile Robot Competition and Exhibition,KSU Willie in Semantic Vision Challenge,"David Gustafson, aaron chavez, michael marlen, andrew king, alejandro alliana, ondrej linda","The KSU Willie entry in the Semantic Vision Challenge will use a variety of classifiers, some standard classifiers and some newly developed classifiers, to learn the classification of images downloaded from the web.  KSU Willie will use those classifiers to identify objects in the environment.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-364.pdf,"Subjects:  19. Vision;
17. Robotics"
364,2007,Mobile Robot Competition and Exhibition,The UBC Semantic Robot Vision System,"Scott Helmer, David Meger, Per-Erik Forssen, Tristram Southey, Sancho McCann, Pooyan Fazli, Jim Little, David Lowe","This abstract outlines the algorithms and robot hardware used in the UBC robot competing in the Semantic Robot Vision Challenge (SRVC), held at the AAAI'07 conference in Vancouver, Canada. 
Successfully completing the SRVC involves smooth integration of tasks such as data acquisition, training, obstacle avoidance, visual search, and object recognition. Given that these tasks span
several research disciplines, successful integration is a formidable task. The value of working on these problems jointly is
that assumptions built into an isolated method will be exposed when
it is integrated, thus highlighting where further research is required. In addition, this will focus research on robots that can navigate safely and identify objects in their environment.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-365.pdf,"Subjects:  17. Robotics;
19. Vision"
365,2007,Mobile Robot Competition and Exhibition,A Robotic Weight Loss Coach,"Cory D. Kidd, Cynthia Breazeal",We present a rationale for studying long-term human-robot interaction and explain why new applications are necessary for this type of experimentation.  The design and implementation of a robot that has been implemented is briefly described with the outline of a study that is under way.,https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-366.pdf,"Subjects:  17. Robotics;
6. Computer-Human Interaction"
366,2007,Mobile Robot Competition and Exhibition,OPTIMOL: A Framework For Online Picture Collection Via Incremental Model Learning,"Li-Jia Li, Juan Carlos Niebles, Li Fei-Fei","OPTIMOL is a novel, automatic dataset collecting and model learning system for object categorization. Our algorithm mimics the human learning process in such a way that, starting from a few training examples, the more confident data you incorporate in the training data, the more reliable models can be learnt. Our system uses the Internet as the (nearly) unlimited resource for images. The learning and image collection processes are done via an iterative and incremental scheme. The goal of this work is

to use this tremendous web resource to learn robust object   category models in order to detect and search for objects in real-world scenes.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-367.pdf,"Subjects:  19. Vision;
12. Machine Learning and Discovery"
367,2007,Mobile Robot Competition and Exhibition,An Implementation of Robot Formations using Local Interactions,"Ross Mead, Jerry B. Weinberg, Jeffrey R. Croxell","Coordinating a group of robots to work in formation has been suggested for a number of tasks, such as urban search-and-rescue, traffic control, and harvesting solar energy. Algorithms for controlling robot formations have been inspired by biological and organizational systems. In our approach to robot formation control, each robot is treated like a cell in a cellular automaton, where local interactions between robots result in a global organization. The algorithm has been demonstrated in simulation. In this paper, we present a physical implementation.",https://aaai.org/Library/AAAI/2007/../../../Papers/AAAI/2007/AAAI07-368.pdf,"Subjects:  17. Robotics;
7.1 Multi-Agent Systems"
