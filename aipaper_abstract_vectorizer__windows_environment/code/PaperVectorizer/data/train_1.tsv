rethinking ai strategy and policy as entangled super wicked problems	paper attempts preliminary analysis general approach ai strategy/policy research lens wicked problems literature wicked problems class social policy problems traditional methods resolution fail super wicked problems refer even complex social policy problems e.g climate change first propose hierarchy three classes ai strategy/policy problems wicked super wicked problems next identify three independent super wicked problems ai strategy/policy propose significant challenges development safe beneficial artificial general intelligence significantly complex nuanced thus posing new degree 'wickedness explore analysis techniques addressing wicked problems super wicked problems leads discussion implications ideas problems ai strategy/policy	positive	0
fairness in deceased organ matching	algorithms given responsibility make decisions impact lives increasing awareness need ensure fairness decisions one first challenges decide fairness means particular context consider fairness deciding match organs donated deceased donors patients due increasing age patients waiting list organs donated current `` first come first served '' mechanism used australia review take account age patients organs consider revise mechanism take account age fairly identify number different types fairness patients regions blood types consider achieved	positive	0
using education as a model to capture good-faith effort for autonomous systems	multiprocess environments comprising several intercommunicating lisp systems straightforward implement due certain fundamental characteristics lisp language experiences four methods establishing necessary communications linkages described features lisp support experimentation interprocess communication identified two key characteristics language important regard 1. lisp programs construct interpret new code run 2. structures within lisp systems accessible name flexible communication methods use ordinary lisp input output functions supplemented small amount system-dependent code create communication linkages treated lisp file structures	positive	0
speaking on behalf of: representation, delegation, and authority in computational text analysis	computational tools often facilitate human work rapidly summarizing large amounts data especially text delegates models measure authority speak behalf people whose data analyzed paper considers consequences delegation draws sociological accounts representation translation examine one particular case application topic modeling blogs written parents children autism spectrum paper illustrates kinds statements topic models computational techniques make behalf people also articulates potential consequences statements paper concludes offering several suggestions address potential harms occur computational models speak behalf someone	positive	0
ai + art = human	past years specialised online offline press blossomed articles art made `` '' artificial intelligence ai narrative rapidly changing fact october 2018 auction house christie 's sold art piece allegedly made `` '' ai draw philosophy art science arguing ai technical object always intertwined human nature despite level autonomy however use creative autonomous agents cultural social implications way experience art creators well audience therefore highlight importance interdisciplinary dialogue promoting culture transparency technology used awareness meaning technology society value creativity lives	positive	0
the role and limits of principles in ai ethics: towards a focus on tensions	last years seen proliferation principles ai ethics substantial overlap different sets principles widespread agreement ai used common good used harm people undermine rights respect widely held values fairness privacy autonomy articulating agreeing principles important starting point drawing comparisons field bioethics highlight limitations principles particular often broad high-level guide ethics practice suggest important next step field ai ethics focus exploring tensions inevitably arise try implement principles practice explicitly recognising tensions begin make decisions resolved specific cases develop frameworks guidelines ai ethics rigorous practically relevant discuss different specific ways tensions arise ai ethics processes might needed resolve	positive	0
degenerate feedback loops in recommender systems	machine learning used extensively recommender systems deployed products decisions made systems influence user beliefs preferences turn affect feedback learning system receives thus creating feedback loop phenomenon give rise so-called `` echo chambers '' `` filter bubbles '' user societal implications paper provide novel theoretical analysis examines role user dynamics behavior recommender systems disentangling echo chamber filter bubble effect addition offer practical solutions slow system degeneracy study contributes toward understanding developing solutions commonly cited issues complex temporal scenario area still largely unexplored	positive	0
meta-descent for online, continual prediction	paper investigates different vector step-size adaptation approaches non-stationary online continual prediction problems vanilla stochastic gradient descent considerably improved scaling update vector appropriately chosen step-sizes many methods including adagrad rmsprop amsgrad keep statistics learning process approximate second order update—a vector approximation inverse hessian another family approaches use meta-gradient descent adapt stepsize parameters minimize prediction error metadescent strategies promising non-stationary problems extensively explored quasi-second order methods first derive general incremental metadescent algorithm called adagain designed applicable much broader range algorithms including semi-gradient updates even accelerations rmsprop provide empirical comparison methods families conclude methods families perform well non-stationary prediction problems meta-descent methods exhibit advantages method particularly robust across several prediction problems competitive state-of-the-art method large-scale time-series prediction problem real data mobile robot	negative	6.436323330693995
compensation at the crossroads: autonomous vehicles and alternative victim compensation schemes	last five years small growing number vehicle accidents involving fully partially autonomous vehicles raised new profoundly novel legal issue liable anyone victims compensated vehicle controlled algorithm rather human driver causes injury answer question implications far beyond resolution individual autonomous vehicle crash cases whether american legal system capable handling cases fairly efficiently implicates likelihood consumers adopt autonomous vehicles b rate implications concern law policy makers immensely autonomous cars stand drastically reduce number fatalities injuries u.s. roadways-and virtually every scholar believes will-getting adjudication compensation aspect autonomous vehicle injuries `` wrong '' speak risks stymieing adoption technology leaving americans risk dying hands human drivers	positive	0
hypergraph optimization for multi-structural geometric model fitting	recently hypergraph-based methods proposed deal problem model fitting computer vision mainly due superior capability hypergraph represent complex relationship data points however hypergraph becomes extremely complicated input data include large number data points usually contaminated noises outliers significantly increase computational burden order overcome problem propose novel hypergraph optimization based model fitting homf method construct simple effective hypergraph specifically homf includes two main parts adaptive inlier estimation algorithm vertex optimization iterative hyperedge optimization algorithm hyperedge optimization proposed method highly efficient obtain accurate model fitting results within iterations moreover homf directly apply spectral clustering achieve good fitting performance extensive experimental results show homf outperforms several state-of-the-art model fitting methods synthetic data real images especially sampling efficiency handling data severe outliers	negative	5.987732458626851
 norms, rewards, and the intentional stance: comparing machine learning approaches to ethical training	challenge training ai systems perform responsibly beneficially inspired different approaches teaching system people want acceptable attain world paper compare work reinforcement learning particular inverse reinforcement learning norm inference approach test two systems present results using idea `` intentional stance '' explain norm inference approach work even another agent acting strictly according reward functions way norm inference presents promising explicitly accountable approach design ai systems start	positive	0
imli: an incremental framework for maxsat-based learning of interpretable classification rules	wide adoption machine learning critical domains medical diagnosis law education propelled need interpretable techniques due need end users understand reasoning behind decisions due learning systems computational intractability interpretable learning led practitioners design heuristic techniques fail provide sound handles tradeoff accuracy interpretability motivated success maxsat solvers past decade recently maxsat-based approach called mlic proposed seeks reduce problem learning interpretable rules expressed conjunctive normal form cnf maxsat query mlic shown achieve accuracy similar state art black-box classifiers generating small interpretable cnf formulas runtime performance mlic significantly lagging renders approach unusable practice context authors raised question possible achieve best worlds i.e. sound framework interpretable learning take advantage maxsat solvers scaling real-world instances paper take step towards answering question affirmation propose imli incremental approach maxsat based framework achieves scalable runtime performance via partition-based training methodology extensive experiments benchmarks arising uci repository demonstrate imli achieves three orders magnitude runtime improvement without loss accuracy interpretability	positive	0
mpd-al: an efficient membrane potential driven aggregate-label learning algorithm for spiking neurons	one long-standing questions biology machine learning neural networks may learn important features input activities delayed feedback commonly known temporal credit-assignment problem aggregate-label learning proposed resolve problem matching spike count neuron magnitude feedback signal however existing threshold-driven aggregate-label learning algorithms computationally intensive resulting relatively low learning efficiency hence limiting usability practical applications order address limitations propose novel membrane-potential driven aggregate-label learning algorithm namely mpd-al algorithm easiest modifiable time instant identified membrane potential traces neuron guild synaptic adaptation based presynaptic neurons ’ contribution time instant experimental results demonstrate proposed algorithm enables neurons generate desired number spikes detect useful clues embedded within unrelated spiking activities background noise better learning efficiency state-of-the-art tdp1 multi-spike tempotron algorithms furthermore propose data-driven dynamic decoding scheme practical classification tasks aggregate labels hard define scheme effectively improves classification accuracy aggregate-label learning algorithms demonstrated speech recognition task	negative	6.876931377919391
margins and opportunity	use statistical quantity margin -- distance decision boundary classified point gap two scores -- formalize principle equal opportunity -- chance improve one 's outcome regardless group status leads better definition opportunity recognizes example strongly rejected individual offered less recourse weakly rejected one despite shared outcome also leads simpler algorithms since real-valued margins easier analyze optimize discrete outcomes formalize two ways protected group may guaranteed equal opportunity 1 social mobility acceptance within reach group conversely general population n't cushioned rejection 2 contrast within group good candidates get substantially higher scores bad candidates preventing so-called 'token effect simple linear classifier seems offer roughly equal opportunity experimentally mathematically	positive	0
cgmh: constrained sentence generation by metropolis-hastings sampling	real-world applications natural language generation often constraints target sentences addition fluency naturalness requirements existing language generation techniques usually based recurrent neural networks rnns however non-trivial impose constraints rnns maintaining generation quality since rnns generate sentences sequentially beam search first word last paper propose cgmh novel approach using metropolis-hastings sampling constrained sentence generation cgmh allows complicated constraints occurrence multiple keywords target sentences handled traditional rnn-based approaches moreover cgmh works inference stage require parallel corpora training evaluate method variety tasks including keywords-to-sentence generation unsupervised sentence paraphrasing unsupervised sentence error correction cgmh achieves high performance compared previous supervised methods sentence generation code released https //github.com/ningmiao/cgmh	negative	7.247523483121768
show, attend and read: a simple and strong baseline for irregular text recognition	recognizing irregular text natural scene images challenging due large variance text appearance curvature orientation distortion existing approaches rely heavily sophisticated model designs and/or extra fine-grained annotations extent increase difficulty algorithm implementation data collection work propose easy-to-implement strong baseline irregular scene text recognition using offthe-shelf neural network components word-level annotations composed 31-layer resnet lstmbased encoder-decoder framework 2-dimensional attention module despite simplicity proposed method robust achieves state-of-the-art performance irregular text recognition benchmarks comparable results regular text datasets code released	negative	7.1264336164458655
connecting language to images: a progressive attention-guided network for simultaneous image captioning and language grounding	image captioning visual language grounding two important tasks image understanding seldom considered together paper propose progressive attention-guided network pagnet simultaneously generates image captions predicts bounding boxes caption words pagnet mainly two distinctive properties progressively refine predictive results image captioning updating attention map predicted bounding boxes ii learns bounding boxes words using weakly supervised strategy combines frameworks multiple instance learning mil markov decision process mdp using attention map generated captioning process pagnet significantly reduces search space mdp conduct experiments benchmark datasets demonstrate effectiveness pagnet results show pagnet achieves best performance	negative	6.8665067091351375
optimization of hierarchical regression model with application to optimizing multi-response regression k-ary trees	fast convenient well-known way toward regression induce prune binary tree however little attempt toward improving performance induced regression tree paper presents meta-algorithm capable minimizing regression loss function thus improving accuracy given hierarchical model k-ary regression trees proposed method minimizes loss function node one one split nodes leads solving instance-based cost-sensitive classification problem node ’ data points leaf nodes method leads simple regression problem case binary univariate multivariate regression trees computational complexity training linear samples hence method scalable large trees datasets also briefly explore possibilities applying proposed method classification tasks show algorithm significantly better test error compared state-ofthe- art tree algorithms end accuracy memory usage query time method compared recently introduced forest models depict time proposed method able achieve better similar accuracy tangibly faster query time smaller number nonzero weights	negative	8.173982021049596
triple classification using regions and fine-grained entity typing	triple knowledge-graph takes form consists head relation tail triple classification used determine truth value unknown triple hard task 1-to-n relations using vector-based embedding approach propose new region-based embedding approach using fine-grained type chains novel geometric process presented extend vectors pre-trained entities n-balls n-dimensional balls condition head balls shall contain tail balls algorithm achieves zero energy cost therefore serves case study perfectly imposing tree structures vector space unknown triple h r x predicted true x ’ n-ball located r-subspace h ’ n-ball following construction known tails h. experiments based large datasets derived benchmark datasets wn11 fb13 wn18 results show performance new method related length type chain quality pre-trained entityembeddings performances long chains welltrained entity-embeddings outperform methods literature source codes datasets located https //github.com/gnodisnait/mushroom	negative	5.126671731821261
rs3cis: robust single-step spectral clustering with intrinsic subspace	spectral clustering widely adopted mine structures data clusters clustering performance spectral clustering depends largely quality constructed affinity graph especially data noise subspace learning transform original input features low-dimensional subspace help produce robust method therefore learn intrinsic subspace construct pure affinity graph dataset noise challenge spectral clustering order deal challenge new robust single-step spectral clustering intrinsic subspace rs3cis method proposed paper rs3cis uses local representation method projects original data low-dimensional subspace row-sparse transformation matrix uses 2,1-norm transformation matrix penalty term achieve noise suppression addition rs3cis introduces laplacian matrix rank constraint output affinity graph explicit clustering structure makes final clustering result obtained single-step constructing affinity matrix one synthetic dataset six real benchmark datasets used verify performance proposed method performing clustering projection experiments experimental results show rs3cis outperforms related methods respect clustering quality robustness dimension reduction	negative	7.153405861696228
avs-net: automatic visual surveillance using relation network	visual surveillance closed circuit television cctv help prevent crime paper propose automatic visual surveillance network avs-net simultaneously performs image processing object detection determine dangers situations captured cctv addition add relation module infer relationships objects images experimental results show relation module greatly improves classification accuracy even enough information	negative	7.528892308240756
regulating lethal and harmful autonomy: drafting a protocol vi of the convention on certain conventional weapons 	short paper provides two partial drafts protocol vi might added existing five protocols convention certain conventional weapons ccw regulate `` lethal autonomous weapons systems '' laws draft sets line tolerance `` human loop '' critical functions select engage draft b sets line tolerance human `` wider loop '' includes critical function defining target classes well select engage draft represents interpretation ngos campaign stop killer robots seeking get enacted draft b cautious draft based dutch concept `` meaningful human control wider loop '' seek ban system currently exists draft may likely achieve consensus required un ccw process list weapons banned drafts provided along rationale draft drafts intended stimulate debate precise form binding instrument laws would take laws banned	positive	0
preferences and ethical principles in decision making	want people trust ai systems need provide systems create ability discriminate humans would consider good bad decisions quality decision based preferences optimization criteria decision makers also properties related impact decision whether ethical complies constraints priorities given feasibility constraints safety regulations cp-net formalism 2 convenient expressive way model preferences providing effective compact way qualitatively model preferences outcomes i.e. decisions combinatorial structure 3 7 wish incorporate ethical moral norms based constraints decision context means subjective preferences decision makers source information consider 1 8 indeed depending context may consider specific ethical principles derived appropriate ethical theory various laws norms preferences important preferences ethical principles conflict principles override subjective preferences decision maker therefore essential well founded techniques evaluate whether preferences compatible set ethical principles measure much preferences deviate ethical principles	positive	0
multi-task learning with multi-view attention for answer selection and knowledge base question answering	answer selection knowledge base question answering kbqa two important tasks question answering qa systems existing methods solve two tasks separately requires large number repetitive work neglects rich correlation information tasks paper tackle answer selection kbqa tasks simultaneously via multi-task learning mtl motivated following motivations first answer selection kbqa regarded ranking problem one text-level knowledge-level second two tasks benefit answer selection incorporate external knowledge knowledge base kb kbqa improved learning contextual information answer selection fulfill goal jointly learning two tasks propose novel multi-task learning scheme utilizes multi-view attention learned various perspectives enable tasks interact well learn comprehensive sentence representations experiments conducted several real-world datasets demonstrate effectiveness proposed method performance answer selection kbqa improved also multi-view attention scheme proved effective assembling attentive information different representational perspectives	negative	6.826094776246464
cake, death, and trolleys: dilemmas as benchmarks of ethical decision-making	artificial intelligence ai systems becoming part lives societies decisions systems make us need ensure decisions make positive individual societal ethical impact estimate good system making ethical decisions benchmarking used evaluate good machine process performs respect industry bests paper argue ethical dilemmas used benchmarks estimating ethical performance autonomous system advocate open source repository dilemmas maintained present prototype repository available https //imdb uib.no/dilemmaz/articles/all1	positive	0
 rationalization: a neural machine translation approach to generating natural language explanations	introduce \em ai rationalization approach generating explanations autonomous system behavior human performed behavior describe rationalization technique uses neural machine translation translate internal state-action representations autonomous agent natural language evaluate technique frogger game environment training autonomous game playing agent rationalize action choices using natural language natural language training corpus collected human players thinking loud play game motivate use rationalization approach explanation generation show results two experiments evaluating effectiveness rationalization results evaluations show neural machine translation able accurately generate rationalizations describe agent behavior rationalizations satisfying humans alternative methods explanation	positive	0
data driven platform for organizing scientific articles relevant to biomimicry	life earth presents elegant solutions many challenges innovators entrepreneurs across disciplines face every day facilitate innovations inspired nature emerging need systems bring relevant biological information application-oriented market paper discuss approach assembling system uses machine learning techniques assess scientific article 's potential usefulness innovators classifies articles way helps innovators find information relevant challenges attempting solve	positive	0
 inverse norm conflict resolution	previous work provided `` norm conflict resolution '' algorithm allowing agents stochastic domains represented markov decision processes `` maximally satisfy '' set moral social norms norms represented statements linear temporal logic ltl required agent designer provide weights specifying relative importance norm paper propose `` inverse norm conflict resolution '' algorithm learning weights demonstration approach minimizes cost function based relative entropy policy encoding observed behavior policy representing optimal norm-following behavior demonstrate effectiveness algorithm simple gridworld domain	positive	0
the kelly growth optimal portfolio with ensemble learning	competitive alternative markowitz mean-variance portfolio kelly growth optimal portfolio drawn sufficient attention investment science growth optimal portfolio theoretically guaranteed dominate portfolio probability 1 long run practically tends highly risky short term moreover empirical analysis performance enhancement studies practical settings surprisingly short particular handle challenging realistic condition insufficient training data barely investigated order fill voids especially grappling difficulty small samples paper propose growth optimal portfolio strategy equipped ensemble learning synergically leverage bootstrap aggregating algorithm random subspace method portfolio construction mitigate estimation error analyze behavior hyperparameter selection proposed strategy simulation corroborate effectiveness comparing out-of-sample performance 10 competing strategies four datasets experimental results lucidly confirm new strategy superiority extensive evaluation criteria	negative	8.05693791678641
data-distortion guided self-distillation for deep neural networks	knowledge distillation effective technique widely used transferring knowledge network another network despite effective improvement network performance dependence accompanying assistive models complicates training process single network need large memory time cost paper design elegant self-distillation mechanism transfer knowledge different distorted versions training data without reliance accompanying models specifically potential capacity single network excavated learning consistent global feature distributions posterior distributions class probabilities across distorted versions data extensive experiments multiple datasets i.e. cifar-10/100 imagenet demonstrate proposed method effectively improve generalization performance various network architectures alexnet resnet wide resnet densenet outperform existing distillation methods little extra training efforts	negative	6.692053731763735
ea reader: enhance attentive reader for cloze-style question answering via multi-space context fusion	query-document semantic interactions essential success many cloze-style question answering models recently researchers proposed several attention-based methods predict answer focusing appropriate subparts context document paper design novel module produce query-aware context vector named multi-space based context fusion mscf following considerations 1 interactions applied across multiple latent semantic spaces 2 attention measured bit level token level moreover extend mscf multi-hop architecture unified model called enhanced attentive reader ea reader iterative inference process reader equipped novel memory update rule maintains understanding documents read update write operations conduct extensive experiments four real-world datasets results demonstrate ea reader outperforms state-of-the-art models	negative	8.16055351329851
explanatory interactive machine learning	although interactive learning puts user loop learner remains mostly black box user understanding reasons behind predictions queries important assessing learner works turn trust consequently propose novel framework explanatory interactive learning step learner explains query user user interacts answering query correcting explanation demonstrate boost predictive explanatory powers trust learned model using text e.g svms image classification e.g neural networks experiments well user study	positive	0
stnet: local and global spatial-temporal modeling for action recognition	despite success deep learning static image understanding remains unclear effective network architectures spatial-temporal modeling videos paper contrast existing cnn+rnn pure 3d convolution based approaches explore novel spatialtemporal network stnet architecture local global modeling videos particularly stnet stacks n successive video frames super-image 3n channels applies 2d convolution super-images capture local spatial-temporal relationship model global spatialtemporal structure apply temporal convolution local spatial-temporal feature maps specifically novel temporal xception block proposed stnet employs separate channel-wise temporal-wise convolution feature sequence video extensive experiments kinetics dataset demonstrate framework outperforms several state-of-the-art approaches action recognition strike satisfying trade-off recognition accuracy model complexity demonstrate generalization performance leaned video representations ucf101 dataset	negative	6.741893754107878
cleaning noisy and heterogeneous metadata for record linking across scholarly big datasets	automatically extracted metadata scholarly documents pdf formats usually noisy heterogeneous often containing incomplete fields erroneous values one common way cleaning metadata use bibliographic reference dataset challenge match records corpora high precision existing solution based information retrieval string similarity titles works well titles cleaned introduce system designed match scholarly document entities noisy metadata reference dataset blocking function uses classic bm25 algorithm find matching candidates reference data indexed elasticsearch core components use supervised methods combine features extracted available metadata fields system also leverages available citation information match entities combination metadata citation achieves high accuracy significantly outperforms baseline method test dataset apply system match database citeseerx web science pubmed dblp method deployed citeseerx system clean metadata link records scholarly big datasets	negative	7.493733545299619
incomplete contracting and ai alignment	suggest analysis incomplete contracting developed law economics researchers provide useful framework understanding ai alignment problem help generate systematic approach finding solutions first provide overview incomplete contracting literature explore parallels work problem ai alignment emphasize misalignment principal agent core focus economic analysis highlight technical results economics literature incomplete contracts may provide insights ai alignment researchers core contribution however bring bear insight economists urged absorb legal scholars behavioral scientists fact human contracting supported substantial amounts external structure generally available institutions culture law supply implied terms fill gaps incomplete contracts propose research agenda ai alignment work focuses problem build ai replicate human cognitive processes connect individual incomplete contracts supporting external structure	positive	0
epistemic therapy for bias in automated decision-making	despite recent interest critical machine learning literature `` bias '' artificial intelligence ai systems nature specific biases stemming interaction machines humans data remains ambiguous influenced gendler 's work human cognitive biases introduce concept alief-discordant belief tension intuitive moral dispositions designers explicit representations generated algorithms discussion alief-discordant belief diagnoses ethical concerns arise designing ai systems atop human biases furthermore codify relationship data algorithms engineers components cognitive discordance comprising novel epistemic framework ethics ai	positive	0
adversarial binary collaborative filtering for implicit feedback	fast item recommendation based implicit feedback vital practical scenarios due data-abundance challenging lack negative samples large number recommended items recent adversarial methods unifying generative discriminative models promising since generative model negative sampler gradually improves iteration continues however binary-valued generative model still unexplored within min-max framework important accelerating item recommendation optimizing binary-valued models difficult due non-smooth nondifferentiable end propose two novel methods relax binarization based error function gumbel trick generative model optimized many popular solvers sgd admm binary-valued generative model evaluated within min-max framework four real-world datasets shown superiority competing hashing-based recommendation algorithms addition proposed framework approximate discrete variables precisely applied solve discrete optimization problems	negative	7.223473424412077
framing artificial intelligence in american newspapers	publics perceptions new scientific advances ai often informed influenced news coverage understand artificial intelligence ai framed u.s. newspapers content analysis based framing theory journalism science communication conducted study identified dominant topics frames well risks benefits ai covered five major american newspapers 2009 2018. results indicated business technology primary topics news coverage ai benefits ai discussed frequently risks risks ai generally discussed greater specificity additionally episodic issue framing societal impact framing frequently used	positive	0
sparse adversarial perturbations for videos	although adversarial samples deep neural networks dnns intensively studied static images extensions videos never explored compared images attacking video needs consider spatial cues also temporal cues moreover improve imperceptibility well reduce computation cost perturbations added frames possible i.e. adversarial perturbations temporally sparse motivates propagation perturbations denotes perturbations added current frame transfer next frames via temporal interactions thus extra perturbations needed frames misclassify end propose first white-box video attack method utilizes l2,1-norm based optimization algorithm compute sparse adversarial perturbations videos choose action recognition targeted task networks cnn+rnn architecture threat models verify method thanks propagation compute perturbations shortened version video adapt long version video fool dnns experimental results ucf101 dataset demonstrate even one frame video perturbed fooling rate still reach 59.7	negative	7.456661414995324
a formal approach to explainability	regard explanations blending input sample model 's output offer definitions capture various desired properties function generates explanations study links properties explanation-generating functions intermediate representations learned models able show example activations given layer consistent explanation subsequent layers addition study intersection union explanations way construct new explanations	positive	0
the seductive allure of artificial intelligence-powered neurotechnology	neuroscience explanations-even completely irrelevant-have shown exert `` seductive allure '' individuals leading judge bad explanations arguments favorably seems similarly seductive allure artificial intelligence ai technologies leading people `` overtrust '' systems even witnessed system perform poorly ai-powered neurotechnologies begun proliferate recent years particularly based electroencephalography eeg represent potentially doubly-alluring combination enormous potential benefit applying ai techniques neuroscience `` decode '' brain activity associated mental states efforts still early stages danger using unproven technologies prematurely especially important real-world contexts yet premature use begun emerge several high-stakes set-tings including law health wellness employment transportation light potential seductive allure technologies need vigilant monitoring scientific validity challenging unsubstantiated claims misuse still actively supporting continued development proper use	positive	0
learning a deep convolutional network for colorization in monochrome-color dual-lens system	monochrome-color dual-lens system gray image captured monochrome camera better quality color image color camera color information get high-quality color images desired colorize gray image color image reference related works usually use hand-crafted methods search best-matching pixel reference image pixel input gray image copy color best-matching pixel result propose novel deep convolution network solve colorization problem end-to-end way based observation pixel input image usually exist multiple pixels reference image correct colors method performs weighted average colors candidate pixels reference image utilize candidate pixels correct colors weight values pixels input image reference image obtained learning weight volume using deep feature representations attention operation proposed focus useful candidate pixels 3-d regulation performed learn context information addition correct wrongly colorized pixels occlusion regions propose color residue joint learning module correct colorization result input gray image guidance evaluate method scene flow cityscapes middlebury sintel datasets experimental results show method largely outperforms state-of-the-art methods	negative	8.006627856055275
an autonomous architecture that protects the right to privacy	advent widespread adoption wearable cameras autonomous robots raises important issues related privacy mobile cameras systems record may re-transmit enormous amounts video data used identify track characterize behavior general populous paper presents preliminary computational architecture designed preserve specific types privacy video stream identifying categories individuals places things require higher normal privacy protection paper describes architecture whole well preliminary results testing aspects system intention implement test system ground robots small uavs demonstrate system provide selective low-level masking deletion data requiring higher privacy protection	positive	0
crowdsourcing with fairness, diversity and budget constraints	recent studies shown labels collected crowdworkers discriminatory respect sensitive attributes gender race raises questions suitability using crowdsourced data use training machine learning algorithms work address problem fair diverse data collection crowd budget constraints propose novel algorithm maximizes expected accuracy collected data ensuring errors satisfy desired notions fairness provide guarantees performance algorithm show algorithm performs well practice experiments real dataset	positive	0
human trust measurement using an immersive virtual reality autonomous vehicle simulator	recent studies indicate people negatively predisposed toward utilizing autonomous systems findings highlight necessity conducting research better understand evolution trust humans growing autonomous technologies self-driving cars sdc research presents new approach real-time trust measurement passengers sdcs utilized new structured data collection approach along virtual reality sdc simulator understand various autonomous driving scenarios increase decrease human trust trust re-built case incidental failures verify methodology designed conducted empirical experiment 50 human subjects results experiment indicated subjects could rebuild trust reasonable time frame system demonstrated faulty behavior analysis showed approach highly effective collecting real-time data human subjects lays foundation more-involved future research domain human trust autonomous driving	positive	0
global explanations of neural networks: mapping the landscape of predictions	barrier wider adoption neural networks lack interpretability local explanation methods exist one prediction global attributions still reduce neural network decisions single set features response present approach generating global attributions called gam explains landscape neural network predictions across subpopulations gam augments global explanations proportion samples attribution best explains specifies samples described attribution global explanations also tunable granularity detect fewer subpopulations demonstrate gam 's global explanations 1 yield known feature importances simulated data 2 match feature weights interpretable statistical models real data 3 intuitive practitioners user studies transparent predictions gam help ensure neural network decisions generated right reasons	positive	0
neural collective graphical models for estimating spatio-temporal population flow from aggregated data	propose probabilistic model estimating population flow defined populations transition areas time given aggregated spatio-temporal population data since information individual trajectories aggregated data straightforward estimate population flow proposed method utilize collective graphical model learn individual transition models aggregated data analytically marginalizing individual locations learning spatio-temporal collective graphical model aggregated data ill-posed problem since number parameters estimated exceeds number observations proposed method reduces effective number parameters modeling transition probabilities neural network takes locations origin destination areas time day inputs modeling automatically learn nonlinear spatio-temporal relationships flexibly among transitions locations times four real-world population data sets japan china demonstrate proposed method estimate transition population accurately existing methods	negative	8.174678315539495
trolleymod v1.0: an open-source simulation and data-collection platform for ethical decision making in autonomous vehicles	paper presents trolleymod v1.0 open-source platform based carla simulator collection ethical decision-making data autonomous vehicles platform designed facilitate experiments aiming observe record human decisions actions high-fidelity simulations ethical dilemmas occur context driving targeting experiments class trolley problems trolleymod provides seamless approach creating new experimental settings environments realistic physics-engine high-quality graphical capabilities carla unreal engine also trolleymod provides straightforward interface carla environment python enable implementation custom controllers deep reinforcement learning agents results experiments used sociological analyses well training tuning value-aligned autonomous vehicles based social values inferred observations	positive	0
understanding black box model behavior through subspace explanations	predictive models increasingly assist human experts e.g. doctors day-to-day decision making crucial experts able explore understand models behave different feature subspaces order know trust end propose model understanding subspace explanations muse novel model agnostic framework facilitates understanding given black box model explaining behaves subspaces characterized certain features interest framework provides end users e.g. doctors flexibility customizing model explanations allowing input features interest construction explanations guided novel objective function propose simultaneously optimize fidelity original model unambiguity interpretability explanation specifically objective allows us learn optimality guarantees small number compact decision sets captures behavior given black box model unambiguous well-defined regions feature space experimental evaluation real-world datasets user studies demonstrate approach generate customizable highly compact easy-to-understand yet accurate explanations various kinds predictive models compared state-of-the-art baselines	positive	0
reinforcement learning and inverse reinforcement learning with system 1 and system 2	inferring person 's goal behavior important problem applications ai e.g automated assistants recommender systems workhorse model task rational actor model amounts assuming people stable reward functions discount future exponentially construct optimal plans rational actor assumption techniques inverse reinforcement learning irl used infer person 's goals actions competing model dual-system model decisions result interplay fast automatic heuristic-based system 1 slower deliberate calculating system 2. generalize dual system framework case markov decision problems show compute optimal plans dual-system agents show dual-system agents exhibit behaviors incompatible rational actor assumption show naive applications rational-actor irl behavior dual-system agents generate wrong inference agents goals suggest interventions actually reduce agent 's overall utility finally adapt simple irl algorithm correctly infer goals dual system decision-makers allows us make interventions help rather hinder dual-system agent 's ability reach true goals	positive	0
sadih: semantic-aware discrete hashing	due low storage cost fast query speed hashing recognized accomplish similarity search largescale multimedia retrieval applications particularly supervised hashing recently received considerable research attention leveraging label information preserve pairwise similarities data points hamming space however still remain two crucial bottlenecks 1 learning process full pairwise similarity preservation computationally unaffordable unscalable deal big data 2 available category information data well-explored learn discriminative hash functions overcome challenges propose unified semantic-aware discrete hashing sadih framework aims directly embed transformed semantic information asymmetric similarity approximation discriminative hashing function learning specifically semantic-aware latent embedding introduced asymmetrically preserve full pairwise similarities skillfully handle cumbersome n×n pairwise similarity matrix meanwhile semantic-aware autoencoder developed jointly preserve data structures discriminative latent semantic space perform data reconstruction moreover efficient alternating optimization algorithm proposed solve resulting discrete optimization problem extensive experimental results multiple large-scale datasets demonstrate sadih clearly outperform state-of-the-art baselines additional benefit lower computational costs	negative	4.216363258601632
mapping informal settlements in developing countries using machine learning and low resolution multi-spectral data	informal settlements home socially economically vulnerable people planet order deliver effective economic social aid non-government organizations ngos united nations children 's fund unicef require detailed maps locations informal settlements however data regarding informal formal settlements primarily unavailable available often incomplete due part cost complexity gathering data large scale address challenges work provide three contributions 1 brand new machine learning dataset purposely developed informal settlement detection 2 show possible detect informal settlements using freely available low-resolution lr data contrast previous studies use very-high resolution~ vhr satellite aerial imagery something cost-prohibitive ngos 3 demonstrate two effective classification schemes curated data set one cost-efficient ngos another cost-prohibitive ngos additional utility integrate schemes semi-automated pipeline converts either lr vhr satellite image binary map encodes locations informal settlements	positive	0
semantic adversarial network with multi-scale pyramid attention for video classification	two-stream architecture shown strong performance video classification task key idea learn spatiotemporal features fusing convolutional networks spatially temporally however problems within architecture first relies optical flow model temporal information often expensive compute store second limited ability capture details local context information video data third lacks explicit semantic guidance greatly decrease classification performance paper proposed new two-stream based deep framework video classification discover spatial temporal information rgb frames moreover multi-scale pyramid attention mpa layer semantic adversarial learning sal module introduced integrated framework mpa enables network capturing global local feature generate comprehensive representation video sal make representation gradually approximate real video semantics adversarial manner experimental results two public benchmarks demonstrate proposed methods achieves state-of-the-art results standard video datasets	negative	7.926978790666908
matrix completion for graph-based deep semi-supervised learning	convolutional neural networks cnns provided promising achievements image classification problems however training cnn model relies large number labeled data considering vast amount unlabeled data available web important make use data conjunction small set labeled data train deep learning model paper introduce new iterative graph-based semi-supervised learning gssl method train cnn-based classifier using large amount unlabeled data small amount labeled data method first construct similarity graph nodes represent cnn features corresponding data points labeled unlabeled edges tend connect data points class label graph missing label unsupervised nodes predicted using matrix completion method based rank minimization criterion next step use constructed graph calculate triplet regularization loss added supervised loss obtained initially labeled data update cnn network parameters	negative	7.960074386704946
towards provably moral ai agents in bottom-up learning frameworks	examine moral machine decision making inspired central question posed rossi respect moral preferences ai systems based statistical machine learning provide natural way explain justify decisions used embedding morality machine way allows us prove nothing morally wrong happen argue evaluation held standards human agent removing demand ethical behaviour always achieved introduce four key meta-qualities desired moral standards proceed clarify prove agent correctly learn perform moral actions given set samples within certain error bounds group-dynamic approach enables us demonstrate learned models converge common function achieve stability explain valuable intrinsic consistency check made possible derivation logical statements machine learning model work proposes approach building ethical ai systems coming perspective artificial intelligence research sheds important light understanding much learning required order intelligent agent behave morally negligible error	positive	0
modelling and influencing the ai bidding war: a research agenda	race technological supremacy ai could lead serious negative consequences especially whenever ethical safety procedures underestimated even ignored leading potentially rejection ai general enjoy benefits provided safe ethical trustworthy ai systems crucial incentivise participants appropriate strategies ensure mutually beneficial normative behaviour safety-compliance parties involved little attention given understanding dynamics emergent behaviours arising ai bidding war moreover influence achieve certain desirable outcomes e.g ai public good participant compliance bridge gap paper proposes research agenda develop theoretical models capture key factors ai race revealing strategic behaviours may emerge hypothetical scenarios therein strategies incentive agreement modelling directly applicable systematically analyse different types incentives namely positive vs. negative peer vs. institutional combinations influence safety-compliant behaviours time behaviours configured ensure desired global outcomes studying time mechanisms influence ai development agenda provide actionable policies showing need employed deployed order achieve compliance thereby avoid disasters well loosing confidence trust ai general	positive	0
ranking-based deep cross-modal hashing	cross-modal hashing receiving increasing interests low storage cost fast query speed multi-modal data retrievals however existing hashing methods based hand-crafted raw level features objects may optimally compatible coding process besides hashing methods mainly designed handle simple pairwise similarity complex multilevel ranking semantic structure instances associated multiple labels well explored yet paper propose ranking-based deep cross-modal hashing approach rdcmh rdcmh firstly uses feature label information data derive semi-supervised semantic ranking list next expand semantic representation power hand-crafted features rdcmh integrates semantic ranking information deep cross-modal hashing jointly optimizes compatible parameters deep feature representations hashing functions experiments real multi-modal datasets show rdcmh outperforms competitive baselines achieves state-of-the-art performance cross-modal retrieval applications	negative	6.361288481100928
incorrigibility in the cirl framework	value learning system incentives follow shutdown instructions assuming shutdown instruction provides information technical sense actions lead valuable outcomes however assumption robust model mis-specification e.g. case programmer errors demonstrate presenting supervised pomdp scenarios errors parameterized reward function remove incentive follow shutdown commands difficulties parallel discussed soares et al 2015 paper corrigibility argue important consider systems follow shutdown commands weaker set assumptions e.g. one small verified module correctly implemented opposed entire prior probability distribution and/or parameterized reward function discuss difficulties simple ways attempt attain sorts guarantees value learning framework	positive	0
multiaccuracy: black-box post-processing for fairness in classification	prediction systems successfully deployed applications ranging disease diagnosis predicting credit worthiness image recognition even overall accuracy high systems may exhibit systematic biases harm specific subpopulations biases may arise inadvertently due underrepresentation data used train machine-learning model result intentional malicious discrimination develop rigorous framework *multiaccuracy* auditing post-processing ensure accurate predictions across *identifiable subgroups* algorithm multiaccuracy-boost works setting black-box access predictor relatively small set labeled data auditing importantly black-box framework allows improved fairness accountability predictions even predictor minimally transparent prove multiaccuracy-boost converges efficiently show initial model accurate identifiable subgroup post-processed model also experimentally demonstrate effectiveness approach improve accuracy among minority subgroups diverse applications image classification finance population health interestingly multiaccuracy-boost improve subpopulation accuracy e.g `` black women '' even sensitive features e.g `` race '' `` gender '' given algorithm explicitly	positive	0
fast pmi-based word embedding with efficient use of unobserved patterns	continuous word representations capture semantic information corpus building blocks many natural language processing tasks pre-trained word embeddings used sentiment analysis text classification question answering paper propose new word embedding algorithm works smoothed positive pointwise mutual information ppmi matrix obtained word-word co-occurrence counts one major contributions propose objective function optimization framework exploits full capacity “ negative examples ” unobserved insignificant wordword co-occurrences order push unrelated words away improves distribution words latent space also propose kernel similarity measure latent space effectively calculate similarities high dimensions moreover propose approximate alternative algorithm using modified vantage point tree reduce computational complexity algorithm |v |log|v respect number words vocabulary trained various word embedding algorithms articles wikipedia 2.1 billion tokens show method outperforms state-of-the-art word similarity tasks good margin	negative	7.689156826570979
complex moment-based supervised eigenmap for dimensionality reduction	dimensionality reduction methods project highdimensional data low-dimensional space matrix trace optimization widely used clustering classification matrix trace optimization problem leads eigenvalue problem low-dimensional subspace construction preserving certain properties original data however existing methods use eigenvectors construct low-dimensional space may lead loss useful information achieving successful classification herein overcome deficiency information loss propose novel complex moment-based supervised eigenmap including multiple eigenvectors dimensionality reduction furthermore proposed method provides general formulation matrix trace optimization methods incorporate ridge regression models linear dependency covariate variables univariate labels reduce computational complexity also propose efficient parallel implementation proposed method numerical experiments indicate proposed method competitive compared existing dimensionality reduction methods recognition performance additionally proposed method exhibits high parallel efficiency	negative	6.97032150166342
hierarchical deep feature learning for decoding imagined speech from eeg	propose mixed deep neural network strategy incorporating parallel combination convolutional cnn recurrent neural networks rnn cascaded deep autoencoders fully connected layers towards automatic identification imagined speech eeg instead utilizing raw eeg channel data compute joint variability channels form covariance matrix provide spatio-temporal representations eeg networks trained hierarchically extracted features passed onto next network hierarchy final classification using publicly available eeg based speech imagery database demonstrate around 23.45 improvement accuracy baseline method approach demonstrates promise mixed dnn approach complex spatialtemporal classification problems	negative	6.781747236382216
end-to-end structure-aware convolutional networks for knowledge base completion	knowledge graph embedding active research topic knowledge base completion progressive improvement initial transe transh distmult et al current state-of-the-art conve conve uses 2d convolution embeddings multiple layers nonlinear features model knowledge graphs model efficiently trained scalable large knowledge graphs however structure enforcement embedding space conve recent graph convolutional network gcn provides another way learning graph node embedding successfully utilizing graph connectivity structure work propose novel end-to-end structureaware convolutional network sacn takes benefit gcn conve together sacn consists encoder weighted graph convolutional network wgcn decoder convolutional network called conv-transe wgcn utilizes knowledge graph node structure node attributes edge relation types learnable weights adapt amount information neighbors used local aggregation leading accurate embeddings graph nodes node attributes graph represented additional nodes wgcn decoder conv-transe enables state-of-the-art conve translational entities relations keeps link prediction performance conve demonstrate effectiveness proposed sacn standard fb15k-237 wn18rr datasets gives 10 relative improvement state-of-theart conve terms hits 1 hits 3 hits 10	negative	6.80655578779988
improving hypernymy prediction via taxonomy enhanced adversarial learning	hypernymy basic semantic relation computational linguistics expresses “ is-a ” relation generic concept specific instances serving backbone taxonomies ontologies although several nlp tasks related hypernymy prediction extensively addressed methods fully exploited large number hypernymy relations web-scale taxonomies	negative	7.813417548430152
 fair forests: regularized tree induction to minimize model bias	potential lack fairness outputs machine learning algorithms recently gained attention within research community well society broadly surprisingly prior work developing tree-induction algorithms building fair decision trees fair random forests methods widespread popularity one simultaneously interpretable non-linear easy-to-use paper develop knowledge first technique induction fair decision trees.we show `` fair forest '' retains benefits tree-based approach providing greater accuracy fairness alternatives `` group fairness '' `` individual fairness '' also introduce new measures fairness able handle multinomial continues attributes well regression problems opposed binary attributes labels finally demonstrate new robust evaluation procedure algorithms considers dataset entirety rather specific protected attribute	positive	0
towards gene function prediction via multi-networks representation learning	multi-networks integration methods achieved prominent performance many network-based tasks approaches often incur information loss problem paper propose novel multi-networks representation learning method based semi-supervised autoencoder termed deepmne captures complex topological structures network takes correlation among multinetworks account experimental results two realworld datasets indicate deepmne outperforms existing state-of-the-art algorithms	negative	7.3796397324731515
towards a just theory of measurement: a principled social measurement assurance program	formal definitions fairness machine learning ml proposed place within broader institutional model fair decision-making remains ambiguous paper interpret ml tool revealing measures fail capture purported constructs interest augmenting given institution 's understanding interventions priorities rather codifying `` fair '' principles ml models directly use ml thus understood form quality assurance existing institutions exposing epistemic fault lines measurement practices drawing friedler et al 's 2016 recent discussion representational mappings previous discussions ontology measurement propose social measurement assurance program smap ml encourages expert deliberation given decision-making procedure examining unanticipated previously unexamined covariates example apply rawlsian principles fairness smap produce provisional theory measurement would guide use ml achieving fairness case child abuse allegheny county	positive	0
transferable attention for domain adaptation	recent work domain adaptation bridges different domains adversarially learning domain-invariant representation distinguished domain discriminator existing methods adversarial domain adaptation mainly align global images across source target domains however obvious regions image transferable forcefully aligning untransferable regions may lead negative transfer furthermore images significantly dissimilar across domains resulting weak image-level transferability end present transferable attention domain adaptation tada focusing adaptation model transferable regions images implement two types complementary transferable attention transferable local attention generated multiple region-level domain discriminators highlight transferable regions transferable global attention generated single image-level domain discriminator highlight transferable images extensive experiments validate proposed models exceed state art results standard domain adaptation datasets	negative	7.5030882329447195
uncovering and mitigating algorithmic bias through learned latent structure	recent research highlighted vulnerabilities modern machine learning based systems bias especially towards segments society under-represented training data work develop novel tunable algorithm mitigating hidden potentially unknown biases within training data algorithm fuses original learning task variational autoencoder learn latent structure within dataset adaptively uses learned latent distributions re-weight importance certain data points training method generalizable across various data modalities learning tasks work use algorithm address issue racial gender bias facial detection systems evaluate algorithm pilot parliaments benchmark ppb dataset specifically designed evaluate biases computer vision systems demonstrate increased overall performance well decreased categorical bias debiasing approach	positive	0
shared moral foundations of embodied artificial intelligence	sophisticated ai 's make decisions respond complex situations may wonder whether decisions align moral values human beings argue pessimistic worries value alignment problem overstated order achieve intelligence full generality adaptiveness cognition ai 's need embodied sense embodied cognition research program embodiment yield ai 's share moral foundations namely coordination sociality acknowledgement shared resources consequently expect broad moral alignment human beings ai 's ai 's likely show variation values find amongst human beings	positive	0
companion robots: the hallucinatory danger of human-robot interactions	advent so-called companion robots raising many ethical concerns among scholars public opinion focusing mainly robots caring elderly paper analyze concerns distinguish directly ascribable robotic instead pre-existent one `` deception objection '' namely ethical unacceptability deceiving user simulated nature robot 's behaviors argue inconsistency charge today formulated underline risk human-robot interaction become hallucinatory relation human would subjectify robot dynamic meaning-overload finally analyze definition `` quasi-other '' relating notion `` uncanny '' goal paper argue main concern companion robots simulation human-like interaction absence autonomous robotic horizon meaning addition absence could lead human build hallucinatory reality based relation robot	positive	0
the dark side of ethical robots	concerns risks associated advances artificial intelligence prompted calls greater efforts toward robust beneficial ai including machine ethics recently roboticists responded initiating development so-called ethical robots robots would ideally evaluate consequences actions morally justify choices emerging field promises develop extensively next years however paper point inherent limitation emerging field ethical robots show building ethical robots also inevitably enables construction unethical robots three experiments show remarkably easy modify ethical robot behaves competitively even aggressively reason cognitive machinery required make ethical robot always corrupted make unethical robots discuss implications finding governance ethical robots conclude risks unscrupulous actors might compromise robot 's ethics great raise serious doubts wisdom embedding ethical decision making real-world safety-critical robots driverless cars	positive	0
jointly extracting multiple triplets with multilayer translation constraints	triplets extraction essential pivotal step automatic knowledge base construction captures structural information unstructured text corpus conventional extraction models use pipeline named entity recognition relation classification extract entities relations respectively ignore connection two tasks recently several neural network-based models proposed tackle problem achieved state-of-the-art performance however unable extract multiple triplets single sentence yet commonly seen real-life scenarios close gap propose paper joint neural extraction model multitriplets namely tme capable adaptively discovering multiple triplets simultaneously sentence via ranking translation mechanism experiment tme exhibits superior performance achieves improvement 37.6 f1 score state-of-the-art competitors	negative	8.189803655957803
privacy-preserving machine learning based data analytics on edge devices	emerging machine learning ml techniques deep neural network widely used today 's applications services however social awareness privacy personal data rapidly rising becomes pressing challenging societal issue keep personal data private benefit data analytics power ml techniques time paper argue avoid costs reduce latency data processing minimise raw data revealed service providers many future ai ml services could deployed users devices internet edge rather putting everything cloud moving ml-based data analytics cloud edge devices brings series challenges make three contributions paper first besides widely discussed resource limitation edge devices identify two challenges yet recognised existing literature lack suitable models users difficulties deploying services users second present preliminary work first systematic solution i.e zoo fully support construction composing deployment ml models edge local devices third deployment example ml service proved easy compose deploy zoo evaluation shows superior performance compared state-of-art deep learning platforms google ml services	positive	0
utilizing housing resources for homeless youth through the lens of multiple multi-dimensional knapsacks	1 million homeless youth u.s. year reduce homelessness u.s. housing urban development hud housing communities provide housing programs/services homeless youth goal improving long-term situation housing communities facing difficult task filling housing programs many youths possible subject resource constraints meeting needs youth currently assignment manually done humans working housing communities paper consider problem assigning homeless youth housing programs subject resource constraints provide initial abstract model setting show problem maximizing total assigned youth programs model apx-hard solve problem non-trivially formulate multiple multi-dimensional knapsack problem mmdkp known approximation algorithm provide first interpretable easy-to-use greedy algorithm logarithmic approximation ratio solving general mmdkp conduct experiments random realistic instances housing assignment settings show algorithm efficient effective solving large instances 1 million youth	positive	0
sub-committee approval voting and generalized justified representation axioms	social choice replete various settings including single-winner voting multi-winner voting probabilistic voting multiple referenda public decision making study general model social choice called sub-committee voting scv simultaneously generalizes settings focus sub-committee voting approvals propose extensions justified representation axioms considered proportional representation approval-based committee voting study properties relations axioms axioms analyze whether representative committee exists also examine complexity computing verifying committee	positive	0
actionable auditing: investigating the impact of publicly naming biased performance results of commercial ai products	although algorithmic auditing emerged key strategy expose systematic biases embedded software platforms struggle understand real-world impact audits scholarship impact algorithmic audits increasing algorithmic fairness transparency commercial systems nascent analyze impact publicly naming disclosing performance results biased ai systems investigate commercial impact gender shades first algorithmic audit gender skin type performance disparities commercial facial analysis models paper 1 outlines audit design structured disclosure procedure used gender shades study 2 presents new performance metrics targeted companies ibm microsoft megvii face++ pilot parliaments benchmark ppb august 2018 3 provides performance results ppb non-target companies amazon kairos 4 explores differences company responses shared corporate communications contextualize differences performance ppb within 7 months original audit find three targets released new api versions targets reduced accuracy disparities males females darker lighter-skinned subgroups significant update occurring darker-skinned female subgroup underwent 17.7 30.4 reduction error audit periods minimizing disparities led 5.72 8.3 reduction overall error pilot parliaments benchmark ppb target corporation apis overall performance non-targets amazon kairos lags significantly behind targets error rates 8.66 6.60 overall error rates 31.37 22.50 darker female subgroup respectively	positive	0
learning a visual tracker from a single movie without annotation	recent success deep network visual trackers learning largely relies human labeled data however expensive annotate recently unsupervised methods proposed explore learning visual trackers without labeled data performance lags far behind supervised methods identify main bottleneck methods inconsistent objectives off-line training online tracking stages address problem propose novel unsupervised learning pipeline based discriminative correlation filter network method iteratively updates tracker alternating target localization network optimization particular propose learn network single movie could easily obtained collecting thousands video clips millions images extensive experiments demonstrate approach insensitive employed movies trained visual tracker achieves leading performance among existing unsupervised learning approaches even compared network trained human labeled bounding boxes tracker achieves similar results many tracking benchmarks code available https //github.com/zjjconan/ul-tracker-aaai2019	negative	7.872059821151197
hierarchical attention network for image captioning	recently attention mechanism successfully applied image captioning existing attention methods established low-level spatial features high-level text features limits richness captions paper propose hierarchical attention network han enables attention calculated pyramidal hierarchy features synchronously pyramidal hierarchy consists features diverse semantic levels allows predicting different words according different features hand due different modalities features multivariate residual module mrm proposed learn joint representations features mrm able model projections extract relevant relations among different features furthermore introduce context gate balance contribution different features compared existing methods approach applies hierarchical features exploits several multimodal integration strategies significantly improve performance han verified benchmark mscoco dataset experimental results indicate model outperforms state-of-the-art methods achieving bleu1 score 80.9 cider score 121.7 karpathy ’ test split	negative	7.2843496466230135
the adversarial attack and detection under the fisher information metric	many deep learning models vulnerable adversarial attack i.e. imperceptible intentionally-designed perturbations input cause incorrect output networks paper using information geometry provide reasonable explanation vulnerability deep learning models considering data space non-linear space fisher information metric induced neural network first propose adversarial attack algorithm termed one-step spectral attack ossa method described constrained quadratic form fisher information matrix optimal adversarial perturbation given first eigenvector vulnerability reflected eigenvalues larger eigenvalue vulnerable model attacked corresponding eigenvector taking advantage property also propose adversarial detection method eigenvalues serving characteristics attack detection algorithms numerically optimized work efficiently large datasets evaluations show superior performance compared methods implying fisher information promising approach investigate adversarial attacks defenses	negative	7.1569299341063015
 from algorithmic black boxes to adaptive white boxes: declarative decision-theoretic ethical programs as codes of ethics	many programs algorithms largely parameterized especially based heuristics quality results depends parameter setting different inputs often different optimal settings program tuning hence great importance existing tuning techniques treat program black-box hence leverage internal program states achieve better tuning propose white-box tuning technique implemented library user compose complex program tuning tasks adding small number library calls original program providing callback functions experiments 13 widely-used real-world programs show technique substantially improves data processing results outperforms opentuner state-of-the-art black-box tuning technique	positive	0
designing non-greedy reinforcement learning agents with diminishing reward shaping	paper intends address issue rl agents possessing varying capabilities resources may acquired stronger agents leaving weaker ones `` starving '' introduce simple method train non-greedy agents multi-agent reinforcement learning scenarios nearly extra cost model achieve following goals designing non-greedy agent non-homogeneous equality need local information cost-effective generalizable configurable propose idea diminishing reward makes agent feel less satisfied consecutive rewards obtained idea allows agents behave less greedy with-out need explicitly coding ethical pattern monitor agents status given framework resources distributed equally without running risk reaching homogeneous equality designed two games gathering game hunter prey evaluate quality model	positive	0
detecting bias in black-box models using transparent model distillation	dissertation research grounded field interpretability aim develop methods explain interpret predictions black-box machine learning models help creators well users machine learning models increase trust understanding models doctoral consortium paper summarize previous current research projects interpretability describe future plans research area	positive	0
monogrnet: a geometric reasoning network for monocular 3d object localization	localizing objects real 3d space plays crucial role scene understanding particularly challenging given single rgb image due geometric information loss imagery projection propose monogrnet amodal 3d object localization monocular rgb image via geometric reasoning observed 2d projection unobserved depth dimension monogrnet single unified network composed four task-specific subnetworks responsible 2d object detection instance depth estimation ide 3d localization local corner regression unlike pixel-level depth estimation needs per-pixel annotations propose novel ide method directly predicts depth targeting 3d bounding box ’ center using sparse supervision 3d localization achieved estimating position horizontal vertical dimensions finally monogrnet jointly learned optimizing locations poses 3d bounding boxes global context demonstrate monogrnet achieves state-of-the-art performance challenging datasets	negative	7.614550418802537
regularizing fully convolutional networks for time series classification by decorrelating filters	deep neural networks prone overfitting especially small training data regimes often networks overparameterized resulting learned weights tend strong correlations however convolutional networks general fully convolution neural networks fcns particular shown relatively parameter efficient recently successfully applied time series classification tasks paper investigate application different regularizers correlation learned convolutional filters fcns using batch normalization bn regularizer time series classification tsc tasks results demonstrate despite orthogonal initialization filters average correlation across filters especially filters higher layers tends increase training proceeds indicating redundancy filters mitigate redundancy propose strong regularizer using simple yet effective filter decorrelation proposed method yields significant gains classification accuracy 44 diverse time series datasets ucr tsc benchmark repository	negative	8.202195161618874
fair transfer learning with missing protected attributes	risk assessment growing use machine learning models used high-stakes applications especially ones regulated anti-discrimination laws governed societal norms fairness important ensure learned models propagate scale biases may exist training data paper add additional challenge beyond fairness unsupervised domain adaptation covariate shift source target distribution motivated real-world problem risk assessment new markets health insurance united states mobile money-based loans east africa provide precise formulation machine learning covariate shift score parity problem formulation focuses situations protected attributes available either source target domain propose two new weighting methods prevalence-constrained covariate shift pccs require protected attributes target domain target-fair covariate shift tfcs require protected attributes source domain empirically demonstrate efficacy two applications	positive	0
deep reinforcement learning via past-success directed exploration	balance exploration exploitation always core challenge reinforcement learning paper proposes “ past-success exploration strategy combined softmax action selection ” pse-softmax adaptive control method taking advantage characteristics online learning process agent adapt exploration parameters dynamically proposed strategy tested openai gym discrete continuous control tasks experimental results show pse-softmax strategy delivers better performance deep reinforcement learning algorithms basic exploration strategies	negative	6.9842486516572535
measuring and mitigating unintended bias in text classification	introduce illustrate new approach measuring mitigating unintended bias machine learning models definition unintended bias parameterized test set subset input features illustrate used evaluate text classifiers using synthetic test set public corpus comments annotated toxicity wikipedia talk pages also demonstrate imbalances training data lead unintended bias resulting models therefore potentially unfair applications use set common demographic identity terms subset input features measure bias technique permits analysis common scenario demographic information authors readers unavailable bias mitigation must focus content text mitigation method introduce unsupervised approach based balancing training dataset demonstrate approach reduces unintended bias without compromising overall model quality	positive	0
fully convolutional video captioning with coarse-to-fine and inherited attention	automatically generating natural language description video extremely complicated challenging task tackle obstacles traditional lstm-based model video captioning propose novel architecture generate optimal descriptions videos focuses constructing new network structure generate sentences superior basic model lstm establishing special attention mechanisms provide useful visual information caption generation scheme discards traditional lstm exploits fully convolutional network coarse-to-fine inherited attention designed according characteristics fully convolutional structure model outperform basic lstm-based model also achieve comparable performance state-of-the-art methods	negative	7.545909158470749
graph cnns with motif and variable temporal block for skeleton-based action recognition	hierarchical structure different semantic roles joints human skeleton convey important information action recognition conventional graph convolution methods modeling skeleton structure consider physically connected neighbors joint joints type thus failing capture highorder information work propose novel model motif-based graph convolution encode hierarchical spatial structure variable temporal dense block exploit local temporal information different ranges human skeleton sequences moreover employ non-local block capture global dependencies temporal domain attention mechanism model achieves improvements stateof-the-art methods two large-scale datasets	negative	8.121088803629391
mapping missing population in rural india: a deep learning approach with satellite imagery	millions people worldwide absent country 's census accurate current granular population metrics critical improving government allocation resources measuring disease control responding natural disasters studying aspect human life communities satellite imagery provide sufficient information build population map without cost time government census present two convolutional neural network cnn architectures efficiently effectively combine satellite imagery inputs multiple sources accurately predict population density region paper use satellite imagery rural villages india population labels 2011 secc census best model achieves better performance previous papers well landscan community standard global population distribution	positive	0
human action transfer based on 3d model reconstruction	present practical effective method human action transfer given sequence source action limited target information aim transfer motion source target although recent works based gan vae achieved impressive results action transfer 2d still exists lot problems avoided distorted discontinuous human body shape blurry cloth texture paper try solve problems novel 3d viewpoint one hand design skeleton-to-3d-mesh generator generate 3d model achieves huge improvement appearance reconstruction furthermore add temporal connection improve smoothness model hand instead directly utilizing image rgb space transform target appearance information uv space pose transformation specially unlike conventional graphics render method directly projects visible pixels uv space transformation according pixel ’ semantic information perform experiments human3.6m humaneva-i evaluate performance pose generator qualitative quantitative results show method outperforms methods based generation method 2d additionally compare render method graphic methods human3.6m people-snapshot comparison results show render method robust effective	negative	7.3550930434139445
recurrent poisson process unit for speech recognition	past years resurgence interest using recurrent neural network-hidden markov model rnn-hmm automatic speech recognition asr modern recurrent network models long shortterm memory lstm simple recurrent unit sru demonstrated promising results task recently several scientific perspectives fields neuroethology speech production suggest human speech signals may represented discrete point patterns involving acoustic events speech signal based hypothesis may pose challenges rnn-hmm acoustic modeling firstly arbitrarily discretizes continuous input interval features fixed frame rate may introduce discretization errors secondly occurrences acoustic events unknown furthermore training targets rnn-hmm obtained inferior models giving rise misalignments paper propose recurrent poisson process rpp seen collection poisson processes series time intervals intensity evolves according rnn hidden states encode history acoustic signal aims allocating latent acoustic events continuous time events efficiently drawn rpp using sampling-free solution analytic form speech signal containing latent acoustic events reconstructed/sampled dynamically discretized acoustic features using linear interpolation weight parameters estimated onset events processes integrated sru forming final model called recurrent poisson process unit rppu experimental evaluations asr tasks including chime-2 wsj0 wsj0 1 demonstrate effectiveness benefits rppu example achieves relative wer reduction 10.7 state-of-the-art models wsj0	negative	7.019006335191079
segan: structure-enhanced generative adversarial network for compressed sensing mri reconstruction	generative adversarial networks gans powerful tools reconstructing compressed sensing magnetic resonance imaging cs-mri however recent works lack exploration structure information mri images crucial clinical diagnosis tackle problem propose structure-enhanced gan segan aims restoring structure information local global scale segan defines new structure regularization called patch correlation regularization pcr allows efficient extraction structure information addition enhance ability uncover structure information propose novel generator su-net incorporating multiple-scale convolution filters layer besides theoretically analyze convergence stochastic factors contained training process experimental results show segan able learn target structure information achieves state-of-theart performance cs-mri reconstruction	negative	5.254656653181883
safeguarded dynamic label regression for noisy supervision	learning noisy labels imperative big data era since reduces expensive labor accurate annotations previous method learning noise transition enjoyed theoretical guarantees applied scenario class-conditional noise however approach critically depends accurate pre-estimated noise transition usually impractical subsequent improvement adapts preestimation form softmax layer along training progress however parameters softmax layer highly tweaked fragile performance easily get stuck undesired local minimums overcome issue propose latent class-conditional noise model lccn models noise transition bayesian form projecting noise transition dirichlet-distributed space learning constrained simplex instead adhoc parametric space furthermore specially deduce dynamic label regression method lccn iteratively infer latent true labels jointly train classifier model noise approach theoretically safeguards bounded update noise transition avoids arbitrarily tuning via batch samples extensive experiments conducted controllable noise data cifar10 cifar-100 datasets agnostic noise data clothing1m webvision17 datasets experimental results demonstrated proposed model outperforms several state-of-the-art methods	negative	6.9624016946181655
robust estimation of similarity transformation for visual object tracking	existing correlation filter-based tracking approaches estimate simple axis-aligned bounding boxes capable recovering underlying similarity transformation tackle challenging problem paper propose new correlation filter-based tracker novel robust estimation similarity transformation large displacements order efficiently search large 4-dof space real-time formulate problem two 2-dof sub-problems apply efficient block coordinates descent solver optimize estimation result specifically employ efficient phase correlation scheme deal scale rotation changes simultaneously log-polar coordinates moreover variant correlation filter used predict translational motion individually experimental results demonstrate proposed tracker achieves promising prediction performance compared state-of-the-art visual object tracking methods still retaining advantages high efficiency simplicity conventional correlation filter-based tracking methods	negative	4.20368294805121
deep reactive policies for planning in stochastic nonlinear domains	recent advances applying deep learning planning shown deep reactive policies drps powerful fast decision-making complex environments however important limitation current drp-based approaches either need optimal planners used ground truth supervised learning setting sample complexity high-variance policy gradient estimators particularly troublesome continuous state-action domains order overcome limitations introduce framework training drps continuous stochastic spaces via gradient-based policy search general approach explicitly encode parametric policy deep neural network formulate probabilistic planning problem optimization task stochastic computation graph exploiting re-parameterization transition probability densities optimization solved leveraging gradient descent algorithms able handle non-convex objective functions benchmark approach stochastic planning domains exhibiting arbitrary differentiable nonlinear transition cost functions e.g. reservoir control hvac navigation results show drps 125,000 continuous action parameters optimized approach problems 30 state fluents 30 action fluents inexpensive hardware 6 minutes also observed speedup 5 orders magnitude average inference time per decision step drps compared state-of-the-art online gradient-based planners level solution quality required	negative	6.535203834355343
mfbo-ssm: multi-fidelity bayesian optimization for fast inference in state-space models	nonlinear state-space models ubiquitous modeling real-world dynamical systems sequential monte carlo smc techniques also known particle methods well-known class parameter estimation methods general class state-space models existing smc-based techniques rely excessive sampling parameter space makes computation intractable large systems tall data sets bayesian optimization techniques used fast inference state-space models intractable likelihoods techniques aim find maximum likelihood function sequential sampling parameter space single smc approximator various smc approximators different fidelities computational costs often available sample-based likelihood approximation paper propose multi-fidelity bayesian optimization algorithm inference general nonlinear state-space models mfbo-ssm enables simultaneous sequential selection parameters approximators accuracy speed algorithm demonstrated numerical experiments using synthetic gene expression data gene regulatory network model real data vix stock price index	negative	8.200852691195905
killer robots and human dignity	lethal autonomous weapon systems laws become center internationally relevant ethical debate deontological arguments based putative legal compliance failures creation accountability gaps along wide consequentialist arguments based factors like ease engaging wars leveraged number different states organizations try reach global consensus ban laws paper focus one strand deontological arguments-ones based human dignity merely asserting laws pose threat human dignity would question begging independent evidence based morally relevant distinction humans laws needed least four reasons think capacity emotion morally relevant distinction first concept human dignity given subjective definition whether lethal force administered humans laws seems irrelevant second far clear human combatants either relevant capacity emotion capacity exercised relevant circumstances third capacity emotion actually impediment exercising combatant 's ability treat enemy respectfully fourth strong inductive evidence believe capacity sufficiently well described carried artificially intelligent programs	positive	0
large-scale visual relationship understanding	large scale visual understanding challenging requires model handle widely-spread imbalanced distribution 〈subject relation object〉 triples real-world scenarios large numbers objects relations seen commonly others barely seen develop new relationship detection model embeds objects relations two vector spaces discriminative capability semantic affinity preserved learn visual semantic module map features two modalities shared space matched pairs features discriminate unmatched also maintain close distances semantically similar ones benefiting model achieve superior performance even visual entity categories scale 80,000 extremely skewed class distribution demonstrate efficacy model large imbalanced benchmark based visual genome comprises 53,000+ objects 29,000+ relations scale previous work evaluated show superiority model competitive baselines original visual genome dataset 80,000+ categories also show state-of-the-art performance vrd dataset scene graph dataset subset visual genome 200 categories	negative	6.633199239906389
 software malpractice in the age of ai: a guide for the wary tech company	professional malpractice concept heightened duties entrusted special knowledge crucial tasks rooted history yet since dawn computer age courts united states almost universally rejected theory software malpractice declining hold software engineers professional standards doctors lawyers engineers changing however speed software based artificial intelligence technologies replacing professionals already subject professional liability society already decided cases millennia ago tasks warrant special accountability new analysis human closest line adverse event ai expands pressure courts go one level causal chain search human agency professional accountability mount essay analyzes case law rejecting software malpractice clues doctrine might go age ai discusses technology companies learn safety enhancements doctors lawyers historic professionals adapted heightened legal scrutiny years	positive	0
learning to steer by mimicking features from heterogeneous auxiliary networks	training many existing end-to-end steering angle prediction models heavily relies steering angles supervisory signal without learning much richer contexts methods susceptible presence sharp road curves challenging traffic conditions strong shadows severe lighting changes paper considerably improve accuracy robustness predictions heterogeneous auxiliary networks feature mimicking new effective training method provides us much richer contextual signals apart steering direction specifically train steering angle predictive model distilling multi-layer knowledge multiple heterogeneous auxiliary networks perform related different tasks e.g. image segmentation optical flow estimation opposed multi-task learning method require expensive annotations related tasks target set made possible applying contemporary off-the-shelf networks target set mimicking features different layers transformation auxiliary networks discarded training without affecting runtime efficiency model approach achieves new state-of-the-art udacity comma.ai outperforming previous best large margin 12.8 52.1 1 respectively encouraging results also shown berkeley deep drive bdd dataset	negative	5.102598766388837
ewgan: entropy-based wasserstein gan for imbalanced learning	paper propose novel oversampling strategy dubbed entropy-based wasserstein generative adversarial network ewgan generate data samples minority classes imbalanced learning first construct entropyweighted label vector class characterize data imbalance different classes concatenate entropyweighted label vector original feature vector data sample feed wgan model train generator generator trained concatenate entropy-weighted label vector random noise feature vectors feed generator generate data samples minority classes experimental results two benchmark datasets show samples generated proposed oversampling strategy help improve classification performance data highly imbalanced furthermore proposed strategy outperforms state-of-the-art oversampling algorithms terms classification accuracy	negative	8.007920125324745
the right to confront your accuser: opening the black box of forensic dna software	results forensic dna software systems regularly introduced compelling evidence criminal trials requests defendants evaluate results generated often denied furthermore mounting evidence problems failures disclose substantial changes methodology oversight bodies substantial differences results generated different software systems society purports guarantee defendants right face accusers confront evidence role black-box forensic software systems moral decision making criminal justice paper examine case forensic statistical tool fst forensic dna system developed 2010 new york city 's office chief medical examiner ocme 5 years expert witness review requested defense teams denied even protective order system used 1300 criminal cases first expert review finally permitted 2016 many problems identified including undisclosed function capable dropping evidence could beneficial defense overall findings substantial motion release full source code fst publicly granted paper quantify impact undisclosed function samples ocme 's validation study discuss potential impact individual defendants specifically find 104 439 samples 23.7 triggered undisclosed data-dropping behavior change skewed results toward false inclusion individuals whose dna present evidence sample beyond consider changes criminal justice system could prevent problems like going unresolved future	positive	0
embodiment, anthropomorphism, and intellectual property rights for ai creations	computational creativity emerging branch artificial intelligence ai concerned algorithms create novel high-quality ideas artifacts either autonomously semi-autonomously collaboration people quite simply algorithms may described artificial innovation engines technologies raise questions authorship/inventorship agency become muddled social context induced ai may physically-embodied anthropomorphized questions fundamentally intertwined provision appropriate incentives conducting commercializing computational creativity research intellectual property regimes paper reviews current understanding intellectual property rights ai explores possible framings intellectual property policy social context	positive	0
putting fairness principles into practice: challenges, metrics, and improvements	researchers become aware passionate algorithmic fairness explosion papers laying new metrics suggesting algorithms address issues calling attention issues existing applications machine learning research greatly expanded understanding concerns challenges deploying machine learning much less work seeing rubber meets road paper provide case-study application fairness machine learning research production classification system offer new insights measure address algorithmic fairness issues discuss open questions implementing equality opportunity describe fairness metric conditional equality takes account distributional differences provide new approach improve fairness metric model training demonstrate efficacy improving performance real-world product	positive	0
similarity preserving deep asymmetric quantization for image retrieval	quantization widely adopted large-scale multimedia retrieval due effectiveness coding highdimensional data deep quantization models demonstrated achieve state-of-the-art retrieval accuracy however training deep models given large-scale database highly time-consuming large amount parameters involved existing deep quantization methods often sample subset database training may end unsatisfactory retrieval performance large portion label information discarded alleviate problem propose novel model called similarity preserving deep asymmetric quantization spdaq directly learn compact binary codes quantization codebooks items database efficiently spdaq makes use image subset well label information database items image subset items database items mapped two different correlated distributions label similarity well preserved efficient optimization algorithm proposed learning extensive experiments conducted four widely-used benchmark datasets demonstrate superiority proposed spdaq model	negative	5.988908659652225
learning existing social conventions via observationally augmented self-play	order artificial agents coordinate effectively people must act consistently existing conventions e.g navigate traffic language speak coordinate teammates group 's conventions viewed choice equilibrium coordination game consider problem agent learning policy coordination game simulated environment using policy enters existing group multiple possible conventions show learning policy via multi-agent reinforcement learning marl likely find policies achieve high payoffs training time fail coordinate real group agent enters assume access small number samples behavior true convention show augment marl objective help find policies consistent real group 's convention three environments literature traffic communication team coordination observe augmenting marl small amount imitation learning greatly increases probability strategy found marl fits well existing social convention show works even environment standard training methods rarely find true convention agent 's partners	positive	0
jill watson doesn’t care if you’re pregnant: grounding ai ethics in empirical studies	jill watson name virtual teaching assistant georgia tech course artificial intelligence jill answers routine frequently asked questions class discussion forum paper outline ethical issues arose development deployment virtual teaching assistant posit experiments jill watson critical deeply understanding ai ethics	positive	0
near-lossless binarization of word embeddings	word embeddings commonly used starting point many nlp models achieve state-of-the-art performances however large vocabulary many dimensions floating-point representations expensive terms memory calculations makes unsuitable use low-resource devices method proposed paper transforms real-valued embeddings binary embeddings preserving semantic information requiring 128 256 bits vector leads small memory footprint fast vector operations model based autoencoder architecture also allows reconstruct original vectors binary ones experimental results semantic similarity text classification sentiment analysis tasks show binarization word embeddings leads loss ∼2 accuracy vector size reduced 97 furthermore top-k benchmark demonstrates using binary vectors 30 times faster using real-valued vectors	negative	6.610019674340947
automated rule base completion as bayesian concept induction	considerable attention recently devoted problem automatically extending knowledge bases applying form inductive reasoning vast majority existing work centred around so-called knowledge graphs paper consider setting input consists set existential rules end exploit vector space representation considered concepts partly induced rule base partly pre-trained word embedding inspired recent approaches concept induction model rule templates vector space embedding using gaussian distributions unlike many existing approaches learn rules directly exploiting regularities given rule base require database concept relation instances given result method applied wide variety ontologies present experimental results demonstrate effectiveness method	negative	7.515239497064613
segregated temporal assembly recurrent networks for weakly supervised multiple action detection	paper proposes segregated temporal assembly recurrent star network weakly-supervised multiple action detection model learns untrimmed videos supervision video-level labels makes prediction intervals multiple actions specifically first assemble video clips according class labels attention mechanism learns class-variable attention weights thus helps noise relieving background actions secondly build temporal relationship actions feeding assembled features enhanced recurrent neural network finally transform output recurrent neural network corresponding action distribution order generate precise temporal proposals design score term called segregated temporal gradient-weighted class activation mapping st-gradcam fused attention weights experiments thumos ’ 14 activitynet1.3 datasets show approach outperforms state-of-theart weakly-supervised method performs par fully-supervised counterparts	negative	6.898770641855663
costs and benefits of fair representation learning	machine learning algorithms increasingly used make support important decisions people 's lives led interest problem fair classification involves learning make decisions non-discriminatory respect sensitive variable race gender several methods proposed solve problem including fair representation learning cleans input data used algorithm remove information sensitive variable show using fair representation learning intermediate step fair classification incurs cost compared directly solving problem refer thecost mistrust show fair representation learning fact addresses different problem interest data user trusted access sensitive variable quantify benefits fair representation learning showing subsequent use cleaned data unfair benefits identify result restricting decisions adversarial data users costs due applying restrictions data users	positive	0
dueling bandits with qualitative feedback	formulate study novel multi-armed bandit problem called qualitative dueling bandit qdb problem agent observes numeric qualitative feedback pulling arm employ regret dueling bandit db problem duel carried comparing qualitative feedback although naively use classic db algorithms solving qdb problem reduction significantly worsens performance—actually qdb problem probability one arm wins duel another arm directly estimated without carrying actual duels paper1 propose direct algorithms qdb problem theoretical analysis shows proposed algorithms significantly outperform db algorithms incorporating qualitative feedback experimental results also demonstrate vast improvement existing db algorithms	negative	7.323450135765597
hierarchical classification based on label distribution learning	hierarchical classification challenging problem class labels organized predefined hierarchy one primary challenge hierarchical classification small training set issue local module local classifiers previous hierarchical classification approaches prone over-fitting becomes major bottleneck hierarchical classification fortunately labels local module correlated siblings true label provide additional supervision information instance paper proposes novel method deal small training set issue key idea method represent correlation among labels label distribution generates label distribution contains supervision information label given instance learns mapping instance label distribution experimental results several hierarchical classification datasets show method significantly outperforms state-of-theart hierarchical classification approaches	negative	6.229359105695039
counterfactual fairness in text classification through robustness	paper study counterfactual fairness text classification asks question would prediction change sensitive attribute referenced example different toxicity classifiers demonstrate counterfactual fairness issue predicting `` people gay '' toxic `` people straight '' nontoxic offer metric counterfactual token fairness ctf measuring particular form fairness text classifiers describe relationship group fairness offer three approaches blindness counterfactual augmentation counterfactual logit pairing clp optimizing counterfactual token fairness training bridging robustness fairness literature empirically find blindness clp address counterfactual token fairness methods harm classifier performance varying tradeoffs group fairness approaches measurement optimization provide new path forward addressing fairness concerns text classification	positive	0
robots can be more than black and white: examining racial bias towards robots	previous studies showed using 'shooter bias paradigm people demonstrate similar racial bias toward dark colored robots light colored robots i.e. black vs. white toward humans similar skin tones 3 however effect could argued result social priming additionally raises question people might respond robots middle color spectrum i.e. brown whether effects moderated perceived anthropomorphism robots conducted two experiments first examine whether shooter bias tendencies shown towards robots driven social priming whether diversification robot color level anthropomorphism influenced shooter bias results showed shooter bias influenced social priming interestingly introducing new color robot removed shooter bias tendencies entirely however varying anthropomorphism robots moderate level shooter bias contrary expectations robots perceived participants different levels anthropomorphism	positive	0
kernelized hashcode representations for relation extraction	kernel methods produced state-of-the-art results number nlp tasks relation extraction suffer poor scalability due high cost computing kernel similarities natural language structures recently proposed technique kernelized locality-sensitive hashing klsh significantly reduce computational cost applicable classifiers operating knn graphs propose use random subspaces klsh codes efficiently constructing explicit representation nlp structures suitable general classification methods propose approach optimizing klsh model classification problems maximizing approximation mutual information klsh codes feature vectors class labels evaluate proposed approach biomedical relation extraction datasets observe significant robust improvements accuracy w.r.t state-ofthe-art classifiers along drastic orders-of-magnitude speedup compared conventional kernel methods	negative	7.0000914465636015
a meta-learning approach for custom model training	transfer-learning meta-learning two effective methods apply knowledge learned large data sources new tasks few-class few-shot target task settings i.e classes training examples available target task meta-learning approaches optimize future task learning outperformed typical transfer approach initializing model weights pretrained starting point experimentally show metalearning algorithms work well few-class setting generalize well many-shot many-class cases paper propose joint training approach combines transfer-learning meta-learning benefiting advantages method obtains improved generalization performance unseen target tasks few- many-class few- many-shot scenarios	negative	5.746468892204575
feature sampling based unsupervised semantic clustering for real web multi-view content	real web datasets often associated multiple views long short commentaries users preference however rapid growth user generated texts view dataset large feature space leads computational challenge matrix decomposition process paper propose novel multi-view clustering algorithm based non-negative matrix factorization attempts use feature sampling strategy order reduce complexity iteration process particular method exploits unsupervised semantic information learning process capture intrinsic similarity graph regularization moreover use hilbert schmidt independence criterion hsic explore unsupervised semantic diversity information among multi-view contents one web item overall objective minimize loss function multi-view non-negative matrix factorization combines intra-semantic similarity graph regularizer inter-semantic diversity term compared state-of-the-art methods demonstrate effectiveness proposed method large real-world dataset doucom three smaller datasets	negative	5.68840774949058
ethically aligned opportunistic scheduling for productive laziness	artificial intelligence ai mediated workforce management systems e.g. crowdsourcing long-term success depends workers accomplishing tasks productively resting well dual objective summarized concept productive laziness existing scheduling approaches mostly focus efficiency overlook worker wellbeing proper rest order enable workforce management systems follow ieee ethically aligned design guidelines prioritize worker wellbeing propose distributed computational productive laziness cpl approach paper intelligently recommends personalized work-rest schedules based local data concerning worker 's capabilities situational factors incorporate opportunistic resting achieve superlinear collective productivity without need explicit coordination messages extensive experiments based real-world dataset 5,000 workers demonstrate cpl enables workers spend 70 effort complete 90 tasks average providing ethically aligned scheduling existing approaches	positive	0
sax breakpoints for random forest based real-time contrast control chart	manufacturing process process monitoring important real-time contrast rtc control chart outperforms existing monitoring methods however performance rtc control chart depends classifier existing rtc charts use random forest rf support vector machine svm kernel linear discriminant analysis klda classifier rf classifier find cause faults performance lower others therefore suggest data representation method improve rf based rtc control chart symbolic aggregate approximation sax famous method improve performance classification clustering convert input data using sax change parameters sax alphabet size breakpoints improve performance experiment shows represented data efficient method improve performance rtc control chart	negative	7.689702426898293
x-dmm: fast and scalable model based text clustering	text clustering widely studied problem text mining domain dirichlet multinomial mixture dmm model based clustering algorithms shown good performance cope high dimensional sparse text data obtaining reasonable results clustering accuracy computational efficiency however time complexity dmm model training proportional average document length number clusters making inefficient scaling long text large corpora common realworld applications documents organization retrieval recommendation paper leverage symmetric prior setting dirichlet distribution build indices decrease time complexity sampling-based training dmm k∗l k∗u k number clusters l average length document u average number unique words document introduce metropolis-hastings sampling algorithm reduces sampling time complexity k∗u u nearly-to-convergence training stages moreover also parallelize dmm model training obtain acceleration using uncollapsed gibbs sampler combine optimizations highly efficient implementation called x-dmm enables dmm model scale long large-scale text clustering evaluate performance x-dmm several real world datasets experimental results show xdmm achieves substantial speed compared existing state-of-the-art algorithms without clustering accuracy degradation	negative	7.450195973098744
towards optimal discrete online hashing with balanced similarity	facing large-scale image datasets online hashing serves promising solution online retrieval prediction tasks encodes online streaming data compact binary codes simultaneously updates hash functions renew codes existing dataset end existing methods update hash functions solely based new data batch without investigating correlation new data existing dataset addition existing works update hash functions using relaxation process corresponding approximated continuous space remains open problem directly apply discrete optimizations online hashing paper propose novel supervised online hashing method termed balanced similarity online discrete hashing bsodh solve problems unified framework bsodh employs well-designed hashing algorithm preserve similarity streaming data existing dataset via asymmetric graph regularization identify “ data-imbalance ” problem brought constructed asymmetric graph restricts application discrete optimization problem therefore novel balanced similarity proposed uses two equilibrium factors balance similar dissimilar weights eventually enables usage discrete optimizations extensive experiments conducted three widely-used benchmarks demonstrate advantages proposed method stateof-the-art methods	negative	6.054413048186689
semi-supervised feature selection with adaptive discriminant analysis	paper propose novel adaptive discriminant analysis semi-supervised feature selection namely sada instead computing fixed similarities performing feature selection sada simultaneously learns adaptive similarity matrix projection matrix w iterative method iteration computed projected distance learned w w computed learned s. therefore sada learn better projection matrix w weakening effect noise features adaptive similarity matrix experimental results 4 data sets show superiority sada compared 5 semisupervised feature selection methods	negative	7.369111473366502
invisible influence: artificial intelligence and the ethics of adaptive choice architectures	several years scholars good reason largely preoccupied worries use artificial intelligence machine learning ai/ml tools make decisions us recently significant attention turned potentially alarming problem use ai/ml influence decision-making contexts make decisions -- behavioral economists call choice architectures -- increasingly technologically-laden say algorithms increasingly determine wide variety contexts sets options choose way options framed moreover artificial intelligence machine learning ai/ml makes possible options framings -- choice architectures -- tailored individual chooser constructed based information collected individual preferences interests aspirations vulnerabilities goal influencing decisions time habituated technologies pay little notice philosophers technology put transparent us -- effectively invisible argue invisible layer technological mediation structures influences decision-making renders us deeply susceptible manipulation absent guarantee technologies used manipulate exploit individuals little reason trust	positive	0
learning to embed sentences using attentive recursive trees	sentence embedding effective feature representation deep learning-based nlp tasks one prevailing line methods using recursive latent tree-structured networks embed sentences task-specific structures however existing models explicit mechanism emphasize taskinformative words tree structure end propose attentive recursive tree model ar-tree words dynamically located according importance task specifically construct latent tree sentence proposed important-first strategy place attentive words nearer root thus ar-tree inherently emphasize important words bottomup composition sentence embedding propose end-to-end reinforced training strategy ar-tree demonstrated consistently outperform least comparable state-of-the-art sentence embedding methods three sentence understanding tasks	negative	7.232746758614667
dynamic capsule attention for visual question answering	visual question answering vqa recent advances well advocated use attention mechanism precisely link question potential answer areas difficulty question increases vqa models adopt multiple attention layers capture deeper visual-linguistic correlation negative consequence explosion parameters makes model vulnerable over-fitting especially limited training examples given paper propose extremely compact alternative static multi-layer architecture towards accurate yet efficient attention modeling termed dynamic capsule attention capsatt inspired recent work capsule network capsatt treats visual features capsules obtains attention output via dynamic routing updates attention weights calculating coupling coefficients underlying output capsules meanwhile capsatt also discards redundant projection matrices make model much compact quantify capsatt three benchmark vqa datasets i.e. coco-qa vqa1.0 vqa2.0 compared traditional multi-layer attention model capsatt achieves significant improvements 4.1 5.2 2.2 three datasets respectively moreover much fewer parameters approach also yields competitive results compared latest vqa models verify generalization ability capsatt also deploy another challenging multi-modal task image captioning state-of-the-art performance achieved simple network structure	negative	8.021403679507785
paradoxes in fair computer-aided decision making	computer-aided decision making -- human decision-maker aided computational classifier making decision -- becoming increasingly prevalent instance judges least nine states make use algorithmic tools meant determine `` recidivism risk scores '' criminal defendants sentencing parole bail decisions subject much recent debate whether algorithmic tools `` fair '' sense discriminate certain groups e.g. races people main result shows `` non-trivial '' computer-aided decision making either classifier must discriminatory rational decision-maker using output classifier forced discriminatory provide complete characterization situations fair computer-aided decision making possible	positive	0
learning object context for dense captioning	dense captioning challenging task detects visual elements images also generates natural language sentences describe previous approaches leverage object information images task however objects provide valuable cues help predict locations caption regions caption regions often highly overlap objects i.e caption regions usually parts objects combinations meanwhile objects also provide important information describing target caption region corresponding description depicts properties also involves interactions objects image work propose novel scheme object context encoding long short-term memory lstm network automatically learn complementary object context caption region transferring knowledge objects caption regions contextual objects arranged sequence progressively fed context encoding module obtain context features learned object context features region features used predict bounding box offsets generate descriptions context learning procedure conjunction optimization location prediction caption generation thus enabling object context encoding lstm capture aggregate useful object context experiments benchmark datasets demonstrate superiority proposed approach state-of-the-art methods	negative	5.506227328674868
loss-aversively fair classification	use algorithmic learning-based decision making scenarios affect human lives motivated number recent studies investigate decision making systems potential unfairness discrimination subjects based sensitive features like gender race however judging fairness newly designed decision making system studies overlooked important influence people 's perceptions fairness new algorithm changes status quo i.e. decisions existing decision making system motivated extensive literature behavioral economics behavioral psychology prospect theory propose notion fair updates refer loss-averse updates loss-averse updates constrain updates yield improved beneficial outcomes subjects compared status quo propose tractable proxy measures would allow notion incorporated training variety linear non-linear classifiers show proxy measures combined existing measures training nondiscriminatory classifiers.our evaluation using synthetic real-world datasets demonstrates proposed proxy measures effective desired tasks	positive	0
partially generative neural networks for gang crime classification with partial information	1 million homicides robberies aggravated assaults occur united states year crimes often classified different types based circumstances surrounding crime e.g. domestic violence gang-related despite recent technological advances ai machine learning additional classification tasks still done manually specially trained police officers paper provide first attempt develop automatic system classifying crimes particular study question classifying whether given violent crime gang-related introduce novel partially generative neural networks pgnn able accurately classify gang-related crimes full information available partial information pgnn first generative-classification model enables work features test examples missing using crime event dataset los angeles covering 2014-2016 experimentally show pgnn outperforms typically used classifiers problem classifying gang-related violent crimes	positive	0
transparency and explanation in deep reinforcement learning neural networks	autonomous ai systems entering human society near future provide services work alongside humans systems accepted trusted users able understand reasoning process system i.e system transparent system transparency enables humans form coherent explanations system 's decisions actions transparency important user trust also software debugging certification recent years deep neural networks made great advances multiple application areas however deep neural networks opaque paper report work transparency deep reinforcement learning networks drln networks extremely successful accurately learning action control image input domains atari games paper propose novel general method incorporates explicit object recognition processing deep reinforcement learning models b forms basis development `` object saliency maps '' provide visualization internal states drlns thus enabling formation explanations c incorporated existing deep reinforcement learning framework present computational results human experiments evaluate approach	positive	0
 a framework for grounding the moral status of intelligent machines	propose framework derived moral theory assessing moral status intelligent machines using framework claim current foreseeable intelligent machines approximately much moral status plants trees environmental entities claim raises question obligations could moral agent e.g. normal adult human toward intelligent machine propose threshold moral obligation `` functional morality '' wallach allen 20 upper limit obligations exceed upper limit obligations toward plants trees environmental entities	positive	0
what’s up with privacy? : user preferences and privacy concerns in intelligent personal assistants	recent breakthroughs artificial intelligence ai allowed individuals rely automated systems variety reasons systems currently popular voice-enabled systems like echo amazon home google also called intelligent personal assistants ipas though rising concerns privacy ethical implications users ipas seem continue using systems aim investigate extent users concerned privacy handling concerns using ipas utilizing reviews posted online along responses survey paper provides set insights detected markers related user interests privacy challenges insights suggest users systems irrespective concerns privacy generally positive terms utilizing ipas everyday lives however significant percentage users concerned privacy take actions address related concerns percentage users expressed privacy concerns learned `` always listening '' feature devices concern privacy increased	positive	0
sign-full random projections	method 1-bit “ sign-sign ” random projections popular tool efficient search machine learning large datasets given two d-dim data vectors u v ∈ ℝd one generate x ∑i=1d uiri ∑i=1d viri ri ∼ n 0 1 iid one estimate cosine similarity ρ sgn x sgn paper study series estimators “ sign-full ” random projections first prove e sgn x √2/πρ provides estimator ρ. interestingly estimator substantially improved normalizing y. study estimators based e y−1x≥0 y+1x 0 normalized version analyze theoretical limit using mle conclude among proposed estimators single estimator achieve close theoretical optimal asymptotic variance entire range ρ. hand estimators combined achieve variance close mle applications near neighbor search duplicate detection knn-classification etc training data first transformed via random projections signs projected data points stored i.e. sgn x original training data discarded new data point arrives apply random projections necessarily need quantize projected data i.e. 1-bit therefore sign-full random projections practically useful gain essentially comes additional cost	negative	6.589546399191022
backbone cannot be trained at once: rolling back to pre-trained network for person re-identification	person re-identification reid task shortage trainable dataset common utilize fine-tuning method using classification network pre-trained large dataset however relatively difficult sufficiently finetune low-level layers network due gradient vanishing problem work propose novel fine-tuning strategy allows low-level layers sufficiently trained rolling back weights high-level layers initial pre-trained weights strategy alleviates problem gradient vanishing low-level layers robustly trains low-level layers fit reid dataset thereby increasing performance reid tasks improved performance proposed strategy validated via several experiments furthermore without addons pose estimation segmentation strategy exhibits state-of-the-art performance using vanilla deep convolutional neural network architecture	negative	6.907476299267728
non-discriminatory machine learning through convex fairness criteria	introduce novel technique achieve non-discrimination machine learning without sacrificing convexity probabilistic interpretation also propose new notion fairness machine learning called weighted proportional fairness show technique satisfies subjective fairness criterion	positive	0
contextualized non-local neural networks for sequence learning	recently large number neural mechanisms models proposed sequence learning selfattention exemplified transformer model graph neural networks gnns attracted much attention paper propose approach combines draws complementary strengths two methods specifically propose contextualized non-local neural networks cn3 dynamically construct task-specific structure sentence leverage rich local dependencies within particular neighbourhood	negative	7.25611684913747
legible normativity for ai alignment: the value of silly rules	become commonplace assert autonomous agents built follow human rules behavior -- social norms laws human laws norms complex culturally varied systems many cases agents learn rules requires autonomous agents models human rule systems work make reliable predictions rules paper contribute building models analyzing overlooked distinction important rules call silly rules -- rules discernible direct impact welfare show silly rules render normative system robust adaptable response shocks perceived stability make normativity legible humans increase legibility ai systems well ai systems integrate human normative systems suggest may important models include representations silly rules	positive	0
unsupervised domain adaptation by matching distributions based on the maximum mean discrepancy via unilateral transformations	propose simple yet effective method unsupervised domain adaptation training test distributions different standard supervised learning methods perform poorly semi-supervised domain adaptation methods developed case labeled data target domain available however target data often unlabeled practice therefore unsupervised domain adaptation require labels target data receiving lot attention proposed method minimizes discrepancy source target distributions input features transforming feature space source domain since unilateral transformations transfer knowledge source domain target one without reducing dimensionality proposed method effectively perform domain adaptation without losing information transfered proposed method assumed transformed features original features differ small residual preserve relationship features labels transformation learned aligning higher-order moments source target feature distributions based maximum mean discrepancy enables compare two distributions without density estimation transformation found learn supervised models using transformed source data labels use two real-world datasets demonstrate experimentally proposed method achieves better classification performance existing methods unsupervised domain adaptation	negative	7.4990405630960595
algorithmic greenlining: an approach to increase diversity	contexts college admissions hiring image search decision-makers often aspire formulate selection criteria yield high-quality diverse results however simultaneously optimizing quality diversity challenging especially decision-maker know true quality criterion instead must rely heuristics intuition introduce algorithmic framework takes input user 's selection criterion may yield high-quality homogeneous results using application-specific notion substitutability algorithms suggest similar criteria diverse results spirit statistical demographic parity instance given image search query `` chairman '' suggests alternative queries similar gender-diverse `` chairperson '' context college admissions apply algorithm dataset students applications rediscover texas 's `` top 10 rule '' input criterion act score cutoff output class rank cutoff automatically accepting students top decile graduating class historically policy effective admitting students perform well college come diverse backgrounds complement empirical analysis learning-theoretic guarantees estimating true diversity criterion based historical data	positive	0
the heart of the matter: patient autonomy as a model for the wellbeing of technology users	draw concepts medical ethics consider computer science ai particular develop critical tools thinking concretely technology 's impact wellbeing people use focus patient autonomy -- -the ability set terms one 's encounter medicine -- -and mediating concepts informed consent decisional capacity enable doctors honor patients autonomy messy non-ideal circumstances comparative study organized around fictional case study heart patient cardiac implants using case study identify points overlap difference medical ethics technology ethics leverage discussion intertwined scenario offer initial practical suggestions adapt concepts decisional capacity informed consent discussion technology design	positive	0
towards optimal fine grained retrieval via decorrelated centralized loss with normalize-scale layer	recent advances fine-grained image retrieval prefer learning convolutional neural network cnn specific fullyconnect layer designed loss function discriminative feature representation essentially loss establish robust metric efficiently distinguish high-dimensional features within outside fine-grained categories end existing loss functions defected two aspects feature relationship encoded inside training batch local scope leads low accuracy b error established mean square needs pairwise distance computation training set results low efficiency paper propose novel metric learning scheme termed normalize-scale layer decorrelated global centralized ranking loss achieves extremely efficient discriminative learning i.e. 5× speedup triplet loss 12 recall boost cars196 method originates classic softmax loss global structure directly optimize distance metric well inter/intra class distance tackle issue hypersphere layer global centralized ranking loss pairwise decorrelated learning particular first propose normalize-scale layer eliminate gap metric distance measuring distance retrieval dot product dimension reduction classification second relationship features encoded global centralized ranking loss targets optimizing metric distance globally accelerating learning procedure finally centers decorrelated gram-schmidt process leading extreme efficiency 20 epochs training procedure discriminability feature learning conducted quantitative evaluations two fine-grained retrieval benchmark superior performance demonstrates merits proposed approach state-of-the-arts	negative	8.061665409710258
(when) can ai bots lie?	ability ai agent build mental models open pathways manipulating exploiting human hopes achieving greater good fact behavior necessarily require malicious intent rather borne cooperative scenarios also beyond scope misinterpretation intents case value alignment problems thus effectively engineered desired i.e algorithms exist optimize behavior models misspecified misused techniques pose several unresolved ethical moral questions regards design autonomy paper illustrate issues teaming scenario investigate perceived participants thought experiment finally end discussion moral implications behavior perspective doctor-patient relationship	positive	0
regulating autonomous vehicles: a policy proposal	widespread deployment testing autonomous vehicles real-world environments raises key questions systems regulated much current debate presupposes regulatory system currently use regular vehicles also appropriate semi- fully-autonomous ones opposition first argue serious challenges regulating autonomous vehicles using current approaches due nature autonomous capabilities connections operational domains also systems tasks surrounding uncertainties instead argue vehicles autonomous capabilities similar key respects drugs medical inter-ventions thus propose `` first principles '' basis dynamic regulatory system staged approvals monitoring analogous system used u.s. food drug administration provide details operation potential system conclude characterizing benefits costs plausibility	positive	0
deep convolutional sum-product networks	give conditions convolutional neural networks cnns define valid sum-product networks spns one subclass called convolutional spns cspns implemented using tensors also suffer shallow fortunately tensors augmented maintaining valid spns yields larger subclass cnns call deep convolutional spns dcspns convolutional sum-pooling layers form rich directed acyclic graph structures one salient feature dcspns rigorous probabilistic model exploit multiple kinds probabilistic reasoning including marginal inference probable explanation mpe inference allows alternative method learning dcspns using vectorized differentiable mpe plays similar role generator generative adversarial networks gans image sampling yet another application demonstrating robustness dcspns preliminary results image sampling encouraging since dcspn sampled images exhibit variability experiments image completion show dcspns significantly outperform competing methods achieving several state-of-the-art mean squared error mse scores left-completion bottom-completion benchmark datasets	negative	5.896870679047424
scale invariant fully convolutional network: detecting hands efficiently	existing hand detection methods usually follow pipeline multiple stages high computation cost i.e. feature extraction region proposal bounding box regression additional layers rotated region detection paper propose new scale invariant fully convolutional network sifcn trained end-to-end fashion detect hands efficiently specifically merge feature maps high low layers iterative way handles different scales hands better less time overhead comparing concatenating simply moreover develop complementary weighted fusion cwf block make full use distinctive features among multiple layers achieve scale invariance deal rotated hand detection present rotation map get rid complex rotation derotation layers besides design multi-scale loss scheme accelerate training process significantly adding supervision intermediate layers network compared state-of-the-art methods algorithm shows comparable accuracy runs 4.23 times faster speed viva dataset achieves better average precision oxford hand detection dataset speed 62.5 fps	negative	7.381643122411333
human-in-the-loop feature selection	feature selection crucial step conception machine learning models often performed via datadriven approaches overlook possibility tapping human decision-making model ’ designers users present human-in-the-loop framework interacts domain experts collecting feedback regarding variables samples evaluate relevant task hand information modeled via reinforcement learning derive per-example feature selection method tries minimize model ’ loss function focusing pertinent variables human perspective report results proof-of-concept image classification dataset real-world risk classification task model successfully incorporated feedback experts improve accuracy	negative	8.117082754324656
perceptions of domestic robots?? normative behavior across cultures	domestic service robots become common widespread must programmed efficiently accomplish tasks aligning actions relevant norms first step equip domestic robots normative reasoning competence understanding norms people apply behavior robots specific social contexts end conducted online survey chinese united states participants asked select preferred normative action domestic service robot take number scenarios paper makes multiple contributions extensive survey first collect data attitudes people normative behavior domestic robots b across cultures c study relative priorities among norms domain present findings discuss implications building computational models robot normative reasoning	positive	0
inferring work task automatability from ai expert evidence	despite growing alarm machine learning technologies automating jobs little good evidence activities automated using technologies contribute first dataset kind surveying 150 top academics industry experts machine learning robotics ai receiving 4,500 ratings automatable specific tasks today present probabilistic machine learning model learn patterns connecting expert estimates task automatability skills knowledge abilities required perform tasks model infers automatability 2,000 work activities show automation differs across types activities types occupations sensitivity analysis identifies specific skills knowledge abilities activities drive higher lower automatability provide quantitative evidence perceived automatable using state-of-the-art machine learning technology consider societal impacts results task-level approaches	positive	0
human-ai learning performance in multi-armed bandits	people frequently face challenging decision-making problems outcomes uncertain unknown artificial intelligence ai algorithms exist outperform humans learning tasks thus opportunity ai agents assist people learning tasks effectively work use multi-armed bandit controlled setting explore direction pair humans selection agents observe well human-agent team performs find team performance beat human agent performance isolation interestingly also find agent 's performance isolation necessarily correlate human-agent team 's performance drop agent performance lead disproportionately large drop team performance settings even improve team performance pairing human agent performs slightly better make perform much better pairing agent performs make perform much worse results suggest people different exploration strategies might perform better agents match strategy overall optimizing human-agent team performance requires going beyond optimizing agent performance understanding agent 's suggestions influence human decision-making	positive	0
adversarial framing for image and video classification	neural networks prone adversarial attacks general attacks deteriorate quality input either slightly modifying pixels occluding patch paper propose method keeps image unchanged adds adversarial framing border image show empirically method able successfully attack state-of-theart methods image video classification problems notably proposed method results universal attack fast test time source code found github.com/zajaczajac/adv_framing	negative	5.518860280426452
learning non-uniform hypergraph for multi-object tracking	majority multi-object tracking mot algorithms based tracking-by-detection scheme use higher order dependencies among objects tracklets makes less effective handling complex scenarios work present new near-online mot algorithm based non-uniform hypergraph model different degrees dependencies among tracklets unified objective nodes hypergraph correspond tracklets hyperedges different degrees encode various kinds dependencies among specifically instead setting weights hyperedges different degrees empirically learned automatically using structural support vector machine algorithm ssvm several experiments carried various challenging datasets i.e. pets09 parkinglot sequence subwayface mot16 benchmark demonstrate method achieves favorable performance state-of-the-art mot methods	negative	7.81727691902779
rsa: byzantine-robust stochastic aggregation methods for distributed learning from heterogeneous datasets	paper propose class robust stochastic subgradient methods distributed learning heterogeneous datasets presence unknown number byzantine workers byzantine workers learning process may send arbitrary incorrect messages master due data corruptions communication failures malicious attacks consequently bias learned model key proposed methods regularization term incorporated objective function robustify learning task mitigate negative effects byzantine attacks resultant subgradient-based algorithms termed byzantine-robust stochastic aggregation methods justifying acronym rsa used henceforth contrast existing algorithms rsa rely assumption data independent identically distributed i.i.d workers hence fits wider class applications theoretically show rsa converges near-optimal solution learning error dependent number byzantine workers ii convergence rate rsa byzantine attacks stochastic gradient descent method free byzantine attacks numerically experiments real dataset corroborate competitive performance rsa complexity reduction compared state-of-the-art alternatives	negative	8.001422648201697
 understanding convolutional networks with apple : automatic patch pattern labeling for explanation	1961 group established within ibm test systems programs released customer usage goal group assure ibm management program released would satisfactorily usable customer one step taken group develop monitor device would permit programmers record information handled cpu execution intent use recorded information analyze basic nature programs goal developing adequate tests system program another potential use device measurement hardware performance disk-arm motion microsecond levels	positive	0
spatial and temporal mutual promotion for video-based person re-identification	video-based person re-identification crucial task matching video sequences person across multiple camera views generally features directly extracted single frame suffer occlusion blur illumination posture changes leads false activation missing activation regions corrupts appearance motion representation explore abundant spatial-temporal information video sequences key solve problem end propose refining recurrent unit rru recovers missing parts suppresses noisy parts current frame ’ features referring historical frames rru quality frame ’ appearance representation improved use spatial-temporal clues integration module stim mine spatial-temporal information upgraded features meanwhile multilevel training objective used enhance capability rru stim cooperation modules spatial temporal features mutually promote final spatial-temporal feature representation discriminative robust extensive experiments conducted three challenging datasets i.e. ilids-vid prid-2011 mars experimental results demonstrate approach outperforms existing state-of-the-art methods video-based person re-identification ilids-vid mars achieves favorable results prid-2011	negative	8.12710190739017
taking advantage of multitask learning for fair classification	central goal algorithmic fairness reduce bias automated decision making unavoidable tension exists accuracy gains obtained using sensitive information part statistical model commitment protect characteristics often due biases present data using sensitive information functional form classifier improves classification accuracy paper show possible get best worlds optimize model accuracy fairness without explicitly using sensitive feature functional form model thereby treating different individuals equally method based two key ideas one hand propose use multitask learning mtl enhanced fairness constraints jointly learn group specific classifiers leverage information sensitive groups hand since learning group specific models might permitted propose first predict sensitive features learning method use predicted sensitive feature train mtl fairness constraints enables us tackle fairness three-pronged approach increasing accuracy group enforcing measures fairness training protecting sensitive information testing experimental results two real datasets support proposal showing substantial improvements accuracy fairness	positive	0
impacts on trust of healthcare ai	artificial intelligence robotics rapidly moving healthcare playing key roles specific medical functions including diagnosis clinical treatment much focus technology development human-machine interactions leading host related technology-centric questions paper focus instead impact technologies human-human interactions relationships within healthcare domain particular argue trust plays central role relationships healthcare domain introduction healthcare ai potentially significant impacts relations trust contend healthcare ai systems ought treated assistive technologies go beyond usual functions medical devices result need rethink regulation healthcare ai systems ensure advance relevant values propose three distinct guidelines universalized across federal regulatory boards ensure patient-doctor trust detrimentally affected deployment widespread adoption healthcare ai technologies	positive	0
fairness in relational domains	ai machine learning tools used increasing frequency decision making domains affect peoples lives employment education policing loan approval uses raise concerns biases algorithmic discrimination motivated development fairness-aware machine learning however existing fairness approaches based solely attributes individuals many cases discrimination much complex taking account social organizational connections individuals important introduce new notions fairness able capture relational structure domain use first-order logic provide flexible expressive language specifying complex relational patterns discrimination furthermore extend existing statistical relational learning framework probabilistic soft logic psl incorporate definition relational fairness refer fairness-aware framework fairpsl fairpsl makes use logical definitions fairnesss also supports probabilistic interpretation particular show perform maximum posteriori map inference exploiting probabilistic dependencies within domain avoiding violation fairness guarantees preliminary empirical evaluation shows able make accurate fair decisions	positive	0
rgbd based gaze estimation via multi-task cnn	paper tackles rgbd based gaze estimation convolutional neural networks cnns specifically propose decompose gaze point estimation eyeball pose head pose 3d eye position estimation compared rgb image-based gaze tracking depth modality helps facilitate head pose estimation 3d eye position estimation captured depth image however usually contains noise black holes noticeably hamper gaze tracking thus propose cnn-based multi-task learning framework simultaneously refine depth images predict gaze points utilize generator network depth image generation generative neural network gan generator network partially shared gaze tracking network gan-based depth synthesizing optimizing whole network simultaneously depth image synthesis improves gaze point estimation vice versa since existing rgbd dataset eyediap small build large-scale rgbd gaze tracking dataset performance evaluation far know largest rgbd gaze dataset terms number participants comprehensive experiments demonstrate method outperforms existing methods large margin dataset eyediap dataset	negative	6.167066927300766
adversarial training for community question answer selection based on multi-scale matching	community-based question answering cqa websites represent important source information result problem matching valuable answers corresponding questions become increasingly popular research topic frame task binary relevant/irrelevant classification problem present adversarial training framework alleviate label imbalance issue employ generative model iteratively sample subset challenging negative samples fool classification model models alternatively optimized using reinforce algorithm proposed method completely different previous ones negative samples training set directly used uniformly down-sampled propose using multi-scale matching explicitly inspects correlation words ngrams different levels granularity evaluate proposed method semeval 2016 semeval 2017 datasets achieves state-of-the-art similar performance	negative	7.7243620899971575
capnet: continuous approximation projection for 3d point cloud reconstruction using 2d supervision	knowledge 3d properties objects necessity order build effective computer vision systems however lack large scale 3d datasets major constraint datadriven approaches learning properties consider task single image 3d point cloud reconstruction aim utilize multiple foreground masks supervisory data alleviate need large scale 3d datasets novel differentiable projection module called ‘ capnet ’ introduced obtain 2d masks predicted 3d point cloud key idea model projections continuous approximation points point cloud overcome challenges sparse projection maps propose loss formulation termed ‘ affinity loss ’ generate outlierfree reconstructions significantly outperform existing projection based approaches large-scale synthetic dataset show utility generalizability 2d supervised approach experiments real-world dataset lack 3d data serious concern enhance reconstructions also propose test stage optimization procedure obtain reconstructions display high correspondence observed input image	negative	7.446760151069611
dopamine: double-sided masked cnn for pixel adaptive multiplicative noise despeckling	propose dopamine new neural network based multiplicative noise despeckling algorithm algorithm inspired neural aide n-aide recently proposed neural adaptive image denoiser original naide designed additive noise case show framework i.e. adaptively learning network pixel-wise affine denoisers minimizing unbiased estimate mse applied multiplicative noise case well moreover derive double-sided masked cnn architecture control variance activation values layer converge fast high denoising performance supervised training experimental results show dopamine possesses high adaptivity via fine-tuning network parameters based given noisy image achieves significantly better despeckling results compared sar-drn state-of-the-art cnn-based algorithm	negative	8.093751493550371
global explanations of neural networks: mapping the landscape of predictions	barrier wider adoption neural networks lack interpretability local explanation methods exist one prediction global attributions still reduce neural network decisions single set features response present approach generating global attributions called gam explains landscape neural network predictions across subpopulations gam augments global explanations proportion samples attribution best explains specifies samples described attribution global explanations also tunable granularity detect fewer subpopulations demonstrate gam 's global explanations 1 yield known feature importances simulated data 2 match feature weights interpretable statistical models real data 3 intuitive practitioners user studies transparent predictions gam help ensure neural network decisions generated right reasons	positive	0
weighted channel dropout for regularization of deep convolutional neural network	work propose novel method named weighted channel dropout wcd regularization deep convolutional neural network cnn different dropout randomly selects neurons set zero fully-connected layers wcd operates channels stack convolutional layers specifically wcd consists two steps i.e. rating channels selecting channels three modules i.e. global average pooling weighted random selection random number generator filters channels according activation status plugged two consecutive layers unifies original dropout channel-wise dropout wcd totally parameter-free deployed training phase slight computation cost network test phase remains unchanged thus inference cost added besides combining existing networks requires re-pretraining imagenet thus well-suited application small datasets finally wcd vggnet-16 resnet-101 inception-v3 experimentally evaluated multiple datasets extensive results demonstrate wcd bring consistent improvements baselines	negative	7.418897006777115
exploiting moral values to choose the right norms	norms constitute regulative mechanisms extensively enacted groups organisations societies however 'choosing right norms establish constitutes open problem requires consideration number constraints norm relations preference criteria e.g involved moral values paper advances state art normative multiagent systems literature formally defining problem proposing encoding linear program automatically solved	positive	0
multi-dimensional classification via knn feature augmentation	multi-dimensional classification mdc deals problem one instance associated multiple class variables specifies class membership w.r.t one specific class space existing approaches learn mdc examples focusing modeling dependencies among class variables potential usefulness manipulating feature space ’ investigated paper first attempt towards feature manipulation mdc proposed enriches original feature space knnaugmented features specifically simple counting statistics class membership neighboring mdc examples used generate augmented feature vector way discriminative information class space encoded feature space help train multi-dimensional classification model validate effectiveness proposed feature augmentation techniques extensive experiments eleven benchmark data sets well four state-of-the-art mdc approaches conducted experimental results clearly show compared original feature space classification performance existing mdc approaches significantly improved incorporating knn-augmented features	negative	8.166933406842873
using deceased-donor kidneys to initiate chains of living donor kidney paired donations: algorithm and experimentation	design flexible algorithm exploits deceased donor kidneys initiate chains living donor kidney paired donations combining deceased living donor allocation mechanisms improve quantity quality kidney transplants advantages approach measured using retrospective data pool donor/recipient incompatible desensitized pairs padua university hospital largest center living donor kidney transplants italy experiments show remarkable improvement number patients incompatible donor could transplanted decrease number desensitization procedures increase number ut patients patients unlikely transplanted immunological reasons waiting list could receive organ	positive	0
heterogeneous transfer learning via deep matrix completion with adversarial kernel embedding	heterogeneous transfer learning htl aims solve transfer learning problems source domain target domain heterogeneous types features existing htl approaches either explicitly learn feature mappings heterogeneous domains implicitly reconstruct heterogeneous cross-domain features based matrix completion techniques paper propose new htl method based deep matrix completion framework kernel embedding distributions trained adversarial manner learning heterogeneous features across domains conduct extensive experiments two different vision tasks demonstrate effectiveness proposed method compared number baseline methods	negative	7.6982448536437005
how do fairness definitions fare? examining public attitudes towards algorithmic definitions of fairness	best way define algorithmic fairness many definitions fairness proposed computer science literature clear agreement particular definition work investigate ordinary people 's perceptions three fairness definitions across two online experiments test definitions people perceive fairest context loan decisions whether fairness perceptions change addition sensitive information i.e. race loan applicants overall one definition calibrated fairness tends pre- ferred others results also provide support principle affirmative action	positive	0
creating fair models of atherosclerotic cardiovascular disease risk	guidelines management atherosclerotic cardiovascular disease ascvd recommend use risk stratification models identify patients likely benefit cholesterol-lowering therapies models differential performance across race gender groups inconsistent behavior across studies potentially resulting inequitable distribution beneficial therapy work leverage adversarial learning large observational cohort extracted electronic health records ehrs develop `` fair '' ascvd risk prediction model reduced variability error rates across groups empirically demonstrate approach capable aligning distribution risk predictions conditioned outcome across several groups simultaneously models built high-dimensional ehr data also discuss relevance results context empirical trade-off fairness model performance	positive	0
spell once, summon anywhere: a two-level open-vocabulary language model	show spellings known words help us deal unknown words open-vocabulary nlp tasks method propose used extend closedvocabulary generative model paper specifically consider case neural language modeling bayesian generative story combines standard rnn language model generating word tokens sentence rnnbased spelling model generating letters word type two rnns respectively capture sentence structure word structure kept separate linguistics invoking second rnn generate spellings novel words context obtain open-vocabulary language model known words embeddings naturally inferred combining evidence type spelling token context comparing baselines including novel strong baseline beat previous work establish state-of-the-art results multiple datasets	negative	7.869877367207664
frontier search and plan reconstruction in oversubscription planning	oversubscription planning osp problem choosing action sequence reaches state high utility given budget total action cost formulation allows us handle situations under-constrained resources allow us achieve possible goal facts optimal osp task constrained finding path achieves state maximal utility incremental bfbb search algorithm landmark-based approximations proposed osp heuristic search address tasks non-negative 0-binary utility functions incremental bfbb maintained best solution far set reference states extended non-redundant value-carrying states discovered search iteration requires search re-start order exploit new knowledge obtained along search recent work proposed approach relative estimation achievements value-driven landmarks address arbitrary utility functions incrementally improves best existing solution far eliminating need maintain set reference states propose progressive frontier search algorithm alleviates need re-start scratch new information acquired capturing frontier achieved end iteration used dynamic reference point continue search leading improved efficiency search	negative	7.360148612962803
semi-parametric sampling for stochastic bandits with many arms	consider stochastic bandit problem large candidate arm set setting classic multi-armed bandit algorithms assume independence among arms adopt non-parametric reward model inefficient due large number arms exploiting arm correlations based parametric reward model arm features contextual bandit algorithms efficient also suffer large regret practical applications due reward estimation bias mis-specified model assumption incomplete features paper propose novel bayesian framework called semi-parametric sampling sps problem employs semi-parametric function reward model specifically parametric part sps models expected reward parametric function arm feature efficiently eliminate poor arms candidate set non-parametric part sps adopts nonparametric reward model revises parametric estimation avoid estimation bias especially remained candidate arms give implementation sps linear sps lsps utilizes linear function parametric part semi-parametric environment theoretical analysis shows lsps achieves better regret bound i.e o̴ √n1−α dα √t α ∈ 0 1 existing approaches also experiments demonstrate superiority proposed approach	negative	6.271132972964551
regulating artificial intelligence: proposal for a global solution	given ubiquity artificial intelligence ai modern societies clear individuals corporations countries grappling legal ethical issues use global problems require global solutions propose establishment international ai regulatory agency -- drawing interdisciplinary expertise -- could create unified framework regulation ai technologies inform development ai policies around world urge organization developed deliberate haste issues cryptocurrencies personalized political ad hacking autonomous vehicles autonomous weaponized agents already reality affecting international trade politics war	positive	0
modeling epistemological principles for bias mitigation in ai systems: an illustration in hiring decisions	artificial intelligence ai used extensively automatic decision making broad variety scenarios ranging credit ratings loans recommendations movies traditional design guidelines ai models focus essentially accuracy maximization recent work shown economically irrational socially unacceptable scenarios discrimination unfairness likely arise unless issues explicitly addressed undesirable behavior several possible sources biased datasets used training may detected black-box models pointing connections bias ai problem induction focus popper 's contributions hume 's offer logical theory preferences ai model preferred others purely rational grounds one attempts refutation based accuracy fairness inspired epistemological principles paper proposes structured approach mitigate discrimination unfairness caused bias ai systems proposed computational framework models selected enhanced attempts refutation illustrate discussion focus hiring decision scenarios ai system filters job applicants go interview phase	positive	0
requirements for an artificial agent with norm competence	human behavior frequently guided social moral norms human community exist without norms robots enter human societies must therefore behave norm-conforming ways well however currently solid cognitive computational model available human norms represented activated learned provide conceptual psychological analysis key properties human norms identify demands properties put artificial agent incorporates norms-demands format norm representations structured organization learning algorithms	positive	0
distributionally adversarial attack	recent work adversarial attack shown projected gradient descent pgd adversary universal first-order adversary classifier adversarially trained pgd robust wide range first-order attacks worth noting original objective attack/defense model relies data distribution p x typically form risk maximization/minimization e.g. max/min ep x l x p x unknown data distribution l · loss function however since pgd generates attack samples independently data sample based l · procedure necessarily lead good generalization terms risk optimization paper achieve goal proposing distributionally adversarial attack daa framework solve optimal adversarial-data distribution perturbed distribution satisfies l∞ constraint deviates original data distribution increase generalization risk maximally algorithmically daa performs optimization space potential data distributions introduces direct dependency data points generating adversarial samples daa evaluated attacking state-of-the-art defense models including adversarially-trained models provided mit madrylab notably daa ranks first place madrylab ’ white-box leaderboards reducing accuracy secret mnist model 88.56 l∞ perturbations ε 0.3 accuracy secret cifar model 44.71 l∞ perturbations ε 8.0 code experiments released https //github.com/tianzheng4/distributionally-adversarial-attack	negative	6.886875622323714
long short-term memory with dynamic skip connections	recent years long short-term memory lstm successfully used model sequential data variable length however lstm still experience difficulty capturing long-term dependencies work tried alleviate problem introducing dynamic skip connection learn directly connect two dependent words since dependency information training data propose novel reinforcement learning-based method model dependency relationship connect dependent words proposed model computes recurrent transition functions based skip connections provides dynamic skipping advantage rnns always tackle entire sentences sequentially experimental results three natural language processing tasks demonstrate proposed method achieve better performance existing methods number prediction experiment proposed model outperformed lstm respect accuracy nearly 20	negative	7.16739232162945
soft facial landmark detection by label distribution learning	existing facial landmark detection algorithms regard manually annotated landmarks precise hard labels therefore accurate annotated landmarks essential training algorithms however many cases exist deviations manual annotations landmarks marked facial parts occlusion large poses always accurate means “ ground truth ” landmarks usually annotated precisely case reasonable use soft labels rather explicit hard labels therefore paper proposes associate bivariate label distribution bld landmark image bld covers neighboring pixels around original manually annotated point alleviating problem inaccurate landmarks generating bld landmark proposed method firstly learns mappings image patch bld landmark predicted blds used deformable model fitting process obtain final facial shape image experimental results show proposed method performs better compared state-of-the-art facial landmark detection algorithms furthermore proposed method appears much robust landmark noise training set compared baselines	negative	6.619341721321689
acm: adaptive cross-modal graph convolutional neural networks for rgb-d scene recognition	rgb image classification achieved significant performance improvement resurge deep convolutional neural networks however mono-modal deep models rgb image still several limitations applied rgb-d scene recognition 1 images scene classification usually contain one typical object flexible spatial distribution object-level local features also considered addition global scene representation 2 multi-modal features rgb-d scene classification still under-utilized simply combining modal-specific features suffers semantic gaps different modalities 3 existing methods neglect complex relationships among multiple modality features considering limitations paper proposes adaptive crossmodal acm feature learning framework based graph convolutional neural networks rgb-d scene recognition order make better use modal-specific cues approach mines intra-modality relationships among selected local features one modality leverage multi-modal knowledge effectively proposed approach models inter-modality relationships two modalities cross-modal graph cmg evaluate proposed method two public rgb-d scene classification datasets sun-rgbd nyud v2 proposed method achieves state-of-the-art performance	negative	7.221977550943848
hyperadam: a learnable task-adaptive adam for network training	deep neural networks traditionally trained using humandesigned stochastic optimization algorithms sgd adam recently approach learning optimize network parameters emerged promising research topic however learned black-box optimizers sometimes fully utilize experience human-designed optimizers therefore limitation generalization ability paper new optimizer dubbed hyperadam proposed combines idea “ learning optimize ” traditional adam optimizer given network training parameter update iteration generated hyperadam adaptive combination multiple updates generated adam varying decay rates combination weights decay rates hyperadam adaptively learned depending task hyperadam modeled recurrent neural network adamcell weightcell statecell justified state-of-the-art various network training multilayer perceptron cnn lstm	negative	7.685667303681839
a computational model of commonsense moral decision making	introduce computational model building moral autonomous vehicles learning generalizing human moral judgments draw cognitively inspired model people young children learn moral theories sparse noisy data integrate observations made different people different groups problem moral learning autonomous vehicles cast learning weigh different features dilemma using utility calculus goal making trade-offs reflect people make wide variety moral dilemma modeling structures individuals groups hierarchical bayesian model show individual 's moral values -- well group 's shared values -- inferred sparse noisy data evaluate approach data moral machine web application collects human judgments moral dilemmas involving autonomous vehicles show model rapidly accurately infers people 's preferences predict difficulty moral dilemmas limited data	positive	0
efficient gaussian process classification using pólya-gamma data augmentation	propose scalable stochastic variational approach gp classification building pólya-gamma data augmentation inducing points unlike former approaches obtain closed-form updates based natural gradients lead efficient optimization evaluate algorithm real-world datasets containing 11 million data points demonstrate two orders magnitude faster state-of-the-art competitive terms prediction performance	negative	6.3014598142617615
value alignment, fair play, and the rights of service robots	ethics safety research artificial intelligence increasingly framed terms `` alignment '' human values interests argue turing 's call `` fair play machines '' early often overlooked contribution alignment literature turing 's appeal fair play suggests need correct human behavior accommodate machines surprising inversion value alignment treated today reflections `` fair play '' motivate novel interpretation turing 's notorious `` imitation game '' condition intelligence instead value alignment machine demonstrates minimal degree alignment norms conversation instance go undetected interrogated human carefully distinguish interpretation moral turing test motivated principle fair play instead depends imitation human moral behavior finally consider framework fair play used situate debate robot rights within alignment literature argue extending rights service robots operating public spaces `` fair '' precisely sense encourages alignment interests humans machines	positive	0
an ai race: rhetoric and risks	rhetoric race strategic advantage increasingly used regard development artificial intelligence ai sometimes military context also broadly rhetoric also reflects real shifts strategy industry research groups compete limited pool talented researchers nation states china announce ambitious goals global leadership ai paper assesses potential risks ai race narrative actual competitive race develop ai incentivising corner-cutting safe-ty governance increasing risk conflict explores role research community respond-ing risks briefly explores alternative ways rush develop powerful ai could framed instead foster collaboration respon-sible progress	positive	0
chinese ner with height-limited constituent parsing	paper investigate improve chinese named entity recognition ner jointly modeling ner constituent parsing framework neural conditional random fields crf reformulate parsing task heightlimited constituent parsing computational complexity significantly reduced majority phrase-level grammars retained specifically unified model neural semi-crf neural tree-crf proposed simultaneously conducts word segmentation part-ofspeech pos tagging ner parsing challenge comes train infer joint model solved previously design dynamic programming algorithm training inference whose complexity n·4h n sentence length h height limit addition derive pruning algorithm joint model prunes 99.9 search space 2 loss ground truth data experimental results ontonotes 4.0 dataset demonstrated proposed model outperforms state-of-the-art method 2.79 points f1-measure	negative	3.133806487589027
online embedding compression for text classification using low rank matrix factorization	deep learning models become state art natural language processing nlp tasks however deploying models production system poses significant memory constraints existing compression methods either lossy introduce significant latency propose compression method leverages low rank matrix factorization training compress word embedding layer represents size bottleneck nlp models models trained compressed re-trained downstream task recover accuracy maintaining reduced size empirically show proposed method achieve 90 compression minimal impact accuracy sentence classification tasks outperforms alternative methods like fixed-point quantization offline word embedding compression also analyze inference time storage space method flop calculations showing compress dnn models configurable ratio regain accuracy loss without introducing additional latency compared fixed point quantization finally introduce novel learning rate schedule cyclically annealed learning rate calr empirically demonstrate outperform popular adaptive learning rate algorithms sentence classification benchmark	negative	4.378594933834393
a generic approach to accelerating belief propagation based incomplete algorithms for dcops via a branch-and-bound technique	belief propagation approaches max-sum variants important methods solve large-scale distributed constraint optimization problems dcops however problems n-ary constraints algorithms face huge challenge since computational complexity scales exponentially number variables function holds paper present generic easy-touse method based branch-and-bound technique solve issue called function decomposing state pruning fdsp theoretically prove fdsp provide monotonically non-increasing upper bounds speed belief propagation based incomplete dcop algorithms without effect solution quality also empirically evaluation indicates fdsp reduce 97 search space least effectively accelerate max-sum compared state-of-the-art	negative	7.6469110359903425
ethical challenges in data-driven dialogue systems	use dialogue systems medium human-machine interaction increasingly prevalent paradigm growing number dialogue systems use conversation strategies learned large datasets well documented instances interactions system resulted biased even offensive conversations due data-driven training process highlight potential ethical issues arise dialogue systems research including implicit biases data-driven systems rise adversarial examples potential sources privacy violations safety concerns special considerations reinforcement learning systems reproducibility concerns also suggest areas stemming issues deserve investigation initial survey hope spur research leading robust safe ethically sound dialogue systems	positive	0
m2det: a single-shot object detector based on multi-level feature pyramid network	feature pyramids widely exploited state-of-the-art one-stage object detectors e.g. dssd retinanet refinedet two-stage object detectors e.g. mask rcnn detnet alleviate problem arising scale variation across object instances although object detectors feature pyramids achieve encouraging results limitations due simply construct feature pyramid according inherent multiscale pyramidal architecture backbones originally designed object classification task newly work present multi-level feature pyramid network mlfpn construct effective feature pyramids detecting objects different scales first fuse multi-level features i.e multiple layers extracted backbone base feature second feed base feature block alternating joint thinned u-shape modules feature fusion modules exploit decoder layers ushape module features detecting objects finally gather decoder layers equivalent scales sizes construct feature pyramid object detection every feature map consists layers features multiple levels evaluate effectiveness proposed mlfpn design train powerful end-to-end one-stage object detector call m2det integrating architecture ssd achieve better detection performance state-of-the-art one-stage detectors specifically mscoco benchmark m2det achieves ap 41.0 speed 11.8 fps single-scale inference strategy ap 44.2 multi-scale inference strategy new stateof-the-art results among one-stage detectors code made available https //github.com/qijiezhao/m2det	negative	6.6929025136632845
active fairness in algorithmic decision making	society increasingly relies machine learning models automated decision making yet efficiency gains automation come paired concern algorithmic discrimination systematize inequality recent work proposed optimal post-processing methods randomize classification decisions fraction individuals order achieve fairness measures related parity errors calibration methods however raised concern due information inefficiency intra-group unfairness pareto sub-optimality entail present work proposes alternativeactive framework fair classification deployment decision-maker adaptively acquires information according needs different groups individuals towards balancing disparities classification performance propose two methods information collection adapted group- individual-level needs respectively show real-world datasets achieve 1 calibration single error parity e.g. equal opportunity 2 parity false positive false negative rates i.e. equal odds moreover show leveraging additional degree freedom active approaches substantially outperform randomization-based classifiers previously considered optimal avoiding limitations intra-group unfairness	positive	0
frame and feature-context video super-resolution	video super-resolution current state-of-the-art approaches either process multiple low-resolution lr frames produce output high-resolution hr frame separately sliding window fashion recurrently exploit previously estimated hr frames super-resolve following frame main weaknesses approaches 1 separately generating output frame may obtain high-quality hr estimates resulting unsatisfactory flickering artifacts 2 combining previously generated hr frames produce temporally consistent results case short information flow cause significant jitter jagged artifacts previous super-resolving errors constantly accumulated subsequent frames	negative	7.15290187462233
sociotechnical systems and ethics in the large	advances ai techniques computing platforms triggered lively expanding discourse ethical decision making autonomous agents much recent work ai concentrates challenges moral decision making decision-theoretic perspective especially representation various ethical dilemmas approaches may useful general productive moral decision making context-driven forms decision making contrast consider ethics standpoint individual agent wider sociotechnical systems sts agent operates contribution paper conception ethical sts founded governance takes account stakeholder values normative constraints agents outcomes states sts obtain due actions taken agents important element conception accountability necessary adequate consideration outcomes prima facie appear ethical unethical focusing sts provides basis tackling difficult problems ethics norms sts give operational basis agent decision making	positive	0
when do people want ai to make decisions?	ai systems soon sophisticated enough make consequential decisions although technology flourished also need public appraisals ai systems playing important roles article reports surveys preferences ai systems making decisions various domains well experiments intervene preferences find preferences contingent subjects previous exposure computer systems making kinds decisions interventions designed mimic previous exposure successfully encourage subjects hospitable computer systems making weighty decisions	positive	0
on influencing individual behavior for reducing transportation energy expenditure in a large population	research aims developing intelligent systems reduce transportation-related energy expenditure large city influencing individual behavior introduce copter intelligent travel assistant evaluates multi-modal travel alternatives find plan acceptable person given context preferences propose formulation acceptable planning brings together ideas ai machine learning economics formulation incorporated copter producing acceptable plans real-time adopt novel empirical evaluation framework combines human decision data high-fidelity simulation demonstrate 4 energy reduction 20 delay reduction realistic deployment scenario los angeles california usa	positive	0
calibrated stochastic gradient descent for convolutional neural networks	stochastic gradient descent sgd variants optimized gradient estimators may expensive compute true gradient many scenarios paper introduces calibrated stochastic gradient descent csgd algorithm deep neural network optimization theorem developed prove unbiased estimator network variables obtained probabilistic way based lipschitz hypothesis work significantly distinct existing gradient optimization methods providing theoretical framework unbiased variable estimation deep learning paradigm optimize model parameter calculation particular develop generic gradient calibration layer easily used build convolutional neural networks cnns experimental results demonstrate cnns csgd optimization scheme improve stateof-the-art performance natural image classification digit recognition imagenet object classification object detection tasks work opens new research directions developing efficient sgd updates analyzing backpropagation algorithm	negative	7.257838236007956
toward the engineering of virtuous machines	various traditions 'virtue ethics umbrella studied extensively advocated ethicists clear exists version virtue ethics rigorous enough target machine ethics take include engineering ethical sensibility machine robot study ethics humans might create artificial agents begin address presenting embryonic formalization key part virtue-ethics theory namely learning virtue focus exemplars moral virtue work based part computational formal logic previously used formally model ethical theories principles therein implement models artificial agents	positive	0
building jiminy cricket: an architecture for moral agreements among stakeholders	autonomous system constructed manufacturer operates society subject norms laws interacting end-users address challenge moral values views stakeholders integrated reflected moral behavior autonomous system propose artificial moral agent architecture uses techniques normative systems formal argumentation reach moral agreements among stakeholders show architecture used ethical practical reasoning collaborative decision-making also explanation moral behavior	positive	0
