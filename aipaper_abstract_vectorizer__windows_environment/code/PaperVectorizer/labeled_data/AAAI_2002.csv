,conference_year,category,title,author,abstract,download_url,keywords,8
0,2002,Contents,AAAI Organization,,Organization of AAAI in 2002.,https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-182.pdf,,29
1,2002,Contents,Program Committee,,Program committee of AAAI-02.,https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-183.pdf,,29
2,2002,Contents,,Outstanding Paper Award,Outstanding paper from the AAAI-02 conference.,https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-184.pdf,,46
3,2002,Contents,Sponsors,,Sponsors of AAAI-02.,https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-185.pdf,,20
4,2002,Contents,Preface,,Preface to the AAAI-02 / IAAI-02 proceedings.,https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-186.pdf,,45
5,2002,Contents,Invited Talks,,Abstracts of the AAAI-02 invited talks and panels.,https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-187.pdf,,50
6,2002,Constraint Satisfaction,The Yard Allocation Problem,"Ping Chen, Zhaohui Fu, and Andrew Lim, National University of Singapore","The Yard Allocation Problem (YAP) is a real-life resource allocation problem faced by the Port of Singapore Authority (PSA). We first show that YAP is NP-Hard. As the problem is NP-Hard, we propose several heuristics, including Tabu Search methods with short and long term memory, a ""Squeaky Wheel"" Optimization (SWO) method, and a new hybrid which combines SWO with TS to solve the problem. Extensive experiments show very favorable results for our new hybrid method.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-001.pdf,,468
7,2002,Constraint Satisfaction,Integrating Local Search and Network Flow to Solve the Inventory Routing Problem,"Hoong Chuin Lau, National University of Singapore; Qizhang Liu, ASPrecise Pte Ltd; Hirotaka Ono, Kyushu University","The inventory routing problem is one of important and practical problems in logistics. It involves the integration of inventory management and vehicle routing, both of which are known to be NP-hard. In this paper, we combine local search and network flows to solve the inventory management problem, by utilizing the minimum cost flow sub-solutions as a guiding measure for local search. We then integrate with a standard VRPTW solver to present experimental results for the overall inventory routing problem, based on instances extended from the Solomon benchmark problems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-002.pdf,,573
8,2002,Constraint Satisfaction,Generating Random Solutions for Constraint Satisfaction Problems,"Rina Dechter and Kalev Kask, University of California, Irvine; Eyal Bin and Roy Emek, IBM Research Laboratory in Haifa","The paper presents a method for generating solutions of a constraint satisfaction problem (CSP) uniformly at random. The main idea is to transform the constraint network into a belief network that expresses a uniform random distribution over its set of solutions and then use known sampling algorithms over belief networks. The motivation for this tasks comes from hardware verification. Random test program generation for hardware verification can be modeled and performed through CSP techniques, and is an application in which uniform random solution sampling is required.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-003.pdf,,574
9,2002,Constraint Satisfaction,Graph Coloring with Quantum Heuristics,"Alex Fabrikant, University of California, Berkeley; Tad Hogg, HP Labs","We present a quantum computer heuristic search algorithm for graph coloring. This algorithm uses a new quantum operator, appropriate for nonbinary-valued constraint satisfaction problems, and information available in partial colorings. We evaluate the algorithm empirically with small graphs near a phase transition in search performance. It improves on two prior quantum algorithms: unstructured search and a heuristic applied to the satisfiability (SAT) encoding for graph coloring. An approximate asymptotic analysis suggests polynomial-time cost for hard graph coloring problems, on average.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-004.pdf,,595
10,2002,Constraint Satisfaction,Reducing Search Space in Local Search for Constraint Satisfaction,"H. Fang, Yale University; Y. Kilani and J.H.M. Lee, The Chinese University of Hong Kong; P.J. Stuckey, University of Melbourne","Typically local search methods for solving constraint satisfaction problems such as GSAT,WalkSAT and DLM treat the problem as an optimization problem. Each constraint contributes part of a penalty function in assessing trial valuations. Local search examines the neighbours of the current valuation, using the penalty function to determine a better neighbor valuations to move to, until finally a solution which satisfies all constraints is found. In this paper we investigate using some of the constraints, rather than as part of a penalty function, as hard constraints, that are always satisfied by every trial valuation visited. In this way the constraints reduce the possible neighbours in each move and also the overall search space. The treating of some constraints as hard requires that the space of valuations that are satisfied is connected in order to guarantee that a solution can be found from any starting position within the region. Treating some constraints as hard also provides difficulties for the search mechanism since the search space becomes more jagged, and there are more deep local minima. A new escape strategy is needed. We show in this paper how, for DIMACS translations of binary CSPs, treating some constraints as hard can signifi- cantly improve search performance of the DLM local search method.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-005.pdf,,1327
11,2002,Constraint Satisfaction,Preference-Based Search and Multi-Criteria Optimization,Ulrich Junker,"Many real-world AI problems (e.g. in configuration) are weakly constrained, thus requiring a mechanism for characterizing and finding the preferred solutions. Preference-based search (PBS) exploits preferences between decisions to focus search to preferred solutions, but does not efficiently treat preferences on defined criteria such as the total price or quality of a configuration. We generalize PBS to compute balanced, extreme, and Pareto-optimal solutions for general CSP’s, thus handling preferences on and between multiple criteria. A master-PBS selects criteria based on trade-offs and preferences and passes them as optimization objective to a sub-PBS that performs a constraint-based Branch-and-Bound search. We project the preferences of the selected criterion to the search decisions to provide a search heuristics and to reduce search effort, thus giving the criterion a high impact on the search. The resulting method will particularly be effective for CSP’s with large domains that arise if configuration catalogs are large.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-006.pdf,,1041
12,2002,Constraint Satisfaction,Human-Guided Tabu Search,"Gunnar W. Klau, Vienna University of Technology; Neal Lesh and
Joe Marks, Mitsubishi Electric Research Laboratories; Michael Mitzenmacher, Harvard University","We present a human-guidable and general tabu search algorithm. Our work expands on previous interactive optimization techniques that provide for substantial human control over a simple, exhaustive search algorithm. User experiments in four domains confirm that human guidance can improve the performance of tabu search and that people obtain superior results by guiding a tabu algorithm than by guiding an exhaustive algorithm.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-007.pdf,,427
13,2002,Constraint Satisfaction,Node and Arc Consistency in Weighted CSP,"Javier Larrosa, Universitat Politecnica de Catalunya","Recently, a general definition of arc consistency (AC) for soft constraints has been proposed. In this paper we specialize this definition to weighted CSP and introduce a O(ed3) algorithm. Then, we refine the definition and introduce a stronger form of arc consistency (AC*) along with a O(n2 d3) algorithm. We empirically demonstrate that AC* is likely to be much better than AC in terms of pruned values.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-008.pdf,,406
14,2002,Constraint Satisfaction,"Model Induction: A New Source of CSP Model Redundancy / 54
","Y. C. Law and J. H. M. Lee, The Chinese University of Hong Kong","Based on the notions of viewpoints, models, and channeling constraints, the paper introduces model induction, a systematic transformation of constraints in an existing model to constraints in another viewpoint. Meant to be a general CSP model operator, model induction is useful in generating redundant models, which can be further induced or combined with the original model or other mutually redundant models. We propose three ways of combining redundant models using model induction, model channeling, and model intersection. Experimental results on the Langford’s problem confirm that our proposed combined models exhibit improvements in efficiency and robustness over the original single models.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-009.pdf,,700
15,2002,Knowledge Representation,On Computing all Abductive Explanations,"Thomas Eiter, Technische Universität Wien; Kazuhisa Makino, Osaka University","We consider the computation of all respectively a polynomial subset of the explanations of an abductive query from a Horn theory, and pay particular attention to whether the query is a positive or negative letter, the explanation is based on literals from an assumption set, and the Horn theory is represented in terms of formulas or characteristic models. We derive tractability results, one of which refutes a conjecture by Selman and Levesque, as well as intractability results, and furthermore also semi-tractability results in terms of solvability in quasi-polynomial time. Our results complement previous results in the literature, and elucidate the computational complexity of generating the set of explanations.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-010.pdf,,719
16,2002,Knowledge Representation,Measuring Inconsistency in Knowledge via Quasi-Classical Models,"Anthony Hunter, University College London","The language for describing inconsistency is underdeveloped. If a knowledgebase (a set of formulae) is inconsistent, we need more illuminating ways to say how inconsistent it is, or to say whether one knowledgebase is ""more inconsistent"" than another. To address this, we provide a general characterization of inconsistency, based on quasi-classical logic (a form of paraconsistent logic with a more expressive semantics than Belnap’s four-valued logic, and unlike other paraconsistent logics, allows the connectives to appear to behave as classical connectives). We analyse inconsistent knowledge by considering the conflicts arising in the minimal quasi-classical models for that knowledge. This is used for a measure of coherence for each knowledgebase, and for a preference ordering, called the compromise relation, over knowledgebases. In this paper, we formalise this framework, and consider applications in managing heterogeneous sources of knowledge.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-011.pdf,,958
17,2002,Knowledge Representation,A Hoare-Style Proof System for Robot Programs,"Yongmei Liu, University of Toronto","Golog is a situation calculus-based logic programming language for high-level robotic control. This paper explores Hoare’s axiomatic approach to program verification in the Golog context. We present a novel Hoare-style proof system for partial correctness of Golog programs. We prove total soundness of the proof system, and relative completeness of a subsystem of it for procedureless Golog programs. Examples are given to illustrate the use of the proof system.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-012.pdf,,463
18,2002,Knowledge Representation,Representing and Reasoning about Mappings between Domain Models,"Jayant Madhavan, University of Washington; Philip A. Bernstein, Microsoft Research; Pedro Domingos and Alon Y. Halevy, University of Washington","Mappings between disparate models are fundamental to any application that requires interoperability between heterogeneous data and applications. Generating mappings is a labor-intensive and error prone task. To build a system that helps users generate mappings, we need an explicit representation of mappings. This representation needs to have well-defined semantics to enable reasoning and comparison between mappings. This paper first presents a powerful framework for defining languages for specifying mappings and their associated semantics. We examine the use of mappings and identify the key inference problems associated with mappings. These properties can be used to determine whether a mapping is adequate in a particular context. Finally, we consider an instance of our framework for a language representing mappings between relational data. We present sound and complete algorithms for the corresponding inference problems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-013.pdf,,934
19,2002,Knowledge Representation,A Regression Based Adaptation Strategy for Case-Based Reasoning,"David Patterson, Niall Rooney, and Mykola Galushka, University of Ulster at Jordanstown","Adaptation is the least well studied process in case-based reasoning (CBR). The main reasons for this are the potentially complex nature of implementing adaptation knowledge and the difficulties associated with acquiring quality knowledge in the first place and competently maintaining it over time. For these reasons most CBR systems are designed to leave the adaptation component to the expert and therefore function simply as case retrieval systems as opposed to truly reasoning systems. Here we present a competent adaptation strategy, which uses a modified regression algorithm to automatically discover and implement locally specific adaptation knowledge in CBR. The advantages of this approach are that the adaptation knowledge acquisition process is automated, localised, guaranteed to be specific to the task at hand, and there is no adaptation knowledge maintenance burden on the system. The disadvantage is that the time taken to form solutions is increased but we also show how a novel indexing scheme based on k-means clustering can help reduce this overhead considerably.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-014.pdf,,1085
20,2002,Knowledge Representation,Cluster Ensembles - A Knowledge Reuse Framework for Combining Partitionings,"Alexander Strehl and Joydeep Ghosh, The University of Texas at Austin Logic Programming","It is widely recognized that combining multiple classification or regression models typically provides superior results compared to using a single, well-tuned model. However, there are no well known approaches to combining multiple non-hierarchical clusterings. The idea of combining cluster labelings without accessing the original features leads us to a general knowledge reuse framework that we call cluster ensembles. Our contribution in this paper is to formally define the cluster ensemble problem as an optimization problem and to propose three effective and efficient combiners for solving it based on a hypergraph model. Results on synthetic as well as real data sets are given to show that cluster ensembles can (i) improve quality and robustness, and (ii) enable distributed clustering.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-015.pdf,,797
21,2002,Knowledge Representation,Logic Programming with Ordered Disjunction,"Gerhard Brewka, Universität Leipzig","Logic programs with ordered disjunction (LPODs) combine ideas underlying Qualitative Choice Logic, a logic recently introduced by Brewka, Benferhat and Le Berre, and answer set programming. Logic programming under answer set semantics is extended with a new connective called ordered disjunction. The new connective allows us to represent alternative, ranked options for problem solutions in the heads of rules: A x B intuitively means: if possible A, but if A is not possible then at least B. The semantics of logic programs with ordered disjunction is based on a preference relation on answer sets. LPODs are useful for applications in design and configuration and can serve as a basis for qualitative decision making.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-016.pdf,,720
22,2002,Knowledge Representation,A Three-Valued Characterization for Strong Equivalence of Logic Programs,"Pedro Cabalar, University of Corunna","In this work we present additional results related to the property of strong equivalence of logic programs. This property asserts that two programs share the same set of stable models, even under the addition of new rules. As shown in a recent work by Lifschitz, Pearce and Valverde, strong equivalence can be simply reduced to equivalence in the logic of Here-and-There (HT). In this paper we provide an alternative based on 3-valued logic, using also, as a first step, a classical logic charaterization. We show that the 3-valued encoding provides a direct interpretation for nested expressions but, when moving to an unrestricted syntax, it generally yields different results from HT.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-017.pdf,,687
23,2002,Knowledge Representation,ASSAT: Computing Answer Sets of a Logic Program by SAT Solvers,"Fangzhen Lin and Yuting Zhao, Hong Kong University of Science and Technology","We propose a new translation from normal logic programs with constraints under the answer set semantics to propositional logic. Given a logic program, we show that by adding, for each loop in the program, a corresponding loop formula to the program’s completion, we obtain a one-to-one correspondence between the answer sets of the program and the models of the resulting propositional theory. Compared with the translation by Ben-Eliyahu and Dechter, ours has the advantage that it does not use any extra variables, and is considerably simpler, thus easier to understand. However, in the worst case, it requires computing exponential number of loop formulas. To address this problem, we propose an approach that adds loop formulas a few at a time, selectively. Based on these results, we implemented a system called ASSAT(X), depending on the SAT solver X used, and tested it on a variety of benchmarks including the graph coloring, the blocks world planning, and Hamiltonian Circuit domains. The results are compared with those by smodels and dlv, and it shows a clear edge of ASSAT(X) over them in these domains.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-018.pdf,,1115
24,2002,Learning,"State Abstraction for Programmable Reinforcement Learning Agents / 119
","David Andre and Stuart J. Russell, University of California, Berkeley","Safe state abstraction in reinforcement learning allows an agent to ignore aspects of its current state that are irrelevant to its current decision, and therefore speeds up dynamic programming and learning. This paper explores safe state abstraction in hierarchical reinforcement learning, where learned behaviors must conform to a given partial, hierarchical program. Unlike previous approaches to this problem, our methods yield significant state abstraction while maintaining hierarchical optimality, i.e., optimality among all policies consistent with the partial program. We show how to achieve this for a partial programming language that is essentially Lisp augmented with nondeterministic constructs. We demonstrate our methods on two variants of Dietterich’s taxi domain, showing how state abstraction and hierarchical optimality result in faster learning of better policies and enable the transfer of learned skills from one problem to another.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-019.pdf,,954
25,2002,Learning,Contentful Mental States for Robot Baby,"Paul R. Cohen, University of Massachusetts; Tim Oates, University of Maryland; Carole R. Beal, University of Massachusetts; Niall Adams, Imperial College, London","In this paper we claim that meaningful representations can be learned by programs, although today they are almost always designed by skilled engineers. We discuss several kinds of meaning that representations might have, and focus on a functional notion of meaning as appropriate for programs to learn. Specifically, a representation is meaningful if it incorporates an indicator of external conditions and if the indicator relation informs action. We survey methods for inducing kinds of representations we call structural abstractions. Prototypes of sensory time series are one kind of structural abstraction, and though they are not denoting or compositional, they do support planning. Deictic representations of objects and prototype representations of words enable a program to learn the denotational meanings of words. Finally, we discuss two algorithms designed to find the macroscopic structure of episodes in a domain-independent way.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-020.pdf,,943
26,2002,Learning,Data Perturbation for Escaping Local Maxima in Learning,"Gal Elidan, Matan Ninio, and Nir Friedman, Hebrew University; Dale Shuurmans, University of Waterloo","Almost all machine learning algorithms -- be they for regression, classification or density estimation -- seek hypotheses that optimize a score on training data. In most interesting cases, however, full global optimization is not feasible and local search techniques are used to discover reasonable solutions. Unfortunately, the quality of the local maxima reached depends on initialization and is often weaker than the global maximum. In this paper, we present a simple approach for combining global search with local optimization to discover improved hypotheses in general machine learning problems. The main idea is to escape local maxima by perturbing the training data to create plausible new ascent directions, rather than perturbing hypotheses directly. Specifically, we consider example-reweighting strategies that are reminiscent of boosting and other ensemble learning methods, but applied in a different way with a different goal: to produce a single hypothesis that achieves a good score on training and test data. To evaluate the performance of our algorithms we consider a number of problems in learning Bayesian networks from data, including discrete training problems (structure search), continuous training problems (parametric EM, non-linear logistic regression), and mixed training problems (Structural EM) -- on both synthetic and real-world data. In each case, we obtain state of the art performance on both training and test data.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-021.pdf,,1452
27,2002,Learning,Progressive Rademacher Sampling,"Tapio Elomaa and Matti Kääriäinen, University of Helsinki","Sampling can enhance processing of large training example databases, but without knowing all of the data, or the example producing process, it is impossible to know in advance what size of a sample to choose in order to guarantee good performance. Progressive sampling has been suggested to circumvent this problem. The idea in it is to increase the sample size according to some schedule until accuracy close to that which would be obtained using all of the data is reached. How to determine this stopping time efficiently and accurately is a central difficulty in progressive sampling. We study stopping time determination by approximating the generalization error of the hypothesis rather than by assuming the often observed shape for the learning curve and trying to detect whether the final plateau has been reached in the curve. We use data dependent generalization error bounds. Instead of using the common cross validation approach, we use the recently introduced Rademacher penalties, which have been observed to give good results on simple concept classes. We experiment with two-level decision trees built by the learning algorithm T2. It finds a hypothesis with the minimal error with respect to the sample. The theoretically well motivated stopping time determination based on Rademacher penalties gives results that are much closer to those attained using heuristics based on assumptions on learning curve shape than distribution independent estimates based on VC dimension do.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-022.pdf,,1491
28,2002,Learning,Pruning and Dynamic Scheduling of Cost-Sensitive Ensembles,"Wei Fan, IBM T.J. Watson Research; Fang Chu, University of California, Los Angeles;
Haixun Wang and Philip S. Yu, IBM T.J. Watson Research","Previous research has shown that averaging ensemble can scale up learning over very large cost-sensitive datasets with linear speedup independent of the learning algorithms. At the same time, it achieves the same or even better accuracy than a single model computed from the entire dataset. However, one major drawback is its inefficiency in prediction since every base model in the ensemble has to be consulted in order to produce a final prediction. In this paper, we propose several approaches to reduce the number of base classifiers. Among various methods explored, our empirical studies have shown that the benefit-based greedy approach can safely remove more than 90\% of the base models while maintaining or even exceeding the prediction accuracy of the original ensemble. Assuming that each base classifier consumes one unit of prediction time, the removal of 90% of base classifiers translates to a prediction speedup of 10 times. On top of pruning, we propose a novel dynamic scheduling approach to further reduce the ""expected"" number of classifiers employed in prediction. It measures the confidence of a prediction by a subset of classifiers in the pruned ensemble. This confidence is used to decide if more classifiers are needed in order to produce a prediction that is the same as the original unpruned ensemble. This approach reduces the ""expected"" number of classifiers by another 25% to 75% without loss of accuracy.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-023.pdf,,1436
29,2002,Learning,Specific-to-General Learning for Temporal Events,"Alan Fern, Robert Givan, and Jeffrey Mark Siskind, Purdue University","We study the problem of supervised learning of event classes in a simple temporal event-description language. We give lower and upper bounds and algorithms for the subsumption and generalization problems for two expressively powerful subsets of this logic, and present a positive-examples-only specific-to-general learning method based onthe resulting algorithms. We also present a polynomial-time computable ""syntactic"" subsumption test that implies semantic subsumption without being equivalent to it. A generalization algorithm based on syntactic subsumption can be used in place of semantic generalization to improve the asymptotic complexity of the resulting learning algorithm. A companion paper shows that our methods can be applied to duplicate the performance of human-coded concepts in the substantial application domain of video event recognition.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-024.pdf,,858
30,2002,Learning,"Learning Temporal, Relational, Force-Dynamic Event Definitions from Video","Alan Fern, Jeffrey Mark Siskind, and Robert Givan, Purdue University","We present and evaluate a novel implemented approach for learning to recognize events in video. First, we introduce a sublanguage of event logic, called k-AMA, that is sufficiently expressive to represent visual events yet sufficiently restrictive to support learning. Second, we develop a specific-to-general learning algorithm for learning event definitions in k-AMA. Finally, we apply this algorithm to the task of learning event definitions from video and show that it yields definitions that are competitive with hand-coded ones.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-025.pdf,,534
31,2002,Learning,Structural Extension to Logistic Regression: Discriminative Parameter Learning of Belief Net Classifiers,"Russell Greiner, University of Alberta; Wei Zhou, University of Waterloo","Bayesian belief nets (BNs) are often used for classification tasks --- typically to return the most likely ""class label"" for each specified instance. Many BN-learners, however, attempt to find the BN that maximizes a different objective function (viz., likelihood, rather than classification accuracy), typically by first learning an appropriate graphical structure, then finding the maximal likelihood parameters for that structure. As these parameters may not maximize the classification accuracy, ""discriminative learners"" follow the alternative approach of seeking the parameters that maximize conditionallikelihood (CL), over the distribution of instances the BN will have to classify. This paper first formally specifies this task, and shows how it relates to logistic regression, which corresponds to finding the optimal CL parameters for a naive-bayes structure. After analyzing its inherent (sample and computational) complexity, we then present a general algorithm for this task, ELR, which applies to arbitrary BN structures and which works effectively even when given the incomplete training data. This paper presents empirical evidence that ELR works better than the standard ""generative"" approach in a variety of situations, especially in common situation where the BN-structure is incorrect.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-026.pdf,,1306
32,2002,Learning,Bootstrap Learning for Place Recognition,"Benjamin Kuipers and Patrick Beeson, The University of Texas at Austin","We present a method whereby a robot can learn to recognize places with high accuracy, in spite of perceptual aliasing (different places appear the same) and image variability (the same place appears differently). The first step in learning place recognition restricts attention to distinctive states identified by the map-learning algorithm, and eliminates image variability by unsupervised learning of clusters of similar sensory images. The clusters define views associated with distinctive states, often increasing perceptual aliasing. The second step eliminates perceptual aliasing by building a causal/topological map and using history information gathered during exploration to disambiguate distinctive states. The third step uses the labeled images for supervised learning of direct associations from sensory images to distinctive states. We evaluate the method using a physical mobile robot in two environments, showing high recognition rates in spite of large amounts of perceptual aliasing.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-027.pdf,,1000
33,2002,Learning,Minimum Majority Classification and Boosting,"Philip M. Long, Genome Institute of Singapore","Motivated by a theoretical analysis of the generalization of boosting, we examine learning algorithms that work by trying to fit data using a simple majority vote over a small number of a collection of hypotheses. We provide experimental evidence that an algorithm based on this principle outputs hypotheses that often generalize nearly as well as those output by boosting, and sometimes better. We also provide experimental evidence for an additional reason that boosting algorithms generalize well, that they take advantage of cases in which there are many simple hypotheses with independent errors.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-028.pdf,,601
34,2002,Learning,Content-Boosted Collaborative Filtering for Improved Recommendations,"Prem Melville, Raymond J. Mooney, and Ramadass Nagarajan, University of Texas at Austin","Most recommender systems use Collaborative Filtering or Content-based methods to predict new items of interest for a user. While both methods have their own advantages, individually they fail to provide good recommendations in many situations. Incorporating components from both methods, a hybrid recommender system can overcome these shortcomings. In this paper, we present an elegant and effective framework for combining content and collaboration. Our approach uses a content-based predictor to enhance existing user data, and then provides personalized suggestions through collaborative filtering. We present experimental results that show how this approach, Content-Boosted Collaborative Filtering, performs better than a pure content-based predictor, pure collaborative filter, and a naive hybrid approach.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-029.pdf,,812
35,2002,Learning,Constructive Adaptive User Interfaces - Composing Music Based on Human Feelings,"Masayuki Numao, Shoichi Takagi, and Keisuke Nakamura, Tokyo Institute of Technology","We propose a method to locate relations and constraints between a music score and its impressions, by which we show that machine learning techniques may provide a powerful tool for composing music and analyzing human feelings. We examine its generality by modifying some arrangements to provide the subjects with a specified impression. This paper introduces some user interfaces, which are capable of predicting feelings and creating new objects based on seed structures, such as spectra and their transition for sounds that have been extracted and are perceived as favorable by the test subject.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-030.pdf,,597
36,2002,Learning,Reinforcement Learning for POMDPs Based on Action Values and Stochastic Optimization,"Theodore J. Perkins, University of Massachusetts Amherst","We present a new, model-free reinforcement learning algorithm for learning to control partially-observable Markov decision processes. The algorithm incorporates ideas from action-value based reinforcement learning approaches, such as Q-Learning, as well as ideas from the stochastic optimization literature. Key to our approach is a new definition of action value, which makes the algorithm theoretically sound for partially-observable settings. We show that special cases of our algorithm can achieve probability one convergence to locally optimal policies in the limit, or probably approximately correct hill-climbing to a locally optimal policy in a finite number of samples.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-031.pdf,,678
37,2002,Learning,Polynomial-Time Reinforcement Learning of Near-Optimal Policies,"Karèn Pivazyan and Yoav Shoham, Stanford University","Inspired by recent results on polynomial time reinforcement algorithms that accumulate near-optimal rewards, we look at the related problem of quickly learning near-optimal policies. The new problem is obviously related to the previous one, but different in important ways. We provide simple algorithms for MDPs, zero-sum and common-payoff Stochastic Games, and a uniform framework for proving their polynomial complexity. Unlike the previously studied problem, these bounds use the minimum between the mixing time and a new quantity - the spectral radius. Unlike the previous results, our results apply uniformly to the average and discounted cases.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-032.pdf,,650
38,2002,Learning,Constrained Formulations and Algorithms for Stock-Price Predictions Using Recurrent FIR Neural Networks,"Benjamin W. Wah and Minglun Qian, University of Illinois, Urbana-Champaign","In this paper, we develop new constrained artificial-neural-network (ANN) formulations and learning algorithms to predict future stock prices, a difficult time-series prediction problem. Specifically, we characterize stock prices as a non-stationary noisy time series, identify its predictable low-frequency components, develop strategies to predict missing low-frequency information in the lag period of a filtered time series, model the prediction problem by a recurrent FIR ANN, formulate the training problem of the ANN as a constrained optimization problem, develop new constraints to incorporate the objectives in cross validation, solve the learning problem using algorithms based on the theory of Lagrange multipliers for nonlinear discrete constrained optimization, and illustrate our prediction results on three stock time series.There are two main contributions of this paper. First, we present a new approach to predict missing low-pass data in the lag period when low-pass filtering is applied on a time series. Such predictions allow learning to be carried out more accurately. Second, we propose new constraints on cross validation that can improve significantly the accuracy of learning in a constrained formulation. Our experimental results demonstrate good prediction accuracy in a 10-day horizon.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-033.pdf,,1315
39,2002,Learning,Rule-Based Anomaly Pattern Detection for Detecting Disease Outbreaks,"Weng-Keen Wong and Andrew Moore, Carnegie Mellon University; Gregory Cooper and Michael Wagner, University of Pittsburgh","This paper presents an algorithm for performing early detection of disease outbreaks by searching a database of emergency department cases for anomalous patterns. Traditional techniques for anomaly detection are unsatisfactory for this problem because they identify individual data points that are rare due to particular combinations of features. When applied to our scenario, these traditional algorithms discover isolated outliers of particularly strange events, such as someone accidentally shooting their ear, that are not indicative of a new outbreak. Instead, we would like to detect anomalous patterns. These patterns are groups with specific characteristics whose recent pattern of illness is anomalous relative to historical patterns. We propose using a rule-based anomaly detection algorithm that characterizes each anomalous pattern with a rule. The significance of each rule is carefully evaluated using Fisher’s Exact Test and a randomization test. Our algorithm is compared against a standard detection algorithm by measuring the number of false positives and the timeliness of detection. Simulated data, produced by a simulator that creates the effects of an epidemic on a city, is used for evaluation. The results indicate that our algorithm has significantly better detection times for common significance thresholds while having a slightly higher false positive rate.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-034.pdf,,1385
40,2002,Learning,Extended Isomap for Pattern Classification,"Ming-Hsuan Yang, Honda Fundamental Research Labs","The Isomap method has demonstrated promising results in finding low dimensional manifolds from data points in the high dimensional input space. While classical subspace methods use Euclidean or Manhattan metrics to represent distances between data points and apply Principal Component Analysis to induce linear manifolds, the Isomap method estimates geodesic distances between data points and then uses Multi-Dimensional Scaling to induce low dimensional manifolds. Since the Isomap method is developed based on reconstruction principle, it may not be optimal from the classification viewpoint. In this paper, we present an extended Isomap method that utilizes Fisher Linear Discriminant for pattern classification. Numerous experiments on image data sets show that our extension is more effective than the original Isomap method for pattern classification. Furthermore, the extended Isomap method shows promising results compared with best methods in the face recognition literature.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-035.pdf,,984
41,2002,Learning,Hierarchical Latent Class Models for Cluster Analysis,"Nevin L. Zhang, Hong Kong University of Science and Technology","Latent class models are used for cluster analysis of categorical data. Underlying such a model is the assumption that the observed variables are mutually independent given the class variable. A serious problem with the use of latent class models, known as local dependence, is that this assumption is often untrue. In this paper we propose hierarchical latent class models as a framework where the local dependence problem can be addressed in a principled manner. We develop a search-based algorithm for learning hierarchical latent class models from data. The algorithm is evaluated using both synthetic and real-world data.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-036.pdf,,625
42,2002,Markov Decision Processes,A POMDP Formulation of Preference Elicitation Problems,"Craig Boutilier, University of Toronto","Preference elicitation is a key problem facing the deployment of intelligent systems that make or recommend decisions on the behalf of users. Since not all aspects of a utility function have the same impact on object-level decision quality, determining which information to extract from a user is itself a sequential decision problem, balancing the amount of elicitation effort and time with decision quality. We formulate this problem as a partially-observable Markov decision process (POMDP). Because of the continuous nature of the state and action spaces of this POMDP, standard techniques cannot be used to solve it. We describe methods that exploit the special structure of preference elicitation to deal with parameterized belief states over the continuous state space, and gradient techniques for optimizing parameterized actions. These methods can be used with a number of different belief state representations, including mixture models.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-037.pdf,,947
43,2002,Markov Decision Processes,Segmenting Time Series with a Hybrid Neural Networks - Hidden Markov Model,"Laura Firoiu and Paul R. Cohen, University of Massachusetts Amherst","This paper describes work on a hybrid HMM/ANN system for finding patterns in a time series, where a pattern is a function that can be approximated by a recurrent neural network embedded in the state of a hidden Markov model. The most likely path of the hidden Markov model is used both for re-training the HMM/ANN model and for segmenting the time series into pattern occurrences. The number of patterns is determined from the data by first increasing the number of networks as long as the likelihood of the segmentation increases, then reducing this number to satisfy an MDL criterion. In experiments with artificial data the algorithm correctly identified the generating functions. Preliminary results with robot data show that potentially useful patterns that can be associated with low-level concepts can be induced this way.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-038.pdf,,829
44,2002,Markov Decision Processes,Context-Specific Multiagent Coordination and Planning with Factored MDPs,"Carlos Guestrin, Shobha Venkataraman, and Daphne Koller, Stanford University","We present an algorithm for coordinated decision making in cooperative multiagent settings, where the agents’ value function can be represented as a sum of context-specific value rules. The task of finding an optimal joint action in this setting leads to an algorithm where the coordination structure between agents depends on the current state of the system and even on the actual numerical values assigned to the value rules. We apply this framework to the task of multiagent planning in dynamic systems, showing how a joint value function of the associated Markov Decision Process can be approximated as a set of value rules using an efficient linear programming algorithm. The agents then apply the coordination graph algorithm at each iteration of the process to decide on the highest-value joint action, potentially leading to a different coordination pattern at each step of the plan.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-039.pdf,,891
45,2002,Markov Decision Processes,Nearly Deterministic Abstractions of Markov Decision Processes,"Terran Lane and Leslie Pack Kaelbling, MIT Artificial Intelligence Laboratory","We examine scaling issues for a restricted class of compactly representable Markov decision process planning problems. For one stochastic mobile robotics package delivery problem it is possible to decouple the stochastic local-navigation problem from the deterministic global-routing one and to solve each with dedicated methods. Careful construction of macro actions allows us to effectively ""hide"" navigational stochasticity from the global routing problem and to approximate the latter with off-the-shelf combinatorial optimization routines for the traveling salesdroid problem, yielding a net exponential speedup in planning performance. We give analytic conditions on when the macros are close enough to deterministic for the approximation to be good and demonstrate the performance of our method on small and large simulated navigation problems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-040.pdf,,851
46,2002,Markov Decision Processes,The Size of MDP Factored Policies,"Paolo Liberatore, Università di Roma ""La Sapienza""","Policies of Markov Decision Processes (MDPs) tell the next action to execute, given the current state and (possibly) the history of actions executed so far. Factorization is used when the number of states is exponentially large: both the MDP and the policy can be then represented using a compact form, for example employing circuits. We prove that there are MDPs whose optimal policies require exponential space even in factored form.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-041.pdf,,435
47,2002,Markov Decision Processes,On Policy Iteration as a Newton’s Method and Polynomial Policy Iteration Algorithms,"Omid Madani, University of Alberta","Policy iteration is a popular technique for solving Markov decision processes (MDPs). It is easy to describe and implement, and has excellent performance in practice. But not much is known about its complexity. The best upper bound remains exponential, and the best lower bound is a trivial Omega(n) on the number of iterations, where n is the number of states. This paper improves the upper bounds to a polynomial for policy iteration on MDP problems with special graph structure. Our analysis is based on the connection between policy iteration and Newton’s method for finding the zero of a convex function. The analysis offers an explanation as to why policy iteration is fast. It also leads to polynomial bounds on several variants of policy iteration for MDPs for which the linear programming formulation requires at most two variables per inequality (MDP(2)). The MDP(2) class includes deterministic MDPs under discounted and average reward criteria.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-042.pdf,,956
48,2002,Markov Decision Processes,Efficient Utility Functions for Ceteris Paribus Preferences,"Michael McGeachie, Massachusetts Institute of Technology; Jon Doyle, North Carolina State University","Ceteris paribus (other things being equal) preference provides a convenient means for stating constraints on numeric utility functions, but direct constructions of numerical utility representations from such statements have exponential worst-case cost. This paper describes more efficient constructions that combine analysis of utility independence with constraint-based search.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-043.pdf,,378
49,2002,Markov Decision Processes,Greedy Linear Value-Approximation for Factored Markov Decision Processes,"Relu Patrascu, University of Waterloo; Pascal Poupart, University of Toronto; Dale Schuurmans, University of Waterloo; Craig Boutilier, University of Toronto; Carlos Guestrin, Stanford University","Significant recent work has focused on using linear representations to approximate value functions for factored Markov decision processes (MDPs). Current research has adopted linear programming as an effective means to calculate approximations for a given set of basis functions, tackling very large MDPs as a result. However, a number of issues remain unresolved: How accurate are the approximations produced by linear programs? How hard is it to produce better approximations? and Where do the basis functions come from? To address these questions, we first investigate the complexity of minimizing the Bellman error of a linear value function approximation---showing that this is an inherently hard problem. Nevertheless, we provide a branch and bound method for calculating Bellman error and performing approximate policy iteration for general factored MDPs. These methods are more accurate than linear programming, but more expensive. We then consider linear programming itself and investigate methods for automatically constructing sets of basis functions that allow this approach to produce good approximations. The techniques we develop are guaranteed to reduce L1 error, but can also empirically reduce Bellman error.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-044.pdf,,1226
50,2002,Markov Decision Processes,Piecewise Linear Value Function Approximation for Factored MDPs,"Pascal Poupart and Craig Boutilier, University of Toronto; Relu Patrascu and Dale Schuurmans, University of Waterloo","A number of proposals have been put forth in recent years for the solution of Markov decision processes (MDPs) whose state (and sometimes action) spaces are factored. One recent class of methods involves linear value function approximation, where the optimal value function is assumed to be a linear combination of some set of basis functions, with the aim of finding suitable weights. While sophisticated techniques have been developed for finding the best approximation within this constrained space, few methods have been proposed for choosing a suitable basis set, or modifying it if solution quality is found wanting. We propose a general framework, and specific proposals, that address both of these questions. In particular, we examine weakly coupled MDPs where a number of subtasks can be viewed independently modulo resource constraints. We then describe methods for constructing a piecewise linear combination of the subtask value functions, using greedy decision tree techniques. We argue that this architecture is suitable for many types of MDPs whose combinatorics are determined largely by the existence multiple conflicting objectives.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-045.pdf,,1150
51,2002,Markov Decision Processes,Bayesian Networks for Speech and Image Integration,"Sven Wachsmuth and Gerhard Sagerer, Bielefeld University","The realization of natural human-computer interfaces suffers from a wide range of restrictions concerning noisy data, vague meanings, and context dependence. An essential aspect of everyday communication is the ability of humans to ground verbal interpretations in visual perception. Thus, the system has to be able to solve the correspondence problem of relating verbal and visual descriptions of the same object. This contribution proposes a new and innovative solution to this problem using Bayesian networks. In order to capture vague meanings of adjectives used by the speaker, psycholinguistic experiments are evaluated. Object recognition errors are taken into account by conditional probabilities estimated on test sets. The Bayesian network is dynamically built up from verbal object description and is evaluated by an inference technique combining bucket elimination and conditioning. Results show that speech and image data is interpreted more robustly in the combined case than in the case of isolated interpretations.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-046.pdf,,1030
52,2002,Markov Decision Processes,Value Iteration Working with Belief Subsets,"Weihong Zhang, Washington University; Nevin L. Zhang, Hong Kong University of Science and Technology","Value iteration is a popular algorithm for solving POMDPs. However, it is inefficient in practice. The primary reason is that it needs to conduct value updates for all the belief states in the (continuous) belief space. In this paper, we study value iteration working with a subset of the belief space, i.e., it conducts value updates only for belief states in the subset. We present a way to select belief subset and describe an algorithm to conduct value iteration over the selected subset. The algorithm is attractive in that it works with belief subset but also retains the quality of the generated values. Given a POMDP, we show how to a priori determine whether the selected subset is a proper subset of belief space. If this is the case, the algorithm carries the advantages of representation in space and efficiency in time.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-047.pdf,,832
53,2002,Multiagent Systems,Complexity of Manipulating Elections with Few Candidates,"Vincent Conitzer and Tuomas Sandholm, Carnegie Mellon University","In multiagent settings where the agents have different preferences, preference aggregation is a central issue. Voting is a general method for preference aggregation, but seminal results have shown that all general voting protocols are manipulable. One could try to avoid manipulation by using protocols where determining a beneficial manipulation is hard. Especially among computational agents, it is reasonable to measure this hardness by computational complexity. Some earlier work has been done in this area, but it was assumed that the number of voters and candidates is unbounded. We derive hardness results for the more common setting where the number of candidates is small but the number of voters can be large. We show that with complete information about the others’ votes, individual manipulation is easy, and coalitional manipulation is easy with unweighted voters. However, constructive coalitional manipulation with weighted voters is intractable for all of the voting protocols under study, except in the Cup protocol. Destructive manipulation tends to be easier, except in the Single Transferable Vote protocol. Randomizing over instantiations of the protocols (such as schedules of a Cup) can be used to make manipulation hard. Finally, we show that under weak assumptions, if weighted coalitional manipulation with complete information about the others’ votes is hard in some voting protocol, then individual and unweighted manipulation is hard when there is uncertainty about the others’ votes.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-048.pdf,,1513
54,2002,Multiagent Systems,A Logic-Based Model of Intentions for Multi-Agent Subcontracting,"John Grant, Towson University; Sarit Kraus, Bar-Ilan University and University of Maryland; Donald Perlis, University of Maryland","We present a formalism for representing the intentions of agents engaged in cooperative planning and acting. We focus on cases where one agent alone cannot accomplish a complex task and must subcontract with other agents. Evolving intentions over time during the planning and acting, and the conditions under which an agent can adopt and maintain an intention, are central. In particular, the time taken to plan and to subcontract are modeled explicitly in the logic. This explicit time-representation is used to account for the time it takes an agent to adopt an intention. We use a syntactic approach presenting a formal logical calculus that can be regarded as a meta-logic that describes the reasoning and activities of the agents. We write some of the axioms of this meta-language and explain the minimal model semantics, in which one model, the intended model, represents the actual beliefs, intentions, and actions of the agents. We also prove several results showing that under the appropriate conditions the agents will act as expected.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-049.pdf,,1045
55,2002,Multiagent Systems,Reinforcement Learning of Coordination in Cooperative Multi-Agent Systems,"Spiros Kapetanakis and Daniel Kudenko, University of York","We report on an investigation of reinforcement learning techniques for the learning of coordination in cooperative multi-agent systems. Specifically, we focus on a novel action selection strategy for Q-learning. The new technique is applicable to scenarios where mutual observation of actions is not possible. To date, reinforcement learning approaches for such independent agents did not guarantee convergence to the optimal joint action in scenarios with high miscoordination costs. We improve on previous results by demonstrating empirically that our extension causes the agents to converge almost always to the optimal joint action even in these difficult cases.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-050.pdf,,666
56,2002,Multiagent Systems,The Design of Collectives of Agents to Control Non-Markovian Systems,"John W. Lawson and David H. Wolpert, NASA Ames Research Center","The ""Collective Intelligence"" (COIN) framework concerns the design of collectives of reinforcement-learning agents such that their interaction causes a provided ""world"" utility function concerning the entire collective to be maximized. Previously, we applied that framework to scenarios involving Markovian dynamics where no re-evolution of the system from counter-factual initial conditions (an often expensive calculation) is permitted. This approach sets the individual utility function of each agent to be both aligned with the world utility, and at the same time, easy for the associated agents to optimize. Here we extend that approach to systems involving non-Markovian dynamics. In computer simulations, we compare our techniques with each other and with conventional ""team games"" We show whereas in team games performance often degrades badly with time, it steadily improves when our techniques are used. We also investigate situations where the system’s dimensionality is effectively reduced. We show that this leads to difficulties in the agents’ ability to learn. The implication is that ""learning"" is a property only of high-enough dimensional systems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-051.pdf,,1165
57,2002,Multiagent Systems,(Im)possibility of Safe Exchange Mechanism Design,"Tuomas Sandholm and XiaoFeng Wang, Carnegie Mellon University","Safe exchange is a key issue in multiagent systems, especially in electronic transactions where nondelivery is a major problem. In this paper we present a unified framework for modeling safe exchange mechanisms. It captures the disparate earlier approaches as well as new safe exchange mechanisms (e.g., reputation locking). Being an overarching framework, it also allows us to study what is inherently possible and impossible in safe exchange. We study this under different game-theoretic solution concepts, with and without a trusted third party, and with an offline third party that only gets involved if the exchange fails. The results vary based on the generality of the exchange setting, the existence (or creative construction) of special types of items to be exchanged, and the magnitude of transfer costs, defection costs, and escrow fees. Finally, we present an incentive-compatible negotiation protocol for selecting the best safe exchange mechanism when the agents do not know each others’ costs for the different alternatives.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-052.pdf,,1039
58,2002,Multiagent Systems,Multi-Agent Algorithms for Solving Graphical Games,"David Vickrey and Daphne Koller, Stanford University","Consider the problem of a group of agents trying to find a stable strategy profile for a joint interaction. A standard approach is to describe the situation as a single multi-player game and find an equilibrium strategy profile of that game. However, most algorithms for finding equilibria are computationally expensive; they are also centralized, requiring that all relevant payoff information be available to a single agent (or computer) who must determine the entire equilibrium profile. In this paper, we exploit two ideas to address these problems. We consider structured game representations, where the interaction between the agents is sparse, an assumption that holds in many real-world situations. We also consider the slightly relaxed task of finding an approximate equilibrium. We present two algorithms for finding approximate equilibria in these games, one based on a hill-climbing approach and one on constraint satisfaction. We show that these algorithms exploit the game structure to achieve faster computation. They are also inherently local, requiring only limited communication between directly interacting agents. They can thus be scaled to games involving large numbers of agents, provided the interaction between the agents is not too dense.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-053.pdf,,1263
59,2002,Multiagent Systems,Distributed Breakout Revisited,"Weixiong Zhang and Lars Wittenburg, Washington University","Distributed breakout algorithm (DBA) is an efficient method for solving distributed constraint satisfaction problems (CSP). Inspired by its potential of being an efficient, low-overhead agent coordination method for problems in distributed sensor networks, we study DBA’s properties in this paper. We specifically show that on an acyclic graph of $n$ nodes, DBA can find a solution in $O(n^2)$ synchronized distributed steps. This completeness result reveals DBA’s superiority over conventional local search on acyclic graphs and implies its potential as a simple self-stabilization method for tree-structured distributed systems. We also show a worst case of DBA in a cyclic graph where it never terminates. To overcome this problem on cyclic graphs, we propose two stochastic variations to DBA. Our experimental analysis shows that stochastic DBAs are able to avoid DBA’s worst-case scenarios and has similar performance as that of DBA.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-054.pdf,,938
60,2002,Auctions,Solving Concisely Expressed Combinatorial Auction Problems,"Craig Boutilier, University of Toronto","Combinatorial auctions provide a valuable mechanism for the allocation of goods in settings where buyer valuations exhibit complex structure with respect to substitutability and complementarity. Most algorithms are designed to work with explicit ""flat"" bids for concrete bundles of goods. However, logical bidding languages allow the expression of complex utility functions in a natural and concise way, and have recently attracted considerable attention. Despite the power of logical languages, no current winner determination algorithms exploit the specific structure of logically specified bids to solve problems more effectively. In this paper, we describe techniques to do just this. Specifically, we propose a direct integer program (IP) formulation of the winner determination problem for bids in the LGB logical language. This formulation is linear in the size of the problem and can be solved effectively using standard optimization packages. We compare this formulation and its solution time to those of the corresponding set of flat bids, demonstrating the immense utility of exploiting the structure of logically expressed bids. We also consider an extension of LGB and show that these can also be solved using linear constraints.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-055.pdf,,1242
61,2002,Auctions,Partial-Revelation VCG Mechanism for Combinatorial Auctions,"Wolfram Conen, XONAR GmbH; Tuomas Sandholm, Carnegie Mellon University","Winner determination in combinatorial auctions has received significant interest in the AI community in the last 3 years. Another difficult problem in combinatorial auctions is that of eliciting the bidders’ preferences. We introduce a progressive, partial-revelation mechanism that determines an efficient allocation and the Vickrey payments. The mechanism is based on a family of algorithms that explore the natural lattice structure of the bidders’ combined preferences. The mechanism elicits utilities in a natural sequence, and aims at keeping the amount of elicited information and the effort to compute the information minimal. We present analytical results on the amount of elicitation. We show that no value-querying algorithm that is constrained to querying feasible bundles can save more elicitation than one of our algorithms. We also show that one of our algorithms can determine the Vickrey payments as a costless by-product of determining an optimal allocation.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-056.pdf,,976
62,2002,Auctions,Bidding Clubs in First-Price Auctions,"Kevin Leyton-Brown, Yoav Shoham, and Moshe Tennenholtz, Stanford University","We introduce a class of mechanisms, called bidding clubs, that allow agents to coordinate their bidding in auctions. Bidding clubs invite a set of agents to join, and each invited agent freely chooses whether to accept the invitation or whether to participate independently in the auction. Clubs first conduct a ""pre-auction""; depending on the outcome of the pre-auction some subset of the members of the club bid in the primary auction in a prescribed way. We model this setting as a Bayesian game, including agents’ choices of whether or not to accept a bidding club’s invitation. We examine the specific case of bidding clubs for first-price auctions, showing the existence of a Bayes-Nash equilibrium where agents choose to participate in bidding clubs when invited and truthfully declare their valuations to the coordinator. Furthermore, we show that the existence of bidding clubs benefits all agents, including those who do not belong to a bidding club.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-057.pdf,,960
63,2002,Auctions,Truthful Approximation Mechanisms for Restricted Combinatorial Auctions,"Ahuva Mu'alem and Noam Nisan, The Hebrew University of Jerusalem vi","When attempting to design a truthful mechanism for a computationally hard problem such as combinatorial auctions, one is faced with the problem that most efficiently computable heuristics can not be embedded in any truthful mechanism (e.g. VCG-like payment rules will not ensure truthfulness). We develop a set of techniques that allow constructing efficiently computable truthful mechanisms for combinatorial auctions in the special case where only the valuation is unknown by the mechanism (the single parameter case). For this case we extend the work of Lehmann O'Callaghan, and Shoham, who presented greedy heuristics, and show how to use IF-THEN-ELSE constructs, perform a partial search, and use the LP relaxation. We apply these techniques for several types of combinatorial auctions, obtaining truthful mechanisms with provable approximation ratios.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-058.pdf,,857
64,2002,Auctions,Structural Leverage and Fictitious Play in Sequential Auctions,"Weili Zhu and Peter R. Wurman, North Carolina State University","We model sequential, sealed-bid auctions as a sequential game with imperfect and incomplete information. We develop an agent that, through fictitious play, constructs a policy for the auctions that takes advantage of information learned in the early stages of the game, and is flexible with respect to assumptions about the other bidders’ valuations. Because the straightforward expansion of the incomplete information game is intractable, we develop more concise representations that take advantage of the sequential auctions’ natural structure. We examine the performance of our agent versus agents that play perfectly, agents that also create policies using Monte-Carlo, and agents that play myopically. The technique performs quite well in these empirical studies, though the tractable problem size is still quite small.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-059.pdf,,824
65,2002,Game Theory,Vote Elicitation: Complexity and Strategy-Proofness,"Vincent Conitzer and Tuomas Sandholm, Carnegie Mellon University","Preference elicitation is a central problem in AI, and has received significant attention in single-agent settings. It is also a key problem in multiagent systems, but has received little attention here so far. In this setting, the agents may have different preferences that often must be aggregated using voting. This leads to interesting issues because what, if any, information should be elicited from an agent depends on what other agents have revealed about their preferences so far. In this paper we study effective elicitation, and its impediments, for the most common voting protocols. It turns out that in the Single Transferable Vote protocol, even knowing when to terminate elicitation is NP-complete, while this is easy for all the other protocols under study. Even for these protocols, determining how to elicit effectively is NP-complete, even with perfect suspicions about how the agents will vote. The exception is the Plurality protocol where such effective elicitation is easy. We also show that elicitation introduces additional opportunities for strategic manipulation by the voters. We demonstrate how to curtail the space of elicitation schemes so that no such additional strategic issues arise.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-060.pdf,,1217
66,2002,Game Theory,Dispersion Games: General Definitions and Some Specific Learning Results,"Trond Grenager, Rob Powers, and Yoav Shoham, Stanford University","Dispersion games are the generalization of the anti-coordination game to arbitrary numbers of agents and actions. In these games agents prefer outcomes in which the agents are maximally dispersed over the set of possible actions. This class of games models a large number of natural problems, including load balancing in computer science, niche selection in economics, and division of roles within a team in robotics. Our work consists of two main contributions. First, we formally define and characterize some interesting classes of dispersion games. Second, we present several learning strategies that agents can use in these games, including traditional learning rules from game theory and artificial intelligence, as well as some special purpose strategies. We then evaluate analytically and empirically the performance of each of these strategies.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-061.pdf,,852
67,2002,Game Theory,Competitive Safety Analysis,"Moshe Tennenholtz, Stanford University","Much work in AI deals with the selection of proper actions in a given (known or unknown) environment. However, the way to select a proper action when facing other agents is quite unclear. Most work in AI adopts classical game-theoretic equilibrium analysis to predict agent behavior in such settings. Needless to say, this approach does not provide us with any guarantee for the agent. In this paper we introduce competitive safety analysis. This approach bridges the gap between the desired normative AI approach, where a strategy should be selected in order to guarantee a desired payoff, and equilibrium analysis. We show that a safety level strategy is able to guarantee the value obtained in a Nash equilibrium, in several classical computer science settings. Then, we discuss the concept of competitive safety strategies, and illustrate its use in a decentralized load balancing setting, typical to network problems. In particular, we show that when we have many agents, it is possible to guarantee an expected payoff which is a factor of 8/9 of the payoff obtained in a Nash equilibrium. Finally, we discuss the extension of the above concepts to Bayesian games, and illustrate their use in a basic auctions setup.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-062.pdf,,1221
68,2002,Natural Language Processing,Learning Pattern Rules for Chinese Named Entity Extraction,"Tat-Seng Chua and Jimin Liu, National University of Singapore","Named entity (NE) extraction in Chinese is very difficult task because of the flexibility in the language structure and uncertainty in word segmentation. It is equivalent to relation and information extraction problems in English. This paper presents a hybrid rule induction approach to extract NEs in Chinese. The method induces rules and names and their context, and generalizes these rules using linguistic lexical chaining. In order to handle the ambiguities and other contextual problems peculiar to Chinese, we supplement the basic method with other approaches such as the default-exception tree and decision tree. We tested our method on the MET2 test set and the method has been found to out-perform all reported methods with an overall F1 measure of over 91%.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-063.pdf,,768
69,2002,Natural Language Processing,Language Modeling for Soft Keyboards,"Joshua Goodman and Gina Venolia, Microsoft Research; Keith Steury, Microsoft Corporation; Chauncey Parker, University of Washington","We describe how language models, combined with models of pen placement, can be used to significantly reduce the error rate of soft keyboard usage, by allowing for cases in which a key press is outside of a key boundary. Language models predict the probabilities of words or letters. Soft keyboards are images of keyboards on a touch screen used for input on Personal Digital Assistants. When a soft keyboard user hits a key near the boundary of a key position, we can use the language model and key press model to select the most probable key sequence, rather than the sequence dictated by strict key boundaries. This leads to an overall error rate reduction by a factor of 1.67 to 1.87.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-064.pdf,,687
70,2002,Natural Language Processing,CobotDS: A Spoken Dialogue System for Chat,"Michael Kearns, University of Pennsylvania; Charles Isbell, Georgia Institute of Technology; Satinder Singh, Syntek Capital; Diane Litman, University of Pittsburgh; Jessica Howe, Massachussetts Institute of Technology","We describe CobotDS, a spoken dialogue system providing access to a well-known internet chat server called LambdaMOO. CobotDS provides real-time, two-way, natural language communication between a phone user and the multiple users in the text environment. We describe a number of the challenging design issues we faced, and our use of summarization, social filtering and personalized grammars in tackling them. We report a number of empirical findings from a small user study.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-065.pdf,,475
71,2002,Natural Language Processing,Exploiting Auditory Fovea in Humanoid-Human Interaction,"Kazuhiro Nakadai, Kitano Symbiotic Systems Project, ERATO; Hiroshi G. Okuno, Kitano Symbiotic Systems Project, ERATO and Kyoto University; Hiroaki Kitano, Kitano Symbiotic Systems Project, ERATO and Sony Computer Science Laboratories, Inc.","A robot’s auditory perception of the real world should be able to cope with motor and other noises caused by the robot’s own movements in addition to environment noises and reverberation. This paper presents the active direction-pass filter (ADPF) that separates sounds originating from a specified direction detected by a pair of microphones. Thus the ADPF is based on directional processing - a process used in visual processing. The ADPF is implemented by hierarchical integration of visual and auditory processing with hypothetical reasoning of interaural phase difference (IPD) and interaural intensity difference (IID) for each sub-band. The ADPF gives differences in resolution in sound localization and separation depending on where the sound comes from: the resolving power is much higher for sounds coming directly from the front of the humanoid than for sounds coming from the periphery. This directional resolving property is similar to that of the eye whereby the visual fovea at the center of the retina is capable of much higher resolution than is the periphery of the retina. To exploit the corresponding ""auditory fovea,"" the ADPF controls the direction of the head. The human tracking and sound source separation based on the ADPF is implemented on the upper-torso of the humanoid and runs in real-time using distributed processing by 5 PCs networked via a gigabit ethernet. The signal-to-noise ratio (SNR) and noise reduction ratio of each sound separated by the ADPF from a mixture of two or three speeches of the same volume were increased by about 2.2\,dB and 9\,dB, respectively",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-066.pdf,,1601
72,2002,Natural Language Processing,Towards CST-Enhanced Summarization,"Zhu Zhang, Sasha Blair-Goldensohn, and Dragomir R. Radev, University of Michigan","In this paper, we propose to enhance the process of automatic extractive multi-document text summarization by taking into account cross-document structural relationships as posited in Cross-document Structure Theory (CST). An arbitrary multi-document extract can be CST-enhanced by replacing low-salience sentences with other sentences that increase the total number of CST relationships included in the summary. We show that CST-enhanced summaries outperform their unmodified counterparts using the relative utility evaluation metric. We also show that the effect of a CST relationship on an extract depends on its type.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-067.pdf,,621
73,2002,Planning,Planning with a Language for Extended Goals,"Ugo Dal Lago, Marco Pistore, and Paolo Traverso, ITC-IRST","Planning for extended goals in non-deterministic domains is one of the most significant and challenging planning problems. In spite of the recent results in this field, no work has proposed a language designed specifically for planning. As a consequence, it is still impossible to specify and plan for several classes of goals that are typical of real world applications, like for instance ""try to achieve a goal whenever possible,"" or ""if you fail to achieve a goal, recover by trying to achieve something else."" We propose a new goal language that allows for capturing the intended meaning of these goals. We give a semantics to this language that is radically different from the usual semantics for extended goals, e.g., the semantics for LTL or CTL. Finally, we implement an algorithm for planning for extended goals expressed in this language, and experiment with it on a parametric domain.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-068.pdf,,895
74,2002,Planning,Symbolic Heuristic Search for Factored Markov Decision Processes,"Zhengzhu Feng, University of Massachusetts; Eric A. Hansen, Mississippi State University","We describe a planning algorithm that integrates two approaches to solving Markov decision processes with large state spaces. State abstraction is used to avoid evaluating states individually. Forward search from a start state, guided by an admissible heuristic, is used to avoid evaluating all states. We combine these two approaches in a novel way that exploits symbolic model-checking techniques and demonstrates their usefulness for decision-theoretic planning.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-069.pdf,,465
75,2002,Planning,Plan Evaluation with Incomplete Action Descriptions,"Andrew Garland and Neal Lesh, Cambridge Research Laboratory, MERL","This paper presents a framework that justifies an agent’s goal-directed behavior, even in the absence of a provably correct plan. Most prior planning systems rely on a complete causal model and circumvent the frame problem by implicitly assuming that no unspecified relationships exist between actions and the world. In our approach, a domain modeler provides explicit statements about which actions have been incompletely specified. Thus, an agent can minimize its dependence on implicit assumptions when selecting an action sequence to achieve its goals.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-070.pdf,,556
76,2002,Planning,Algorithms for a Temporal Decoupling Problem in Multi-Agent Planning,"Luke Hunsberger, Harvard University","The Temporal Decoupling Problem (TDP) arises when a group of agents collaborating on a set of temporally-dependent tasks seek to coordinate their execution of those tasks by applying additional temporal constraints sufficient to ensure that agents working on different tasks may operate independently. This paper: (1) formally defines the TDP, (2) presents theorems that give necessary and sufficient conditions for solutions to the TDP, (3) presents a family of sound and complete algorithms for solving the TDP, and (4) compares the performance of several variations of the basic algorithm. Although this work was motivated by a problem in collaborative multi-agent planning, it represents a contribution to the theory of Simple Temporal Networks that is independent of the motivating application.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-071.pdf,,799
77,2002,Planning,D*Lite,"Sven Koenig, Georgia Institute of Technology; Maxim Likhachev, Carnegie Mellon University","Incremental heuristic search methods use heuristics to focus their search and reuse information from previous searches to find solutions to series of similar search tasks much faster than is possible by solving each search task from scratch. In this paper, we apply Lifelong Planning A* to robot navigation in unknown terrain, including goal-directed navigation in unknown terrain and mapping of unknown terrain. The resulting D* Lite algorithm is easy to understand and analyze. It implements the same behavior as Stentz' Focussed Dynamic A* but is algorithmically different. We prove properties about D* Lite and demonstrate experimentally the advantages of combining incremental and heuristic search for the applications studied. We believe that these results provide a strong foundation for further research on fast replanning methods in artificial intelligence and robotics.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-072.pdf,,879
78,2002,Planning,Speeding Up the Calculation of Heuristics for Heuristic Search-Based Planning,"Yaxin Liu, Sven Koenig and David Furcy, Georgia Institute of Technology","Heuristic search-based planners, such as HSP 2.0, solve STRIPS-style planning problems efficiently but spend about eighty percent of their planning time on calculating the heuristic values. In this paper, we systematically evaluate alternative methods for calculating the heuristic values for HSP 2.0 and demonstrate that the resulting planning times differ substantially. HSP 2.0 calculates each heuristic value by solving a relaxed planning problem with a dynamic programming method similar to value iteration. We identify two different approaches for speeding up the calculation of heuristic values, namely to order the value updates and to reuse information from the calculation of previous heuristic values. We then show how these two approaches can be combined, resulting in our PINCH method. PINCH outperforms both of the other approaches individually as well as the methods used by HSP 1.0 and HSP 2.0 for most of the large planning problems tested. In fact, it speeds up the planning time of HSP 2.0 by up to eighty percent in several domains and, in general, the amount of savings grows with the size of the domains, allowing HSP 2.0 to solve larger planning problems than was possible before in the same amount of time and without changing its overall operation.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-073.pdf,,1273
79,2002,Planning,Iterative-Refinement for Action Timing Discretization,"Todd W. Neller, Gettysburg College","Artificial intelligence search algorithms search discrete systems. To apply such algorithms to continuous systems, such systems must first be discretized, i.e. approximated as discrete systems. Action-based discretization requires that both action parameters and action timing be discretized. We focus on the problem of action timing discretization. After describing an epsilon-admissible variant of Korf’s recursive best-first search (epsilon-RBFS), we introduce iterative-refinement epsilon-admissible recursive best-first search (IR epsilon-RBFS) which offers significantly better performance for initial time delays between search states over several orders of magnitude. Lack of knowledge of a good time discretization is compensated for by knowledge of a suitable solution cost upper bound.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-074.pdf,,796
80,2002,Planning,A Logical Measure of Progress for Planning,"Aarati Parmar, Stanford University","Heuristic search planners are so far the most successful. Almost all use as their heuristic an estimate of the distance to a goal state. We formalize a logical measure of progress, defined as a predicate P(x,s) true of objects x at a situation s. Actions which increase P’s extension are guaranteed to move closer to a goal situation, so that P enables us to form plans without search. One example of a measure of progress is the concept of final position used in BlocksWorld. It is not clear how to find a P for an arbitrary domain, so instead we identify three different classes of domains and conditions which allow us to construct a measure of progress. An obvious P will not deliver optimal plans, but it should encode plans which are ""good enough."" Our paradigm is entirely within first-order logic, allowing us to extend our results to concurrent domains and those containing non-trivial state constraints. It turns out P not only encodes goal orderings, but subgoal orderings. P also gives rise to a strategy function a(s) which can be used to create a universal (complete) teleo-reactive (TR) program. Given the fact that P-increasing actions will never require backtracking, this TR program can be a powerful on-line planner.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-075.pdf,,1235
81,2002,Actions and Temporal Reasoning,Reasoning about Actions in a Probabilistic Setting,"Chitta Baral, Nam Tran, and Le-Chi Tuan, Arizona State University","In this paper we present a language to reason about actions in a probabilistic setting and compare our work with earlier work by Pearl. The main feature of our language is its use of static and dynamic causal laws, and use of unknown (or background) variables -- whose values are determined by factors beyond our model -- in incorporating probabilities. We use two kind of unknown variables: inertial and non-inertial. Inertial unknown variables are helpful in assimilating observations and modeling counterfactuals and causality; while non-inertial unknown variables help characterize stochastic behavior, such as the outcome of tossing a coin, that are not impacted by observations. Finally, we give a glimpse of incorporating probabilities into reasoning with narratives.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-076.pdf,,774
82,2002,Actions and Temporal Reasoning,A Method for Metric Temporal Reasoning,"Mathias Broxvall, Linköpings Universitet","Several methods for temporal reasoning with metric time have been suggested -- for instance, Horn Disjunctive Linear Relations (Horn DLRs). However, it has been noted that implementing this algorithm is non-trivial since it builds on fairly complicated polynomial-time algorithms for linear programming. Instead, an alternative approach which augments Allen’s interval algebra with a Simple Temporal Problem (STP) has been suggested. In this paper, we present a new point-based approach STP* for reasoning about metric temporal constraints. STP* subsumes the tractable preconvex fragment of the augmented interval algebra and can be viewed as a slightly restricted version of Horn DLRs. We give an easily implementable algorithm for deciding satisfiability of STP* and demonstrate experimentally its efficiency. We also give a method for finding solutions to consistent STP* problem instances.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-077.pdf,,893
83,2002,Actions and Temporal Reasoning,Non-Markovian Control in the Situation Calculus,"Alfredo Gabaldon, University of Toronto","The property that the executability and the effects of an action are determined entirely by the current state or situation is known asthe Markov property and is assumed in most formalizations of action. It is not difficult, however, to run into scenarios when the Markov property is not present. We consider removing this assumption from the situation calculus based formalization of actions of Reiter, which forms the basis of the programming language Golog, and define an operator for regressing formulas that quantify over past situations, with respect to such nonMarkovian basic action theories.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-078.pdf,,599
84,2002,Probabilistic and Causal Reasoning,Visual Exploration and Incremental Utility Elicitation,"Jim Blythe, USC Information Sciences Institute","Incremental utility elicitation (IUE) is a decision-theoretic framework in which tools simultaneously make suggestions to a human decision maker based on an incomplete model of the decision maker’s utility function, and update the model based on feedback from the user. Most systems that perform IUE construct and ask questions about a small number of alternatives in order to build a model of the user’s preferences. We describe a system called VEIL that is based on visual exploration of the available alternatives and provides visual cues about their estimated utility based on IUE. VEIL uses a linear programming formulation to make fast updates to the utility estimate based on the user’s expressed preferences between pairs of alternatives. In experiments, VEIL’s update method converges quickly to make good suggestions and help the user form an overall impression of the space of alternatives.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-079.pdf,,901
85,2002,Probabilistic and Causal Reasoning,A Graphical Criterion for the Identification of Causal Effects in Linear Models,"Carlos Brito and Judea Pearl, University of California, Los Angeles","This paper concerns the assessment of direct causal effects from a combination of:(i) non-experimental data, and (ii) qualitative domain knowledge. Domain knowledge is encoded in the form of a directed acyclic graph (DAG), in which all interactions are assumed linear, and some variables are presumed to be unobserved. The paper establishes a sufficient criterion for the identifiability of all causal effects in such models as well as a procedure for estimating the causal effects from the observed covariance matrix.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-080.pdf,,518
86,2002,Probabilistic and Causal Reasoning,A Distance Measure for Bounding Probabilistic Belief Change,"Hei Chan and Adnan Darwiche, University of California, Los Angeles","We propose a distance measure between two probability distributions, which allows one to bound the amount of belief change that occurs when moving from one distribution to another. We contrast the proposed measure with some well known measures, including KL-divergence, showing how they fail to be the basis for bounding belief change as is done using the proposed measure. We then present two practical applications of the proposed distance measure: sensitivity analysis in belief networks and probabilistic belief revision. We show how the distance measure can be easily computed in these applications, and then use it to bound global belief changes that result from either the perturbation of local conditional beliefs or the accommodation of soft evidence. Finally, we show that two well known techniques in sensitivity analysis and belief revision correspond to the minimization of our proposed distance measure and, hence, can be shown to be optimal from that viewpoint.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-081.pdf,,976
87,2002,Probabilistic and Causal Reasoning,Strategies for Determining Causes of Events,"Mark Hopkins, University of California, Los Angeles","In this paper, we study the problem of determining actual causes of events in specific scenarios, based on a definition of actual cause proposed by Halpern and Pearl. To this end, we explore two different search-based approaches, enrich them with admissible pruning techniques and compare them experimentally. We also consider the task of designing algorithms for restricted forms of the problem.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-082.pdf,,396
88,2002,Probabilistic and Causal Reasoning,Tree Approximation for Belief Updating,"Robert Mateescu, Rina Dechter, and Kalev Kask, University of California, Irvine","The paper presents a parameterized approximation scheme for probabilistic inference. The scheme, called Mini-Clustering (MC), extends the partition-based approximation offered by mini-bucket elimination, to tree decompositions. The benefit of this extension is that all single-variable beliefs are computed (approximately) at once, using a two-phase message-passing process along the cluster tree. The resulting approximation scheme allows adjustable levels of accuracy and efficiency, in anytime style. Empirical evaluation against competing algorithms such as iterative belief propagation and Gibbs sampling demonstrates the potential of the MC approximation scheme for several classes of problems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-083.pdf,,700
89,2002,Probabilistic and Causal Reasoning,Accuracy Versus Efficiency Trade-offs in Probabilistic Diagnosis,"Irina Rish, Mark Brodie, and Sheng Ma, IBM T.J. Watson Research Center","This paper studies the accuracy/efficiency trade-off in probabilistic diagnosis formulated as finding the most-likely explanation (MPE) in a Bayesian network. Our work is motivated by a practical problem of efficient real-time fault diagnosis in computer networks using test transactions, or probes, sent through the network. The key efficiency issues include both the cost of probing (e.g., the number of probes), and the computational complexity of diagnosis, while the diagnostic accuracy is crucial for maintaining high levels of network performance. Herein, we derive a lower bound on the diagnostic accuracy that provides necessary conditions for the number of probes needed to achieve an asymptotically error-free diagnosis as the network size increases, given prior fault probabilities and a certain level of noise in probe outcomes. Since the exact MPE diagnosis is generally intractable in large networks, we investigate next the accuracy/efficiency trade-offs for very simple and efficient local approximation techniques, based on variable-elimination (the mini-bucket scheme). Our empirical studies show that these approximations ""degrade gracefully"" with noise and often yield an optimal solution when noise is low enough, and our initial theoretical analysis explains this behavior for the simplest (greedy) approximation. These encouraging results suggest the applicability of such approximations to certain almost-deterministic diagnostic problems that often arise in practical applications.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-084.pdf,,1507
90,2002,Probabilistic and Causal Reasoning,A General Identification Condition for Causal Effects,"Jin Tian and Judea Pearl, University of California, Los Angeles","This paper concerns the assessment of the effects of actions or policy interventions from a combination of: (i) nonexperimental data, and (ii) substantive assumptions. The assumptions are encoded in the form of a directed acyclic graph, also called ""causal graph,"" in which some variables are presumed to be unobserved. The paper establishes a necessary and sufficient criterion for the identifiability of the causal effects of a singleton variable on all other variables in the model, and a powerful sufficient criterion for the effects of a singleton variable on any set of variables.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-085.pdf,,586
91,2002,Probabilistic and Causal Reasoning,A New Characterization of the Experimental Implications of Causal Bayesian Networks,"Jin Tian and Judea Pearl, University of California, Los Angeles","We offer a complete characterization of the set of distributions that could be induced by local interventions on variables governed by a causal Bayesian network. We show that such distributions must adhere to three norms of coherence, and we demonstrate the use of these norms as inferential tools in tasks of learning and identification. Testable coherence norms are subsequently derived for networks containing unmeasured variables.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-086.pdf,,434
92,2002,Robotics,Robust Global Localization Using Clustered Particle Filtering,"Adam Milstein, Javier Nicolás Sánchez, and Evan Tang Williamson, Stanford University","Global mobile robot localization is the problem of determining a robot’s pose in an environment, using sensor data, when the starting position is unknown. A family of probabilistic algorithms known as Monte Carlo Localization (MCL) is currently among the most popular methods for solving this problem. MCL algorithms represent a robot’s belief by a set of weighted samples, which approximate the posterior probability of where the robot is located by using a Bayesian formulation of the localization problem. This article presents an extension to the MCL algorithm, which addresses its problems when localizing in highly symmetrical environments; a situation where MCL is often unable to correctly track equally probable poses for the robot. The problem arises from the fact that sample sets in MCL often become impoverished, when samples are generated according to their posterior likelihood. Our approach incorporates the idea of clusters of samples and modifies the proposal distribution considering the probability mass of those clusters. Experimental results are presented that show that this new extension to the MCL algorithm successfully localizes in symmetric environments where ordinary MCL often fails.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-087.pdf,,1213
93,2002,Robotics,Experiences with a Mobile Robotic Guide for the Elderly,"Michael Montemerlo, Joelle Pineau, Nicholas Roy, Sebastian Thrun, and Vandi Verma, Carnegie Mellon University","This paper describes an implemented robot system, which relies heavily on probabilistic AI techniques for acting under uncertainty. The robot Pearl and its predecessor Flo have been developed by a multi-disciplinary team of researchers over the past three years. The goal of this research is to investigate the feasibility of assisting elderly people with cognitive and physical activity limitations through interactive robotic devices, thereby improving their quality of life. The robot’s task involves escorting people in an assisted living facility---a time-consuming task currently carried out by nurses. Its software architecture employs probabilistic techniques at virtually all levels of perception and decision making. During the course of experiments conducted in an assisted living facility, the robot successfully demonstrated that it could autonomously provide guidance for elderly residents. While previous experiments with fielded robot systems have provided evidence that probabilistic techniques work well in the context of navigation, we found the same to be true of human robot interaction with elderly people.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-088.pdf,,1128
94,2002,Robotics,FastSLAM: A Factored Solution to the Simultaneous Localization and Mapping Problem,"Michael Montemerlo and Sebastian Thrun, Carnegie Mellon University; Daphne Koller and Ben Wegbreit, Stanford Universit","The ability to simultaneously localize a robot and accurately map its surroundings is considered by many to be a key prerequisite of truly autonomous robots. However, few approaches to this problem scale up to handle the very large number of landmarks present in real environments. Kalman filter-based algorithms, for example, require time quadratic in the number of landmarks to incorporate each sensor observation. This paper presents FastSLAM, an algorithm that recursively estimates the full posterior distribution over robot pose and landmark locations, yet scales logarithmically with the number of landmarks in the map. This algorithm is based on an exact factorization of the posterior into a product of conditional landmark distributions and a distribution over robot paths. The algorithm has been run successfully on as many as 50,000 landmarks, environments far beyond the reach of previous approaches. Experimental results demonstrate the advantages and limitations of the FastSLAM algorithm on both simulated and real-world data.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-089.pdf,,1042
95,2002,Robotics,Watch Their Moves: Applying Probabilistic Multiple Object Tracking to Autonomous Robot Soccer,"Thorsten Schmitt, Michael Beetz, Robert Hanek, and Sebastian Buck, Munich University of Technology","In many autonomous robot applications robots must be capable of estimating the positions and motions of moving objects in their environments. In this paper, we apply probabilistic multiple object tracking to estimating the positions of opponent players in autonomous robot soccer. We extend an existing tracking algorithm to handle multiple mobile sensors with uncertain positions, discuss the specification of probabilistic models needed by the algorithm, and describe the required vision-interpretation algorithms. The multiple object tracking has been successfully applied throughout the RoboCup 2001 world championship.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-090.pdf,,623
96,2002,Robotics,CD*: A Real-Time Resolution Optimal Re-Planner for Globally Constrained Problems,"Anthony Stentz, Carnegie Mellon University","Many problems in robotics and AI, such as the find-path problem, call for optimal solutions that satisfy global constraints. The problem is complicated when the cost information is unknown, uncertain, or changing during execution of the solution. Such problems call for efficient re-planning during execution to account for the new information acquired. This paper presents a novel real-time algorithm, Constrained D* (CD*), that re-plans resolution optimal solutions subject to a global constraint. CD* performs a binary search on a weight parameter that sets the balance between the optimality and feasibility cost metrics. In each stage of the search, CD* uses Dynamic A* (D*) to update the weight selection for that stage. On average, CD* updates a feasible and resolution optimal plan in less than a second, enabling it to be used in a real-time robot controller. Results are presented for simulated problems. To the author’s knowledge, CD* is the fastest algorithm to solve this class of problems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-091.pdf,,1003
97,2002,Satisfiability,Enhancing Davis Putnam with Extended Binary Clause Reasoning,"Fahiem Bacchus, University of Toronto","The backtracking based Davis Putnam (DPLL) procedure remains the dominant method for deciding the satisfiability of a CNF formula. In recent years there has been much work on improving the basic procedure by adding features like improved heuristics and data structures, intelligent backtracking, clause learning, etc. Reasoning with binary clauses in DPLL has been a much discussed possibility for achieving improved performance, but to date solvers based on this idea have not been competitive with the best unit propagation based DPLL solvers. In this paper we experiment with a DPLL solver called 2cls+eq that makes more extensive use of binary clause reasoning than has been tried before. The results are very encouraging---2cls+eq is competitive with the very best DPLL solvers. The techniques it uses also open up a number of other possibilities for increasing our ability to solve SAT problems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-092.pdf,,901
98,2002,Satisfiability,Comparing Phase Transitions and Peak Cost in PP-Complete Satisfiability Problems,"Delbert D. Bailey, Víctor Dalmau, and Phokion G. Kolaitis, University of California, Santa Cruz","The study of phase transitions in algorithmic problems has revealed that usually the critical value of the constrainedness parameter at which the phase transition occurs coincides with the value at which the average cost of natural solvers for the problem peaks. In particular, this confluence of phase transition and peak cost has been observed for the Boolean satisfiability problem and its variants, where the solver used is a Davis-Putnam-type procedure or a suitable modification of it. Here, we investigate the relationship between phase transitions and peak cost for a family of PP-complete satisfiability problems, where the solver used is a symmetric Threshold Counting Davis-Putnam (TCDP) procedure, i.e., a modification of the Counting Davis-Putnman procedure for computing the number of satisfying assignments of a Boolean formula. Our main experimental finding is that, for each of the PP-complete problems considered, the asymptotic probability of solvability undergoes a phase transition at some critical ratio of clauses to variables, but this critical ratio does not always coincide with the ratio at which the average search cost of the symmetric TCDP procedure peaks. Actually, for some of these problems the peak cost occurs at the boundary or even outside of the interval in which the probability of solvability drops from 0.9 to 0.1, and we analyze why this happens.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-093.pdf,,1388
99,2002,Satisfiability,"A Compiler for Deterministic, Decomposable Negation Normal Form","Adnan Darwiche, University of California, Los Angeles","We present a compiler for converting CNF formulas into deterministic, decomposable negation normal form (d-DNNF). This is a logical form that has been identified recently and shown to support a number of operations in polynomial time, including clausal entailment; model counting, minimization and enumeration; and probabilistic equivalence testing. d-DNNFs are also known to be a superset of, and more succinct than, OBDDs. The polytime logical operations supported by d-DNNFs are a subset of those supported by OBDDs, yet are sufficient for model-based diagnosis and planning applications. We present experimental results oncompiling a variety of CNF formulas, some generated randomly and others corresponding to digital circuits. A number of the formulas we were able to compile efficiently could not be similarly handled by some state-of-the-art model counters, nor by somestate-of-the-art OBDD compilers.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-094.pdf,,909
100,2002,Satisfiability,Inference Methods for a Pseudo-Boolean Satisfiability Solver,"Heidi E. Dixon and Matthew L. Ginsberg, CIRL / University of Oregon","We describe two methods of doing inference during search for a pseudo-Boolean version of the RELSAT method. One inference method is the pseudo-Boolean equivalent of learning. A new constraint is learned in response to a contradiction with the purpose of eliminating the set of assignments that caused the contradiction. We show that the obvious way of extending learning to pseudo-Boolean is inadequate and describe a better solution. We also describe a second inference method used by the Operations Research community. The method cannot be applied to the standard resolution-based AI algorithms, but is useful for pseudo-Boolean versions of the same AI algorithms. We give experimental results showing that the pseudo-Boolean version of RELSAT outperforms its clausal counterpart on problems from the planning domain.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-095.pdf,,819
101,2002,Satisfiability,Automated Discovery of Composite SAT Variable-Selection Heuristics,"Alex Fukunaga, University of California, Los Angeles","Variants of GSAT and Walksat are among the most successful SAT local search algorithms. We show that several well-known SAT local search algorithms are the result of novel combininations of a set of variable selection primitives. We describe class, an automated heuristic discovery system which generates new, effective variable selection heuristic functions using a simple composition operator. New heuristics discovered by class are shown to be competitive with the best Walksat variants, including Novelty+ and R-Novelty+. We also analyze the local search behavior of the learned heuristics using the depth, mobility, and coverage metrics recently proposed by Schuurmans and Southey.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-096.pdf,,686
102,2002,Satisfiability,Learning for Quantified Boolean Logic Satisfiability,"Enrico Giunchiglia, Massimo Narizzano, and Armando Tacchella, DIST - Università di Genova","Learning, i.e., the ability to record and exploit some information which is unveiled during the search, proved to be a very effective AI technique for problem solving and, in particular, for constraint satisfaction. We introduce learning as a general purpose technique to improve the performances of decision procedures for Quantified Boolean Formulas (QBFs). Since many of the recently proposed decision procedures for QBFs solve the formula using search methods, the addition of learning to such procedures has the potential of reducing useless explorations of the search space. To show the applicability of learning for QBF satisfiability we have implemented it in QuBE, a state-of-the-art QBF solver. While the backjumping engine embedded in QuBE provides a good starting point for our task, the addition of learning required us to devise new data structures and led to the definition and implementation of new pruning strategies. We report some experimental results that witness the effectiveness of learning. Noticeably, QuBE augmented with learning is able to solve instances that were previously out if its reach. To the extent of our knowledge, this is the first time that learning is proposed, implemented and tested for QBFs satisfiability.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-097.pdf,,1251
103,2002,Satisfiability,An Adaptive Noise Mechanism for WalkSAT,"Holger H. Hoos, University of British Columbia","Stochastic local search algorithms based on the WalkSAT architecture are among the best known methods for solving hard and large instances of the propositional satisfiability problem (SAT). The performance and behaviour of these algorithm critically depends on the setting of the noise parameter, which controls the greediness of the search process. The optimal setting for the noise parameter varies considerably between different types and sizes of problem instances; consequently, considerable manual tuning is typically required to obtain peak performance. In this paper, we characterise the impact of the noise setting on the behaviour of WalkSAT and introduce a simple adaptive noise mechanism for WalkSAT that does not require manual adjustment for different problem instances. We present experimental results indicating that by using this self-tuning noise mechanism, various WalkSAT variants (including WalkSAT/SKC and Novelty+) achieve performance levels close to their peak performance for instance-specific, manually tuned noise settings.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-098.pdf,,1050
104,2002,Satisfiability,A Mixture-Model for the Behaviour of SLS Algorithms for SAT,"Holger H. Hoos, University of British Columbia","Stochastic Local Search (SLS) algorithms are amongst the most effective approaches for solving hard and large propositional satisfiability (SAT) problems. Prominent and successful SLS algorithms for SAT, including many members of the WalkSAT and GSAT families of algorithms, tend to show highly regular behaviour when applied to hard SAT instances: The run-time distributions (RTDs) of these algorithms are closely approximated by exponential distributions. The deeper reasons for this regular behaviour are, however, essentially unknown. In this study we show that there are hard problem instances, e.g., from the phase transition region of the widely studied class of Uniform Random 3-SAT instances, for which the RTDs for well-known SLS algorithms such as GWSAT or WalkSAT/SKC deviate substantially from exponential distributions. We investigate these irregular instances and show that the respective RTDs can be modelled using mixtures of exponential distributions. We present evidence that such mixture distributions reflect stagnation behaviour in the search process caused by ""traps"" in the underlying search spaces. This leads to the formulation of a new model of SLS behaviour as a simple Markov process. This model subsumes and extends earlier characterisations of SLS behaviour and provides plausible explanations for many empirical observations.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-099.pdf,,1357
105,2002,Satisfiability,SetA*: An Efficient BDD-Based Heuristic Search Algorithm,"Rune M. Jensen, Randal E. Bryant, and Manuela M. Veloso, Carnegie Mellon University","In this paper we combine the goal directed search of A* with the ability of BDDs to traverse an exponential number of states in polynomial time. We introduce a new algorithm, SetA*, that generalizes A* to expand sets of states in each iteration. SetA* has substantial advantages over BDDA*, the only previous BDD-based A* implementation we are aware of. Our experimental evaluation proves SetA* to be a powerful search paradigm. For some of the studied problems it outperforms BDDA*, A*, and BDD-based breadth-first search by several orders of magnitude. We believe exploring sets of states to be essential when the heuristic function is weak. For problems with strong heuristics, SetA* efficiently specializes to single-state search and consequently challenges single-state heuristic search in general.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-100.pdf,,803
106,2002,Satisfiability,Dynamic Restart Policies,"Henry Kautz, University of Washington; Eric Horvitz, Microsoft Research; Yongshao Ruan, University of Washington; Carla Gomes and Bart Selman, Cornell University","We describe theoretical results and empirical study of context-sensitive restart policies for randomized search procedures. The methods generalize previous results on optimal restart policies by exploiting dynamically updated beliefs about the probability distribution for run time. Rather than assuming complete knowledge or zero knowledge about the run-time distribution, we formulate restart policies that consider real-time observations about properties of instances and the solver’s activity. We describe background work on the application of Bayesian methods to build predictive models for run time, introduce an optimal policy for dynamic restarts that considers predictions about run time, and perform a comparative study of traditional fixed versus dynamic restart policies.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-101.pdf,,783
107,2002,Satisfiability,Using Weighted MAX-SAT Engines to Solve MPE,"James D. Park, University of California, Los Angeles","Logical and probabilistic reasoning are closely related. Many examples in each group have natural analogs in the other. One example is the strong relationship between weighted MAX-SAT and MPE. This paper presents a simple reduction of MPE to weighted MAX-SAT. It also investigates approximating MPE by converting it to a weighted MAX-SAT problem, then using the incomplete methods for solving weighted MAX-SAT to generate a solution. We show that converting MPE problems to MAX-SAT problems and using a method designed for MAX-SAT to solve them often produces solutions that are vastly superior to the previous local search methods designed directly for the MPE problem.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-102.pdf,,670
108,2002,Satisfiability,Easy Predictions for the Easy-Hard-Easy Transition,"Andrew J. Parkes, CIRL / University of Oregon","We study the scaling properties of sequential and parallel versions of a local search algorithm, WalkSAT, in the easy regions of the easy-hard-easy phase transition (PT) in Random 3SAT. In the underconstrained region, we study scaling of the sequential version of WalkSAT. We find linear scaling at fixed clause/variable ratio. We also study the case in which a parameter inspired by ""finite-size scaling"" is held constant. The scaling then also appears to be a simple power law. Combining these results gives a simple prediction for the performance of WalkSAT over most of the easy region. The experimental results suggest that WalkSAT is acting as a threshold algorithm, but with threshold below the satisfiability threshold. Performance of a parallel version of WalkSAT is studied in the over-constrained region. This is more difficult because it is an optimization rather than decision problem. We use the solution quality, the number of unsatisfied clauses, obtained by the sequential algorithm to set a target for its parallel version. We find that qualities obtained by the sequential search with O(n) steps, are achievable by the parallel version in O(log(n)) steps. Thus, the parallelization is efficient for these ""easy MAXSAT"" problems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-103.pdf,,1247
109,2002,Satisfiability,"The Interface between P and NP: COL, XOR, NAE, 1-in-k, and Horn SAT","Toby Walsh, University College Cork","We study in detail the interface between P and NP by means of five new problem classes. Like the well known 2+p-SAT problem, these new problems smoothly interpolate between P and NP by mixing together a polynomial and a NP-complete problem. In many cases, the polynomial subproblem can dominate the problem’s satisfiability and the search complexity. However, this is not always the case, and understanding why remains a very interesting open question. We identify phase transition behavior in each of these problem classes. Surprisingly we observe transitions with both smooth and sharp regions. Finally we show how these problem classes can help to understand algorithm behavior by considering search trajectories through the phase space.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-104.pdf,,740
110,2002,Search,Scheduling Contract Algorithms on Multiple Processors,"Daniel S. Bernstein, Theodore J. Perkins, and Shlomo Zilberstein, University of Massachusetts; Lev Finkelstein, Technion - Israel Institute of Technology","Anytime algorithms offer a tradeoff between computation time and the quality of the result returned. They can be divided into two classes: contract algorithms, for which the total run time must be specified in advance, and interruptible algorithms, which can be queried at any time for a solution. An interruptible algorithm can be constructed from a contract algorithm by repeatedly activating the contract algorithm with increasing run times. The acceleration ratio of a run-time schedule is a worst-case measure of how inefficient the constructed interruptible algorithm is compared to the contract algorithm. The smallest acceleration ratio achievable on a single processor is known. Using multiple processors, smaller acceleration ratios are possible. In this paper, we provide a schedule for m processors and prove that it is optimal for all m. Our results provide general guidelines for the use of parallel processors in the design of real-time systems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-105.pdf,,960
111,2002,Search,Searching for Backbones and Fat: A Limit-Crossing Approach with Applications,"Sharlee Climer and Weixiong Zhang, Washington University","Backbone variables are the elements that are common to all optimal solutions of a problem instance. We call variables that are absent from every optimal solution fat variables. Identification of backbone and fat variables is a valuable asset when attempting to solve complex problems. In this paper, we demonstrate a method for identifying backbones and fat. Our method is based on an intuitive concept, which we refer to as limit-crossing. Limit-crossing occurs when we force the lower bound of a graph problem to exceed the upper bound by applying the lower-bound function to a constrained version of the graph. A desirable feature of this procedure is that it uses approximation functions to derive exact information about optimal solutions. In this paper, we prove the validity of the limit-crossing concept as well as other related properties. Then we exploit limit-crossing and devise a pre-processing tool for discovering backbone and fat arcs for various instances of the Asymmetric Traveling Salesman Problem (ATSP). Our experimental results demonstrate the power of the limit-crossing method. We compare our pre-processor with the Carpaneto, Dell'Amico, and Toth pre-processor for several different classes of ATSP instances and reveal dramatic performance improvements.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-106.pdf,,1280
112,2002,Search,Multiple-Goal Search Algorithms and their Application to Web Crawling,"Dmitry Davidov and Shaul Markovitch, Technion",The work described in this paper presents a new framework for heuristic search where the task is to collect as many goals as possible within the allocated resources. We show the inadequacy of traditional distance heuristics for this type of tasks and present alternative types of heuristics that are more appropriate for multiple-goal search. In particular we introduce the yield heuristic that estimates the cost and the benefit of exploring a subtree below a search node. We present a learning algorithm for inferring the yield based on search experience. We apply our adaptive and non-adaptive multiple-goal search algorithms to the web crawling problem and show their efficiency.,https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-107.pdf,,683
113,2002,Search,Optimal Schedules for Parallelizing Anytime Algorithms: The Case of Independent Processes,"Lev Finkelstein, Shaul Markovitch, and Ehud Rivlin, Technion","The performance of anytime algorithms having a non-deterministic nature can be improved by solving simultaneously several instances of the algorithm-problem pairs. These pairs may include different instances of a problem (like starting from a different initial state), different algorithms (if several alternatives exist), or several instances of the same algorithm (for non-deterministic algorithms). In this paper we present a general framework for optimal parallelization of independent processes. We show a mathematical model for this framework, present algorithms for optimal scheduling, and demonstrate its usefulness on a real problem.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-108.pdf,,642
114,2002,Search,Optimal Depth-First Strategies for And-Or Trees,"Russell Greiner and Ryan Hayward, University of Alberta; Michael Molloy, University of Toronto","Many tasks require evaluating a specified boolean expression f over a set of probabilistic tests where we know the probability that each test will succeed, and also the cost of performing each test. A strategy specifies when to perform which test, towards determining the overall outcome of f. This paper investigates the challenge of finding the strategy with the minimum expected cost. We observe first that this task is typically NP-hard -- eg, when tests can occur many times within f, or when there are probabilistic correlations between the test outcomes. We therefore focus on the situation where the tests are probabilistically independent and each appears only once in f. Here, f can be written as an and-or tree, where each internal node corresponds to either the ""And"" or ""Or"" of its children, and each leaf node is a probabilistic test. There is an obvious depth-first approach to evaluating such and-or trees: First evaluate each penultimate subtree in isolation; then reduce this subtree to a single ""mega-test"" with appropriate cost and probability, and recur on the resulting reduced tree. After formally defining this approach, we show first that it produces the optimal strategy for shallow (depth 1 or 2) and-or trees, then show it can be arbitrarily bad for deeper trees. We next consider a larger, natural subclass of strategies -- those that can be expressed as a linear sequence of tests -- and show that the best such ""linear strategy"" can also be very much worse than the optimal strategy in general. Finally, we show that our results hold in a more general model, where internal nodes can also be probabilistic tests.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-109.pdf,,1643
115,2002,Search,A New Algorithm for Optimal Bin Packing,"Richard E. Korf, University of California, Los Angeles","We consider the NP-complete problem of bin packing. Given a set of numbers, and a set of bins of fixed capacity, find the minimum number of bins needed to contain all the numbers, such that the sum of the numbers assigned to each bin does not exceed the bin capacity. We present a new algorithm for optimal bin packing. Rather than considering the different bins that each number can be placed into, we consider the different ways in which each bin can be packed. Our algorithm appears to be asymptotically faster than the best existing optimal algorithm, and runs more that a thousand times faster on problems with 60 numbers.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-110.pdf,,627
116,2002,Search,Memory-Efficient A* Heuristics for Multiple Sequence Alignment,"Matthew McNaughton, Paul Lu, Jonathan Schaeffer, and Duane Szafron, University of Alberta","The time and space needs of an A* search are strongly influenced by the quality of the heuristic evaluation function. Usually there is a trade-off since better heuristics may require more time and/or space to evaluate. Multiple sequence alignment is an important application for single-agent search. The traditional heuristic uses multiple pairwise alignments that require relatively little space. Three-way alignments produce better heuristics, but they are not used in practice due to the large space requirements. This paper presents a memory-efficient way to represent three-way heuristics as an octree. The required portions of the octree are computed on demand. The octree-supported three-way heuristics result in such a substantial reduction to the size of the A* open list that they offset the additional space and time requirements for the three-way alignments. The resulting multiple sequence alignments are both faster and use less memory than using A* with traditional pairwise heuristics.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-111.pdf,,1001
117,2002,Search,PROMPTDIFF: A Fixed-Point Algorithm for Comparing Ontology Versions,"Natalya F. Noy and Mark A. Musen, Stanford University","As ontology development becomes a more ubiquitous and collaborative process, the developers face the problem of maintaining versions of ontologies akin to maintaining versions of software code in large software projects. Versioning systems for software code provide mechanisms for tracking versions, checking out versions for editing, comparing different versions, and so on.We can directly reuse many of these mechanisms for ontology versioning. However, version comparison for code is based on comparing text files---an approach that does not work for comparing ontologies. Two ontologies can be identical but have different text representation. We have developed the PromptDiff algorithm, which integrates different heuristic matchers for comparing ontology versions. We combine these matchers in a fixed-point manner, using the results of one matcher as an input for others until the matchers produce no more changes. The current implementation includes ten matchers but the approach is easily extendable to an arbitrary number of matchers. Our evaluation showed that PromptDiff correctly identified 96% of the matches in ontology versions from large projects.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-112.pdf,,1164
118,2002,Search,On Preference-Based Search in State Space Graphs,"Patrice Perny, LIP6 - University of Paris VI; Olivier Spanjaard, LAMSADE - University of Paris IX","The aim of this paper is to introduce a general framework for preference-based search in state space graphs with a focus on the search of the preferred solutions. After introducing a formal definition of preference-based search problems, we introduce the PBA* algorithm, a generalization of the A* algorithm, designed to process quasi-transitive preference relations defined over the set of solutions. Then, considering a particular subclass of preference structures characterized by two axioms called Weak Preadditivity and Monotonicity, we establish termination, completeness and admissibility results for PBA*. We also show that previous generalizations of A* are particular instances of PBA*. The interest of our algorithm is illustrated on a preference-based web access problem.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-113.pdf,,783
119,2002,Search,An Average-Case Analysis of Graph Search,"Anup K. Sen, Indian Institute of Management Calcutta; Amitava Bagchi, University of Texas at Dallas; Weixiong Zhang, Washington University","Many problems in real-world applications require searching graphs. Understanding the performance of search algorithms has been one of the eminent tasks of heuristic search research. Despite the importance of graph search algorithms, the research of analyzing their performance is limited, and most work on search algorithm analysis has been focused on tree search algorithms. One of the major obstacles to analyzing graph search is that no single graph is an appropriate representative of graph search problems. In this paper, we propose one possible approach to analyzing graph search: Analyzing the performance of graph search algorithms on a representative graph of a cluster of problems. We specifically consider job-sequencing problems in which a set of jobs must be sequenced on a machine such that a penalty function is minimized. We analyze the performance of A* graph search algorithm on an abstract model that closely represents job sequencing problems. It is an extension to a model widely used previously for analyzing tree search. One of the main results of our analysis is the existence of a gap of computational cost between two classes of job sequencing problems, one with exponential and the other with polynomial complexity. We provide experimental results showing that real job sequencing problems indeed have a huge difference on computational costs under different conditions.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-114.pdf,,1397
120,2002,Vision,Detection and Classification of Motion Boundaries,"Richard Mann, University of Waterloo; Allan D. Jepson, University of Toronto","We segment the trajectory of a moving object into piecewise smooth motion intervals separated by motion boundaries. Motion boundaries are classified into various types, including starts, stops, pauses, and discontinuous changes of motion due to force impulses. We localize and classify motion boundaries by fitting a mixture of two polynomials near the boundary. Given a classification of motion boundaries, we use naive physical rules to infer a set of changing contact relationships which explain the observed motion. We show segmentation and classification results for several image sequences of a basketball undergoing gravitational and nongravitational motion.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-115.pdf,,665
121,2002,Vision,Recognizing Multitasked Activities from Video Using Stochastic Context-Free Grammar,"Darnell Moore, Texas Instruments; Irfan Essa, Georgia Institute of Technology","In this paper, we present techniques for recognizing complex, multitasked activities from video. Visual information like image features and motion appearances, combined with domain-specific information, like object context is used initially to label events. Each action event is represented with a unique symbol, allowing for a sequence of interactions to be described as an ordered symbolic string. Then, a model of stochastic context-free grammar (SCFG), which is developed using underlying rules of an activity, is used to provide the structure for recognizing semantically meaningful behavior over extended periods. Symbolic strings are parsed using the Earley-Stolcke algorithm to determine the most likely semantic derivation for recognition. Parsing substrings allows us to recognize patterns that describe high-level, complex events taking place over segments of the video sequence. We introduce new parsing strategies to enable error detection and recovery in stochastic context-free grammar and methods of quantifying group and individual behavior in activities with separable roles. We show through experiments, with a popular card game, the recognition of high-level narratives of multi-player games and the identification of player strategies and behavior using computer vision.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-116.pdf,,1291
122,2002,Vision,The OD Theory of TOD: The Use and Limits of Temporal Information for Object Discovery,"Brandon C. S. Sanders and Randal C. Nelson, University of Rochester; Rahul Sukthankar, Compaq Research (CRL)","We present the theory behind TOD (the Temporal Object Discoverer), a novel unsupervised system that uses only temporal information to discover objects across image sequences acquired by any number of uncalibrated cameras. The process is divided into three phases: (1) Extraction of each pixel’s temporal signature, a partition of the pixel’s observations into sets that stem from different objects; (2) Construction of a global schedule that explains the signatures in terms of the lifetimes of a set of quasi-static objects; (3) Mapping of each pixel’s observations to objects in the schedule according to the pixel’s temporal signature. Our Global Scheduling (GSched) algorithm provably constructs a valid and complete global schedule when certain observability criteria are met. Our Quasi-Static Labeling (QSL) algorithm uses the schedule created by GSched to produce the maximally-informative mapping of each pixel’s observations onto the objects they stem from. Using GSched and QSL, TOD ignores distracting motion, correctly deals with complicated occlusions, and naturally groups observations across cameras. The sets of 2D masks recovered are suitable for unsupervised training and initialization of object recognition and tracking systems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-117.pdf,,1248
123,2002,Web and Information Extraction,A Maximum Entropy Approach to Information Extraction from Semi-Structured and Free Text,"Hai Leong Chieu, DSO National Laboratories; Hwee Tou Ng, National University of Singapore","In this paper, we present a classification-based approach towards single-slot as well as multi-slot information extraction (IE). For single-slot IE, we worked on the domain of Seminar Announcements, where each document contains information on only one seminar. For multi-slot IE, we worked on the domain of Management Succession. For this domain, we restrict ourselves to extracting information sentence by sentence, in the same way as (Soderland 1999). Each sentence can contain information on several management succession events. By using a classification approach based on a maximum entropy framework, our system achieves higher accuracy than the best previously published results in both domains.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-118.pdf,,701
124,2002,Web and Information Extraction,Reviewing the Design of DAML+OIL: An Ontology Language for the Semantic Web,"Ian Horrocks, University of Manchester; Peter F. Patel-Schneider, Bell Labs Research; Frank van Harmelen, Vrije Universiteit","In the current ""Syntactic Web,"" uninterpreted syntactic constructs are given meaning only by private off-line agreements that are inaccessible to computers. In the Semantic Web vision, this is replaced by a web where both data and its semantic definition are accessible and manipulable by computer software. DAML+OIL is an ontology language specifically designed for this use in the Web; it exploits existing Web standards (XML and RDF), adding the familiar ontological primitives of object oriented and frame based systems, and the formal rigor of a very expressive description logic. The definition of DAML+OIL is now over a year old, and the language has been in fairly widespread use. In this paper, we review DAML+OIL’s relation with its key ingredients (XML, RDF, OIL, DAML-ONT, Description Logics), we discuss the design decisions and trade-offs that were the basis for the language definition, and identify a number of implementation challenges posed by the current language. These issues are important for designers of other representation languages for the Semantic Web, be they competitors or successors of DAML+OIL, such as the language currently under definition by W3C.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-119.pdf,,1183
125,2002,Web and Information Extraction,Stochastic Link and Group Detection,"Jeremy Kubica, Andrew Moore, Jeff Schneider, and Yiming Yang, Carnegie Mellon University","Link detection and analysis has long been important in the social sciences and in the government intelligence community. A significant effort is focused on the structural and functional analysis of ``known'' networks. Similarly, the detection of individual links is important but is usually done with techniques that result in ``known'' links. More recently the internet and other sources have led to a flood of circumstantial data that provide probabilistic evidence of links. Co-occurence in news articles and simultaneous travel to the same location are two examples. We propose a probabilistic model of link generation based on membership in groups. The model considers both observed link evidence and demographic information about the entities. The parameters of the model are learned via a maximum likelihood search. In this paper we describe the model and then show several heuristics that make the search tractable. We test our model and optimization methods on synthetic data sets with a known ground truth and a database of news articles.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-120.pdf,,1048
126,2002,"Innovative Applications of Artificial Intelligence Papers
Deployed Applications","MiTAP, Text and Audio Processing for Bio-Security: A Case Study","Laurie Damianos, Jay Ponte, Steve Wohlever, Florence Reeder, David Day, George Wilson, and Lynette Hirschman, The MITRE Coporation","MiTAP (MITRE Text and Audio Processing) is a prototype system available for monitoring infectious disease outbreaks and other global events. MiTAP focuses on providing timely, multi-lingual, global information access to medical experts and individuals involved in humanitarian assistance and relief work. Multiple information sources in multiple languages are automatically captured, filtered, translated, summarized, and categorized by disease, region, information source, person, and organization. Critical information is automatically extracted and tagged to facilitate browsing, searching, and sorting. The system supports shared situational awareness through collaboration, allowing users to submit other articles for processing, annotate existing documents, post directly to the system, and flag messages for others to see. MiTAP currently stores eight hundred thousand articles and processes an additional 2000 to 10,000 daily, delivering up-to-date information to dozens of regular users.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-121.pdf,,996
127,2002,"Innovative Applications of Artificial Intelligence Papers
Deployed Applications",RightNow eService Center: Internet Customer Service Using a Self-Learning Knowledge Base,"Stephen D. Durbin, Doug Warner, J. Neal Richter, and Zuzana Gedeon, RightNow Technologies, Inc.","Delivering effective customer service via the Internet requires attention to many aspects of knowledge management if it is to be convenient and satisfying for customers, while at the same time efficient and economical for the company or other organization. In RightNow eService Center, such management is enabled by automatically gathering meta-knowledge about the Answer documents held in the core knowledge base. A variety of AI techniques are used to facilitate the construction, maintenance, and navigation of the knowledge base. These include collaborative filtering, swarm intelligence, fuzzy logic, natural language processing, text clustering, and classification rule learning. Customers using eService Center report dramatic decreases in support costs and increases in customer satisfaction due to the ease of use provided by the ""self-learning"" features of the knowledge base.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-122.pdf,,886
128,2002,"Innovative Applications of Artificial Intelligence Papers
Deployed Applications",Staff Scheduling for Inbound Call Centers and Customer Contact Centers,"Alex Fukunaga, Ed Hamilton, Jason Fama, David Andre, Ofer Matan, and Illah Nourbakhsh, Blue Pumpkin Software","The staff scheduling problem is a critical problem in the call center (or more generally, customer contact center) industry. This paper describes Director, a staff scheduling system for contact centers. Director is a constraint-based system that uses AI search techniques to generate schedules that satisfy and optimize a wide range of constraints and service quality metrics. Director has been successfully deployed at over 800 contact centers, with significant measurable benefits, some of which are documented in case studies included in this paper.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-123.pdf,,552
129,2002,"Innovative Applications of Artificial Intelligence Papers
Deployed Applications",A Decision-Support System for Quote Generation,"Richard Goodwin, Rama Akkiraju, and Fred Wu, IBM T.J. Watson Research Center","In this paper, we describe a prototype agent-based decision-support system for helping suppliers respond to requests for quote in a business-to-business supply chain. The system provides suggested ways of fulfilling requests and shows alternatives that illustrate tradeoffs in quality, cost and timelines, which allows the decision maker to consider alternatives that reduce cost and improve customer value. The system is implemented in Java and we use examples from paper manufacturing to illustrate the features of our system. In on going work, we are enhancing the prototype to include probabilistic reasoning techniques so that it can create conditional plans that maximize expected utility, subject to the risk preferences of the decision maker. We are also exploring the use of data mining techniques to infer customer preferences and to estimate the probability of winning an order, with a given quote.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-124.pdf,,909
130,2002,"Innovative Applications of Artificial Intelligence Papers
Deployed Applications",UTTSExam: A Campus-Wide University Exam-Timetabling System,"Andrew Lim, Juay-Chin Ang, Wee-Kit Ho, and Wee-Chong Oon, National University of Singapore","UTTSExam is the exam-scheduling portion of the University Timetable Scheduler (UTTS) software, an automated university timetabling program developed in the National University of Singapore. It was successfully used to schedule the examination timetable for the first semester of the 2001/2002 academic year in NUS, a task involving 27,235 students taking 1,350 exams. The use of the software resulted in significant time savings in the scheduling of the timetable and a shortening of the examination period. This paper explains the development and design of UTTSExam.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-125.pdf,,567
131,2002,"Innovative Applications of Artificial Intelligence Papers
Deployed Applications",A Structure Based Configuration Tool: Drive Solution Designer - DSD,"Christoph Ranze, encoway GmbH and Co KG; Thorsten Scholz and Thomas Wagner, University of Bremen, TZI; Andreas Günter, University of Hamburg; Otthein Herzog, University of Bremen, TZI; Oliver Hollmann, encoway GmbH and Co Inc.; Christoph Schlieder, University of Bremen, TZI; Volker Arlt, Lenze AG","In this paper, we describe the configuration tool Drive Solution Designer (DSD). The DSD is used by sales engineers of the company Lenze AG (www.lenze.com) for the configuration of complex drive systems in order to make on-site offers together with the customer. The aim of this process is to generate a consistent solution which fulfills the functional requirements of the user along with optimization criteria such as price and delivery time. The preparation of a technical offer requires fundamental knowledge of complex physical and in particular technical correlations of drive components, in depth knowledge of the product catalog as well as high empirical knowledge about the order of the parameterization of the components. In order to meet these requirements knowledge-based AI-techniques are required. In the DSD we use a domain independent incremental structure-based configuration approach with different knowledge representation mechanisms and a sophisticated declarative control. Currently DSD is used with great success by approx. 150 sales engineers of the company Lenze for the design layout task. The introduction of the DSD lead to a drastic time reduction for drive solution development and reduces incorrect solutions to nearly 0 percent.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-126.pdf,,1259
132,2002,"Innovative Applications of Artificial Intelligence Papers
Deployed Applications",Development and Deployment of a Disciple Agent for Center of Gravity Analysis,"Gheorghe Tecuci, George Mason University and US Army War College; Mihai Boicu, Dorin Marcu, Bogdan Stanescu, and Cristina Boicu, George Mason University; Jerry Comello and Antonio Lopez, US Army War College; James Donlon, George Mason University and US Army War College; William Cleckner, US Army War College","This paper presents new significant advances in the disciple approach for building knowledge-based systems by subject matter experts. It describes the innovative application of this approach to the development of an agent for the analysis of strategic centers of gravity in military conflicts. This application has been deployed in several courses at the US Army War College, and its use has been evaluated. The presented results are those of a multi-faceted research and development effort that synergistically integrates research in artificial intelligence, center of gravity analysis, and practical deployment of an agent into education.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-127.pdf,,640
133,2002,Emerging Applications,Getting from Here to There: Interactive Planning and Agent Execution for Optimizing Travel,"José Luis Ambite, Greg Barish, Craig A. Knoblock, Maria Muslea, and Jean Oh, University of Southern California; Steven Minton, Fetch Technologies","Planning and monitoring a trip is a common but complicated human activity. Creating an itinerary is nontrivial because it requires coordination with existing schedules and making a variety of interdependent choices. Once planned, there are many possible events that can affect the plan, such as schedule changes or flight cancellations, and checking for these possible events requires time and effort. In this paper, we describe how Heracles and Theseus, two information gathering and monitoring tools that we built, can be used to simplify this process. Heracles is a hierarchical constraint planner that aids in interactive itinerary development by showing how a particular choice (e.g., destination airport) affects other choices (e.g., possible modes of transportation, available airlines, etc.). Heracles builds on an information agent platform, called Theseus, that provides the technology for efficiently executing agents for information gathering and monitoring tasks. In this paper we present the technologies underlying these systems and describe how they are applied to build a state-of-the-art travel system.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-128.pdf,,1120
134,2002,Emerging Applications,WhyNot: Debugging Failed Queries in Large Knowledge Bases,"Hans Chalupsky and Thomas A. Russ, University of Southern California","When a query to a knowledge-based system fails and returns ""unknown"", users are confronted with a problem: Is relevant knowledge missing or incorrect? Is there a problem with the inference engine? Was the query ill-conceived? Finding the culprit in a large and complex knowledge base can be a hard and laborious task for knowledge engineers and might be impossible for non-expert users. To support such situations we developed a new tool called ""WhyNot"" as part of the PowerLoom knowledge representation and reasoning system. To debug a failed query, WhyNot tries to generate a small set of plausible partial proofs that can guide the user to what knowledge might have been missing, or where the system might have failed to make a relevant inference. A first version of the system has been deployed to help debug queries to a version of the Cyc knowledge base containing over 1,000,000 facts and over 35,000 rules.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-129.pdf,,914
135,2002,Emerging Applications,An Analogy Ontology for Integrating Analogical Processing and First-Principles Reasoning,"Kenneth D. Forbus and Thomas Mostek, Northwestern University; Ron Ferguson, Georgia Institute of Technology","This paper describes an analogy ontology, a formal representation of some key ideas in analogical processing, that supports the integration of analogical processing with first-principles reasoners. The ontology is based on Gentner’s structure-mapping theory, a psychological account of analogy and similarity. The semantics of the ontology are enforced via procedural attachment, using cognitive simulations of structure-mapping to provide analogical processing services. Queries that include analogical operations can be formulated in the same way as standard logical inference, and analogical processing systems in turn can call on the services of first-principles reasoners for creating cases and validating their conjectures. We illustrate the utility of the analogy ontology by demonstrating how it has been used in three systems: A crisis management analogical reasoner that answers questions about international incidents, a course of action analogical critiquer that provides feedback about military plans, and a comparison question-answering system for knowledge capture. These systems rely on large, general-purpose knowledge bases created by other research groups, thus demonstrating the generality and utility of these ideas.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-130.pdf,,1237
136,2002,Emerging Applications,Applying Perceptually Driven Cognitive Mapping to Virtual Urban Environments,"Randall W. Hill, Jr., Changhee Han, and Michael van Lent, USC Institute for Creative Technologies","This paper describes a method for building a cognitive map of a virtual urban environment. Our routines enable virtual humans to map their environment using a realistic model of perception. We based our implementation on a computational framework proposed by Yeap and Jefferies (1999) for representing a local environment as a structure called an Absolute Space Representation (ASR). Their algorithms compute and update ASRs from a 2-1/2D sketch of the local environment, and then connect the ASRs together to form a raw cognitive map. Our work extends the framework developed by Yeap and Jefferies in three important ways. First, we implemented the framework in a virtual training environment, the Mission Rehearsal Exercise (Swartout et al. 2001). Second, we describe a method for acquiring a 2-1/2D sketch in a virtual world, a step omitted from their framework, but which is essential for computing an ASR. Third, we extend the ASR algorithm to map regions that are partially visible through exits of the local space. Together, the implementation of the ASR algorithm along with our extensions will be useful in a wide variety of applications involving virtual humans and agents who need to perceive and reason about spatial concepts in urban environments.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-131.pdf,,1260
137,2002,Emerging Applications,Toward Practical Knowledge-Based Tools for Battle Planning and Scheduling,"Alexander Kott, Larry Ground, and Ray Budd, BBN Technologies; Lakshmi Rebbapragada, U.S. Army CECOM/RDEC/C2D; John Langston, Austin Information Systems","Use of knowledge-based decision aids can help alleviate the challenges of planning complex military operations. We describe the CADET system, a knowledge-based tool capable of producing automatically (or with human guidance) Army battle plans with realistic degree of detail and complexity. In ongoing experiments, it compared favorably with human planners. Tight interleaving of planning, adversary estimates, scheduling, routing, attrition and consumption processes comprise the computational approach of this tool. Although originally developed for Army large-unit operations, the technology is generic. In this paper, we focus particularly on the engineering tradeoffs in the design of the tool, and on the experimental comparative evaluation of the tool’s performance.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-132.pdf,,773
138,2002,Emerging Applications,Knowledge Formation and Dialogue Using the KRAKEN Toolset,"Kathy Panton, Pierluigi Miraglia, Nancy Salay, Robert C. Kahlert, David Baxter, and Roland Reagan, Cycorp, Inc.","The KRAKEN toolset is a comprehensive interface for knowledge acquisition that operates in conjunction with the Cyc knowledge base. The KRAKEN system is designed to allow subject-matter experts to make meaningful additions to an existing knowledge base, without the benefit of training in the areas of artificial intelligence, ontology development, or logical representation. Users interact with KRAKEN via a natural-language interface, which translates back and forth between English and the KB’s logical representation language. A variety of specialized tools are available to guide users through the process of creating new concepts, stating facts about those concepts, and querying the knowledge base. KRAKEN has undergone two independent performance evaluations. In this paper we describe the general structure and several of the features of KRAKEN, focussing on key aspects of its functionality in light of the specific knowledge-formation and acquisition challenges they are intended to address.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-133.pdf,,1002
139,2002,Emerging Applications,AI on the Battlefield: An Experimental Exploration,"Robert Rasch, Battle Command Battle Lab; Alexander Kott, BBN Technologies; Kenneth D. Forbus, Northwestern University","The US Army Battle Command Battle Lab conducted an experiment with the ICCES system -- an integrated decision aid for performing several critical steps of a US Army Brigade Military Decision Making Process: from capturing a high-level Course of Action to producing a detailed analysis and plan of tasks. The system integrated several available technologies based largely on AI techniques, ranging from qualitative spatial interpretation of course-of-action diagrams to interleaved adversarial planning and scheduling. The experiment dispelled concerns about potential negative impacts of such tools on the creative aspects of the art of war, showed a potential for dramatic time savings in the MDMP process, and confirmed the maturity and suitability of the technologies for near-future deployment.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-134.pdf,,798
140,2002,Emerging Applications,Intelligent Control of Auxiliary Ship Systems,"David Scheidt, Christopher McCubbin, Michael Pekala, Shon Vick, and David Alger, The Johns Hopkins University","The Open Autonomy Kernel (OAK) is an architecture for autonomous distributed control. OAK addresses control as a three-step process: diagnosis, planning and execution. OAK is specifically designed to support ""hard"" control problems in which the system is complex, sensor coverage is incomplete, and distribution of control is desired. A unique combination of model-based reasoning and autonomous agents is used. Model-based reasoning is used to perform diagnosis. Observations and execution are distributed using autonomous intelligent agents. Planning is performed with some simple script or graph-spanning planners. A prototype OAK system designed to control the chilled water distribution system of a Navy surface ship has been developed and is described.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-135.pdf,,758
141,2002,Emerging Applications,Computational Vulnerability Analysis for Information Survivability,"Howard Shrobe, Massachusetts Institute of Technology","The Infrastructure of modern society is controlled by software systems. These systems are vulnerable to attacks; several such attacks, launched by ""recreation hackers"" have already led to severe disruption. However, a concerted and planned attack whose goal is to reap harm could lead to catastrophic results (for example, by disabling the computers that control the electrical power grid for a sustained period of time). The survivability of such information systems in the face of attacks is therefore an area of extreme importance to society. This paper is set in the context of self-adaptive survivable systems: software that judges the trustworthiness of the computational resources in its environment and which chooses how to achieve its goals in light of this trust model. Each self-adaptive survivable system detects and diagnoses compromises of its resources, taking whatever actions are necessary to recover from attack. In addition, a long-term monitoring system collects evidence from intrusion detectors, fire-walls and all the self-adaptive components, building a composite trust-model used by each component. Self-adaptive surviable systems contain models of their intended behavior, models of the required computational resources, models of the ways in which these resources may be compromised and finally, models of the ways in which a system may be attacked and how such attacks can lead to compromises of the computational resources. In this paper we focus on Computational Vulnerability Analysis: a system that, given a description of a computational environment, deduces all of the attacks that are possible. In particular its goal is to develop multi-stage attack models in which the compromise of one resource is used to facilitate the compromise of other, more valuable resources. Although our ultimate aim is to use these models online as part of a self-adaptive system, there are other offline uses as well which we are deploying first to help system administrators assess the vulnerabilitities of their computing environment.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-136.pdf,,2052
142,2002,Emerging Applications,A Web-Based Ontology Browsing and Editing System,"Jérôme Thoméré, SRI International; Ken Barker, University of Texas at Austin; Vinay Chaudhri, SRI International; Peter Clark, Boeing Research and Technology; Michael Eriksen and Sunil Mishra, SRI International; Bruce Porter, University of Texas at Austin; Andres Rodriguez, SRI International","Making logic-based AI representations accessible to ordinary users has been an ongoing challenge for the successful deployment of knowledge bases. Past work to meet this objective has resulted in a variety of ontology editing tools and task-specific knowledge-acquisition methods. In this paper, we describe a Web-based ontology browsing and editing system with the following features: (a) well-organized English-like presentation of concept descriptions and (b) use of graphs to enter concept relationships, add/delete lists, and analogical correspondences. No existing tool supports these features. The system is Web-based and its user interface uses a mixture of HTML and Java. It has undergone significant testing and evaluation in the context of a real application.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-137.pdf,,770
143,2002,Emerging Applications,The 2001 Trading Agent Competition,"Michael P. Wellman, University of Michigan; Amy Greenwald, Brown University; Peter Stone, AT&T Labs - Research; Peter R. Wurman, North Carolina State University","The 2001 Trading Agent Competition was the second in a series of events aiming to shed light on research issues in automating trading strategies. Based on a challenging market scenario in the domain of travel shopping, the competition presents agents with difficult issues in bidding strategy, market prediction, and resource allocation. Entrants in 2001 demonstrated substantial progress over the prior year, with the overall level of competence exhibited suggesting that trading in online markets is a viable domain for highly autonomous agents.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-138.pdf,,547
144,2002,Student Abstracts,Multiple Instance Learning with Generalized Support Vector Machines,"Stuart Andrews, Thomas Hofmann, and Ioannis Tsochantaridis, Brown University","In pattern classification it is usually assumed that a training set of patterns along with their class labels is available. Multiple-Instance Learning (MIL) generalizes this problem setting by making weaker assumptions about the labeling information. We propose to generalize Support Vector Machines to take into account such weak labeling of the type found in MIL. Our method is able to identify superior discriminant functions, as is demonstrated in experiments on synthetic and image datasets.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-139.pdf,,496
145,2002,Student Abstracts,Toward a Framework for Assembling Broken Pottery Vessels,"Stuart Andrews and David H. Laidlaw, Brown University","This paper addresses how to automatically reconstruct pottery vessels from a collection of sherds using a variety of features and their comparisons. We present a computational framework that is founded on the primitive operations of ""match"" proposal and evaluation, where a match defines the geometric relationship between a pair of sherds. This framework affords a natural decomposition of the computation required by an automatic assembly process and provides a concrete basis to evaluate the utility of different features and feature comparisons for assembly. Our framework paves the way for a system to automatically reconstruct pottery vessels. We demonstrate a greedy assembly strategy that predicts likely pairs and triples of sherds using a handful of proposal and evaluation modules.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-140.pdf,,792
146,2002,Student Abstracts,Mixed-Initiative Exception-Based Learning for Knowledge Base Refinement,"Cristina Boicu, Gheorghe Tecuci, and Mihai Boicu, George Mason University","This paper addresses the exception-based refinement of the knowledge base of a learning agent. The knowledge base consists of an ontology that represents the objects from an application domain, and a set of problem solving rules learned from examples of problem solving episodes. Because the ontology is incomplete and is used as the generalization hierarchy for learning, the learned rules generally contain exceptions. The paper proposes a suite of interactive methods for extending the object ontology with new objects and features in order to eliminate the exceptions of the rules. Some are simpler methods for a subject matter expert, while others are more complex ones, requiring the participation of a knowledge engineer. Each method has four major phases: discovery of promising ontology refinement candidates; selection of the candidate; elicitation and refinement of the ontology based on the selected candidate; and refinement of the rules based on the extended ontology. These methods are integrated into the Disciple learning agent shell.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-141.pdf,,1051
147,2002,Student Abstracts,Fuzzy Numbers for the Improvement of Causal Knowledge Representation in Fuzzy Cognitive Maps,"Otto X. Cordero and Enrique Peláez, Information Technology Center - ESPOL","We present an extension of the fuzzy cognitive map knowledge representation, based on fuzzy numbers, to improve the management of uncertainty related to linguistic expressions. In this regard, we also review the fuzzy causal algebra and outline the opportunities for applications.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-142.pdf,,280
148,2002,Student Abstracts,A Genetic Algorithm for Tuning Variable Orderings in Bayesian Network Structure Learning,"Haipeng Guo, Benjamin B. Perry, Julie A. Stilson, and William H. Hsu, Kansas State University","Learning a Bayesian network from data is NP-hard even without considering unobserved or irrelevant variables. Many previous Bayesian network learning algorithms require that a node ordering is available before learning. Unfortunately, this is usually not the case in many real-world applications. To make greedy search usable when node orderings are unknown, we have developed a permutation genetic algorithm (GA) wrapper to tune the variable ordering given as input to K2, a score-based BN learning algorithm. We have used a probabilistic inference criterion as the GA’s fitness function and we are also trying some other criterion to evaluate the learning result such as the learning fixed-point property.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-143.pdf,,707
149,2002,Student Abstracts,A Model Checker for Verifying ConGolog Programs,"Leila Kalantari and Eugenia Ternovska, Simon Fraser University","We describe our work in progress on a model checker for verifying ConGolog programs. ConGolog is a novel high-level programming language for robot control which incorporates a rich account of concurrency, prioritized execution, interrupts, and changes in the world that are beyond robot’s control. The novelty of this language requires new methods of proving correctness. We apply the techniques from XSB tabling and the mu-calculus, to overcome the challenge of verifying complex non-terminating programs, in a terminating time.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-144.pdf,,529
150,2002,Student Abstracts,Analogical Inference over a Common Sense Database,"Thomas Lin, MIT Media Laboratory","This paper shows that by applying analogical inference techniques to a large natural language common sense database, we can generate new, plausible common sense facts. Two systems that do this are described. Being able to generate new facts in this manner allows quick augmentation of the common sense database.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-145.pdf,,311
151,2002,Student Abstracts,MAKEBELIEVE: Using Commonsense Knowledge to Generate Stories,"Hugo Liu and Push Singh, MIT Media Laboratory","This paper introduces MAKEBELIEVE, an interactive story generation agent that uses commonsense knowledge to generate short fictional texts from an initial seed story step supplied by the user. A subset of commonsense de-scribing causality, such as the sentence ""a consequence of drinking alcohol is intoxication,"" is selected from the on-tology of the Open Mind Commonsense Knowledge Base. Binary causal relations are extracted from these sentences and stored as crude trans-frames. By performing fuzzy, creativity-driven inference over these frames, creative ""causal chains"" are produced for use in story generation. The current system has mostly local pair-wise constraints between steps in the story, though global constraints such as narrative structure are being added.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-146.pdf,,774
152,2002,Student Abstracts,Localizing while Mapping: A Segment Approach,"Andrew J. Martignoni III and William D. Smart, Washington University","Localization in mobile robotics is a well studied problem in many environments. Map building with occupancy grids (probabilistic finite element maps of the environment) is also fairly well understood. However, trying to accomplish both localization and mapping at once has proven to be a difficult task. Updating a map with new sensor information before determining the correct adjustment for the starting point and heading can be disastrous. We hope to solve this problem by performing localization on higher-level objects computed from the raw sensor readings. Any object which can be detected from a single sensor reading can be used to help the localization process. In addition, once the data from the robot’s sensors have been turned into a map with human-identifiable features, the map can easily be augmented with additional information about the objects (unique names, attributes, etc).",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-147.pdf,,895
153,2002,Student Abstracts,Multi-Player Game Approach to Solving Multi-Entity Problems,"Wee-Chong Oon and Andrew Lim, National University of Singapore","Many real-world problems involve allocating limited resources to multiple consumers with dissimilar objective functions. Current techniques usually aim to maximize some single weighted sum performance metric, which fails to properly take into account these dissimilar objectives. This research investigates the Multi-Player Game Approach, modeling the problem as a multi-player competitive cum collaborative game where each consumer is a player in the game. It is played in several iterations of bidding, arbitration and negotiation phases. In the bidding phase, the consumers bid for resources using their own customized strategies. In the arbitration phase, resources are allocated to the consumers based on the bids tabled. In the negotiation phase, the consumers attempt to make mutually beneficial trades with each other. Experiments on the university examination timetabling problem suggest that this approach may outperform centralized approaches.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-148.pdf,,954
154,2002,Student Abstracts,BN-Tools: A Software Toolkit for Experimentation in BBNs,"Benjamin Perry and Julie Stilson, Kansas State University","In this paper, I describe BN-Tools, an open-source, Java-based library for experimental research in Bayesian belief networks that implements several popular algorithms for estimation (approximate inference) and learning along with a graphical user interface for interactive display and editing of graphical models. Included in the discussion are our implementations of the Lauritzen-Spiegelhalter algorithm, an adaptive importance sampling algorithm, the K2 learning algorithm, and two genetic algorithm wrappers.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-149.pdf,,513
155,2002,Student Abstracts,Optimizing Parameter Learning Using Temporal Differences,"James F. Swafford II, East Carolina University","Temporal difference algorithms are useful when attempting to predict outcome based on some pattern, such as a vector of evaluation parameters applied to the leaf nodes of a state space search. As time progresses, the vector begins to converge towards an optimal state, in which program performance peaks. Temporal difference algorithms continually modify the weights of a differentiable, continuous evaluation function. As pointed out by De Jong and Schultz, expert systems that rely on experience-based learning mechanisms are more useful in the field than systems that rely on growing knowledge bases. This research focuses on the application of the TDLeaf algorithm to the domain of computer chess. I present empirical data showing the evolution of a vector of evaluation weights and the associated performance ratings under a variety of conditions.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-150.pdf,,852
156,2002,Student Abstracts,Student Modeling for a Web-Based Learning Environment: A Data Mining Approach,"Tiffany Y. Tang and Gordon McCalla, University of Saskatchewan","In this paper, we report on an on-going study of how data mining techniques, if incorporated into web learning environments, can enhance the overall qualities of learning. The focus is on building student models, using a clustering technique based on large generalized sequences recording both learners’ web browsing behavior and the contents of the pages being browsed.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-151.pdf,,370
157,2002,Student Abstracts,An Extended Alternating-Offers Bargaining Protocol for Automated Negotiation in Multi-Agent Systems,"Pinata Winoto, Gordon McCalla, and Julita Vassileva, University of Saskatchewan",This ongoing research focuses on the study of bilateral bargaining mechanism of competitive agents within the context of automated negotiation. Some modifications are proposed to improve conventional alternating-offers bargaining model and corresponding experimentation will be designed to study their advantages/disadvantages.,https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-152.pdf,,327
158,2002,Student Abstracts,Consistency and Set Intersection,"Yuanlin Zhang and Roland H. C. Yap, National University of Singapore","The study of local and global consistency is an important topic in Constraint Networks. In this paper, we give some results on finite set intersections and relate k-consistency to set intersection. We present a proof schema which lifts the results on set intersection to results at a particular level of consistency (including global consistency). This gives a new framework to study consistency in terms of general properties of set intersection. Some well known results on row convex constraints, tightness and looseness can then be derived directly and proved using our proof schema.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-153.pdf,,586
159,2002,Student Abstracts,Incrementally Solving Functional Constraints,"Yuanlin Zhang and Roland H.C. Yap, National University of Singapore","Binary functional constraints represent an important constraint class. An efficient algorithm for determining satisfiability of a static system of functional constraints in O(ed) time is known where e is the number of constraints and d is the size of the domain. However, in most constraint programming systems, constraints are incrementally added to the constraint store. Here, we describe how satisfiability of an incremental system of only functional constraints can be obtained in almost the same time complexity as the static one. In a mixed incremental CSP which contains also non-functional constraints, we propose an algorithm which does eagerelimination to achieve more consistency on the mixed system. The resulting algorithm has complexity O(ed^2 log e) which is comparable to the cost of enforcing arc consistency.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-154.pdf,,826
160,2002,Student Abstracts,Multiple Sequence Alignment Using Anytime A*,"Rong Zhou and Eric A. Hansen, Mississippi State University","We describe an extension of the A* algorithm, called Anytime A*, and show that it is effective in solving search problems that have a very large branching factor, such as the multiple sequence alignment problem in computational biology. We compare its performance to two other modified A* algorithms described in the literature and designed for the same class of problems. We show that Anytime A* offers a good time-space tradeoff.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-155.pdf,,431
161,2002,SIGART/AAAI Doctoral Consortium,Decision-Theoretic Planning for Intelligent User Interfaces,"Thorsten Bohnenberger, Saarland University","Human-computer interaction can sometimes be enhanced if a system can adapt to various aspects of the current situation (e.g., the user’s location, time constraints, cognitive load, and emotional state). It is sometimes useful to consider not only the immediate consequences of adaptation but also its (often uncertain) effects in the future. In the research summarized here, fully observable Markov decision processes have been successfully used to model and plan ahead the uncertain course of interaction for adaptation in two different scenarios. The approach needs to be generalized to deal with partial observability, so that a system cancope with situations in which not only the effects of its actions but also the current state of the interaction is uncertain.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-156.pdf,,767
162,2002,SIGART/AAAI Doctoral Consortium,Efficient Modeling of Temporally Variable User Properties with Dynamic Bayesian Networks,"Boris Brandherm, Saarland University","Dynamic Bayesian networks (DBNs) are well suited to the modeling of temporally variable properties of computer users, such as time pressure and cognitive load. One challenge is to develop new methods for limiting the computational complexity of DBNs, so that they can be applied to real-time user modeling. A second goal is to design and test appropriate structures and preprocessing methods for DBNs that interpret data from a user’s motor behavior and speech, as well as physiological data.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-157.pdf,,492
163,2002,SIGART/AAAI Doctoral Consortium,Learning in Open-Ended Dynamic Distributed Environments,"Doina Caragea, Iowa State University","In some domains (e.g., molecular biology), data repositories are large in size, dynamic, and physically distributed. Consequently, it is neither desirable nor feasible to gather all the data in a centralized location for analysis. Hence, efficient distributed learning algorithms that can operate across multiple data sources without the need to transmit large amounts of data and cumulative learning algorithms that can cope with data sets that grow at rapid rate are needed. We formulate a class of distributed and cumulative learning problems, and present a general strategy for transforming a large class of traditional machine learning algorithms into distributed and cumulative learning algorithms. Our general strategy is based on a decomposition of the learning task into information extraction and hypothesis generation components. We use this approach to construct provably exact distributed algorithms for support vector machines and also for decision tree learning. We formalize the treatment of distributed learning by introducing a family of learning, information extraction and information composition operators and establishing sufficient conditions for provably exact distributed and cumulative learning in terms of general algebraic properties of the operators.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-158.pdf,,1279
164,2002,SIGART/AAAI Doctoral Consortium,Dynamic Bayesian Networks for Automatic Speech Recognition,"Murat Deviren, INRIA-LORIA","State-of-the-art automatic speech recognition (ASR) systems are based on probabilistic modelling of the speech signal using Hidden Markov Models. The limitations of these systems under real life conditions arose a question about the robustness of the underlying acoustic modelling methodology. The scope of my thesis is to explore the formalism of Probabilistic Graphical Models, particularly Dynamic Bayesian Networks, from a theoretical and practical point of view, with the aim of developing reliable models of speech and of developing robust ASR systems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-159.pdf,,558
165,2002,SIGART/AAAI Doctoral Consortium,Combining Inference and Search for the Propositional Satisfiability Problem,"Lyndon Drake and Alan Frisch, University of York; Toby Walsh, University College Cork",The most effective complete method for testing propositional satisfiability (SAT) is backtracking search. Recent research suggests that adding more inference to SAT search procedures can improve their performance. This paper presents two ways to combine neighbour resolution (one such inference technique) with search.,https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-160.pdf,,318
166,2002,SIGART/AAAI Doctoral Consortium,A Bayesian Metareasoner for Algorithm Selection for Real-Time Bayesian Network Inference Problems,"Haipeng Guo, Kansas State University","The aim of this research is to integrate various Bayesian network (BN) inference algorithms into a framework based on Bayesian methods to solving the ""algorithm selection problem"" of real-time BN inference. The metareasoner is a Bayesian network that encodes the uncertain knowledge of dependencies among the characteristics of BN inference problem instances and the performance of the inference algorithms. It is automatically learned from some representative synthetic training data with the guidance of some domain nowledge. Once having this metareasoner network, we can then use it to select the right algorithm for a given Bayesian network inference problem instance and predict the run time performance of the algorithm on this problem instance. Such methods will also be useful in solving other hard problems.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-161.pdf,,816
167,2002,SIGART/AAAI Doctoral Consortium,An Agent Approach to Security in Pervasive Environments,"Lalana Kagal, University of Maryland Baltimore County","Security has always been important in computer systems and has now become even more crucial with open, dynamic environments like the Internet, Semantic Web and wirelessly connected pervasive systems. In such environments, users and resources can be extremely unstable, changing their location, contact information, policies, and even functionality often. Existing security mechanisms fail to meet the requirements of pervasive systems, which include authenticating foreign users, and providing authorization to a large number of dynamic entities in the absence of a central control or a repository. Our research proposes to model pervasive systems using agent technologies and to use principles of distributed trust as an alternative to traditional authentication and access control schemes.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-162.pdf,,791
168,2002,SIGART/AAAI Doctoral Consortium,Generalized Features: Their Application to Classification,"Svetlana Kiritchenko and Stan Matwin, SITE, University of Ottawa","Classification learning algorithms in general, and text classification methods in particular, tend to focus on features of individual training examples, rather than on the relationships between the examples. However, in many situations a set of items contains more information than just feature values of individual items. We propose to recognize and put in use generalized features (or set features) that describe a training example, but that depend on the dataset as a whole, with the goal of achieving better classification accuracy. In particular, we work on the integration of temporal relations into conventional word-based email classification.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-163.pdf,,651
169,2002,SIGART/AAAI Doctoral Consortium,Organizations of Self-Interested Agents,"Foster McGeary, University of Delaware","Organizations are sets of autonomous agents that reach agreements to exchange computational services for value. The formation and operation of organizations is rational and computable, and can be modeled using Artificial Intelligence tools. I extend Multi-Agent Systems technologies by introducing procedures by which sovereign computational agents may form organizations. Organizations formed with the intention to sell products at a profit are taken to be firms, a principal interest of the research. First, domain-level (Virtual Food Court) technologies are created to make products when properly instantiated with the skills and resources (raw materials or other products) they require. Second, agents are endowed with skills that, when applied within technologies, have value derived from the products of the technology. Third, agents negotiate compensation for the application of their skills. Fourth, agents are provided with computable preferences for products and the desire to acquire products to maximize their private welfare. Finally, the agents are permitted to act in accordance with these components and the data they collect themselves. The computational procedures under which sovereign agents exchange data, negotiate skill application and compensation, and make reciprocal commitments are the structures that support the organization of firms among sovereign computational agents.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-164.pdf,,1400
170,2002,SIGART/AAAI Doctoral Consortium,Distributed Constraint Optimization and Its Application to Multiagent Resource Allocation,"Pragnesh Jay Modi, University of Southern California/Information Sciences Institute","Distributed optimization requires the optimization of a global objective function that is distributed among a set of autonomous, communicating agents and is unknown by any individual agent. The problem is inherently distributed and the solution strategy has no control over a given distribution. Constraint based techniques offer a promising approach for coordinating a set of distributed agents to find optimal solutions. However previous work has the following limitations. First, representation is limited to binary good/nogood constraints. In many domains, it is more natural to represent constraints as having degrees of valuation. Second, previous work on distributed optimization problems has relied on synchronous sequential computation to find optimal solutions. This is slow and requires agents to block for messages. Third, previous asychronous approaches lack any guarantees of optimality even when given sufficient time and provide little guidance on how to trade-off solution quality for time-to-solution when time is limited. This work proposes Adopt, an asynchronous, distributed, complete method for solving distributed optimization problems. The fundamental ideas in Adopt are to represent constraints as discrete functions (or valuations) --- instead of binary good/nogood values --- and to use the evaluation of these constraints to measure progress towards optimality. In addition, Adopt uses a sound and complete partial solution combination method to allow non-sequential, asychronous computation. Finally, Adopt is not only provably optimal when given enough time, but allows solution time/quality tradeoffs when time is limited. Adopt is applied to a real-world distributed resource allocation problem. Distributed resource allocation is a general problem in which a set of agents must optimally assign their resources to a set of tasks with respect to certain criteria. It arises in many real-world domains such as distributed sensor networks, disaster rescue, hospital scheduling, and others.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-165.pdf,,2019
171,2002,SIGART/AAAI Doctoral Consortium,Generating Trading Agent Strategies,"Daniel Reeves, University of Michigan","My thesis work concerns the generation of trading agent strategies -- automatically, semi-automatically, and manually. Automatic generation of an agent strategy means creating a system that can read the description of some mechanism and output a strategy for a participating agent. To make this more concrete, consider an extremely simple auction mechanism: a two-player first-price sealed-bid auction. My current system can take such a game description and output the optimal strategy, i.e., the Nash equilibrium. Existing game solvers (Gambit and Gala) can only solve games with an enumerated (finite) set of actions, and this limitation makes it impossible to even approximate the solution to games with a continuum of actions because the size of the game tree quickly explodes. Of course, the optimal strategy for the first-price sealed-bid auction was computed before game solvers existed; however, my algorithm can automatically solve any of a class of games (with certain caveats) that current solvers can’t. In addition to this algorithm for exact solutions, I have an approximation algorithm using Monte Carlo simulation that can handle a more general class of games albeit at high computational cost. Both of the above methods are only tractable for quite simple games. For example, almost any mechanism that involves iterated bidding and multiple auctions is likely not to be tractable for strictly game-theoretic analysis, regardless of whether exact or approximate solutions are sought. An example of such a mechanism that we are analyzing is a simultaneous ascending auction for scheduling resources among a group of agents. In this domain, every agent has certain preferences for acquiring time slots and simultaneous English auctions are held for every slot until bidding stops and the slots are allocated. Since this mechanism is too complicated for the fully automatic techniques described above, we are attempting to generate strategies semi-automatically. Finally, there are domains in which even the semi-automatic method for generating strategies is not yet feasible. These include many real-world market scenarios, but also a particular structured domain---the Trading Agent Competition (TAC). TWe believe this work in designing trading agent strategies for very rich domains will shed light on how to extend our results on the automatic generation of trading agent strategies.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-166.pdf,,2400
172,2002,SIGART/AAAI Doctoral Consortium,A Reputation-Oriented Reinforcement Learning Approach for Agents in Electronic Marketplaces,"Thomas Tran, University of Waterloo","We propose a reputation-oriented reinforcement learning algorithm for buying and selling agents in electronic market environments. We take into account the fact that multiple selling agents may offer the same good with different qualities. In our approach, buying agents learn to avoid the risk of purchasing low qualitiy goods and to maximize their expected value of goods by dynamically maintaining sets of reputable sellers. Selling agents learn to maximize their expected profits by adjusting product prices and by optionally altering the quality of their goods. We feel that our approach should lead to improved satisfaction for buying and selling agents and improved performance for buying agents (in terms of computational cost).",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-167.pdf,,736
173,2002,SIGART/AAAI Doctoral Consortium,A Dialogue System with Digression Handling - An Ontology-Based Approach,"Tzong-Han Tsai, National Taiwan University","Dialogue models fall into two categories. Structural approaches do not emphasize the contextual nature of communication. Plan-based approaches, on the other hand, attempt to recognize users’ goals and plans, and to produce corresponding effects. These two approaches are effective as long as users follow the preplanned scripts closely. However, when digression occurs, it is difficult for the structural approach to handle due to the rigid nature of finite state machines and grammar rules. And the plan-based approach wouldn’t incur the high cost of frequent re-planning and discourse context switching. In this paper, we shall deal with these issues using an ontology-based approach. We use a knowledge representation framework, InfoMap, as our ontology to identify events in utterances. By identifying events in the user’s high level query, InfoMap can create a dialogue strategy that guides the user to an appropriate deeper event, where the system can provide more concrete solutions. When digression occurs, the system either ignores it (if the digressive level is too high in the ontology) or moves to a related topic.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-168.pdf,,1126
174,2002,Intelligent Systems Demonstrations,Disciple-RKF/COG: Agent Teaching by Subject Matter Experts,"Mihai Boicu, George Mason University; Gheorghe Tecuci, George Mason University and US Army War College; Dorin Marcu, Bogdan Stanescu, Cristina Boicu, Catalin Balan, Marcel Barbulescu, and Xianjun Hao, George Mason University","Disciple-RKF/COG is a learning agent shell that can perform many knowledge engineering tasks, and can be used to develop knowledge based systems by subject matter experts, with limited assistance from knowledge engineers. The expert and the agent engage into a mixed-initiative reasoning process during which the expert is teaching the agent his problem solving expertise, and the agent learns from the expert, building, verifying, and improving its knowledge base. Disciple-RKF/COG is used in several courses at the US Army War College. In the ""Military Applications of Artificial Intelligence"" course the students teach personal Disciple agents their own reasoning in Center of Gravity analysis. In the ""Case Studies in Center of Gravity Analysis"" course, a Disciple agent that was taught the expertise of the course’s instructor helps the students to learn about center of gravity analysis, and to develop a case study analysis report.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-169.pdf,,938
175,2002,Intelligent Systems Demonstrations,JYAG and IDEY: A Template-Based Generator and Its Authoring Tool,"Songsak Channarukul, Susan W. McRoy, and Syed S. Ali, University of Wisconsin - Milwaukee","JYAG is the Java implementation of a real-time, general-purpose, template-based generation system (YAG, Yet Another Generator). JYAG enables interactive applications to adapt natural language output to the interactive context without requiring developers to write all possible output strings ahead of time or to embed extensive knowledge of the grammar of the target language in the application. Currently, designers of interactive systems who might wish to include dynamically generated text face a number of barriers; for example designers must decide (1) How hard will it be to link the application to the generator? (2) Will the generator be fast enough? (3) How much linguistic information will the application need to provide in order to get reasonable quality output? (4) How much effort will be required to write a generation grammar that covers all the potential outputs of the application? The design and implementation of our template-based generation system, JYAG, is intended to address each of these concerns.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-170.pdf,,1023
176,2002,Intelligent Systems Demonstrations,Research Applications of the MAGNET Multi-Agent Contracting Testbed,"John Collins and Maria Gini, University of Minnesota","MAGNET is a testbed for exploring decision processes and agent interactions in the domain of multi-agent contracting. MAGNET agents negotiate contracts over multi-step plans that include temporal and precedence constraints, as well as price. Experimental research in this area requires a simulation environment that is sufficiently rich to be easily adapted to a variety of experimental purposes. The MAGNET testbed focuses on the process of determining the form and content of Requests for Quotations (RFQ’s), on the management of the bidding process, and on the evaluation of bids submitted by potential suppliers. All major decision processes are driven by plug-in components with documented API’s and a wealth of configuration parameters, and problem generation and data collection capabilities are well-suited to statistical studies.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-171.pdf,,838
177,2002,Intelligent Systems Demonstrations,SpeechWeb: A Web of Natural-Language Speech Applications,"R. A. Frost, University of Windsor","SpeechWeb consists of a collection of hyperlinked natural-language interfaces to applications which can be accessed through the Internet from speech browsers running on PCs. The applications contain hyperlinks which the browser uses to navigate SpeechWeb. The natural-language interfaces have been constructed as executable specifications of attribute grammars using a domain-specific programming language built for this purpose. The approach to natural-language processing is based on a new efficient compositional semantics that accommodates arbitrarily-nested quantification and negation. The user-independent speech browser is grammar based, and novel techniques have been developed to improve recognition accuracy.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-172.pdf,,719
178,2002,Intelligent Systems Demonstrations,An Automated Negotiator for an International Crisis,"Penina Hoz-Weiss, Bar-Ilan University; Sarit Kraus, Bar-Ilan University and University of Maryland; Jonathan Wilkenfeld and Tara E. Santmire, University of Maryland","We present an automated agent that can negotiate efficiently with humans in bilateral negotiations with time constraints, deadlines, full information, and the possibility of opting out. The negotiation is conducted using a semi-formal language. The model used in constructing the agent is based on a formal analysis of the scenario using game theoretic methods and heuristics for argumentation. The agent receives messages sent by humans, analyzes them and responds. It also initiates discussion on one or more parameters of an agreement. The specific scenario concerns a crisis between Spain and Canada over access to a fishery. The human players are provided with a DSS to analyze the scenario and compare the utility points associated with various outcomes, and with a language editor to facilitate the composition of messages.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-173.pdf,,830
179,2002,Intelligent Systems Demonstrations,"FlexBot, Groo, Patton and Hamlet: Research Using Computer Games as a Platform","Aaron Khoo, Robin Hunicke, Greg Dunham, Nick Trienens, and Muon Van, Northwestern University","This paper describes four systems we intend to demonstrate at the AAAI-02 Conference. The first system is FlexBot, a software agent research platform built using the Half-Life game engine. The remaining three systems are research applications that were developed on top of the FlexBot architecture: (1) Groo -- an efficient bot constructed using behavior-based techniques. (2) Patton -- a system for monitoring and controlling bots through remote, possibly mobile, devices. (3) Hamlet -- the first part of a system for monitoring players and dynamically adjusting gameplay to promote dramatic/narrative immersion. This demonstration is designed to show FlexBot in action and to exhibit the flexibility, efficiency and overall ease with which the FlexBot architecture supports a variety of AI research tasks.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-174.pdf,,807
180,2002,Intelligent Systems Demonstrations,UTTSExam: A University Examination Timetable Scheduler,"Andrew Lim, Juay-Chin Ang, Wee-Kit Ho, and Wee-Chong Oon, National University of Singapore","UTTSExam is a university examination timetable-scheduling program that was successfully employed to create the examination timetable for semester 1 of the 2001/2002 academic year in the National University of Singapore. This demonstration provides insight on the various components of the system, including the hybrid centralized cum decentralized scheduling strategy, the Combined Method scheduling algorithm and the overall process required to create the final timetable.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-175.pdf,,473
181,2002,Intelligent Systems Demonstrations,Multi-ViewPoint Clustering Analysis (MVP-CA) Tool,"Mala Mehrotra, Pragati Synergetic Research Inc.; Dmitri Bobrovnikoff, Intelligent Software Solutions","The MVP-CA tool clusters a knowledge base into related rule sets thus allowing the user to comprehend the knowledge base in terms of conceptually meaningful clusters of rules. The tool is eventually meant to aid knowledge engineers and subject matter experts to author, understand and manage the KB for its maximal utilization.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-176.pdf,,327
182,2002,Intelligent Systems Demonstrations,Fuzzy Neural Networks in a Palm Environment,"Samuel Moyle and Michael Watts, University of Otago School of Business","This paper outlines the achievements made in the area of small expert systems, in particular the use of multiple Fuzzy Neural Networks (FuNN) within a single application implemented on a Palm sized device (Personal Digital Assistant or PDA). Also discussed is the opportunity for using the architecture as a generic problem solving method -- if a Neural Network is an appropriate solution to a problem then a PDA based implementation becomes possible. An overview of a real-world problem is presented. The proposed solution is outlined, as is the use of Fuzzy Neural Networks in the building of a small expert system. The generic architecture implemented, and the reasons for using such a structure, is discussed. Finally, the options for future development are outlined, as proposed by expert evaluators and system developers.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-177.pdf,,827
183,2002,Intelligent Systems Demonstrations,CAUI Demonstration -- Composing Music Based on Human Feelings,"Masayuki Numao, Shoichi Takagi, and Keisuke Nakamura, Tokyo Institute of Technology","We demonstrate a method to locate relations and constraints between a music score and its impressions, by which we show that machine learning techniques may provide a powerful tool for composing music and analyzing human feelings. We examine its generality by modifying some arrangements to provide the subjects with a specified impression. This demonstration introduces some user interfaces, which are capable of predicting feelings and creating new objects based on seed structures, such as spectra and their transition for sounds that have been extracted and are perceived as favorable by the test subject.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-178.pdf,,609
184,2002,Invited Talks,Perspectives on Artificial Intelligence Planning,"Héctor Geffner, Universitat Pompeu Fabra - ICREA","Planning is a key area in artificial intelligence. In its general form, planning is concerned with the automatic synthesis of action strategies (plans) from a description of actions, sensors, and goals. Planning thus contrasts with two other approaches to intelligent behavior: the programming approach, where action strategies are defined by hand, and the learning approach, where action strategies are inferred from experience. Different assumptions about the nature of actions, sensors, and costs lead to various forms of planning: planning with complete information and deterministic actions (classical planning), planning with non-deterministic actions and sensing, planning with temporal and concurrent actions, etc. Most work so far has been devoted to classical planning, where significant changes have taken place in the last few years. On the methodological side, the area has become more empirical, on the technical side, approaches based on heuristic or constrained-based search have become common. In this paper, I try to provide a coherent picture of Planning in AI, making emphasis on the mathematical models that underlie various forms of planning and the ideas that have been found most useful computationally.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-179.pdf,,1227
185,2002,Invited Talks,Most Informative Dimension Reduction,"Amir Globerson and Naftali Tishby, The Hebrew University","Finding effective low dimensional features from empirical co-occurrence data is one of the most fundamental problems in machine learning and complex data analysis. One principled approach to this problem is to represent the data in low dimension with minimal loss of the information contained in the original data. In this paper we present a novel information theoretic principle and algorithm for extracting low dimensional representations, or feature-vectors, that capture as much as possible of the mutual information between the variables. Unlike previous work in this direction, here we do not cluster or quantize the variables, but rather extract continuous feature functions directly from the co-occurrence matrix, using a converging iterative projection algorithm. The obtained features serve, in a well defined way, as approximate sufficient statistics that capture the information in a joint sample of the variables. Our approach is both simpler and more general than clustering or mixture models and is applicable to a wide range of problems, from document categorization to bioinformatics and analysis of neural codes.",https://aaai.org/Library/AAAI/2002/../../../Papers/AAAI/2002/AAAI02-180.pdf,,1130
