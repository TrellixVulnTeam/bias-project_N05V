{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def log_on_text(string):\n",
    "    f = open('log.txt', 'w')\n",
    "    f.write(string + '\\n')\n",
    "    f.close()\n",
    "\n",
    "_columns = ['conference_year', 'category', 'title', 'author', 'institution', 'abstract', 'download_url', 'pdf_file_path', 'keywords', 'publish_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_2019():\n",
    "    None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "  conference_year               category  \\\n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "0            2018  AAAI18 - Applications   \n",
      "\n",
      "                                               title  \\\n",
      "0  Algorithms for Trip-Vehicle Assignment in Ride...   \n",
      "0  EAD: Elastic-Net Attacks to Deep Neural Networ...   \n",
      "0  Learning Differences Between Visual Scanning P...   \n",
      "0  Comparing Population Means Under Local Differe...   \n",
      "0  MuseGAN: Multi-track Sequential Generative Adv...   \n",
      "0  Picasso, Matisse, or a Fake?  Automated Analys...   \n",
      "0  Beyond Distributive Fairness in Algorithmic De...   \n",
      "0                 Distributed Composite Quantization   \n",
      "0  Tensorized Projection for High-Dimensional Bin...   \n",
      "0  Predicting Aesthetic Score Distribution Throug...   \n",
      "0     Norm Conflict Resolution in Stochastic Domains   \n",
      "0  Deep Representation-Decoupling Neural Networks...   \n",
      "0  Early Prediction of Diabetes Complications fro...   \n",
      "0  Learning the Joint Representation of Heterogen...   \n",
      "0  Multi-View Multi-Graph Embedding for Brain Net...   \n",
      "0  Uplink Communication Efficient Differentially ...   \n",
      "0  Learning the Probability of Activation in the ...   \n",
      "0  Generating an Event Timeline About Daily Activ...   \n",
      "0  On Organizing Online Soirees with Live Multi-S...   \n",
      "0  An AI Planning Solution to Scenario Generation...   \n",
      "0  Automated Segmentation of Overlapping Cytoplas...   \n",
      "0  When Social Advertising Meets Viral Marketing:...   \n",
      "0     Synthesis of Programs from Multimodal Datasets   \n",
      "0  CD-CNN: A Partially Supervised Cross-Domain De...   \n",
      "0  Geographic Differential Privacy for Mobile Cro...   \n",
      "0  Catching Captain Jack: Efficient Time and Spac...   \n",
      "0  Video Summarization via Semantic Attended Netw...   \n",
      "0  TIMERS: Error-Bounded SVD Restart on Dynamic N...   \n",
      "0  Ranking Users in Social Networks With Higher-O...   \n",
      "\n",
      "                                              author institution  \\\n",
      "0                       [Xiaohui Bei, Shengyu Zhang]               \n",
      "0  [Pin-Yu Chen, Yash Sharma, Huan Zhang, Jinfeng...               \n",
      "0  [Jonathan Chung, Moshe Eizenman, Uros Rakita, ...               \n",
      "0   [Bolin Ding, Harsha Nori, Paul Li, Joshua Allen]               \n",
      "0  [Hao-Wen Dong, Wen-Yi Hsiao, Li-Chia Yang, Yi-...               \n",
      "0        [Ahmed Elgammal, Yan Kang, Milko Den Leeuw]               \n",
      "0  [Nina Grgić-Hlača, Muhammad Bilal Zafar, Krish...               \n",
      "0       [Weixiang Hong, Jingjing Meng, Junsong Yuan]               \n",
      "0       [Weixiang Hong, Jingjing Meng, Junsong Yuan]               \n",
      "0  [Xin Jin, Le Wu, Xiaodong Li, Siyu Chen, Siwei...               \n",
      "0               [Daniel Kasenberg, Matthias Scheutz]               \n",
      "0  [Zhuo Li, Hongwei Wang, Miao Zhao, Wenjie Li, ...               \n",
      "0  [Bin Liu, Ying Li, Zhaonan Sun, Soumya Ghosh, ...               \n",
      "0  [Luchen Liu, Jianhao Shen, Ming Zhang, Zichang...               \n",
      "0  [Ye Liu, Lifang He, Bokai Cao, Philip S. Yu, A...               \n",
      "0                        [Jian Lou, Yiu-ming Cheung]               \n",
      "0           [Maggie Makar, John Guttag, Jenna Wiens]               \n",
      "0  [Taiki Miyanishi, Jun-ichiro Hirayama, Takuya ...               \n",
      "0  [Chih-Ya Shen, C. P. Kankeu Fotsing, De-Nian Y...               \n",
      "0  [Shirin Sohrabi, Anton V. Riabov, Michael Katz...               \n",
      "0  [Youyi Song, Jing Qin, Baiying Lei, Kup-Sze Choi]               \n",
      "0                                     [Shaojie Tang]               \n",
      "0  [Shantanu Thakoor, Simoni Shah, Ganesh Ramakri...               \n",
      "0  [Jingyuan Wang, Xu He, Ze Wang, Junjie Wu, Nic...               \n",
      "0  [Leye Wang, Gehua Qin, Dingqi Yang, Xiao Han, ...               \n",
      "0  [Xinrun Wang, Bo An, Martin Strobel, Fookwai K...               \n",
      "0  [Huawei Wei, Bingbing Ni, Yichao Yan, Huanyu Y...               \n",
      "0  [Ziwei Zhang, Peng Cui, Jian Pei, Xiao Wang, W...               \n",
      "0  [Huan Zhao, Xiaogang Xu, Yangqiu Song, Dik Lun...               \n",
      "\n",
      "                                            abstract  \\\n",
      "0  We investigate the ride-sharing assignment pro...   \n",
      "0  Recent studies have highlighted the vulnerabil...   \n",
      "0  Bipolar Disorder (BD) and Major Depressive Dis...   \n",
      "0  A statistical hypothesis test determines wheth...   \n",
      "0  Generating music has a few notable differences...   \n",
      "0  This paper proposes a computational approach f...   \n",
      "0  With widespread use of machine learning method...   \n",
      "0  Approximate nearest neighbor (ANN) search is a...   \n",
      "0  Embedding high-dimensional visual features (d-...   \n",
      "0  Aesthetic quality prediction is a challenging ...   \n",
      "0  Artificial agents will need to be aware of hum...   \n",
      "0  Monaural source separation (MSS) aims to extra...   \n",
      "0  Type 2 diabetes mellitus (T2DM) is a chronic d...   \n",
      "0  The availability of a large amount of electron...   \n",
      "0  Network analysis of human brain connectivity i...   \n",
      "0  Preserving differential privacy during empiric...   \n",
      "0  When an infection spreads in a community, an i...   \n",
      "0  Recognizing activities of daily living (ADLs) ...   \n",
      "0  The popularity of live streaming has led to th...   \n",
      "0  Scenario planning is a commonly used method by...   \n",
      "0  We present a novel method for automated segmen...   \n",
      "0  Recent studies reveal that social advertising ...   \n",
      "0  We describe MultiSynth, a framework for synthe...   \n",
      "0  Driven by the wave of urbanization in recent d...   \n",
      "0  For real-world mobile applications such as loc...   \n",
      "0  Pirate syndicates capturing tankers to siphon ...   \n",
      "0  The goal of video summarization is to distill ...   \n",
      "0  Singular Value Decomposition (SVD) is a popula...   \n",
      "0  PageRank has been widely used to measure the a...   \n",
      "\n",
      "                                        download_url pdf_file_path  \\\n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "0  https://aaai.org/ocs/index.php/AAAI/AAAI18/pap...                 \n",
      "\n",
      "                                            keywords publish_date  \n",
      "0                                                                  \n",
      "0  [adversarial machine learning, elastic-net opt...               \n",
      "0  [Bipolar disorder, major depressive disorder, ...               \n",
      "0  [Local model of differential privacy, statisti...               \n",
      "0                                                                  \n",
      "0        [Deep Neural Networks, Art authentication,]               \n",
      "0  [Fair decision making, Machine learning and la...               \n",
      "0                                                                  \n",
      "0                                                                  \n",
      "0  [Image Aesthetic Assessment, Score Distributio...               \n",
      "0  [normative systems, Markov Decision Processes,...               \n",
      "0                                                                  \n",
      "0  [Healthcare, Diabetes, EHR, Survival Analysis,...               \n",
      "0  [Electronic Health Record, Sequential Data Mod...               \n",
      "0  [Brain Network Embedding;Multi-view Learning;T...               \n",
      "0  [Differential Privacy,Frank-Wolfe Algorithm,Di...               \n",
      "0  [healthcare, infectious diseases, probabilisti...               \n",
      "0  [Activity Recognition, Event Timeline Generati...               \n",
      "0                                                                  \n",
      "0  [Applications, Planning and Scheduling, Activi...               \n",
      "0  [cervical cancer, overlapping objects segmenta...               \n",
      "0                                                                  \n",
      "0  [APP: Other Applications, MLA: Applications of...               \n",
      "0                                                                  \n",
      "0  [location privacy, differential privacy, mobil...               \n",
      "0                [Game theory, Security and Privacy]               \n",
      "0                                                                  \n",
      "0                                                                  \n",
      "0  [Motif-based PageRank, Social Networks, Higher...               \n"
     ]
    }
   ],
   "source": [
    "def collect_2018_to_2010():\n",
    "    years = [18, 17, 16, 16, 14, 13, 12, 11, 10]\n",
    "    webpage_url = \"https://aaai.org/Library/AAAI/aaai%scontents.php\"\n",
    "    for year in years:\n",
    "        log_on_text(str(2000+year))\n",
    "        df = pd.DataFrame([], columns=_columns)\n",
    "        paper_year = 2000 + year # <---------------- year\n",
    "        req = requests.get(webpage_url%str(year))\n",
    "        html = req.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        paper_url_list = soup.select('body')[0].select('#content')[0].select('#right')[0].select('#box6')[0].find('div', {'class': 'content'}).findAll('p', {'class': 'left'})\n",
    "        for paper_url in paper_url_list:\n",
    "            paper = paper_url.find('a').get('href').replace('view', 'viewPaper')\n",
    "            \n",
    "            if paper[-4:] == '.pdf':\n",
    "                continue\n",
    "                \n",
    "            paper_req = requests.get(paper)\n",
    "            paper_html = paper_req.text\n",
    "            paper_soup = BeautifulSoup(paper_html, 'html.parser')\n",
    "            #print(paper)\n",
    "            paper_info = paper_soup.select('body')[0].select('#container')[0].select('#body')[0].select('#main')[0]\n",
    "            paper_details = paper_info.find('div',{'id': 'content'})\n",
    "            \n",
    "            paper_category = paper_info.find('div',{'id': 'breadcrumb'}).findAll('a')[3].text # <---------------- category\n",
    "            paper_title = paper_details.find('div',{'id': 'title'}).text # <--------------------------------- title\n",
    "            paper_author = paper_details.find('div',{'id': 'author'}).text # <---------------- author\n",
    "            paper_abstract = paper_details.find('div',{'id': 'abstract'}).find('div').text # <---------------- abstract\n",
    "            paper_keyword = paper_details.find('div',{'id': 'paperSubject'})  # <---------------- title\n",
    "            if paper_keyword == None:\n",
    "                paper_keyword = \"\"\n",
    "            else:\n",
    "                paper_keyword = paper_keyword.find('div').text\n",
    "            paper_download_path = paper_details.find('div',{'id': 'paper'}).find('a').get('href').replace('view', 'viewFile')\n",
    "                                                # <----------------  download_path\n",
    "            df = df.append(pd.DataFrame([[paper_year, paper_category, paper_title, paper_author, '', paper_abstract, paper_download_path, '', paper_keyword, '']], columns=_columns))\n",
    "            \n",
    "            # remove break\n",
    "            # break\n",
    "        df.to_csv('papers/aaai_paper_%s'%str(paper_year))\n",
    "        #remove break\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_dir_path(url):\n",
    "    cnt = 1\n",
    "    while url[-cnt]!='/':\n",
    "        cnt = cnt + 1\n",
    "    return url[:-cnt+1]\n",
    "\n",
    "def collect_2008_to_1980():\n",
    "    years = [2008, 2007, 2006, 2005, 2004, 2002, 2000, 1999, 1998, 1997, 1996, 1994, 1993, 1992, 1991, 1990, 1988, 1987, 1986, 1984, 1983, 1982, 1980]\n",
    "    webpage_url = \"https://aaai.org/Library/AAAI/aaai%scontents.php\"\n",
    "    for year in years:\n",
    "        df = pd.DataFrame([], columns=_columns)\n",
    "        paper_year = year # <---------------- year\n",
    "        log_on_text(str(year))\n",
    "        req = requests.get(webpage_url%(str(year%100)).zfill(2))\n",
    "        html = req.text\n",
    "        soup = BeautifulSoup(html, 'html.parser')\n",
    "        html_tag_list = soup.find('body').select('#content')[0].select('#right')[0].select('#box6')[0].find('div', {'class': 'content'}).findAll(['p', 'h3', 'h4'])\n",
    "        paper_category = \"\"\n",
    "        for x in html_tag_list:\n",
    "            if x.name == 'p' and x.has_attr('class') and paper_category != \"\":\n",
    "                if x == html_tag_list[-1] and (x.text.find('Index') != -1 or x.text.find('index') != -1):\n",
    "                    continue\n",
    "\n",
    "                paper_tmp = x.find('a')\n",
    "                if paper_tmp == None:\n",
    "                    continue\n",
    "                else:\n",
    "                    paper_tmp = paper_tmp.get('href')\n",
    "                paper = get_dir_path(webpage_url%(str(year%100)).zfill(2)) + paper_tmp\n",
    "                \n",
    "                if paper[-4:] == '.pdf':\n",
    "                    continue\n",
    "\n",
    "                paper_req = requests.get(paper)\n",
    "                paper_html = paper_req.text\n",
    "                paper_soup = BeautifulSoup(paper_html, 'html.parser')\n",
    "                if paper_soup.find('body') == None:\n",
    "                    paper_title = paper_soup.find('h1').text # <---------------- title\n",
    "                    paper_info = paper_soup.findAll('p')\n",
    "                    paper_author = paper_info[0].text # <---------------- author\n",
    "                    paper_abstract = paper_info[1].text # <---------------- abstract\n",
    "                    paper_info = paper_info[2:]\n",
    "                    paper_keyword = \"\"\n",
    "                    for info in paper_info:\n",
    "                        if info.text.find('Subject') != -1:\n",
    "                            paper_keyword = info.text # <------------- paper_keyword\n",
    "                    paper_download_path = get_dir_path(paper)+paper_soup.find('h1').find('a').get('href') # <----------- path\n",
    "                else:\n",
    "                    paper_info = paper_soup.find('body').find('div')\n",
    "                    paper_title = paper_info.find('h1').text # <---------------- title\n",
    "                    paper_info = paper_info.findAll('p')\n",
    "                    paper_author = paper_info[0].text # <---------------- author\n",
    "                    paper_abstract = paper_info[1].text # <---------------- abstract\n",
    "                    paper_info = paper_info[2:]\n",
    "                    paper_keyword = \"\"\n",
    "                    for info in paper_info:\n",
    "                        if info.text.find('Subject') != -1:\n",
    "                            paper_keyword = info.text # <------------- paper_keyword\n",
    "                    paper_download_path = get_dir_path(paper)+paper_soup.find('h1').find('a').get('href') # <----------- path\n",
    "                #remove break\n",
    "                #break\n",
    "                df = df.append(pd.DataFrame([[paper_year, paper_category, paper_title, paper_author, '', paper_abstract, paper_download_path, '', paper_keyword, '']], columns=_columns))\n",
    "            \n",
    "            \n",
    "            elif x.name == 'h3' or x.name == 'h4':\n",
    "                paper_category = x.text # <---------------- category\n",
    "        #remove break\n",
    "        df.to_csv('papers/aaai_paper_%s'%str(paper_year))\n",
    "        #break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
